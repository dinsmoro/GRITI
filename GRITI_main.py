#Start of new dynamic distiller of data: GRITI (General Resource for Ionospheric Transient Investigations) 
#RD on 8/23/2018
#
import os 
import numpy as np
import datetime
import aacgmv2 #install with: pip install aacgmv2 [need buildtools what a pain]
import warnings
import gc
import configparser
from copy import deepcopy as deepcopy
from Code.subfun_date_to_dayNum import subfun_date_to_dayNum
from Code.subfun_dayNum_to_date import subfun_dayNum_to_date
from Code.subfun_dateORdayNum_to_fullRange import subfun_dateORdayNum_to_fullRange
from Code.subfun_monthNum_to_word import subfun_monthNum_to_word
from Code.subfun_addADay import subfun_addADay
from Code.subfun_strfind import strfind
from Code.subfun_textNice import textNice
from Code.subfun_isin_row import isin_row
from Code.subfun_satConv import satConv_toInt_fromStr
from Code.subfun_pltPause_create import subfun_pltPause_create

from Code.GRITI_import_TEC_importer import GRITI_import_TEC_importer
from Code.GRITI_import_TEC_Madrigal import GRITI_import_TEC_Madrigal
from Code.GRITI_import_TEC_otherSources import GRITI_import_TEC_otherSources
from Code.GRITI_import_TEC_LISN import GRITI_import_TEC_LISN
from Code.GRITI_import_ISR_Haystack import GRITI_import_ISR_Haystack
from Code.GRITI_import_ISR_Pokerflat import GRITI_import_ISR_Pokerflat
# from Code.GRITI_import_AMPERE import GRITI_import_AMPERE #wronk
# from Code.GRITI_import_AMPERE_preprepared import GRITI_import_AMPERE_preprepared as GRITI_import_AMPERE #wronk also (less than above tho)
from Code.GRITI_import_AMPERE_direct import GRITI_import_AMPERE_direct as GRITI_import_AMPERE
from Code.GRITI_import_Kp import GRITI_import_Kp
from Code.GRITI_import_OMNI import GRITI_import_OMNI
from Code.GRITI_import_SuperMAG import GRITI_import_SuperMAG
from Code.GRITI_import_Mag_NRCan import GRITI_import_Mag_NRCan
from Code.GRITI_import_SuperMAG_stations import GRITI_import_SuperMAG_stations

from Code.GRITI_keo_keogrammer import GRITI_keo_keogrammer
from Code.GRITI_keo_plot import GRITI_keo_plot
from Code.GRITI_keo_plot_wSun import GRITI_keo_plot_wSun
from Code.GRITI_keo_plot_sunCentered import GRITI_keo_plot_sunCentered

from Code.GRITI_spectral_6minAnalysisPlot import GRITI_spectral_6minAnalysisPlot

from Code.GRITI_plot_area_scatter import GRITI_plot_area_scatter

from Code.GRITI_TEC_randomSynth import GRITI_TEC_randomSynth
from Code.GRITI_TEC_keo import GRITI_TEC_keo
from Code.GRITI_TEC_keo_plot_TEC import GRITI_TEC_keo_plot_TEC
from Code.GRITI_TEC_keo_fancyPlot_TEC import GRITI_TEC_keo_fancyPlot_TEC
from Code.GRITI_TEC_keo_fancyPlot_TEC_wDayNite import GRITI_TEC_keo_fancyPlot_TEC_wDayNite
from Code.GRITI_TEC_keo_fancyPlot_TECnISR import GRITI_TEC_keo_fancyPlot_TECnISR
from Code.GRITI_TEC_keo_fancyPlot_TECnNoise import GRITI_TEC_keo_fancyPlot_TECnNoise
from Code.GRITI_TEC_keo_plot_TEC_cutOut import GRITI_TEC_keo_plot_TEC_cutOut
from Code.GRITI_TEC_keo_fancyPlot_TEC_noiseAllViews import GRITI_TEC_keo_fancyPlot_TEC_noiseAllViews
from Code.GRITI_doubleKeo_plot import GRITI_doubleKeo_plot

from Code.GRITI_TEC_avgPt import GRITI_TEC_avgPt
from Code.GRITI_TEC_avgPt_timeMatch import GRITI_TEC_avgPt_timeMatch
from Code.GRITI_TEC_avgPt_HP_timeMatch_plotWithISR_cutOut import GRITI_TEC_avgPt_HP_timeMatch_plotWithISR_cutOut
from Code.GRITI_TEC_avgPt_HP_timeMatch_POPL_plotWithISR_cutOut import GRITI_TEC_avgPt_HP_timeMatch_POPL_plotWithISR_cutOut
from Code.GRITI_TEC_avgPt_HP_timeMatch_POPL_fancyPlot_plotWithISR_cutOut import GRITI_TEC_avgPt_HP_timeMatch_POPL_fancyPlot_plotWithISR_cutOut
from Code.GRITI_TEC_avgPt_HP_timeMatch_plotWithISR_ZenithOnly_cutOut import GRITI_TEC_avgPt_HP_timeMatch_plotWithISR_ZenithOnly_cutOut
from Code.GRITI_TEC_avgPt_HP_timeMatch_POPL_plotWithISR_ZenithOnly_cutOut import GRITI_TEC_avgPt_HP_timeMatch_POPL_plotWithISR_ZenithOnly_cutOut
from Code.GRITI_TEC_avgPt_HP_timeMatch_scargleWithISR_cutOut import GRITI_TEC_avgPt_HP_timeMatch_scargleWithISR_cutOut
from Code.GRITI_TEC_avgPt_HP_timeMatch_POPL_scargleWithISR_cutOut import GRITI_TEC_avgPt_HP_timeMatch_POPL_scargleWithISR_cutOut
from Code.GRITI_TEC_avgPt_HP_timeMatch_POPLnAMPERE_plotWithISR_ZenithOnly_cutOut import GRITI_TEC_avgPt_HP_timeMatch_POPLnAMPERE_plotWithISR_ZenithOnly_cutOut

from Code.GRITI_ISR_Haystack_plot_POPL_HP import GRITI_ISR_Haystack_plot_POPL_HP
from Code.GRITI_ISR_Haystack_plot_POPL import GRITI_ISR_Haystack_plot_POPL
from Code.GRITI_ISR_Haystack_plot_POPL_limited import GRITI_ISR_Haystack_plot_POPL_limited
from Code.GRITI_ISR_Haystack_plot_POPL_scargleSet import GRITI_ISR_Haystack_plot_POPL_scargleSet
from Code.GRITI_ISR_Haystack_plot_POPL_FFTSet import GRITI_ISR_Haystack_plot_POPL_FFTSet
#older SNR options - switched to POPL going forward
from Code.GRITI_ISR_Haystack_plot_SNR_HP import GRITI_ISR_Haystack_plot_SNR_HP
from Code.GRITI_ISR_Haystack_plot_SNR import GRITI_ISR_Haystack_plot_SNR
from Code.GRITI_ISR_Haystack_plot_SNR_limited import GRITI_ISR_Haystack_plot_SNR_limited
from Code.GRITI_ISR_Haystack_plot_scargleSet import GRITI_ISR_Haystack_plot_scargleSet
#other non-SNR or POPL stuff
from Code.GRITI_ISR_Haystack_plot_ionVel import GRITI_ISR_Haystack_plot_ionVel
from Code.GRITI_ISR_Haystack_plot_ionVel_cutOut import GRITI_ISR_Haystack_plot_ionVel_cutOut
from Code.GRITI_ISR_Haystack_plot_ionVel_HP import GRITI_ISR_Haystack_plot_ionVel_HP
from Code.GRITI_ISR_Haystack_plot_ionVel_HP_cutOut import GRITI_ISR_Haystack_plot_ionVel_HP_cutOut
#----Pokerflat ISR plots-----
from Code.GRITI_ISR_Pokerflat_plot_POPL_HP import GRITI_ISR_Pokerflat_plot_POPL_HP
from Code.GRITI_ISR_Pokerflat_plot_POPL import GRITI_ISR_Pokerflat_plot_POPL
from Code.GRITI_ISR_Pokerflat_plot_POPL_limited import GRITI_ISR_Pokerflat_plot_POPL_limited

from Code.GRITI_OMNI_plot import GRITI_OMNI_plot
from Code.GRITI_OMNI_plot_scargle import GRITI_OMNI_plot_scargle
from Code.GRITI_OMNI_plot_FFT import GRITI_OMNI_plot_FFT
from Code.GRITI_Kp_plot import GRITI_Kp_plot
from Code.GRITI_KpOMNI_fancyPlot import GRITI_KpOMNI_fancyPlot
from Code.GRITI_SuperMAG_plot import GRITI_SuperMAG_plot
from Code.GRITI_MECHACOMBO_plot import GRITI_MECHACOMBO_plot

from Code.GRITI_AMPERE_integrator import GRITI_AMPERE_integrator
from Code.GRITI_AMPERE_integrator_plot import GRITI_AMPERE_integrator_plot
from Code.GRITI_AMPERE_integrator_plot_area import GRITI_AMPERE_integrator_plot_area

from Code.GRITI_MagCAN_keo import GRITI_MagCAN_keo
from Code.GRITI_MagCAN_keo_plot import GRITI_MagCAN_keo_plot


from Code.GRITI_combinedPlot_keo_TEC_n_AMPERE_1Dintegration import GRITI_combinedPlot_keo_TEC_n_AMPERE_1Dintegration
from Code.GRITI_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone import GRITI_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone
from Code.GRITI_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone_spectra import GRITI_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone_spectra

from Code.GRITI_movieMaker import GRITI_movieMaker

# import matplotlib.cbook #basemap uses something that'll be depreciated in matplotlib, ignore that warning
# warnings.filterwarnings("ignore",category=matplotlib.MatplotlibDeprecationWarning); #basemap uses something that'll be depreciated in matplotlib, ignore that warning

if( 'FLG_rerunner' in locals() ):
    if( False == True ):
        FLG_rerunner = 'goawayerror'; #coded by the best
    #END IF
    FLG_rerunner['run num'] = FLG_rerunner['run num'] + 1; #increment run number
else:
    FLG_rerunner = {
        'run num':1,
    }; #prep, count from 1
#END IF

try:
    from psutil import cpu_count
    parallel_numCores = cpu_count(logical = False); #for intense calcs only use the real cores
    parallel_numThreads = cpu_count(logical = True); #for lighter calcs use hyperthreads too since the physical core isn't mauled
    # if( parallel_numCores != parallel_numThreads ):
    #     parallel_numCores += parallel_numThreads//2; #add on 1/2 the fake threads b/c there's some extra room for the calcs 
    # #END IF
    parallel_threadsPerProcess = 4; #each process gets 2 hyper threads
except:
    print('WARNING in GRITI_main: CPU count cannot differentiate between logical cores because the "psutil" package is not installed. Code herein will abs choke CPUs with SMT (2 threads per core) w/o logical CPU identification. CPUs w/o SMT will choke either way (toasty!).');
    from multiprocessing import cpu_count
    parallel_numCores = cpu_count(); #use multiprocess to get # of CPU cores
    parallel_numThreads = parallel_numCores; #sameas
    parallel_threadsPerProcess = 2; #each process gets 1 thread to avoid overwhelming what may be a non-hyperthreaded CPU
#END TRY

settings = {}; #prep a settings dictionary

np.random.seed(seed=1776); #prime the random number consistency, great musical #1784
#-----Data Types Supported-----
dataTypes = ['TEC','ISR','AMPERE','OMNI','Kp','SuperMAG','MagCAN','SuperMAG stations']; #list of the data types supported

#-----Read in Config-----
config = configparser.ConfigParser(); #prep the config parser
config.optionxform = str; #stop the parser from making everything lowercase
config.read('GRITI_main_config.ini'); #read the config file
config_sects = config.sections(); #get the sections in the config file
settings_config = {}; #prep a dict
for i in range(0,len(config_sects)):
    config_items = config.items(config_sects[i]); #get the items in a single section of the config
    settings_config[config_sects[i]] = {}; #prep a sub-dict with the section name
    for j in range(0,len(config_items)):
        if( (config_items[j][1] == 'True') | (config_items[j][1] == 'False') ):
            if( config_items[j][1] == 'True' ):
                settings_config[config_sects[i]][config_items[j][0]] = True;
            else:
                settings_config[config_sects[i]][config_items[j][0]] = False;
            #END IF
        else:
            settings_config[config_sects[i]][config_items[j][0]] = config_items[j][1].replace('os.getcwd()',os.getcwd()); #record the items and their results in the sub-dict
        #END IF
        if( config_sects[i] == 'paths' ):
            settings_config[config_sects[i]][config_items[j][0]] = settings_config[config_sects[i]][config_items[j][0]].replace('+',''); #only replace +'s on the paths
        #END IF
    #END FOR j
#END FOR i
settings['config'] = settings_config; #record
settings['config']['parallel num cores'] = parallel_numCores; #num of cores
settings['config']['parallel num threads'] = parallel_numThreads; #num of threads
settings['config']['parallel threads per process'] = parallel_threadsPerProcess; #num of threads per process (ensures calcs are packed)
#testing stuff
import sys
import time
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import make_axes_locatable
import matplotlib.colorbar as pltCB
# BasemapFixDir = settings_config['paths']['basemapFix']; #directory as a variable
# os.environ["PROJ_LIB"] = BasemapFixDir; #hack beacuse people are awful coders
# from mpl_toolkits.basemap import Basemap
import cartopy as cartopy #cartopy replaces basemap b/c it's updated
from matplotlib.path import Path
from Code.subfun_lombscargle import subfun_lombscargle
from matplotlib.ticker import FormatStrFormatter
from Code.subfun_highpass import subfun_highpass

from matplotlib.colors import ListedColormap
from Code.GRITI_movieMaker_subfun_dataGridder import GRITI_movieMaker_subfun_dataGridder
from Code.GRITI_movieMaker_subfun_dayniteCalc import GRITI_movieMaker_subfun_dayniteCalc

#==============PLOT STANDARDIZATION STUFF==============
FONT_smol = 19; #small font (tick mark font size) Default: 19, Big: 23
FONT_axisTick = 23; #small font (tick mark font size) Default: 19, Big: 23
FONT_axisLabel = 28; #medium font (labels) Default: 23, Big: 28
FONT_title = 28; #big font (title only really) Default: 23, Big: 28
FONT_grandiose = 32; #big font (title only really) Default: 26, Big: 32
FONT_font = 'arial';
FONT_weight = 'bold';

PLOT_lineWidth = {
    'thicc':4.00,
    'double plus':3.00,
    'plus':2.25,
    'regular plus':2.00,
    'regular':1.75,
    'smol':1.25,
    'smoller':1,
    'smollerest':0.8,
    }; #standardized line width Thicc / DoublePlus / Plus / RegularPlus / Regular / Smol
# PLOT_color = ['xkcd:purple','xkcd:green','xkcd:blue','xkcd:pink',
#      'xkcd:brown','xkcd:brick red','xkcd:grey','xkcd:orange',
#      'xkcd:teal','xkcd:midnight purple','xkcd:magenta','xkcd:goldenrod',
#      'xkcd:forest green','xkcd:tan','xkcd:periwinkle','xkcd:salmon']; #color set for plotting
PLOT_color = ['#1F77B4','#FF7F0E','#7256C1','#2CA02C','#D81B60','#656565',
              '#0099A9','#3E0402','#480094','#FF4545','#004D40','#9A1A00',
              '#224EB3','#249A7D','#FF45CA','#38FF32','#AF5D03','#00004E','#5F0038']; #color set for plotting [did some work at https://davidmathlogic.com/colorblind/#%231F77B4-%23FF7F0E-%237256C1-%232CA02C-%23D81B60-%23656565-%230099A9-%233E0402-%23480094-%23FF4545-%23004D40-%239A1A00-%23224EB3-%23249A7D-%23FF45CA-%2338FF32-%23AF5D03-%2300004E-%235F0038 to make it better!]
PLOT_color.extend((np.random.randint(0,high=256,size=(200,3))/255).tolist()); #make sure there's enough colors forever
PLOT_lineStyle = ['-','--','-.',':']*25;

import matplotlib.font_manager as fm #import font manager you know
FONT_smolFM = fm.FontProperties(family=FONT_font, weight=FONT_weight, size=FONT_smol); #these are font properties, some plot stuff has this and it tells it all in one go #inconsistent
FONT_axisTickFM = fm.FontProperties(family=FONT_font, weight=FONT_weight, size=FONT_axisTick); #these are font properties, some plot stuff has this and it tells it all in one go #inconsistent
FONT_axisLabelFM = fm.FontProperties(family=FONT_font, weight=FONT_weight, size=FONT_axisLabel); #these are font properties, some plot stuff has this and it tells it all in one go #inconsistent
FONT_titleFM = fm.FontProperties(family=FONT_font, weight=FONT_weight, size=FONT_title); #these are font properties, some plot stuff has this and it tells it all in one go #inconsistent
FONT_grandioseFM = fm.FontProperties(family=FONT_font, weight=FONT_weight, size=FONT_grandiose); #these are font properties, some plot stuff has this and it tells it all in one go #inconsistent

plt.rcParams['font.weight'] = FONT_weight; #sents default font weight to bold for everything else
plt.rcParams['axes.labelweight'] = FONT_weight; #sets default font weight to bold for axis labels
plt.rc('font', size=FONT_axisTick); #default text size
#plt.rc('axes', titlesize=FONT_axisTick); # axes title text size
#plt.rc('axes', labelsize=FONT_axisTick); #x and y label font size
plt.rc('xtick', labelsize=FONT_axisTick); #x tick label font size
plt.rc('ytick', labelsize=FONT_axisTick); #y tick label font size
plt.rc('legend', fontsize=FONT_axisLabel); #legend fornt size
plt.rc('figure', titlesize=FONT_title); #figure title font size (this one didn't do anything, so 2nd here also)
plt.rc('axes', titlesize=FONT_title); #figure title font size (this one did work)
plt.rcParams['axes.labelsize'] = FONT_axisLabel; #try this one also
#plt.rc('text', fontsize=FONT_axisTick); #figure text font size
plt.rcParams['axes.unicode_minus'] = False; #disable big - sign and instead use smol - sign (saves plot space)

#testing stuff - does nothing right now
FLG_derivatate = 0; #the flag # is the derivative order (e.g. 1 is 1st deriv, 2 is 2nd deriv)

#Important stuff
FLG_fancyPlot = 1; #with this flag on, any plot that has a fancy plot mode for papers is activated. if it doesn't have a fancy plot mode, nothing changes
#2 enforces ONLY fancy plots (usually), while 1 (usually) does a regular plot and a fancy saved plot.
journal_width_1C = 3.5; #plot width for a single column plot
journal_width_2C = 7.5; #plot width for a double column plot (full page width)
journal_height_max = 9.8; #plot height limit (can be less)
journal_dpi = 300; #pixels per inch
plot_fileType = '.png'; #file type to save figure as, Default: .png, Alts: .pdf, .jpg, more...
plot_unitBracket_L = '['; #whatevs you want for left bracket around units
plot_unitBracket_R = ']'; #whatevs you want for right bracket around units

#==============User Inputs==============
#Date range goes Year-Month-Day
#dateRange = np.array([[2014,7,30],[2014,8,1]],dtype="int16"); #dates are in int16 because they can be
dateRange = np.array([[2013,5,6],[2013,5,8]],dtype="int16"); #Paper 1 & 2
# dateRange = np.array([[2013,5,6],[2013,5,6]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2013,5,2],[2013,5,13]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2013,3,17],[2013,3,20]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2013,4,9],[2013,4,11]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2013,4,30],[2013,5,14]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2013,11,6],[2013,11,8]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2016,11,29],[2016,11,29]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2016,11,28],[2016,12,3]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2016,11,28],[2016,12,4]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2016,11,20],[2016,12,8]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2017,11,28],[2017,11,30]],dtype="int16"); #dates are in int16 because they can be
#dateRange = np.array([[2015,2,11],[2015,2,13]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2015,3,16],[2015,3,18]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2011,3,11],[2011,3,11]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2017,3,14],[2017,3,16]],dtype="int16"); #Salih Paper
# dateRange = np.array([[2017,3,15],[2017,3,15]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2017,3,13],[2017,3,16]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2017,3,12],[2017,3,16]],dtype="int16"); #dates are in int16 because they can be
dateRange = np.array([[2018,2,1],[2018,4,10]],dtype="int16"); #dates are in int16 because they can be <- big look
dateRange = np.array([[2018,2,1],[2018,2,4]],dtype="int16"); #dates are in int16 because they can be <- big look
# dateRange = np.array([[2018,3,28],[2018,4,7]],dtype="int16"); #dates are in int16 because they can be <- kinda calm
# dateRange = np.array([[2018,4,27],[2018,5,4]],dtype="int16"); #dates are in int16 because they can be <- very calm period [no AMPERE data here yet...]
# dateRange = np.array([[2019,5,17],[2019,5,21]],dtype="int16"); #dates are in int16 because they can be <- kinda calm, one SWPPE
# dateRange = np.array([[2019,6,10],[2019,6,29]],dtype="int16"); #dates are in int16 because they can be <- kinda calm [big SWPPE right before 6/10]
# dateRange = np.array([[2019,8,19],[2019,8,21]],dtype="int16"); #dates are in int16 because they can be <- kinda calm
# dateRange = np.array([[2017,5,3],[2017,5,6]],dtype="int16"); #dates are in int16 because they can be <- pretty calm, 2 days of prob no Bz-south! [2 days was b/c of CME on end May 4/start May 5, cool substorm visible in FAC!]
# dateRange = np.array([[2010,5,25],[2010,5,27]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2018,2,2],[2018,4,4]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2020,5,5],[2020,5,9]],dtype="int16"); #dates are in int16 because they can be <- dense modern dates that I have data processed for
# dateRange = np.array([[2020,6,3],[2020,6,3]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2014,5,5],[2014,5,9]],dtype="int16"); #dates are in int16 because they can be
# dateRange = np.array([[2022,1,14],[2022,1,18]],dtype="int16"); #dates are in int16 because they can be
#dates better go earlier -> later
#print("{}".format(dateRange))
dateRange_zeroHr_override = [2013,5,7]; #overrides the zero hr, which is normally estimated based on the middle of the given dateRange
# dateRange_zeroHr_override = [2017,3,15]; #overrides the zero hr, which is normally estimated based on the middle of the given dateRange

#Choose coordinate reference
coordType = 'geo'; #geo (geographic) or mag (geomagnetic) coordinates. Uses aacgmv2 to shuffle between

#Choose time reference to use for comparison between different data types
time_Reference = 'ISR';
#Options are currently supported data types:
#TEC
#ISR
#AMPERE
ISR_zenithMISA = 0; #0 for Zenith, 1 for MISA for when one ISR comparison is relevant

# settings_paths = {
#     'cwd':os.getcwd(),
#     'data':settings_config['paths']['data'],
#     'plots':settings_config['paths']['plots'],
#     'fancyPlots':settings_config['paths']['fancyplots'],
#     'ffmpeg':settings_config['paths']['ffmpeg'],
#     'cache':settings_config['paths']['cache'],
#     };
settings_paths = deepcopy(settings_config['paths']); #deep copy it
settings_paths['cwd'] = os.getcwd(); #set cwd

folder = [os.getcwd()]; #current working directory, leave it as this call usually
folder.append(settings_config['paths']['data']); #place to save data files to (or read from!)
folder.append(settings_config['paths']['plots']); #place to save data files to (or read from!)
folder.append(settings_config['paths']['fancyPlots']); #place to save data files to (or read from!)
#folder var structure: 0 = running folder, 1 = data folder, 2 = plots folder, 3 = fancyPlots folder
ffmpegLocale = settings_config['paths']['ffmpeg']; #place where ffmpeg.exe is

#--- Ensure plots folder and fancy plots folder exists ---
if( os.path.isdir(settings_paths['plots']) == 0 ): #check if the folder exists
    #if not, make it
    os.makedirs(settings_paths['plots']);
    print('NOTA BENE: MAIN - Created plots directory: '+settings_paths['plots']+'\n');
#END IF
if( os.path.isdir(settings_paths['fancyPlots']) == 0 ): #check if the folder exists
    #if not, make it
    os.makedirs(settings_paths['fancyPlots']);
    print('NOTA BENE: MAIN - Created fancyPlots directory: '+settings_paths['fancyPlots']+'\n');
#END IF
if( os.path.isdir(settings_paths['cache']) == 0 ): #check if the folder exists
    #if not, make it
    os.makedirs(settings_paths['cache']);
    print('NOTA BENE: MAIN - Created Cache directory: '+settings_paths['cache']+'\n');
#END IF

#-----General Plotting Settings-----
settings_spectra = { 
    'windowLength':110, #window length [window type is hamming] - can cause issues if too little data [smooths noise]
    'window type':'hamm', #window type for high-passing
    'window':np.hamming(110),
    'nfft':{'30sec':6144,'1min':3072,'6min':512,'default':512}, #nfft number
    'noverlap':100, #no overlap number - can cause issues if too little data [smooths noise]
    'period limit max':240*60, #sec, time to limit the freq analysis plots to show (maximum)
    'period limit min':30*60, #sec, time to limit the freq analysis plots to show (minimum)
    'filter order':42, #order of filter [orig: 42]
    'filter cutoff period':3*3600, #sec, filter cut off period [defined in hours, coverted to seconds]
    'savgol filter period':180*60, #sec, Sav-Gol filter period [defined in minutes, coverted to seconds]
    'savgol filter order':1 #order of the Sav-Gol fit, 3 is default, 1 is linear
    };

plot_periodLim_max = settings_spectra['period limit max']; #min, time to limit the freq analysis plots to show
# Xaxisvar_SCARGLE = 0:10:plot_Freq_Lim; #create a periodogram x axis tick

#mill for square Mercator style (PlateCarree is actually used in Cartopy, slightly diff but same effect)
#robin for oval shape (only for global plots! reverts to stereographic if not global)
#stere for curved projection stuff
#npstere for polar projection stuff
geoMap_projectionStyle = 'mill'; #type the word in
settings_map = {}; #prep a dict
settings_map['coord type'] = coordType; #record the coordinate type
settings_map['degree label'] = 'arcdeg'; #set degree label, 'arcdeg', '°', '' for none
settings_map['indicate direction'] = [False, {'lat':'\n← South | North →', 'long':'\n← West | East →'}]; #set 1st value of list to true to indicate direction, set 1st value to false to not

plotLatRange = [35,50]; #latitude limit for plotting
plotLongRange = [-85,-60]; #longitude limit for plotting
#-90 to 90 is world, 35 to 50 is good for USA East Coast
#-180 to 180 is world, -85 to -60 is good for USA East Coast

# plotLatRange = [-90,90]; #latitude limit for plotting
# plotLongRange = [-180,180]; #longitude limit for plotting
#-90 to 90 is world, 35 to 50 is good for USA East Coast
#-180 to 180 is world, -85 to -60 is good for USA East Coast

# plotLatRange = [0,90]; #latitude limit for plotting
# plotLongRange = [-180,180]; #longitude limit for plotting

plotLatRange = [40,90]; #latitude limit for plotting AMPERE polar
plotLongRange = [-180,180]; #longitude limit for plotting

# plotLatRange = [50,90]; #latitude limit for plotting
# plotLongRange = [-180,180]; #longitude limit for plotting

# plotLatRange = [35,46]; #latitude limit for plotting close up PA & Jersey [155angle,100N,4wide]
# plotLongRange = [-85,-66]; #longitude limit for plotting close up PA & Jersey

# plotLatRange = [30,50]; #latitude limit for USA West Coast
# plotLongRange = [-130,-110]; #longitude limit for USA West Coast

# plotLatRange = [10,50]; #latitude limit for plotting ENITRE USA
# plotLongRange = [-125,-60]; #longitude limit for plotting ENITRE USA

# plotLatRange = [-50,50]; #latitude limit for plotting USA and SA
# plotLongRange = [-80,-50]; #longitude limit for plotting USA and SA

# plotLatRange = [10,25]; #latitude limit for plotting Arecibo
# plotLongRange = [-75,-50]; #longitude limit for plotting Arecibo

# plotLatRange = [-25,25]; #latitude limit for plotting lower North America & Upper SA
# plotLongRange = [-120,-50]; #longitude limit for plotting lower North America & Upper SA

# plotLatRange = [30,75]; #latitude limit for plotting # #-90 to 90 is world, 35 to 50 is good for USA East Coast
# plotLongRange = [-125,-60]; #longitude limit for plotting usa

# plotLatRange = [30,75]; #latitude limit for USA & ALASKA & CANADA & GREENLAND KINDA
# plotLongRange = [-165,-30]; #longitude limit for USA & ALASKA & CANADA & GREENLAND KINDA (GREENLAND IF -30 not -60)

# plotLatRange = [55,75]; #latitude limit for ALASKA
# plotLongRange = [-170,-130]; #longitude limit for ALASKA

# plotLatRange = [30,75]; #latitude limit for ALASKA & 1/2 of USA/CANADA
# plotLongRange = [-165,-100]; #longitude limit for ALASKA & 1/2 of USA/CANADA

# plotLatRange = [25,50]; #latitude limit for plotting ALL OF USA
# plotLongRange = [-120,-60]; #longitude limit for plotting ALL OF USA

# plotLatRange = [30,75]; #latitude limit for plotting EAST HALF OF USA/CANADA
# plotLongRange = [-100,-60]; #longitude limit for plotting EAST HALF OF USA/CANADA
# plotLatRange = [30,48]; #latitude limit for plotting EAST HALF OF USA/CANADA (for img processing)
# plotLongRange = [-100,-60]; #longitude limit for plotting EAST HALF OF USA/CANADA

# plotLatRange = [25,55]; #latitude limit for plotting EAST HALF OF USA/CANADA
# plotLongRange = [-100,-60]; #longitude limit for plotting EAST HALF OF USA/CANADA

# plotLatRange = [0,75]; #latitude limit for North America & Europe
# plotLongRange = [-180,45]; #longitude limit for North America & Europe

# plotLatRange = [-90,90]; #latitude limit for North & South America
# plotLongRange = [-180,-20]; #longitude limit for North & South America

# plotLatRange = [-90,25]; #latitude limit for Up to Mexico & South America
# plotLongRange = [-120,-20]; #longitude limit for Up to Mexico & South America

# plotLatRange = [-90,5]; #latitude limit for South America
# plotLongRange = [-100,-25]; #longitude limit for South America

# plotLatRange = [30,75]; #latitude limit for Europe
# plotLongRange = [-15,40]; #longitude limit for Europe
# plotLatRange = [17,75]; #latitude limit for Europe !MAG COORDS in 2017 3/15!
# plotLongRange = [69,122]; #longitude limit for Europe !MAG COORDS in 2017 3/15!

# plotLatRange = [30,75]; #latitude limit for Europe (Scandanavia and Italy)
# plotLongRange = [5,30]; #longitude limit for Europe (Scandanavia and Italy)

# plotLatRange = [55,75]; #latitude limit for Europe above 55 and cut off no high lat info long (-15 to 5)
# plotLongRange = [5,40]; #longitude limit for Europe above 55 and cut off no high lat info long (-15 to 5)

# plotLatRange = [30,75]; #latitude limit for Europe small bit
# plotLongRange = [5,40]; #longitude limit for Europe small bit

# plotLatRange = [30,46]; #good for Japan close up
# plotLongRange = [130,146]; #good for Japan close up

# plotLatRange = [20,55]; #good for Japan a bit farther away
# plotLongRange = [115,160]; #good for Japan a bit farther away

# plotLatRange = [15,90]; #latitude limit for top bit of globe
# plotLongRange = [-180,180]; #longitude limit for top bit of globe

# plotLatRange = [30,75]; #latitude limit for 30 to -30, edge of USA to edge of Europe
# plotLongRange = [-30,30]; #longitude limit for 30 to -30, edge of USA to edge of Europe

# plotLatRange = [15,60]; #good for Japan a bit farther away
# plotLongRange = [55,100]; #good for Japan a bit farther away

# plotLatRange = [-15,15]; #good for Malaysia/Indonesia
# plotLongRange = [90,120]; #good for Malaysia/Indonesia

# plotLatRange = [45,90]; #good for North Pole
# plotLongRange = [-180,180]; #good for North Pole

# plotLatRange = [-15,10]; #good for top of South America
# plotLongRange = [-82,-35]; #good for top of South America

# plotLatRange = [-30,-50]; #good for AO magnetic conjugate in South America
# plotLongRange = [-70,-45]; #good for top of South America

# plotLatRange = [-10,-40]; #good for AO magnetic conjugate in South America - 45 deg + 2 deg width special coast
# plotLongRange = [-70+2,-30+2]; #good for top of South America - 45 deg + 2 deg width special coast

# plotLatRange = [34.63,15.01]; #!MAG! good for AO 
# plotLongRange = [20.50,-2.47]; #!MAG! #good for AO
# #
# plotLatRange = [-30,34.63]; #!MAG! good for AO down to AO magnetic conjugate in South America
# plotLongRange = [-2.47,25.50]; #!MAG! #good for AO down to AO magnetic conjugate in South America

#SA Andes regions
# plotLatRange = [-18,-4]; # Peru Andes
# plotLongRange = [-85,-68]; # Peru Andes

# plotLatRange = [-35,-18]; # Chile Andes
# plotLongRange = [-72,-68]; # Chile Andes

# plotLatRange = [-18,-4]; #Peru, for 135deg along Andes
# plotLongRange = [-85,-65]; #Peru, for 135deg along Andes (4 width, too little data I think)


plot_Scatter_Point_Size = 325; #arb. scatter pt size to make it big and easy to see

pointAltitude = 350; #km, altitude where most e-'s are (F region max - assumed)

# filter_cutoffPeriod = 2*3600; #sec, cut off period to high pass filter at (high pass removes anything higher period than # (e.g. 2) hr)
#used in ISR and TEC processing 

# time_cutout_range = [-24*3600,-18*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [17*3600,24*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [0*3600,12*3600]; #sec,
# time_cutout_range = [7*3600,15*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [5.0*3600,15.5*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [35.5*3600,47.9*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [18*3600,35*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [(18-12)*3600,(35-12)*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-17*3600,-7*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [20*3600,24*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-18*3600,-4*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-14*3600,0*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
time_cutout_range = [5*3600,16*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
time_cutout_range = [36*3600,47*3600+58*60]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-18*3600,-4*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
time_cutout_range = [-16*3600,-4*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-18*3600,-8*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-14*3600,0*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-17*3600,-13.5*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-13*3600,-10*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-10*3600,-7*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-7*3600,-3*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
time_cutout_range = [-18*3600,-2*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-9*3600,-3*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-16*3600,-12*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-12*3600,-4*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [12*3600,23*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [29*3600,40*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [29*3600,35*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [4*3600,47*3600+58*60]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [-18*3600,12*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [12*3600,47*3600+58*60]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
time_cutout_range = [16*3600,23*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)
# time_cutout_range = [40*3600,47*3600]; #sec, cut-out this time period for comparison between the ISR & GPS data at the best possible time to compare (night)

# time_cutout_range = [59*3600,69*3600]; #sec, cut-out this time period for comparison



#-----TEC import options-----
settings_TEC_import = { 
    'TEC_maxAmpAllowed':2, #TECU, max val allowed - it is a forced cutoff value (ref data had a max of 396 it seems)
    'TEC_timeTolerance':0.1, #0.1:10% so time tolerance is within 10%. So for 30 sec time steps, 10% time tolerance will make 27-33 sec time stamps be 30 sec time stamps
    'TEC_minElevation':30, #deg, [min elevation angle used to process data, min elevation angle accepted after data is processed]
    'TEC_minimumTimeGap':5*60, #sec, how long to accept a gap in a satellite observation before calling it a new, unrelated observation
    'TEC_deltaTEC_compareValue':6, #median comparator number for choosing stuff on the edges that are out of an acceptable range, inspired by https://stackoverflow.com/questions/11686720/is-there-a-numpy-builtin-to-reject-outliers-from-a-list
    'TEC_dataRate':30, #sec/datapt, the data rate. No super easy way to get it out of the data automatically, so it's a variable to control
    'filter_savGolPeriod':60*60, #sec, filter period for the Sav-Gol filter (only passes this long or longer are kept, many are not longer - very few are 3 hr long)
    'order_savGol':1, #order of the Sav-Gol fit, 3 is default, 1 is linear
    'web_base_name':settings_config['login Madrigal']['name'], #put your name here (for spaces use +'s instead)
    'web_base_email':settings_config['login Madrigal']['email'], #put your email here
    'web_base_affil':settings_config['login Madrigal']['affil'], #put your affiliation here (school etc)
    'web_LISN_creden_user':settings_config['login LISN']['user'], #put your LISN user here
    'web_LISN_creden_pass':settings_config['login LISN']['pass'], #put your LISN password here
    'FLG_dataAggregation':0, #0 don't aggregate nearby TEC values with a site/sat combo, 1 aggregate nearby TEC values with a site/sat combo for MORE DATA PER DATA [does not work atm, may never]
    'TEC_dataAgg_timeAdditionLimit':1*60*60, #sec, time to add on to a satellite's visible time before calling it quits
    'TEC_dataAgg_distToPts':20, #km, distance to extended points for TEC data to exist
    'TEC_dataLimPercent':0.05, #0.05:5%, cut out times with very low data content (less than 5% of the mean data content #)
    'TEC_deltaLim':0.5, #unrelated to above, value between fit/real data to find where ends of the fit where it starts diverging
    'FLG_reqPaddedDays':0, #requires padded days if 1, doesn't require them if 0
    'FLG_deleteOrig':0, #deletes original files if 1, doesn't delete original files if 0 (original being ones DL'd from Madrigal)
    'FLG_deleteUnfilt':0, #deletes unfiltered middle-stage files if 1, doesn't delete unfiltered files if 0 (makes recalc's faster if they're kept)
    'FLG_overwrite':0, #recalcs & overwrites files even if they're there if 1, doesn't recalc and uses files if they're there if 0
    'max retry':3, #number of retries for internet access errors. -1 is infinite retries
    'retry wait set':[10,30,5], #time delay for internet access errors in seconds [start delay, max delay, increment delay each retry] is the order
    'max retry file':3, #number of retries for file read errors. -1 is infinite retries [do not use here]
    };

Re = 6371.0; #km, Earth mean Radius
settings_map['Re'] = Re; #put it in map settings
#from http://nssdc.gsfc.nasa.gov/planetary/factsheet/earthfact.html

MillstoneMISA_azimuth = 168.5; #deg Azimuth from North towards East (assuming geo - none specified)
MillstoneMISA_elev = 66.26; #deg elevation
MillstoneZenith_elev = 88; #deg elevation
#Lat and long reference points
latLong_ref = [];
latLong_refIndex = np.array( (0,1) ); #which one to use
#Location of Millstone Hill
latMillstone = 42.6233; #Deg North MH
longMillstone = -71.4882; #Deg East MH (71.4882 deg West)
# longMillstone = 15; #Deg East, forces it into Europe
#Location of Arecibo
# latMillstone = 18+20/60+36.6/3600; #Deg North AO
# longMillstone = -(66+45/60+11.1/60); #Deg East AO (67some deg West)
# latMillstone = 40; #Deg North !Conjugate! for AO
# longMillstone = -58; #Deg East !Conjugate! for AO (67some deg West)
# latMillstone = 34+51/60+8/3600; #Deg North - Japan MU radar
# longMillstone = 136+6/60+32/3600; #Deg West - Japan MU radar
#Location of Jicamarca
# latMillstone = -11.9515; #Jicamarca
# longMillstone = -76.8744; #Jicamarca
# latMillstone = 59; #Deg North - europe
# longMillstone = 10; #Deg West - europe
# latMillstone = 65; #Deg North - europe high latitude
# longMillstone = 15; #deg west - europe high latitude
# longMillstone = -120; #Deg West - west USA
# longMillstone = -150; #Deg West - Alaska
# longMillstone = 63; #Deg North - Alaska
latLong_ref.append( [latMillstone,longMillstone] ); #record it in the multi-dimensional list *TOP DANGER*
latMillstoneMISA = latMillstone + np.sin( (MillstoneMISA_azimuth+90)*np.pi/180 )*(((pointAltitude/np.tan(MillstoneMISA_elev*np.pi/180) )/Re)*180/np.pi); #deg North (see spreadsheet titled ISR Angle Calc)
longMillstoneMISA = longMillstone - np.cos( (MillstoneMISA_azimuth+90)*np.pi/180 )*(((pointAltitude/np.tan(MillstoneMISA_elev*np.pi/180) )/Re)*180/np.pi); #deg East at MISA (Azimuth is clockwise - cosine gets a negative)
latLong_ref.append( [latMillstoneMISA,longMillstoneMISA] ); #record it in the multi-dimensional list *TOP DANGER*
# latMillstone = 42.6233 - (100/Re)*(180/pi); #Deg North
# plotLatRange = [latMillstone-8,latMillstone+8]; #new latitude limit for plotting
# plotLongRange = [longMillstone-8,longMillstone+8]; #new longitude limit for plotting
# longMillstone = -74.0; #deg east, philly
# longMillstone = 23+10/60; #deg west, Kalix Sweeden (over south africa)
# longMillstone = 140+52/60; #deg west, Sendai Japan (over Eastern Japan)
# longMillstone = 119+44/60+49/3600; #deg west, Marble Bar Australia (over East China/West Australia)
# latMillstone = mean(plotLatRange); #center
# longMillstone = mean(plotLongRange); #center
# latMillstone = 38; #put at 38 deg N
# longMillstone = 37.5; #put at 54 deg E

#==============TEC Data Options==============
FLG_TEC_use = [2,]; #0 uses all TEC sources and combines. 
#Can combine numbers bellow in an array like [2,3,5] to get just those data sources
#1 - Pre-processed data (alternate to 2, will not combine with 2)
#2 - Madrigal Database TEC (will not combine with 1)
#3 - LISN Database TEC
FLG_TEC_noise = 0; #0 regular data
#1 replace TEC values with Gaussian noise - keep time/location
#2 replace TEC values with Gaussian noise and a synthetic wave - keep time/location
noise_background_mean = 0; #delta_vTEC, avg of noise background
noise_background_stdev = 0.3168; #delta_vTEC, standard dev of noise background taken from all vTEC data
#----synthetic wave parameters----
wave_N = 3000; #splits lat/long ranges into chunks
wave_period = np.zeros(2); #preallocate
wave_waveLength = np.zeros(2); #preallocate
wave_angle = np.zeros(2); #preallocate
wave_phase = np.zeros(2); #preallocate
wave_amp = np.zeros(2); #preallocate
wave_period[0] = 1.0*3600; #sec, period of wave
wave_waveLength[0] = 200; #km, wavelength of wave given in paper EPS_2008_Seker
# wave_waveLength = 700; #km, wavelength of wave
# wave_waveLength[0] = 4000; #km, wavelength of wave
# wave_waveLength = 1.21*2800; #km, wavelength of wave
wave_angle[0] = 135; #deg, angle of wave direction
wave_phase[0] = 0; #deg, 0 to 360, phase of wave
wave_amp[0] = 0.0; #delta_vTEC, amplitude of wave
# wave_amp[0] = 0.15; #delta_vTEC, amplitude of wave
#2ND WAVE
wave_period[1] = 1.5*3600; #sec, period of wave
# wave_waveLength[1] = 200; #km, wavelength of wave given in paper EPS_2008_Seker
wave_waveLength[1] = 700; #km, wavelength of wave
# wave_waveLength[1] = 1.21*2800; #km, wavelength of wave
wave_angle[1] = 90; #deg, angle of wave direction
wave_phase[1] = 0; #deg, 0 to 360, phase of wave
wave_amp[1] = 0.35; #delta_vTEC, amplitude of wave
# wave_amp[1] = 0.00; #delta_vTEC, amplitude of wave
wave_latRange = np.array([-90,90]); #arcdeg, latitude range maximum
wave_longRange = np.array([-180,180]); #arcdeg, longitude range maximum

#==============TEC Averaging Options==============
#main TEC settings
TEC_plotLimValu = 0.5; #TECU, limit (+ and -) for plotting the TEC movie and other plots too
settings_TEC = {
    'plot lim':np.array( (-0.5,0.5) ), #TECU, limit (+ and -) for plotting the TEC movie and other plots too
    'colormap':'jet', #TEC colormap [default: jet, optional: viridis]
    'data type':'TEC', #main data type
    'name':'delta-vTEC', #TEC data type name
    'units':' '+plot_unitBracket_L+'TECU'+plot_unitBracket_R, #TEC unit
    'scatter size':40, #kinda arbitrary scatter pt size used for TEC scatter plots
    'source to use':FLG_TEC_use,
    'noise settings':{'noise mode':FLG_TEC_noise, 'noise mean':noise_background_mean, 'noise stdev':noise_background_stdev},
    'snyth wave settings':{'N':wave_N, 'period':wave_period, 'wave length':wave_waveLength, 
                           'angle':wave_angle, 'phase':wave_phase, 'amplitude':wave_amp, 'lat range':wave_latRange, 'long range':wave_longRange},
    'day num limit': 20, #number of days limit to activate justChecking mode 
    }; #prep some TEC settings
#!!!-----0 for off, 1 for on-----!!!
FLG_keo = 1; #averaging TEC in bands, needed for anything with _anyAngle
FLG_keo_plot = 1; #averaging TEC in bands
FLG_keo_plot_timeCutout = 1; #Uses the time cutout range defined above (if 'use local time' is True, the time cutout range is taken to be a UTC time STILL)
#[ONLY FANCY PLOTS]
FLG_keo_dataDensity = 0; #1 shows the data density for the period involved and the area involved (2 shows receiver location, 3 plots both data density and receiver location on two seperate plots)
FLG_keo_plot_wNoise = 0; #[ONLY FANCY PLOT]
FLG_keo_plot_noiseAllViews = 0; #[ONLY FANCY PLOT]only works if latRange=[-90,90]&longRange=[-180,180] - plots time series, east coast noise, world noise in 2 directions (0 and 90)

FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration = 0; #plots avg'd TEC and AMPERE data integrated in the zone
FLG_AMPERE_upTo90 = 1; #0 integrates AMPERE in the TEC averaging zone, 1 integrates AMPERE in the longitudes and min latitude, but max latitude is set to 90
FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone = 0; #plots avg'd TEC and AMPERE data integrated in the entire auroral zone (high latitude)
FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone_spectra = 0; #Scargle or FFT TEC at chosen line lat/long and AMPERE data integrated in entire auroral zone
FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone_spectra_timeMatch = 0; #Scargle or FFT TEC at chosen line lat/long and AMPERE data integrated in entire auroral zone matched to a time frame

FLG_FFTthruTime_KEOnAvgPtnAMPEREintegrated = 0; #perform FFT power spectra walking through time on TEC Keogram & TEC at a pt & AMPERE integrated

FLG_keo_stacker = 0; #stacks keogram days ontop of eachother [1 plots a direct stack, 2 plots the stacks aligned to the 1st day's sunrise time]
FLG_keo_stacker_clip = [False, np.array( (-0.25,0.25) )]; #True at start enables clipping higher/lower values
# FLG_keo_stacker_ignore = [True, {'ref data path':['TEC'], 'data path':['OMNI','Bz GSM'], 'comparison':'less than|0 & nan', 'time offset':122*60}]; #True at start enables, dict is list for the data['path']['to']['data'], the comparison to make, and the comparison value (data needs to be 1D)
# FLG_keo_stacker_ignore = [True, {'ref data path':['TEC'], 'data path':['SuperMAG','SMUs'], 'comparison':'elevated|auto,pos only & rate|auto & nan', 'time offset':122*60}]; #True at start enables, dict is list for the data['path']['to']['data'], the comparison to make, and the comparison value (data needs to be 1D)
# FLG_keo_stacker_ignore = [True, {'ref data path':['TEC'], 'data path':['SuperMAG','SMUs'], 'comparison':'elevated|auto,pos only & nan & sunrisesunset|'+str(latLong_ref[0][0])+','+str(latLong_ref[0][1])+',4500,4500', 'time offset':122*60}]; #True at start enables, dict is list for the data['path']['to']['data'], the comparison to make, and the comparison value (data needs to be 1D)
FLG_keo_stacker_ignore = [True, {'ref data path':['TEC'], 'data path':['SuperMAG','SMUs'], 'comparison':'elevated|auto,pos only & nan', 'time offset':122*60}]; #True at start enables, dict is list for the data['path']['to']['data'], the comparison to make, and the comparison value (data needs to be 1D)
# FLG_keo_stacker_ignore = [True, {'ref data path':['TEC'], 'data path':['SuperMAG','SMUs'], 'comparison':'rate|auto & nan', 'time offset':122*60}]; #True at start enables, dict is list for the data['path']['to']['data'], the comparison to make, and the comparison value (data needs to be 1D)
# FLG_keo_stacker_ignore = [True, {'ref data path':['TEC'], 'data path':[['SuperMAG','SMUs'],['OMNI','Bz GSM']], 'comparison':['elevated|auto,pos only & rate|auto & nan', 'less than|0 & nan'], 'time offset':[122*60, 122*60]}]; #True at start enables, dict is list for the data['path']['to']['data'], the comparison to make, and the comparison value (data needs to be 1D)
FLG_keo_stackerPlot = 0; #plots the stacked keograms


FLG_keo_featureFinder = 0; #find some features, good luck tiger

FLG_keo_zenithOrMISA = 0; #0 for plot vs Zenith ISR, 1 for plot vs MISA ISR
FLG_keo_timeMatch_n_HP_Scargle = 0; #Scargles the data
FLG_keo_Scargle_FFT = 1; #0 for Scargle, 1 for FFT
#FLG_keo_fullTime = 1; #0 for match to Zenith/MISA (norm), 1 for full time (will break stuff later I bet)
#-----Settings for above plots-----
keo_angle = 90; #deg, user defined angle
keo_Width_orig = 360; #arcdeg, total width - not an angle in this instance [put 360 for 0/90/180/270 because the code will autotruncate that]
keo_N = 200; #number of chunks to split the range into  [reg 200 for dense areas, 50 for less dense, 20 for super sparse]
keo_polarMode = 0; #0 for regular plotting, 1 for polar plotting of the averaging area
keo_45vsLatLong = 1; #0 for longitude on xaxis on a 45 degree angle (or multiple of it), 1 for latitude on xaxis
keo_Zoom = 5; #+/-# arcdeg around the Millstone Hill beam of choice, zoom for the time-cut plot
keo_TEC_dataName = 'delta-vTEC'; #set data name without units
keo_TEC_dataName_wUnits = 'delta-vTEC [TECU]'; #set data name with units
keo_TEC_colorMap = settings_TEC['colormap']; #set colormap to use
settings_TEC['keo'] = {
    'keo angle':keo_angle, #deg, user defined angle
    'keo width orig':keo_Width_orig, #arcdeg, total width - not an angle in this instance [put 360 for 0/90/180/270 because the code will autotruncate that
    'keo N':keo_N, #number of chunks to split the range into  [reg 200]
    'keo polar mode':0, #0 for regular plotting, 1 for polar plotting of the averaging area
    'keo 45 lat or long':keo_45vsLatLong, #0 for longitude on xaxis on a 45 degree angle (or multiple of it), 1 for latitude on xaxis
    'keo zoom':5, #+/-# arcdeg around the Millstone Hill beam of choice, zoom for the time-cut plot
    'keo data type':settings_TEC['data type'], #set the main data type
    'keo labels':settings_TEC['name'], #set data name without units
    'keo units':settings_TEC['units'], #set data name with units
    'keo colormap':settings_TEC['colormap'], #set colormap to use
    'keo plot lim':settings_TEC['plot lim'], #TECU, limit (+ and -) for plotting the TEC 
    'keo scatter size':settings_TEC['scatter size'], #kinda arbitrary scatter pt size used for TEC scatter plots
    'source to use':settings_TEC['source to use'], #records the data sources
    'day nite shading':1, #0 No shading, 1 to shade day/nite, 2 to shade manual times, -1 to draw the _|-|_ day/nite mini plot
    'day nite shading times':[0.5,11.35], #the times if above is set to 2
    'day nite shading lettering':True, #letters (True) or not (False) if 'day nite shading' is less than 0 (mini day/nite plot is going on)
    'lat long words':False, #causes lat/long words to be plotted on the keogram area plot x/y axes
    'terrain draw':False, #causes the terrain to be colored in the keo area plot
    'border draw':True, #causes the country borders to be drawn in the keo area plot (useful for close stuff)
    'interpolation':False, #interpolates missing bits, great for intermittant gaps - less useful for edges with no data
    'use local time':False, #plots local time on X axis of keograms if True, otherwise plots UTC time
    'use local time override':[False,latLong_ref[0]], #list, [1st True to override actual local value, 2nd a list of [lat,long] of reference point in desired timezone] (disables plot safeguards to make sure latLongRef is within plot range basically)
    }; #dict of settings
#other types of plots!

#---Double Keo settings---
#This is for a double keo w/ AMPERE data overlay and some plots
FLG_doubleKeo = 0; #double keo enable
FLG_doubleKeo_plot = 0; #double keo plot (2 plots the 2 keos on the same plot with an defined overlap latitude)
FLG_doubleKeo_plot_timeCutout = 0; #plots double keo with the time cutout (2 plots the 2 keos on the same plot with an defined overlap latitude)
# FLG_doubleKeo_plot_include2ndLine = [True, \
#     {'dict path':['MagCAN','EUA','mag$|Y'],'filter':'savgol & savgol denoise *winlen 10'}, \
#      {'dict path':['MagCAN','EUA','mag$|Z'],'filter':'savgol & savgol denoise *winlen 10'}, \
#     ]; #if 1st is True adds a 2nd line with the data from the following strings that delve into the dict (one for each zone)
FLG_doubleKeo_plot_include2ndLine = [True, \
    {'dict path':['MagCAN','RES','mag$|Y'],'filter':'savgol & time match|20'}, \
    {'dict path':['MagCAN','RES','mag$|Z'],'filter':'savgol & time match|20'}, \
    ]; #if 1st is True adds a 2nd line with the data from the following strings that delve into the dict (one for each zone)
# FLG_doubleKeo_plot_include2ndLine = [True, \
#     {'dict path':['MagCAN','EUA','mag$|Z'],'filter':'savgol & time match|20'}, \
#     ]; #just eastern US
FLG_doubleKeo_plot_include2ndLine_delay = [38/60, 110/60]; #delays in hrs (from ideal coefficients found via corr coeff slides) old [38, 48]
# FLG_doubleKeo_plot_include2ndLine_delay = [110/60]; #just eastern US
doubleKeo_latLong = [[[50,75],[-15,40]],[[25,50],[-100,-60]]]; #the 2 sets of lat and long coords
# doubleKeo_latLong = [[[25,50],[-100,-60]]]; #just eastern US
# doubleKeo_latLong = [[[-18,-4],[-85,-68]],[[-35,-18],[-72,-68]]]; #the 2 sets of lat and long coords (Andes)
# doubleKeo_latLong = [[[25,50],[-100,-60]],[[25,50],[-165,-100]]]; #the 2 sets of lat and long coords [west USA]
doubleKeo_angle_orig = [90,90]; #deg, user defined angle
doubleKeo_width_orig = [360,360]; #arcdeg, total width - not an angle in this instance
doubleKeo_N = [200,200]; #number of chunks to split the range into  [reg 200]
# doubleKeo_N = [50,50]; #number of chunks to split the range into  [reg 200] (Andes)
doubleKeo_45vsLatLong = [0,0]; #0 for longitude on xaxis on a 45 degree angle (or multiple of it), 1 for latitude on xaxis
# FLG_doubleKeo_AMPERE_integrateMethod = [2,2]; #0 for averaging within the respective keogram area, 1 for latitudes max is the pole, 2 for a set upper latitude value, 3 for entire hemisphere (based on plot range which hemisphere)
# doubleKeo_AMPERE_integrateMethod_val = [83,73]; #degc,we latitude value to go up to if FLG_doubleKeo_AMPERE_integrateMethod==2 75/65 old
# doubleKeo_AMPERE_coordType = 'geo'; #coord type either geo or mag - only for doubleKeo
FLG_doubleKeo_AMPERE_integrateMethod = [6,6];
doubleKeo_AMPERE_integrateMethod_val = [80,80]; #degc, latitude value to go up to if FLG_doubleKeo_AMPERE_integrateMethod==2
doubleKeo_AMPERE_coordType = 'mag'; #coord type either geo or mag - only for doubleKeo
doubleKeo_AMPERE_radiusNloc = (50, (86.18, 13.27)); #radius around location (lat,long-180to180) [current is geomag coords in 2013 of Thuule, Greenland]
FLG_doubleKeo_AMPERE_filtMethod = 'savgol'; #can be None, high-pass, low-pass, Sav-Gol - filters the data before displaying
doubleKeo_AMPERE_plotLim = False; #plot limit for AMPERE data, set to False for no limit (20000)
# doubleKeo_AMPERE_timeDelay = [+46/60, +64/60]; #1.3 (positive corr) for europe, 2 (positive corr) for USA, 2.5 for Japan
# doubleKeo_AMPERE_timeDelay = [-6/60, +122/60]; #1.2 for europe, 2 for USA, 2.5 for Japan #86
doubleKeo_AMPERE_timeDelay = [+84/60, +122/60]; #1.2 for europe, 2 for USA, 2.5 for Japan #86
# doubleKeo_AMPERE_timeDelay = [+122/60]; #just eastern US
doubleKeo_AMPERE_latAlign = [65, latMillstone]; #65 lat in europe, 42.6233 lat in USA east coast
# doubleKeo_AMPERE_latAlign = [15, longMillstone]; #15 long in europe, millstone hill long in USA east coast [for use with 0 angle]
# doubleKeo_AMPERE_latAlign = [latMillstone]; #just eastern US
# doubleKeo_AMPERE_latAlign = [-12, -33.5]; #(Andes) Jicamarca, Peru and Santiago, Chile
doubleKeo_niteTimes = [False,[-7.5,5],[0.5,11.35]]; #'nite' times in UT for Europe/USA East Coast [make 1st entry False to disable and use auto-nite detection based on location/date]
doubleKeo_arrowTimes = [False,[-11.567-.05,-10.786-.1]]; #[arrow time] for both ends of the arrow. Last one is the arrow head side
doubleKeo_namesNice = ['ΔvTEC Europe','ΔvTEC E USA']; #nice names for plottin'
# doubleKeo_namesNice = ['ΔvTEC E USA']; #nice names for plottin'
#3 set below
# doubleKeo_latLong = [[[30,75],[-15,40]],[[30,75],[-100,-60]],[[30,75],[-165,-100]]]; #the 2 sets of lat and long coords
# doubleKeo_angle_orig = [90,90,90]; #deg, user defined angle
# doubleKeo_width_orig = [360,360,360]; #arcdeg, total width - not an angle in this instance
# doubleKeo_N = [200,200,200]; #number of chunks to split the range into  [reg 200]
# doubleKeo_45vsLatLong = [0,0,0]; #0 for longitude on xaxis on a 45 degree angle (or multiple of it), 1 for latitude on xaxis
# FLG_doubleKeo_AMPERE_integrateMethod = [0,0,0]; #0 for averaging within the respective keogram area, 1 for latitudes max is the pole
# doubleKeo_AMPERE_timeDelay = [+1.0, +1.66, +1.66]; #1 for europe, 1.66 for USA
# doubleKeo_AMPERE_latAlign = [65, latMillstone, latMillstone]; #65 lat in europe, 42.6233 lat in USA east coast
# doubleKeo_AMPERE_niteTimes = [[-8,5],[-1,10],[0.5,18]]; #'nite' times in UT for Europe/USA East Coast
FLG_doubleKeo_xcorr = 0; #calcs cross-correlation spectra and correlation coefficients between the keo and the AMPERE data
# doubleKeo_xcorr_TEC_filtMethod = 'high-pass & 0 mean'; #can be None, 0 mean, high-pass, low-pass, Sav-Gol - filters the data before displaying
# doubleKeo_xcorr_TEC_filtMethod = 'high-pass & 0 mean & savgol denoise';
# doubleKeo_xcorr_TEC_filtMethod = 'savgol & 0 mean & savgol denoise *winlen 5';
doubleKeo_xcorr_TEC_filtMethod = 'savgol & 0 mean';
# doubleKeo_xcorr_TEC_filtMethod = 'none';
# doubleKeo_xcorr_AMPERE_filtMethod = 'high-pass & 0 mean'; #can be None, 0 mean, high-pass, low-pass, Sav-Gol - filters the data before displaying [this is in addition to upper filter option, ideally use this if upper is 'none']
# doubleKeo_xcorr_AMPERE_filtMethod = 'high-pass & 0 mean & savgol denoise';
# doubleKeo_xcorr_AMPERE_filtMethod = 'savgol & 0 mean & savgol denoise *winlen 5';
doubleKeo_xcorr_AMPERE_filtMethod = 'savgol & 0 mean';
# doubleKeo_xcorr_AMPERE_filtMethod = 'none'; #can be None, 0 mean, high-pass, low-pass, Sav-Gol - filters the data before displaying [this is in addition to upper filter option, ideally use this if upper is 'none']
doubleKeo_xcorr_noiseIterations = 100; #iterations to run the noise on
doubleKeo_xcorr_timeRangePer = [False,[[-17*3600,-13.5*3600],[-13*3600,-10*3600]],[[-10*3600,-7*3600],[-7*3600,-3*3600]]]; #sec, time range cutout per keo, each keo gets a specific time range cutout and the results are plotted separately (put False as 1st entry to disable)
doubleKeo_xcorr_timeRangePer_AMPERE_timeDelay = [[+46/60, +84/60],[-6/60, +122/60]]; #corresponds to the time gaps above
# doubleKeo_xcorr_timeRangePer = [[30*3600,40*3600],[0*3600,24*3600]]; #sec, time range cutout per keo, each keo gets a specific time range cutout and the results are plotted separately (put False as 1st entry to disable)
doubleKeo_xcorr_timeRangeSlam = [False,[-16*3600,-12*3600],[-12*3600,-4*3600]]; #sec, time range cutout per keo, combines time ranges from different keos into one congituous thing (put False as 1st entry to disable)
FLG_doubleKeo_xcorr_TECnOMNIxcorr = 1; # enables cross-corr between TEC and OMNI, makes a lot of plots, 2 swtiches it so TEC slides and OMNI static
# doubleKeo_xcorr_OMNI_filtMethod = 'high-pass & 0 mean'; #can be None, 0 mean, high-pass, low-pass, Sav-Gol - filters the data before displaying [this is in addition to upper filter option, ideally use this if upper is 'none']
# doubleKeo_xcorr_OMNI_filtMethod = 'high-pass & 0 mean & savgol denoise';
# doubleKeo_xcorr_OMNI_filtMethod = 'savgol & 0 mean & savgol denoise *winlen 5';
doubleKeo_xcorr_OMNI_filtMethod = 'savgol & 0 mean';
# doubleKeo_xcorr_OMNI_filtMethod = 'none';
FLG_doubleKeo_xcorr_TECnMagCANxcorr = 1; # enables cross-corr between TEC and MagCAN, makes a lot of plots, 2 swtiches it so TEC slides and MagCAN static
# doubleKeo_xcorr_MagCAN_filtMethod = 'high-pass & 0 mean'; #can be None, 0 mean, high-pass, low-pass, Sav-Gol - filters the data before displaying [this is in addition to upper filter option, ideally use this if upper is 'none']
# doubleKeo_xcorr_MagCAN_filtMethod = 'high-pass & 0 mean & savgol denoise';
# doubleKeo_xcorr_MagCAN_filtMethod = 'savgol & 0 mean & savgol denoise *winlen 5';
doubleKeo_xcorr_MagCAN_filtMethod = 'savgol & 0 mean';
# doubleKeo_xcorr_MagCAN_filtMethod = 'none';
FLG_doubleKeo_xcorr_tabulator = True; #saves data in a tabulated way
FLG_doubleKeo_xcorr_fancyPlot = False; #saves certain plots in a fancy way
FLG_doubleKeo_xcorr_disableXcorr = True; #only runs corr essentially (skips xcorr and the plots that are needed to digest xcorr)
FLG_doubleKeo_xcorr_enableCorrPlots = False; #plots correlation coeff vs time offset (lag) plots
FLG_doubleKeo_xcorr_walkingCorr = 0; #enables a walking corr plot between AMPERE/OMNI/SuperMAG/MagCAN - 1 slides those and TEC is static, 2 switches it (use 1)
FLG_doubleKeo_xcorr_timeLim_AMPERE = 3; #Hr, time limit to corr coeff check for the legacy method
FLG_doubleKeo_xcorr_timeLim_OMNI = 6; #unused rn
FLG_doubleKeo_xcorr_timeLim_NRCan = 4; #unused rn


#---Keo for TEC & Magnetometer---
FLG_doubleKeo_TECnMag = 0; #activate this combo
doubleKeo_TECnMag_TEC_latLong = [[25,50],[-100,-60]]; #the 2 sets of lat and long coords
doubleKeo_TECnMag_TEC_angleOrig = 90; #deg, user defined angle
doubleKeo_TECnMag_TEC_widthOrig = 360; #arcdeg, total width - not an angle in this instance [put 360 for 0/90/180/270 because the code will autotruncate that
doubleKeo_TECnMag_TEC_N = 200; #number of chunks to split the range into  [reg 200]
doubleKeo_TECnMag_TEC_polarMode = 0; #0 for regular plotting, 1 for polar plotting of the averaging area
doubleKeo_TECnMag_TEC_45vsLatLong = 1; #0 for longitude on xaxis on a 45 degree angle (or multiple of it), 1 for latitude on xaxis
doubleKeo_TECnMag_TEC_dataName = 'delta-vTEC'; #set data name without units
doubleKeo_TECnMag_TEC_dataName_wUnits = 'delta-vTEC [TECU]'; #set data name with units
doubleKeo_TECnMag_TEC_colorMap = 'jet'; #set colormap to use
doubleKeo_TECnMag_Mag_angle = 90; #deg, user defined angle
doubleKeo_TECnMag_Mag_width = 360; #arcdeg, total width - not an angle in this instance
doubleKeo_TECnMag_Mag_N = 5; #number of chunks to split the range into  [reg 8]
doubleKeo_TECnMag_Mag_polarMode = 0; #0 for regular plotting, 1 for polar plotting of the averaging area
doubleKeo_TECnMag_Mag_45vsLatLong = 1; #0 for longitude on xaxis on a 45 degree angle (or multiple of it), 1 for latitude on xaxis
doubleKeo_TECnMag_Mag_plotLimVal = [-15,15]; #nT, plot limit values
# doubleKeo_TECnMag_Mag_plotLimVal = None; #disable
doubleKeo_TECnMag_Mag_filtMethod = 'savgol'; #can be None, 0 mean, high-pass, low-pass, Sav-Gol - filters the data before displaying
#less important settings for plotting
doubleKeo_TECnMag_Mag_colorMap = 'jet'; #sets the colorbar used
doubleKeo_TECnMag_Mag_normalize = 1; #1 normalizes, 0 doesn't normalize - magnetic field magnitude drops with latitude, normalization keeps it "more comparable" in a way but also not kinda cause it's an absolute number that means things
doubleKeo_TECnMag_Mag_setPlotRange = 1; #1 sets plot range manually, 0 automagically figures it out based on the magnetometers in use
doubleKeo_TECnMag_Mag_setPlotRange_range = [ [50,85],[-100,-50] ]; #full range is around [ [40,85],[-125,-50] ]
doubleKeo_TECnMag_Mag_setStations = 1; #1 sets stations to use, 0 uses all stations
doubleKeo_TECnMag_Mag_setStations_names = ['EUA','RES','CBB','BLC','IQA','SNK','STJ','OTT'];#'BLC','BRD','CBB','EUA','FCC','IQA','MEA','OTT','RES','SNK','STJ','VIC','YKC' #names of the magnetometer stations

#-----0 for off, 1 for on-----
FLG_activityIndex = 0; #calculates an activity index for the delta-vTEC & AMPERE across the globe
FLG_dataCountIndex = 0; #calculates a data count index for the delta-vTEC across the globe

#-----0 for off, 1 for on-----
FLG_avgPt = 0; #averaging TEC at a point, need for anything with _avgPt - also high-pass filters the data
FLG_avgPt_timeMatch = 0; #for TEC - set to ISR cadence & high-pass, for ISR - average #pointAltitude# altitude ISR line by +/- #avgPt_ISRavgAlt# km
#[not needed]FLG_avgPt_HP_timeMatch_POPL = 0; #for TEC - set to ISR cadence & high-pass, for ISR - average #pointAltitude# altitude ISR line by +/- #avgPt_ISRavgAlt# km
FLG_avgPt_HP_timeMatch_plotWithISR_cutOut = 0; #plot the above data with ISR plots, cut out for the time period defined by time_cutout_range
FLG_avgPt_HP_timeMatch_POPL_plotWithISR_cutOut = 0; #plot the above data with ISR plots, cut out for the time period defined by time_cutout_range
FLG_avgPt_HP_timeMatch_plotWithISR_ZenithOnly_cutOut = 0; #plot the above data with ISR plots, cut out for the time period defined by time_cutout_range
FLG_avgPt_HP_timeMatch_POPL_plotWithISR_ZenithOnly_cutOut = 0; #plot the above data with ISR plots, cut out for the time period defined by time_cutout_range
FLG_avgPt_HP_timeMatch_scargleWithISR_cutOut = 0; #scargle the TEC & ISR time series data
FLG_avgPt_HP_timeMatch_POPL_scargleWithISR_cutOut = 0; #scargle the TEC & ISR time series data
FLG_avgPt_HP_timeMatch_POPLnOMNI_scargleORfft_cutOut = 0; #fft or scargle (depending on if there's gaps or not) the TEC & ISR time series data
FLG_avgPt_HP_timeMatch_POPL_CPSD_cutOut = 0; #perform CPSD between TEC & ISR over designated time cutout range (all time series data)
FLG_avgPt_HP_timeMatch_POPLnTECNOISE_CPSD_cutOut = 0; #!!ONLY FANCY PLOT!! perform CPSD between TEC & ISR & TEC noise
FLG_avgPt_HP_timeMatch_POPLnTECNOISE_FFT_cutOut = 0; #!!ONLY FANCY PLOT!! perform FFT on TEC & ISR & TEC noise
FLG_avgPt_HP_timeMatch_POPLnOMNI_CPSD_cutOut = 0; #perform CPSD between TEC & ISR and BzGSM & ISR over designated time cutout range (all time series data)
FLG_avgPt_HP_timeMatch_POPLnOMNI_FFT_cutOut = 0; #perform FFT on TEC & ISR * OMNI over designated time cutout range (all time series data)
FLG_avgPt_HP_timeMatch_POPLnOMNInTECNOISE_CPSD_cutOut = 0; #perform CPSD between TEC & ISR and BzGSM & TEC NOISE averaged over # iterations  over designated time cutout range (all time series data)
FLG_avgPt_HP_timeMatch_POPLnOMNInTECNOISE_FFT_cutOut = 0; #perfom FFT power spectra on TEC & ISR & OMNI BzGSM (or whatever is selected) & TEC NOISE averaged over # iterations (all time series data)
FLG_avgPt_HP_timeMatch_POPLnAMPERE_FFT_cutOut = 0; #perform FFT on TEC & ISR & AMPERE over designated time cutout range (all time series data)
FLG_avgPt_HP_timeMatch_POPLnAMPERE_plotWithISR_ZenithOnly_cutOut = 0; #plot the above data with ISR plots, cut out for the time period defined by time_cutout_range
FLG_AMPERE_log = 1; #makes AMPERE be log
FLG_AMPERE_hp = 1; #makes AMPERE be high-passed (happens after log if log is on, b/c HP can make negative values)
avgPt_TECnoise_iterations = 100; #number of iterations of noise to average together
FLG_avgPt_HP_timeMatch_FFTthruTime_POPLnOMNI = 0; #perform FFT power spectra walking through time on TEC & ISR & OMNI
thruTime_width = 12; #hrs to FFT/CPSD together
thruTime_step = 1; #hrs to step forward by before spectral analysing the _width

#-----Settings for above plots-----
avgPt_pointRadius = 50; #km, radius around the point to search for nearby points
avgPt_ISRavgAlt = 25; #km, +/- altitude range to average ISR by
avgPt_coords = np.array( ((latMillstone, longMillstone),(latMillstoneMISA,longMillstone)) ); #set the coordinates to average around
avgPt_coordsName = ['Millstone Hill ISR','Millstone Hill ISR MISA Beam Location at '+str(pointAltitude)+' km']; #name for it, for plotting
avgPt_plotLatMax = 4; #degc, for avg radius visualization plot, amount to go up/down in lat by wrt the avgPt_coords point specified - long scales automagically so circle is circular
dataReject = 2;#ratio that is multiplied by variance and used to determine how much data to eject
dataRejectMax = 4*dataReject; #maximum multiplier to reach
dataRejectLimit = 25; #percentage, limit on how much data can be jetisoned
dataRejectOrig = dataReject; #record original value
dataRejectLimitOrig = dataRejectLimit; #record original value
settings_map['site coords'] = avgPt_coords;
settings_map['site names'] = avgPt_coordsName;
settings_map['arcdeg or deg symbol'] = False; #False writes the word [arcdeg], True writes degre symbol [°]

#==============TEC Noise Options==============
FLG_multiRunNoise_avgPt_HP_timeMatch = 0; #runs multiple iterations of noise generation to yield multiple realizations of the noise for analysis with the avgPt scheme

#==============ISR Plotting Options==============
#choose the data type to plot
#ISR_type = 'SNR'; #Signal-to-noise ratio - not on many datasets
ISR_type = 'POPL'; #calibrated electron density (#/m^3) assuming Temp Elec == Temp Ion, Range Squared Corrected
#ISR_type = 'Ne'; #calibrated electron density (#/m^3), no assuming Te==Ti, so more NaNs when can't calc it

FLG_ISR_data = 0; #turn on ISR data import only, so it can be used for comparison with other data types
#-----0 for off, 1 for on-----
FLG_ISR_plot_POPL_HP = 0; #plot ISR POPL HP results, both bands
FLG_ISR_plot_POPL_HP_cutOut = 0; #plot ISR POPL HP results, both bands for a time cutout range
FLG_ISR_plot_POPL = 0; #plot ISR POPL no filter results, both bands
FLG_ISR_plot_POPL_limited = 0; #plot ISR POPL no filter results, both bands, limited C axis to ISR_plotLimValu like in the POPL HP plots

FLG_ISR_plot_POPL_ScargleSet = 0; #shows both bands POPL/POPL HP/Scargle of SNR HP all at 300 km altitude
FLG_ISR_plot_POPL_FFTSet = 0; #shows both bands POPL/POPL HP/FFT of SNR HP all at 300 km altitude

ISR_plotLimValu = 0.1; #unitless SNR, limit (+ and -) for plotting ISR stuff
# ISR_POPL_plotLimValu_noFilt = np.array( (1*10**11, 8*10**11) ); #e-/m^3 POPL, limit (- and +) for plotting ISR stuff
ISR_POPL_plotLimValu_noFilt = np.array( (0.5*10**11, 3*10**11) ); #e-/m^3 POPL, limit (- and +) for plotting ISR stuff [Pokerflat]
# ISR_POPL_plotLimValu = np.array( (-2*10**10, 2*10**10) ); #e-/m^3 POPL, limit (- and +) for plotting ISR stuff (no range-squared correction)
ISR_POPL_plotLimValu = np.array( (-2*10**5, 2*10**5) ); #e-/m^3 POPL, limit (- and +) for plotting ISR stuff
# ISR_POPL_plotLimValu = np.array( (-2*10**10.5, 2*10**10.5) ); #e-/m^3 POPL, limit (- and +) for plotting ISR stuff
ISR_RTI_heightLimValues = (90, 550); #km, min and max ylim to apply to ISR RTI plots

#-----Pokerflat ISR Stuff-----
FLG_ISR_Pokerflat_plot_POPL_HP = 0; #plot ISR POPL HP results, both bands
FLG_ISR_Pokerflat_plot_POPL = 0; #plot ISR POPL no filter results, both bands
FLG_ISR_Pokerflat_plot_POPL_limited = 0; #plot ISR POPL no filter results, both bands, limited C axis to ISR_plotLimValu like in the POPL HP plots

ISR_Pokerflat_PrefferedElevation = 90; #deg, elevation angle to plot. To plot all use -1, or a range [90,80] - it gets the ones closest to the ones you wanted (so if 80.88 is a thing, it'll choose that for 80)
ISR_Pokerflat_RTI_heightLimValues = (90, 550); #km, min and max ylim to apply to ISR RTI plots
#ISR_POPL_plotLimValu = np.array( (-9*10**10, 9*10**10) ); #e-/m^3 POPL, limit (- and +) for plotting ISR stuff

#-----0 for off, 1 for on-----
FLG_ISR_plot_ionVel = 0; #plots ion velocity for Zenith and MISA
FLG_ISR_plot_ionVel_cutOut = 0; #plots ion velocity for Zenith and MISA for the time limit specified above
FLG_ISR_plot_ionVel_hp = 0; #plots ion velocity for Zenith and MISA that is filtered
FLG_ISR_plot_ionVel_hp_cutOut = 0; #plots ion velocity for Zenith and MISA that is filtered for the time limit specified above
#------Settings for above plots-----
ISR_ionVel_plotLimValu_noFilt = np.array( (-20, 20) ); #m/s, ion velocity plot limit
ISR_ionVel_plotLimValu = np.array( (-5, 5) ); #m/s, ion velocity plot limit

#-----0 for off, 1 for on-----
FLG_ISR_plot_SNR_HP = 0; #plot ISR SNR HP results, both bands
FLG_ISR_plot_SNR = 0; #plot ISR SNR no filter results, both bands
FLG_ISR_plot_SNR_limited = 0; #plot ISR SNR no filter results, both bands, limited C axis to ISR_plotLimValu like in the SNR HP plots

FLG_ISR_plot_ScargleSet = 0; #shows both bands SNR/SNR HP/Scargle of SNR HP all at 300 km altitude
#-----Settings for above plots-----

#not implemented
FLG_ISR_AMPERE_CPSD_cutOut = 0; #perform CPSD between ISR & JH over designated time cutout range (all time series data)

#==============Kp and OMNI and SuperMAG and NRCanMAG Mecha Ploter Options==============
FLG_MECHACOMBO_plot = 0; #plots
# FLG_MECHACOMBO_plot_names = ['Kp','Bz GSM','Psw','Vsw','Proton Density','PC(N)',['SMLs','SMLd'],['SYM/H','SMR']]; #names of things to plot
# FLG_MECHACOMBO_plot_names = [['Bx GSE & GSM','By GSM','Bz GSM'],'Vsw','Proton Density','PC(N)',['SMLs','SMLd'],['SYM/H','SMR']]; #names of things to plot
# FLG_MECHACOMBO_plot_names = ['Proton Density',['SMR','HUA-X &R detrended','SJG-X &R detrended'],'Psw',['Bx GSE & GSM','By GSM','Bz GSM']]; #names of things to plot for Salih's paper
# FLG_MECHACOMBO_plot_names = ['Bz GSM','Psw','Vsw','PC(N)','EUA-Z &F nan & sav-gol & sav-gol denoise|15',['SMLs','SMLd'],['SYM/H','SMR']]; #names of things to plot
# FLG_MECHACOMBO_plot_names = ['Bz GSM','Psw','AMP:int:JH',['PC(N)','PC(S)'],['EUA-Z &F nan & high-pass & zero-mean & sav-gol denoise|15','EUA-Y &F nan & high-pass & zero-mean & sav-gol denoise|15'],['SMLs','SMLd'],['SYM/H','SMR']]; #names of things to plot
FLG_MECHACOMBO_plot_names = ['Bz GSM','Psw','Vsw',['PC(N)','PC(S)'],['RES-Z &F nan & high-pass & zero-mean & sav-gol denoise|15','RES-Y &F nan & high-pass & zero-mean & sav-gol denoise|15','CBB-X &F nan & high-pass & zero-mean & sav-gol denoise|15'],['SMUs','SMLs'],['SYM/H','SMR']]; #names of things to plot
# FLG_MECHACOMBO_plot_names = ['Bz GSM','Psw','Vsw',['PC(N)','PC(S)'],['SMUs','SMLs'],['SYM/H','SMR']]; #names of things to plot
# FLG_MECHACOMBO_plot_names = ['Bz GSM','Psw','Vsw',['PC(N)','PC(S)'],['SMUs','SMLs'],['SYM/H','SMR'],['SMR00','SMR06','SMR12','SMR18']]; #names of things to plot

FLG_MECHACOMBO_plot_names = ['Bz GSM','Psw','Vsw','PC(N)',['SMUs','SMLs'],['SMUd','SMLd'],['SYM/H','SMR']]; #names of things to plot
FLG_MECHACOMBO_plot_singleColumn = True; #only allow for single column plotting
FLG_MECHACOMBO_plot_mixUnits = False; #allow for data types/units to mix
FLG_MECHACOMBO_plot_timeLim = [None,0-4,12-4]; #time limit in hours wrt 0 hour (if localTime on the timeLim needs to be in local hours) - set 1st value to None to disable (None must be in list a la [None])
# FLG_MECHACOMBO_plot_timeLim = np.asarray(time_cutout_range)/3600;
FLG_MECHACOMBO_plot_localTime = False; #plot the time in the local time defined by latMillstone/longMillstone (even if not millstone of course)

#==============Kp and OMNI Plotting Options==============
#-----0 for off, 1 for on-----
FLG_Kp_plot = 0; #plot Kp for the time period (data from internet)
FLG_OMNI_plot = 0; #plot OMNI for the time period (data from internet)
FLG_OMNI_plot_scargle = 0; #plot scargle of an OMNI data time series (data from internet)
FLG_OMNI_plot_FFT = 0; #plot FFT of an OMNI data time series (data from internet)
FLG_OMNI_plot_combined = 0; #plot OMNI for the time period (data from internet)
FLG_OMNI_stacker = 0; #stack an OMNI data type
FLG_OMNI_stacker_FFT = 0; #get spectra of that stacked OMNI data type
FLG_OMNI_IMFclockAngle = 0; #plots IMF clock angle versus Bz GSM
OMNI_FFT_filtMethod = 'High-Pass'; #options are none, High-Pass, Low-Pass, Sav-Gol
#-----Settings for above plots-----
#Things to think about plotting
#  Bz GSM , Vsw, Psw, SYM/H, Bz GSE, AE
OMNI_plotSet_name = ['Bz GSM','Vsw','Psw','SYM/H']; #names of OMNI data to be plotted in large plot
# OMNI_plotSet_name = ['Bz GSM','Vsw','Psw','Epsilon']; #names of OMNI data to be plotted in large plot
# OMNI_plotSet_name = ['Bz GSM','IMF clock angle','Vsw','Psw']; #names of OMNI data to be plotted in large plot
# OMNI_plotSet_name = ['Bz GSM','SYM/H','IMF clock angle']; #names of OMNI data to be plotted in large plot
# OMNI_plotSet_name = ['Bx GSE & GSM','By GSE','Bz GSE']; #names of OMNI data to be plotted in large plot
OMNI_plotSet_name = ['SYM/H','Bz GSM','PC(N)','Psw','Vsw','Proton Density']; #names of OMNI data to be plotted in large plot
# OMNI_plotSet_name = ['SYM/H','AL','Bz GSM','PC(N)','Psw','Vsw']; #names of OMNI data to be plotted in large plot
# OMNI_plotSet_name = ['SYM/H','AE','AU','AL','Bz GSM','PC(N)','Psw','Vsw','Proton Density']; #names of OMNI data to be plotted in large plot
# OMNI_plotSet_name = ['Psw','Vsw','Proton Density']; #names of OMNI data to be plotted in large plot
OMNI_plotComb_name = ['Bz GSM','SYM/H']; #names of OMNI data to be plotted in large plot [can only be 2 things!]
OMNI_plot_name = 'SYM/H'; #name of OMNI data to be plotted in detailed analysis
OMNI_plot_scargle_name = 'Bz GSM'; #name of OMNI data to be scargle'd
OMNI_plot_scargle_highpassOption = 3; #0 no high-pass, just original data | 1 for original data & high-passed data | 2 for just high-passed data
                                      #3 for original data & delta-data [like how TEC is calc'd] |  
FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated = 0; #perform FFT power spectra walking through time on TEC Keogram & OMNI & AMPERE integrated
FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes = ['Bz GSM','Vsw','Psw','SYM/H']; #OMNI indexes to use
FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes = ['AL','PC(N)','Proton Density','SYM/H']; #OMNI indexes to use
FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_filtMethod = {'TEC':'high-pass','AMPERE':'high-pass','OMNI':'high-pass'};
FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_upTo90 = 2; #0 for averaging within the respective keogram area, 1 for latitudes max is the pole, 2 for a set upper latitude value, 3 for entire hemisphere (all longitudes, 0-90 latitudes)
FFTthruTime_KEOnAMPEREnOMNIintegrated_AMPERE_upToVal = 75; #degc, latitude value to go up to if FLG_doubleKeo_AMPERE_integrateMethod==2
FLG_FFTthruTime_KEOnOMNIintegrated = 0; #perform FFT power spectra walking through time on TEC Keogram & OMNI [same settings as above]

OMNI_delay_wrt_AMPERE = 15/60; #126 alternate
#OMNI delay should be a mostly static offset from the AMPERE data, while the AMPERE data changes with what latitude you want it to coincide with [so scale OMNI delay off of AMPERE w/ a static offset]
# OMNI_delay_wrt_TEC = AMPERE_delay_wrt_TEC-1.0; #per Robins&Zanetti2021 where JH has a +1 hr offset vs. SYM/H


#-- OMNI & AMPERE Correlator --
FLG_OMNInAMPERE_correlator = 0; #1 keeps AMPERE static and slides OMNI, 2 keeps OMNI static and slides AMPERE [use 1]
FLG_OMNInAMPERE_correlator_plot = False; #plot true or false [always reports via text]
FLG_OMNInAMPERE_correlator_shiftDir = 'both'; #pos,neg,both direction to shift in
FLG_OMNInAMPERE_correlator_tabulator = True; #tabulate data if True, only works on mode range and if time ranges are identical
FLG_OMNInAMPERE_correlator_walking = 0; #uses _shiftDir above | 1 keeps AMPERE static and slides OMNI, 2 keeps OMNI static and slides AMPERE [use 1]
#AMPERE uses the integration method with the variable AMPERE_integrateMethod
#uses list from OMNI_plotSet_name to correlate with chosen AMPERE data (AMPERE_dataType)
# FLG_OMNInAMPERE_correlator_options = [['interval',[20*60,'pos']],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]]];
# FLG_OMNInAMPERE_correlator_options = [{'mode':'interval','time interval':20*60,'interval type':'pos'} for _ in range(len(OMNI_plotSet_name))];

# OMNInAMPERE_timeInterval = np.int64(np.round(np.array([[-1256, -1042],[-890, -707],[-565, -490],[-435, -385],[-149, -49],[154, 287],[359, 453],[487, 656],[803, 1081],[1322, 1405],[1552, 1638],[1844, 1877],[1988, 2032],[2385, 2429],[2501, 2549],[2776, 2840]])*60)); #SYM/H positive slopes
# OMNInAMPERE_timeInterval = np.int64(np.round(np.array([[-14.901, -14.405],[-14.206,-13.909],[-13.296,-12.809],[-12.304,-11.303],[-10.699,-10.004],[-9.193,-7.696],[-7.290,-6.704]])*3600)); #JH spipes
# FLG_OMNInAMPERE_correlator_options = [['interval manual',OMNInAMPERE_timeInterval],['interval manual',OMNInAMPERE_timeInterval],['interval manual',OMNInAMPERE_timeInterval],['interval manual',OMNInAMPERE_timeInterval],['interval manual',OMNInAMPERE_timeInterval]];

# FLG_OMNInAMPERE_correlator_options = [{'mode':'interval manual','method':'req', 'data type':'OMNI', 'sub data type':'Bz GSM', 'comparator':'<', 'comparator val':0, 'time enforcer':20*60}]*len(OMNI_plotSet_name); # this call makes the requirement there based on OMNI or AMPERE data, 'req' activates, 'OMNI' is the data type to use, 'Bz GSM' is the sub-data type to use, '<' is "data less than"..., 0 is the number to get Bz GSM less than, 20*60 is the minimum contiguous time requirement in seconds

FLG_OMNInAMPERE_correlator_options = [{'mode':'range','time range':time_cutout_range} for _ in range(len(OMNI_plotSet_name))];
# FLG_OMNInAMPERE_correlator_options = [{'mode':'range','time range':[0*3600,12*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInAMPERE_correlator_options = [{'mode':'range','time range':[12*3600,24*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInAMPERE_correlator_options = [{'mode':'range','time range':[0*3600,24*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInAMPERE_correlator_options = [{'mode':'range','time range':[24*3600,36*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInAMPERE_correlator_options = [{'mode':'range','time range':[-14*3600,-4*3600]} for _ in range(len(OMNI_plotSet_name))];
# FLG_OMNInAMPERE_correlator_options = [{'mode':'range','time range':[-18*3600,-6*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInAMPERE_correlator_options = [{'mode':'range','time range':[-16*3600,-15*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInAMPERE_correlator_options = [['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]]];
# FLG_OMNInAMPERE_correlator_options = [['range',[-15*3600,-6.5*3600]],['range',[-15*3600,-6.5*3600]],['range',[-15*3600,-6.5*3600]],['range',[-15*3600,-6.5*3600]],['range',[-15*3600,-6.5*3600]]];
# FLG_OMNInAMPERE_correlator_options = [['range',[-14*3600,-4*3600]],['range',[-14*3600,-4*3600]],['range',[-14*3600,-4*3600]],['range',[-14*3600,-4*3600]],['range',[-14*3600,-4*3600]]];
# FLG_OMNInAMPERE_correlator_options = [{'mode':'shift'}]*len(OMNI_plotSet_name);

FLG_OMNInAMPERE_Xcorrelator = 0; #1 applies time shift to AMPERE, 2 applies time shift to OMNI [use 2]
FLG_OMNInAMPERE_Xcorrelator_options = [{'time shift':'correlator','time range':time_cutout_range,'sig1 filt':'high-pass & 0 mean','sig2 filt':'high-pass & 0 mean'} for _ in range(len(OMNI_plotSet_name))];
# FLG_OMNInAMPERE_Xcorrelator_options = [{'time shift':None,'time range':[-24*3600,0*3600],'sig1 filt':'sav-gol','sig2 filt':'sav-gol'}]*len(OMNI_plotSet_name);
# FLG_OMNInAMPERE_Xcorrelator_options = [{'time shift':None,'time range':[-14*3600,-4*3600],'sig1 filt':'sav-gol','sig2 filt':'sav-gol'}]*len(OMNI_plotSet_name);

#-- OMNI & TEC Correlator --
FLG_OMNInTEC_correlator = 0; #1 keeps OMNI static and slides AMPERE, 2 keeps AMPERE static and slides OMNI
FLG_OMNInTEC_correlator_plot = True; #plot true or false [always reports via text]
#TEC uses 
#uses list from OMNI_plotSet_name to correlate with chosen AMPERE data (AMPERE_dataType)
# FLG_OMNInTEC_correlator_options = [['interval',[20*60,'pos']],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]]];
FLG_OMNInTEC_correlator_options = [{'mode':'interval','time interval':20*60,'interval type':'pos'} for _ in range(len(OMNI_plotSet_name))];

# FLG_OMNInTEC_correlator_options = np.int64(np.round(np.array([[-1256, -1042],[-890, -707],[-565, -490],[-435, -385],[-149, -49],[154, 287],[359, 453],[487, 656],[803, 1081],[1322, 1405],[1552, 1638],[1844, 1877],[1988, 2032],[2385, 2429],[2501, 2549],[2776, 2840]])*60)); #SYM/H positive slopes
# FLG_OMNInTEC_correlator_options = np.int64(np.round(np.array([[-14.901, -14.405],[-14.206,-13.909],[-13.296,-12.809],[-12.304,-11.303],[-10.699,-10.004],[-9.193,-7.696],[-7.290,-6.704]])*3600)); #JH spipes
# FLG_OMNInTEC_correlator_options = [['interval manual',OMNInAMPERE_timeInterval],['interval manual',OMNInAMPERE_timeInterval],['interval manual',OMNInAMPERE_timeInterval],['interval manual',OMNInAMPERE_timeInterval],['interval manual',OMNInAMPERE_timeInterval]];

FLG_OMNInTEC_correlator_options = [{'mode':'interval manual','method':'req', 'data type':'OMNI', 'sub data type':'Bz GSM', 'comparator':'<', 'comparator val':0, 'time enforcer':20*60}]*len(OMNI_plotSet_name); # this call makes the requirement there based on OMNI or AMPERE data, 'req' activates, 'OMNI' is the data type to use, 'Bz GSM' is the sub-data type to use, '<' is "data less than"..., 0 is the number to get Bz GSM less than, 20*60 is the minimum contiguous time requirement in seconds

FLG_OMNInTEC_correlator_options = [{'mode':'range','time range':time_cutout_range} for _ in range(len(OMNI_plotSet_name))];
# FLG_OMNInTEC_correlator_options = [{'mode':'range','time range':[0*3600,12*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInTEC_correlator_options = [{'mode':'range','time range':[12*3600,24*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInTEC_correlator_options = [{'mode':'range','time range':[0*3600,24*3600]} for _ in range(len(OMNI_plotSet_name))];
# FLG_OMNInTEC_correlator_options = [{'mode':'range','time range':[24*3600,36*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInTEC_correlator_options = [{'mode':'range','time range':[-14*3600,-4*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInTEC_correlator_options = [{'mode':'range','time range':[-18*3600,-6*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInTEC_correlator_options = [{'mode':'range','time range':[-16*3600,-15*3600]}]*len(OMNI_plotSet_name);
# FLG_OMNInTEC_correlator_options = [['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]]];
# FLG_OMNInTEC_correlator_options = [['range',[-15*3600,-6.5*3600]],['range',[-15*3600,-6.5*3600]],['range',[-15*3600,-6.5*3600]],['range',[-15*3600,-6.5*3600]],['range',[-15*3600,-6.5*3600]]];
# FLG_OMNInTEC_correlator_options = [['range',[-14*3600,-4*3600]],['range',[-14*3600,-4*3600]],['range',[-14*3600,-4*3600]],['range',[-14*3600,-4*3600]],['range',[-14*3600,-4*3600]]];
# FLG_OMNInTEC_correlator_options = [{'mode':'shift'}]*len(OMNI_plotSet_name);

#==============SuperMAG Indices Plotting Options==============
SuperMAG_plotSet = ['SME','SMU','SML','SMEs','SMUs','SMLs','SMEd','SMUd','SMLd','SMR']; #some stuff (s means sunlit, d means darkside) SME/U/L equiv to AE/U/L, SMR equiv to SYM/H
SuperMAG_plotSet = ['SME','SMU','SML','SMEs','SMUs','SMLs','SMEd','SMUd','SMLd','SMR','SMR00','SMR06','SMR12','SMR18']; #some stuff (s means sunlit, d means darkside) SME/U/L equiv to AE/U/L, SMR equiv to SYM/H
# for i in range(0,24):
#     SuperMAG_plotSet.append('SMUr'+str(i).zfill(2));
# #END FOR i
FLG_SuperMAG_plot = 0; #plot SuperMAG indices for the time period (must manually download data)

SuperMAG_delay_wrt_AMPERE = 0; #nothing yet

#-- SuperMAG & AMPERE Correlator --
FLG_SuperMAGnAMPERE_correlator = 0; #1 keeps AMPERE static and slides SuperMAG, 2 keeps SuperMAG static and slides AMPERE [use 1]
FLG_SuperMAGnAMPERE_correlator_plot = False; #plot true or false [always reports via text]
FLG_SuperMAGnAMPERE_correlator_shiftDir = 'both'; #pos,neg,both direction to shift in
FLG_SuperMAGnAMPERE_correlator_tabulator = True; #tabulates in CSV the results
FLG_SuperMAGnAMPERE_correlator_walking = 0; #uses _shiftDir above; 1 keeps AMPERE static and slides SuperMAG, 2 keeps SuperMAG static and slides AMPERE [use 1]
FLG_SuperMAGnAMPERE_correlator_options = [{'mode':'range','time range':time_cutout_range} for _ in range(len(SuperMAG_plotSet))];
# FLG_SuperMAGnAMPERE_correlator_options = [{'mode':'range','time range':[-14*3600,-4*3600]} for _ in range(len(SuperMAG_plotSet))];
# FLG_SuperMAGnAMPERE_correlator_options = [{'mode':'range','time range':[12*3600,24*3600]}]*len(SuperMAG_plotSet);

FLG_SuperMAGnAMPERE_Xcorrelator = 0; #1 keeps SuperMAG static and slides AMPERE, 2 keeps AMPERE static and slides SuperMAG [use 2]
FLG_SuperMAGnAMPERE_Xcorrelator_options = [{'time shift':'correlator','time range':time_cutout_range,'sig1 filt':'high-pass & 0 mean','sig2 filt':'high-pass & 0 mean'} for _ in range(len(SuperMAG_plotSet))];
# FLG_SuperMAGnAMPERE_Xcorrelator_options = [{'time shift':None,'time range':[-14*3600,-4*3600],'sig1 filt':'sav-gol','sig2 filt':'sav-gol'}]*len(SuperMAG_plotSet);
# FLG_SuperMAGnAMPERE_Xcorrelator_options = [{'time shift':None,'time range':[12*3600,24*3600],'sig1 filt':'sav-gol','sig2 filt':'sav-gol'}]*len(SuperMAG_plotSet);

settings_SuperMAG = {
    'plot set':SuperMAG_plotSet,
    'delay wrt AMPERE':SuperMAG_delay_wrt_AMPERE,
    'labels':{
        'SME':'SME','SMU':'SMU','SML':'SML',
        # 'SMEs':'SME Sunlit','SMUs':'SMU Sunlit','SMLs':'SML Sunlit',
        # 'SMEd':'SME Darkside','SMUd':'SMU Darkside','SMLd':'SML Darkside',
        'SMEs':'$\mathregular{SME_s}$','SMUs':'$\mathregular{SMU_s}$','SMLs':'$\mathregular{SML_s}$',
        'SMEd':'$\mathregular{SME_d}$','SMUd':'$\mathregular{SMU_d}$','SMLd':'$\mathregular{SML_d}$',
        'SMR':'SMR','SMR00':'$\mathregular{SMR_{00}}$','SMR06':'$\mathregular{SMR_{06}}$','SMR12':'$\mathregular{SMR_{12}}$','SMR18':'$\mathregular{SMR_{18}}$',
        },
    'units':{
        'SME':' [nT]','SMU':' [nT]','SML':' [nT]',
        'SMEs':' [nT]','SMUs':' [nT]','SMLs':' [nT]',
        'SMEd':' [nT]','SMUd':' [nT]','SMLd':' [nT]',
        'SMR':' [nT]','SMR00':' [nT]','SMR06':' [nT]','SMR12':' [nT]','SMR18':' [nT]',
        },
    };
for i in range(0,24):
    settings_SuperMAG['labels']['SMUr'+str(i).zfill(2)] = 'SMU'+str(i).zfill(2); #dynamically make a bunch of labels
    settings_SuperMAG['units']['SMUr'+str(i).zfill(2)] = ' [nT]'; #dynamically make a bunch of labels
    settings_SuperMAG['labels']['SMLr'+str(i).zfill(2)] = 'SML'+str(i).zfill(2); #dynamically make a bunch of labels
    settings_SuperMAG['units']['SMLr'+str(i).zfill(2)] = ' [nT]'; #dynamically make a bunch of labels
#END FOR i
settings['SuperMAG'] = settings_SuperMAG; #set these settings

#==============AMPERE Plotting Options==============
AMPERE_latLongSteps = [1,15]; #[lat, long] - AMPERE comes default [1, 15], anything else will incur significant processing times (spherical RBF!)

#-----0 for off, 1 for on-----
#NOTE the 3 below use the TEC settings above for the same plot styles
FLG_AMPERE_keo = 0; #averaging AMPERE data in bands, needed for anything with _anyAngle
FLG_AMPERE_keo_plot = 0; #averaging AMPERE data in bands
FLG_AMPERE_keo_plot_highlightIMFSouth = True; #highlights IMF south (magnetic reconnection) times
FLG_AMPERE_keo_plot_highlightIMFSouth_type = 'Bz GSM'; #OMNI data type to use for negative == south
FLG_AMPERE_keo_plot_timeCutout = 0; #Uses the time cutout range defined below
FLG_AMPERE_keo_spectra = 0; #spectra plot of the AMPERE keogram
FLG_AMPERE_keo_plot_wSun = 0; #Plots keogram of AMPERE data with sun location plotted as well
FLG_AMPERE_keo_plot_wSunCenter = 0; #plots keogram of AMPERE data with keo pixel under the sun at the center of the plot (it's magic)
FLG_AMPERE_keo_spectra_wSunCenter = 0; #spectra plot of the sun-centered keogram pixel line (it's magic)
settings_AMPERE_keo = {
    'keo angle':90, #deg, user defined angle
    'keo width orig':360, #arcdeg, total width - not an angle in this instance [put 360 for 0/90/180/270 because the code will autotruncate that
    'keo N':50, #number of chunks to split the range into  [90deg -> 50 N, 0deg -> 120 N for 3 step AMPERE (24 for 15 step)]
    'keo polar mode':1, #0 for regular plotting, 1 for polar plotting of the averaging area
    'keo 45 lat or long':1, #0 for longitude on xaxis on a 45 degree angle (or multiple of it), 1 for latitude on xaxis
    'day nite only local':False, #false to display UTC and local time, true to only display local with a UTC conversion
    'lat long words':True, #causes lat/long words to be plotted on the keogram area plot x/y axes
    'keo coord type':'mag', #geo or mag, overrides the main one for keogramming in specific zones
    'terrain draw':False, #causes the terrain to be colored in the keo area plot
    'keo gridder':True, #tells area plotter to grid the data instead of plotting as scatter
    'use local time':False, #plots local time on X axis of keograms if True, otherwise plots UTC time
    }; #dict of settings
#except for
#AMPERE_keo_Ndeg = 1.8; #arcdeg, width of the lines - the N# will be calculated off of this
AMPERE_keo_spectra_filtMethod = 'high-pass'; #options are none, high-pass, low-pass, Sav-Gol
AMPERE_keo_spectra_spectraMethod = 'fft'; #options are FFT, FFT no norm, Lomb-Scargle

AMPERE_delay_wrt_TEC = +122/60; #affects AMPERE data b/c it can have propagation delays to get to the direct measurements at sites (from GPS-TEC or ISR)
OMNI_delay_wrt_TEC = AMPERE_delay_wrt_TEC + OMNI_delay_wrt_AMPERE; #affects AMPERE data b/c it can have propagation delays to get to the direct measurements at sites (from GPS-TEC or ISR)
settings['SuperMAG']['delay wrt TEC'] = AMPERE_delay_wrt_TEC + settings['SuperMAG']['delay wrt AMPERE'];



FLG_AMPERE_scatter_plot_area = 0; #plot AMPERE scattered with geographic features at a time with good data density
#1 plots, 2 plots with an averaging zone drawn
AMPERE_scatter_plot_area_box = np.array([[45,75],[-100,-60]]); #used if above is set to 2

FLG_AMPEREnAMPERE_correlator = 0; #0 off, 1 on - correlates two AMPERE data types from the AMPERE data set
FLG_AMPEREnAMPERE_correlator_dataTypes = ['JH','FAC']; # keeps 1st static and slides 2nd (optimal that 2nd occurs after 1st w/ positive direction enabled only)
FLG_AMPEREnAMPERE_correlator_plot = False; #plot true or false [always reports via text]
FLG_AMPEREnAMPERE_correlator_shiftDir = 'both'; #pos,neg,both direction to shift in
#AMPERE uses the integration method with the variable AMPERE_integrateMethod
#uses list from OMNI_plotSet_name to correlate with chosen AMPERE data (AMPERE_dataType)
# FLG_AMPEREnAMPERE_correlator_options = ['interval',[20*60,'pos']],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]],['range',[-16*3600,-4*3600]];
# FLG_AMPEREnAMPERE_correlator_options = {'mode':'interval','time interval':20*60,'interval type':'pos'};
FLG_AMPEREnAMPERE_correlator_options = {'mode':'range','time range':[0*3600,24*3600]}; #use make your own cutout range
# FLG_AMPEREnAMPERE_correlator_options = {'mode':'range','time range':[-16*3600,-12*3600]}; #use make your own cutout range
FLG_AMPEREnAMPERE_correlator_options = {'mode':'range','time range':time_cutout_range}; #use defined cutout range


FLG_AMPERE_integrate_plot = 0; #plot AMPERE integrated across the northern and southern hemispheres vs time
FLG_AMPERE_integrate_plot_highlightIMFSouth = True; #highlights IMF south (magnetic reconnection) times
FLG_AMPERE_integrate_plot_highlightIMFSouth_type = 'Bz GSM'; #OMNI data type to use for negative == south
FLG_AMPERE_integrate_area = 0; #plot scatter shot of the data
FLG_AMPERE_integrate_scargle = 0; #plot scargle of AMPERE integrated across the defined integration areavs periods [NOT YET]
FLG_AMPERE_integrate_FFT = 0; #plot FFT of AMPERE integrated across the defined integration area vs periods [NOT YET]
FLG_AMPERE_integrate_limArea_plot = 0; #plot AMPERE integrated across the a plot range area vs time
FLG_AMPERE_integrate_limArea_scargle = 0; #plot the scargle  of the AMPERE integrated across the a plot range area
FLG_AMPERE_integrate_andOMNI_AE_plot = 0; #plot AMPERE integrated along with OMNI's AE index vs time
FLG_AMPERE_integrate_andOMNI_AE_plot_scargle = 0; #plot the scargle of the AMPERE integrated along with OMNI's AE index
FLG_AMPERE_integrate_stacker = 0; #stacks integrated AMPERE across the defined integration area vs time
FLG_AMPERE_integrate_stacker_FFT = 0; #plot FFT of integrated AMPEREacross the defined integration area vs periods
#-----Settings for above plots-----
AMPERE_integrateMethod = 6; #0 for averaging within the defined plot area, 1 for latitudes max is the pole, 2 for a set upper latitude value, 3 for entire hemisphere (all longitudes, 0-90 latitudes), 4 for 90 to desginated latitude value for longitude range, 5 for 90 to designated latitude for all longitudes, 6 for desginated latitude to 0 all longs
AMPERE_integrateMethod_val = 80; #degc, latitude value to go up to if AMPERE_integrateMethod==2
AMPERE_integrateMethod_coordType = 'mag'; #reg uses current data type, geo uses geographic, mag uses magnetic
AMPERE_integrateMethod_log = 0; #log or don't log the integrated AMPERE data
AMPERE_integrateMethod_radiusNloc = (50, (86.18, 13.27)); #radius around location (lat,long-180to180) [current is geomag coords in 2013 of Thuule, Greenland]
AMPERE_integrateFFT_filtMethod = 'high-pass'; #options are none, high-pass, low-pass, Sav-Gol
AMPERE_integrateArea_time = -16*3600; #sec, for area plot, UT time to show [aligned to 0 hour], set to False to automatically choose a time
# 'Ped' = Pedersen Conductance [?]
# 'Hall' = Hall Conductance [?]
# 'JH' = Joule Heat [ergs/(cm^2*sec)]
# 'elec poten' = Electric Potential [?]
# 'FAC' = Field-Algined Current [?]
# AMPERE_dataType = 'FAC'; #choose a data type from the above list to plot/investigate
AMPERE_dataType = 'JH'; #choose a data type from the above list to plot/investigate


if( AMPERE_dataType == 'JH' ):
    # AMPERE_plotLimValu = [-np.inf, np.inf]; #no limit
    # AMPERE_plotLimValu = [1,25]; #erg/(cm^2*sec), low and high limits for plotting joule heating - taken from example video (seems Joule Heating low end limit is 1 - nothing less than 1)
    # AMPERE_plotLimValu = [1,15]; #erg/(cm^2*sec), low and high limits for plotting joule heating - taken from example video (seems Joule Heating low end limit is 1 - nothing less than 1)
    # AMPERE_plotLimValu = [1,5]; #erg/(cm^2*sec), low and high limits for plotting joule heating - taken from example video (seems Joule Heating low end limit is 1 - nothing less than 1)
    AMPERE_plotLimValu = [0,1]; #erg/(cm^2*sec)
    # AMPERE_plotLimValu = [0,15]; #erg/(cm^2*sec)
    #AMPERE_plotLimValu = [0,2]; #for log10 plotting
elif( AMPERE_dataType in ['FAC', 'Jr_in', 'Jr_out'] ): #Jr_in and Jr_out are Adelphi outputs, FAC is direct from AMPERE
    # AMPERE_plotLimValu = [-np.inf, np.inf]; #no limit
    # AMPERE_plotLimValu = [-1,1]; #for Field-Aligned Currents
    AMPERE_plotLimValu = [-0.3,0.3]; #for Field-Aligned Currents
    # AMPERE_plotLimValu = [-0.5,0.5]; #for Field-Aligned Currents
elif( AMPERE_dataType in ['FAC +', 'FAC Abs', 'Jr_out +', 'Jr_out Abs', 'Jr_diff Abs']  ):
    # AMPERE_plotLimValu = [-np.inf, np.inf]; #no limit
    # AMPERE_plotLimValu = [-1,1]; #for Field-Aligned Currents
    AMPERE_plotLimValu = [0,0.3]; #for Field-Aligned Currents
    # AMPERE_plotLimValu = [-0.5,0.5]; #for Field-Aligned Currents
elif( AMPERE_dataType in ['FAC -', 'Jr_out -'] ):
    AMPERE_plotLimValu = [-np.inf, np.inf]; #no limit
    # AMPERE_plotLimValu = [-1,1]; #for Field-Aligned Currents
    AMPERE_plotLimValu = [-0.3,0]; #for Field-Aligned Currents
    # AMPERE_plotLimValu = [-0.5,0.5]; #for Field-Aligned Currents
else:
    AMPERE_plotLimValu = [-np.inf, np.inf]; #no limit
#END IF

locAMPERE_pedersenC = 0; #0 = Pedersen Conductance [?]
locAMPERE_hallC = 1; #1 = Hall Conductance [?]
locAMPERE_jouleHeating = 2; #2 = Joule Heat [ergs/(cm^2*sec)]
locAMPERE_elecPoten = 3; #3 = Electric Potential [?]
locAMPERE_fieldC = 4; #4 = Field-Algined Current [?]
AMPERE_plot_indexes = np.array( (0,1,2,3,4) ); #indexes for AMPERE data to plot up
AMPERE_plot_labels = ['Pedersen Cond. [?]','Hall Cond. [?]','Joule Heating [erg/(cm$^2$•s)]','Elec. Poten. [?]','Field-Aligned Curr. [μA/m$^2$]']; #labels for the indexes above
AMPERE_plot_index = 2; #index for AMPERE data to be plotted - 2 is joule heating
AMPERE_plot_scargle_index = 2; #index for AMPERE data to be scargle'd - 2 is joule heating
AMPERE_integrate_highpassOption = 1; #0 no high-pass, just original data | 1 for just high-passed data
if( AMPERE_dataType in ['FAC', 'Jr_in', 'Jr_out',  'Jr_diff', ] ):
    AMPERE_colorMap = 'bwr';
elif( AMPERE_dataType in ['FAC +', 'FAC -',  'Jr_out +', 'Jr_out -'] ):
    AMPERE_colorMap = 'jet';
elif( AMPERE_dataType in ['FAC Abs', 'Jr_out Abs', 'Jr_diff Abs'] ):
    # AMPERE_colorMap = 'YlOrBr';
    AMPERE_colorMap = 'nipy_spectral';
else:
    AMPERE_colorMap = ListedColormap( np.hstack(( np.array( ( (np.linspace(1,0.492063492063492,128)),(np.linspace(1,0.507936507936508,128)),(np.linspace(1,1,128)) ) ) , np.array( ( (np.linspace(0.492063492063492,1,128)) , (np.linspace(0.507936507936508,0,128)) , (np.linspace(1,1,128)) ) ) )).T ); #white to purpleblue to pink (based off of 'cool')
#END IF

settings_AMPERE = {
    'lat long steps':AMPERE_latLongSteps,
    'data type':AMPERE_dataType,
    'integrate method':AMPERE_integrateMethod,
    'integrate method lat val':AMPERE_integrateMethod_val,
    'integrate method coord type':AMPERE_integrateMethod_coordType,
    'integrate method log':AMPERE_integrateMethod_log,
    'integrate method radius n loc':AMPERE_integrateMethod_radiusNloc,
    'delay wrt TEC':AMPERE_delay_wrt_TEC,
    'labels':{
        'Ped':'Pederson Cond.',
        'Hall':'Hall Cond.',
        'JH':'Joule Heating',
        'elec poten':'Elec. Poten.',
        'FAC':'FAC',#'Field-Aligned Curr.'
        'FAC +':'FAC+',#'Field-Aligned Curr.'
        'FAC -':'FAC-',#'Field-Aligned Curr.'
        'FAC Abs':'Abs. FAC',#'Field-Aligned Curr.'
        'JR_in':'JR In', #this is an Adelphi output (smoothed FAC for input into Adelphi)
        'Jr_out':'Calc\'d FAC', #this is an Adelphi output (reproduced FAC)
        'Jr_out +':'Calc\'d FAC+', #this is an Adelphi output (reproduced FAC)
        'Jr_out -':'Calc\'d FAC-', #this is an Adelphi output (reproduced FAC)
        'Jr_out Abs':'Abs. Calc\'d FAC', #this is an Adelphi output (reproduced FAC)
        'Jr_diff':'FACin - FACout',
        'Jr_diffAbs':'Abs. FACin - FACout',
        },
    'units':{
        'Ped':' [?]',
        'Hall':' [?]',
        'JH':' [erg/(cm$^2$•s)]',
        'elec poten':' [?]',
        'FAC':' [μA/m$^2$]',
        'FAC +':' [μA/m$^2$]',
        'FAC -':' [μA/m$^2$]',
        'FAC Abs':' [μA/m$^2$]',
        'JR_in':' [μA/m$^2$]',
        'Jr_out':' [μA/m$^2$]',
        'Jr_out +':' [μA/m$^2$]',
        'Jr_out -':' [μA/m$^2$]',
        'Jr_out Abs':' [μA/m$^2$]',
        'Jr_diff':' [μA/m$^2$]',
        'Jr_diffAbs':' [μA/m$^2$]',
        },
    'colormap':AMPERE_colorMap,
    'scatter size':40, #kinda arbitrary scatter pt size used for TEC scatter plots
    'plot lim':AMPERE_plotLimValu,
    'keo':settings_AMPERE_keo,
    };
settings_AMPERE['keo']['keo data type'] = settings_AMPERE['data type']; #set the main data type
settings_AMPERE['keo']['keo labels'] = settings_AMPERE['labels'][settings_AMPERE['data type']]; #set data name without units
settings_AMPERE['keo']['keo units'] = settings_AMPERE['units'][settings_AMPERE['data type']]; #set data name with units
settings_AMPERE['keo']['keo colormap'] = settings_AMPERE['colormap']; #set colormap to use
settings_AMPERE['keo']['keo plot lim'] = settings_AMPERE['plot lim']; #limit (+ and -) for plotting the AMPERE
settings_AMPERE['keo']['keo scatter size'] = settings_AMPERE['scatter size']; #kinda arbitrary scatter pt size used for TEC scatter plots
settings_AMPERE['keo']['keo area time stamp'] = AMPERE_integrateArea_time;
settings['AMPERE'] = settings_AMPERE; #set these settings

#==============Canadian Magnetometer Plotting Options==============
#v import
MagCAN_delta_method = 'savgol'; #can be None, 0 mean, high-pass, low-pass, Sav-Gol - filters the data before displaying
#v import
FLG_MagCAN_viewAll_magF = 0; #plots all of the Mag sites on a plot as multiple time series
FLG_MagCAN_viewAll_magF_FFT = 0; #plots FFT of all of the Mag sites on a plot as multiple time series
FLG_MagCAN_geoPlot = 0; #plots the geographic locations of the Mag sites

FLG_MagCAN_keo = 0; #makes a keogram of the magnetometer data (there's only a few sites, so keep the N down)
FLG_MagCAN_keo_plot = 0; #plots the keogram of the magnetometer data (there's only a few sites, so keep the N down)
#-----Settings for above plots-----
MagCAN_keo_angle_orig = 90; #deg, user defined angle
MagCAN_keo_width_orig = 360; #arcdeg, total width - not an angle in this instance
MagCAN_keo_N = 5; #number of chunks to split the range into  [reg 8]
MagCAN_keo_polarMode = 0; #0 for regular plotting, 1 for polar plotting of the averaging area
MagCAN_keo_45vsLatLong = 0; #0 for longitude on xaxis on a 45 degree angle (or multiple of it), 1 for latitude on xaxis
MagCAN_keo_plotLimVal = [-25,25]; #nT, plot limit values
MagCAN_keo_plotLimVal = None; #disable plot lim val
#less important settings for plotting
MagCAN_keo_colorbar = 'jet'; #sets the colorbar used
MagCAN_keo_normalize = 1; #1 normalizes, 0 doesn't normalize - magnetic field magnitude drops with latitude, normalization keeps it "more comparable" in a way but also not kinda cause it's an absolute number that means things
MagCAN_keo_setPlotRange = 0; #1 sets plot range manually, 0 automagically figures it out based on the magnetometers in use
MagCAN_keo_setPlotRange_range = [ [55,85],[-100,-50] ]; #full range is around [ [40,85],[-125,-50] ]
MagCAN_keo_setStations = 1; #1 sets stations to use, 0 uses all stations
MagCAN_keo_setStations_names = ['EUA','RES','CBB','IQA','FCC','SNK','STJ','OTT'];#'BLC','BRD','CBB','EUA','FCC','IQA','MEA','OTT','RES','SNK','STJ','VIC','YKC' #names of the magnetometer stations
MagCAN_keo_setStations_names = ['RES','CBB','IQA','FCC','BLC','STJ','OTT'];#'BLC','BRD','CBB','EUA','FCC','IQA','MEA','OTT','RES','SNK','STJ','VIC','YKC' #names of the magnetometer stations
# MagCAN_keo_setStations_names = ['VIC','BRD','OTT','STJ']; #get em rollin

#---MagCAN & AMPERE comparison---
FLG_MagCANnAMPERE_correlator = 0; #1 keeps AMPERE static and slides MagCAN, 2 keeps MagCAN static and slides AMPERE [use 1]
FLG_MagCANnAMPERE_correlator_plot = False; #plot true or false [always reports via text]
FLG_MagCANnAMPERE_correlator_shiftDir = 'both'; #pos,neg,both direction to shift in
FLG_MagCANnAMPERE_correlator_tabulator = True; #tabulates in CSV the results
FLG_MagCANnAMPERE_correlator_walking = 0; #uses _shiftDir above; 1 keeps AMPERE static and slides MagCAN, 2 keeps MagCAN static and slides AMPERE [use 1]
MagCAN_setStations_names = [item+'&|mag'+'$|'+str(i) for item in MagCAN_keo_setStations_names for i in range(3)]; #all 3 vectors
FLG_MagCANnAMPERE_correlator_options = [{'mode':'range','time range':time_cutout_range} for _ in range(len(MagCAN_setStations_names))];

settings_MagCAN = {
    'delta method':MagCAN_delta_method,
    'keo plot name':'Magnitude of Magnetic Field [nT]', #label for plotting
    'keo angle':MagCAN_keo_angle_orig, #orig b/c this can be adjusted slightly if 0 or 90
    'keo width orig':MagCAN_keo_width_orig, #orig b/c this can be adjusted if it's bigger than the averaging area [easy way to guarantee full coverage is to set to 360]
    'keo N':MagCAN_keo_N, #number of times to split the area the keogram covers
    'keo polar mode':MagCAN_keo_polarMode,
    'keo 45 lat/long':MagCAN_keo_45vsLatLong,
    'keo plot lim value':MagCAN_keo_plotLimVal,
    'keo colorbar':MagCAN_keo_colorbar,
    'keo normalize':MagCAN_keo_normalize,
    'keo set plot range':MagCAN_keo_setPlotRange,
    'keo set plot range range':MagCAN_keo_setPlotRange_range,
    'keo set stations':MagCAN_keo_setStations,
    'keo set stations names':MagCAN_keo_setStations_names
    };
settings['MagCAN'] = settings_MagCAN; #set these settings

#==============Machine Learning Options==============
FLG_magicks = 0; #1 for on, 0 for off



#==============Movie Snaps Options==============
#-----0 for off, 1 for on-----
FLG_enable_movieSnaps = 0; #1 for on, 0 for off 
#-----Settings for above plots-----
snaps_type = 11; #see below, the numbering mimics movieType's numbering
#1 = stationary data points
#5 = stationary data points + AMPERE data on same plot (no time average for TEC)
#11 = ONLY AMPERE data
#12 = ONLY AMPERE data w/ time averaging between snaps

snaps_auto = 2; #if 0, uses snaps_Times | 1 will generate them from snaps_auto & steps to take | 2 will generate from snaps_auto_start & _end
#MAKE SURE THEY'RE EVEN!
snaps_times = [ 16, 17, 18, 19 ]; #input some times in hrs for when to take snaps - best way is to make a movie, then choose the times

#Otherwise will automatically generate
snaps_auto_start = -16; #hr, time to start
snaps_auto_start = -11; #hr, time to start
#snaps_auto_start = -13.00; #hr, time to start

#snaps_auto_start = 18; #hr, time to start
#snaps_auto_start = 20.25; #hr, time to start

#snaps_auto_start = 24; #hr, time to start

# snaps_auto_start = 30; #hr, time to start

# snaps_auto_start = 13.50; #hr, time to start

snaps_auto_start = 21; #hr, time to start

snaps_auto_start = 'auto'; #hr, time to start [-11, 20 min steps, 6 steps is nice too], 'auto' chooses the start time as the start edge automagically
snaps_auto_step = 30; #min, time to step
snaps_auto_stepsToTake = 12; #steps to take after the start

snaps_auto_end = 'auto'; #hr, time to end *for snaps_auto == 2*, 'auto' chooses the end time as the end edge automagically
# snaps_auto_end = 24;
#4-8 is a good limit of steps to take.
snaps_dayNiteLine = 2; #0 for no dayNite line, 1 for dayNite line on, 2 for shading of nite time
snaps_dayNiteText = 0; #0 for no dayNite text, 1 for dayNite text on
snaps_sunPos = 1; #0 for no Sun drawn, 1 for Sun drawn
#for the grid spacing, auto makes the Size variable figure out the spaces, otherwise if auto 0 then the direct Spaces is used
FLG_snaps_grid_spaces_auto = 1; #1 to automatically find it based off of the Lat_Size in degc
#good for east-coast sized / japan
#snaps_Grid_Lat_Size = 0.4; #degc, how long a avg square is in latitude, longitude will be calc'd based on figure size
#good for europe sized
snaps_Grid_Lat_Size = 2; #degc, how long a avg square is in latitude, longitude will be calc'd based on figure size
#good for world
#snaps_Grid_Lat_Spaces = 150; #how many spaces to break the latitude range up into (only for stationary data points)
#snaps_Grid_Long_Spaces = 300; #how many spaces to break the longitude range up into (only for stationary data points)
#below good for smaller zones (Japan)
snaps_Grid_Lat_Spaces = 40; #how many spaces to break the latitude range up into (only for stationary data points)
snaps_Grid_Long_Spaces = 80; #how many spaces to break the longitude range up into (only for stationary data points)

#==============Movie Options==============
#-----0 for off, 1 for on-----
FLG_movieCreation_enable = 0; #1 for on, 0 for off 
#-----Settings for above plots-----
movieType = 5; #see below
#0 = dTEC moving data points (Fastest, confusing to actually see what up)
#1 = dTEC stationary data points
#2 = dTEC stationary data points + Zenith ISR overlay on 2nd plot
#3 = dTEC stationary data points + MISA ISR overlay on 2nd plot
#4 = dTEC stationary data points + AMPERE data on same plot with time average to AMPERE data (every X min)
#5 = dTEC stationary data points + AMPERE data on same plot (no time average for TEC)
#6 = dTEC stationary data points + AMPERE data on same plot (no time average for TEC) + TEC plot with line for current time
#7 = dTEC stationary data points + AMPERE data on same plot (no time average for TEC) + 2 TEC plots with line for current time
#71 = dTEC stationary data points + 2 TEC plots with line for current time
#8 = dTEC stationary data points + OMNI Index of User Choice data on same plot (no time average for TEC)
#9 = dTEC stationary data points + AMPERE data on same plot (no time average for TEC) + OMNI Index of User Choice data on 2nd plot (no time average for TEC)
#10 = dTEC stationary data points + AMPERE data on same plot (no time average for TEC) + AMPERE side plot + TEC side plot
#11 = ONLY AMPERE data
movie_MP4 = 1; #1 for MP4, 0 for gif
movie_dayNiteLine = 2; #0 for no dayNite line, 1 for dayNite line on, 2 for daynite shadowing - no text here so setting irrelevant
movie_dayNiteText = 1; #0 for no dayNite text, 1 for dayNite text on
movie_spin = 0; #0 for no spin and sun moves along perimiter, 1 for spin whole plot with sun always at top of plot [I don't think works b/c cartopy weak]
movie_timeLim = 0; #0 for no time limit, 1 for time limit
movie_timeLimRange = np.array([-24,-23]); #hr, hours to limit the movie to
movie_timeDelay = 0; #1 uses time delay for non-direct electron data, 0 ignores the time delay
#good for world
#gif_Grid_Lat_Spaces = 150; #how many spaces to break the latitude range up into (only for stationary data points)
#gif_Grid_Long_Spaces = 300; #how many spaces to break the longitude range up into (only for stationary data points)
#below good for smaller zones (Japan)
#gif_Grid_Lat_Spaces = 80; #how many spaces to break the latitude range up into (only for stationary data points)
#gif_Grid_Long_Spaces = 160; #how many spaces to break the longitude range up into (only for stationary data points)
#ABOVE is depreciated, switched to always square - see gif_Grid_Div now
movie_gridDiv = 2; #number of blocks to divide a 1 deg by 1 deg square into (so 1 would mean a 1x1 block isn't divided, 4 would mean a 1x1 block is divided into 4 parts, and you can actually divide it however you like not just by powers of 4)

movie_desiredMaxRunTime = 8*60; #sec, desired max run time (to keep video limited) - if calc'd over this it will bump from 30 FPS to 60 FPS
movie_FLGdisableFPSShift = 1; #use this to disable the jump to 60 FPS if it makes it go too fast (0 allow 60 FPS jump, 1 disabled)
movie_desiredFrameTime = 0.35; #sec, desired time between frame for MP4 (how long a frame is on the screen)
movie_figureSize = np.array((1920, 949)); #pixels, these values make it fit pretty good, as that's a maximized window's size for a 1080p monitor (W x H in pixels)
movie_figurePPI = 100; #pixels per inch, called DPI in matplotlib, figureSize/figurePPI makes it inches which is what matplotlib uses - 100 is what my 1080p monitor did

movie_saveLocale = settings_config['paths']['plots']; #location of gif (saves in a folder called Plots within the main directory where the code is run)

movie_name = 'movie'; #name of movie to make, add on the rest later



#settings for mapping
settings_map['lat range'] = plotLatRange; #degc; set lat range
settings_map['long range'] = plotLongRange; #degc; set long range
settings_map['world color'] = False; #True turns on coloring land/water; False only does continent outlines (only visible with scatter plots)
settings_map['land color'] = 'xkcd:dusty green'; #sets the land color (if world color = True)
settings_map['water color'] = 'xkcd:powder blue'; #sets the water color (if world color = True)
settings_map['site marker color'] = 'xkcd:violet'; #sets the color of the marker for the Location Of Interest (usually ISR location) on map
settings_map['site marker type'] = (8, 2, 0); #sets the marker used to denote the ocation Of Interest (usually ISR location) marker on maps (8 spokes; asterisk shape; 0 degrees of rotation)
settings_map['site marker size'] = 40; #sets maker size (bigger than the scatter pt size btw) - was 20
# settings_map['site marker color'] = 'xkcd:goldenrod'; #sets the color of the marker for the Location Of Interest (usually ISR location) on map
# settings_map['site marker type'] = '*'; #sets the marker used to denote the ocation Of Interest (usually ISR location) marker on maps (8 spokes; asterisk shape; 0 degrees of rotation)
# settings_map['site marker size'] = 20; #sets maker size (bigger than the scatter pt size btw)
settings_map['TEC scatter size'] = 20; #arb. size to make points
settings_map['AMPERE scatter size'] = 50; #arb. size to make points

# #for compatibility with old code
# gif_ContinentFill = settings_map['world color']; #1 turns on coloring land/water, 0 only does continent outlines
# gif_ContientColor = settings_map['land color']; #sets the land color (if gif_ContinentFill = 1)
# gif_ContinentWaterColor = settings_map['water color']; #sets the water color (if gif_ContinentFill = 1)
# gif_Millstone_Marker_Color = settings_map['site marker color']; #sets the color of the Millstone Hill ISR Zenith marker on maps
# gif_Millstone_Marker = settings_map['site marker type']; #sets the marker used to denote the Millstone Hill ISR Zenith marker on maps (8 spokes, asterisk shape, 0 degrees of rotation)
# gif_Millstone_Marker_Size = settings_map['site marker size']; #arb. size to make a marker (bigger than the scatter pt size btw)
# gif_Scatter_Point_Size_TEC = settings_map['TEC scatter size']; #arb. size to make points
# gif_Scatter_Point_Size_AMPERE = settings_map['AMPERE scatter size']; #arb. size to make points

#FOR movieType = 6/7/71/10 since it has a keogram subplot, this is the range to use:
# gif_plotLatRange = [30,50]; #latitude limit for USA
# gif_plotLongRange = [-125,-60]; #longitude limit for USA
# gif_zoneName = 'USA'; #name it to make it shorter
# gif2_plotLatRange = [30,75]; #latitude limit for Europe
# gif2_plotLongRange = [-15,40]; #longitude limit for Europe
# gif2_zoneName = 'Europe'; #name it to make it shorter
movie_keo1_plotLatRange = [latMillstone-8,latMillstone+8]; #latitude limit for USA
movie_keo1_plotLongRange = [longMillstone-8,longMillstone+8]; #longitude limit for USA
movie_keo1_zoneName = 'PR'; #name it to make it shorter
movie_keo2_plotLatRange = [latMillstone-8,latMillstone+8]; #latitude limit for Europe
movie_keo2_plotLongRange = [longMillstone-8-8,longMillstone+8-8]; #longitude limit for Europe
movie_keo2_zoneName = 'West of PR'; #name it to make it shorter
#these must be within the actual plotLatRange and plotLongRange to work
movie_keo1_keo_angle = 0; #deg, user defined angle
movie_keo1_keo_width = 360; #arcdeg, total width - not an angle in this instance
movie_keo1_keo_N = 40; #number of chunks to split the range into 
movie_keo1_keo_polarMode = 0; #0 for regular plotting, 1 for polar plotting of the averaging area
movie_keo1_keo_45vsLatLong = 0; #0 for longitude on xaxis on a 45 degree angle (or multiple of it), 1 for latitude on xaxis


#for movie stuff, load it in
settings_movie = {
    'movie type':movieType,
    'mp4 mode':movie_MP4, #fallback is gif
    'day nite line':movie_dayNiteLine,
    'day nite text':movie_dayNiteText,
    'spin':movie_spin,
    'time lim':movie_timeLim,
    'time lim range':movie_timeLimRange,
    'use time delays':movie_timeDelay,
    'grid divider':movie_gridDiv,
    'data reject ratio':2, #ratio that is multiplied by variance and used to determine how much data to eject
    'data reject ratio max':4*dataReject, #maximum multiplier to reach
    'data reject perc lim':25, #percentage, limit on how much data can be jetisoned
    'desired max run time':movie_desiredMaxRunTime, #shifts to 60 FPS if runtime will be more than that at 30 FPS
    'disable FPS shift':movie_FLGdisableFPSShift, #disables the shift above
    'desired frame time':movie_desiredFrameTime,
    'fig size':movie_figureSize,
    'fig PPI':movie_figurePPI,
    'name base':movie_name,
    'save locale':movie_saveLocale,
    };
settings_movie['side plots'] = {
    'keo 1 lat range':movie_keo1_plotLatRange,
    'keo 1 long range':movie_keo1_plotLongRange,
    'keo 1 name':movie_keo1_zoneName,
    'keo 2 lat range':movie_keo2_plotLatRange,
    'keo 2 long range':movie_keo2_plotLongRange,
    'keo 2 name':movie_keo2_zoneName,
    'keo 1 angle':movie_keo1_keo_angle,
    'keo 1 width':movie_keo1_keo_width,
    'keo 1 polar mode':movie_keo1_keo_polarMode,
    'keo 1 45 lat or long':movie_keo1_keo_45vsLatLong,
    'keo 2 angle':movie_keo1_keo_angle,
    'keo 2 width':movie_keo1_keo_width,
    'keo 2 polar mode':movie_keo1_keo_polarMode,
    'keo 2 45 lat or long':movie_keo1_keo_45vsLatLong,
    };

#!!!END OF SETTINGS!!!
#==============Ensure custom pltPause function is up to date==============
subfun_pltPause_create(settings_paths['cwd']);

#==============Get Good Time Keeping==============
dateRange_dayNum = subfun_date_to_dayNum(dateRange); #call function to get the date range into dayNumber form (easy to work with)
(dateRange_full, dateRange_dayNum_full) = subfun_dateORdayNum_to_fullRange(dateRange_dayNum); #call fun to get fully enumerated days between range
if( 'dateRange_zeroHr_override' in locals() ):
    if( isinstance(dateRange_zeroHr_override,np.ndarray) == False ):
        dateRange_zeroHr_override = np.int16(np.asarray(dateRange_zeroHr_override)); #convert to numpy array
    #END IF
    if( dateRange_zeroHr_override.size == 3 ):
        dateRange_zeroHr = dateRange_zeroHr_override.copy(); #copy it over for safety
        dateRange_dayNum_zeroHr = subfun_date_to_dayNum(dateRange_zeroHr_override).ravel(); #convert to dayNum
    else:
        dateRange_dayNum_zeroHr = dateRange_zeroHr_override.copy(); #copy it over for safety
        dateRange_zeroHr = subfun_dayNum_to_date(dateRange_zeroHr_override).ravel(); #convert to date
    #END IF
    if( (dateRange_dayNum_zeroHr[0] < dateRange_dayNum_full[0,0]) | (dateRange_dayNum_zeroHr[0] > dateRange_dayNum_full[-1,0]) | (dateRange_dayNum_zeroHr[1] < dateRange_dayNum_full[0,1]) | (dateRange_dayNum_zeroHr[1] > dateRange_dayNum_full[-1,1]) ):
        print('WARNING: Given dateRange_zeroHr_override ('+str(dateRange_zeroHr_override)+') is outside of given dateRange ('+str(dateRange)+'). Estimating something within dateRange as the zero hr!');
        dateRange_dayNum_zeroHr = dateRange_dayNum_full[np.int16( np.floor((len(dateRange_dayNum_full[:,0]) - 1)/2) ),:]; #choose day for when "0 hr" is - makes plots nice, no day units just hr units
        dateRange_zeroHr = dateRange_full[np.int16( np.floor((len(dateRange_dayNum_full[:,0]) - 1)/2) ),:]; #choose day for when "0 hr" is - makes plots nice, no day units just hr units
    #END IF
else:
    dateRange_dayNum_zeroHr = dateRange_dayNum_full[np.int16( np.floor((len(dateRange_dayNum_full[:,0]) - 1)/2) ),:]; #choose day for when "0 hr" is - makes plots nice, no day units just hr units
    dateRange_zeroHr = dateRange_full[np.int16( np.floor((len(dateRange_dayNum_full[:,0]) - 1)/2) ),:]; #choose day for when "0 hr" is - makes plots nice, no day units just hr units
#END IF
dateRange_zeroHr_monthName = subfun_monthNum_to_word(dateRange_zeroHr[1])[0]; #get the month name for plotting uses
dateRange_zeroHr_hrOffset = np.int16( np.floor((len(dateRange_dayNum_full[:,0]) - 1)/2) )*24; #put in the hour offset that makes a 0 to 72 hour range into the right -24 to 48 hour range (ALWAYS SUBTRACT)
dateRange_zeroHr_hrBounds = np.array( [-dateRange_zeroHr_hrOffset , dateRange_dayNum_full.shape[0]*24 - dateRange_zeroHr_hrOffset] ); #create hour date range and put zero hour at desired time
dateRange_zeroHr_hrs = np.arange(0,dateRange_dayNum_full.shape[0]*24+24,24) - dateRange_zeroHr_hrOffset; #hr, the hours that split the day wrt the zero hour day
if( (dateRange_zeroHr[2] == 1) | (dateRange_zeroHr[2] == 21) ): #makes a suffix for the day
    dateRange_zeroHr_dayPostfix = 'st'; #appropriate abbrevs for beauty
elif( (dateRange_zeroHr[2] == 2) | (dateRange_zeroHr[2] == 22) ):
    dateRange_zeroHr_dayPostfix = 'nd'; #appropriate abbrevs for beauty
elif( (dateRange_zeroHr[2] == 3) | (dateRange_zeroHr[2] == 33) ):
    dateRange_zeroHr_dayPostfix = 'rd'; #appropriate abbrevs for beauty
else:
    dateRange_zeroHr_dayPostfix = 'th'; #appropriate abbrevs for beauty
#END IF
dateRange_numDays = dateRange_dayNum_full.shape[0]; #get the number of days

dateRange_dayNum_full_adj = subfun_addADay(dateRange_dayNum_full, padDirection = 0, padNumber = 1); #pad days on both sides
dateRange_full_adj = subfun_dayNum_to_date(dateRange_dayNum_full_adj); #get date version too

time_cutout_range = np.array(time_cutout_range); #convert to numpy array
time_cutout_range_delayed_AMPERE = time_cutout_range + AMPERE_delay_wrt_TEC; #hrs, adjust for a delay with datasets that may have a delay
time_cutout_range_delayed_OMNI = time_cutout_range + OMNI_delay_wrt_TEC; #hrs, adjust for a delay with datasets that may have a delay

#==============Check if justChecking mode is needed for the dates involved==============
#--- Activate justChecking mode on TEC if needed ---
if( dateRange_numDays > settings_TEC['day num limit'] ):
    settings_TEC['justChecking'] = True;
    settings_TEC['keo']['justChecking'] = True;
else:
    settings_TEC['justChecking'] = False; #it's gonna be some work to get this going, so not yet
    settings_TEC['keo']['justChecking'] = False;
#END IF
    
#==============Prepare the AMPERE N# based off of the arcdeg requested==============
#if( keo == 0 ): #0 corresponds to longitude slices
#    AMPERE_keo_N = np.int64(np.round((np.max(plotLongRange) - np.min(plotLongRange))/AMPERE_keo_Ndeg)); #set the # of slices to occur based on the arcdeg distance between each slice
#elif( keo == 90 ): #90 corresponds to latitude slices
#    AMPERE_keo_N = np.int64(np.round((np.max(plotLatRange) - np.min(plotLatRange))/AMPERE_keo_Ndeg)); #set the # of slices to occur based on the arcdeg distance between each slice
#else: #otherwise there's an angle involved so give up
AMPERE_keo_N = keo_N; #just use the orig one - it's on an angle and more math is needed
#END IF
FLG_AMPERE_integrate = False; #set to true if it's needed later - do not set to true here

#==============Declare TEC Filtered File Layout==============
#Integer Layout
#0 = Satellite ID [# that corresponds to GPS sat]
locInt_sat = 0; #index where sat ID is
#1 = Year timestamp [years]
locInt_year = 1; #index where year timestamp is
#2 = Day Number timestamp [days]
locInt_dayNum = 2; #index where day number timestamp is
#3 = Hour timestamp [hrs]
locInt_hour = 3; #index where hour timestamp is
#4 = Minute timestamp [mins]
locInt_min = 4; #index where minute timestamp is
#5 = Second timestamp [secs]
locInt_sec = 5; #index where second timestamp is
locInt_size = 6; #size of the int variable

#Float Layout
#0 = current time in day format [days] - does not support years
locFloat_time = 0; #index where time in days is
#1 = geodedic latitude [arcdeg]
locFloat_lat = 1; #index where geodedic latitude is
#2 = longitude [arcdeg]
locFloat_long = 2; #index where longitude is
#3 = elevation [deg]
locFloat_elev = 3; #index where elevation is
#4 = delta-TEC "kinda de-biased TEC" [TECU]
locFloat_dTEC = 4; #index where delta-TEC is
#5 = delta-TEC error [TECU]
locFloat_dTECerr = 5; #index where the delta-TEC error is
locFloat_size = 6; #size of float variable

#String Layout
#[] = Receiver Site Name (there's no dim on this one) - use .decode('UTF-8') to make it a string again
locString_site = 0; #index where site name is
locString_size = 1; #size of string layout

#==============Declare Preprepared AMPERE File Layout==============
locAMPERE_pedersenC = 0; #0 = Pedersen Conductance [?]
locAMPERE_hallC = 1; #1 = Hall Conductance [?]
locAMPERE_jouleHeating = 2; #2 = Joule Heat [ergs/(cm^2*sec)]
locAMPERE_elecPoten = 3; #3 = Electric Potential [?]
locAMPERE_fieldC = 4; #4 = Field-Algined Current [?]
locAMPERE_time = 5; #5 = time [days] - does not support years 
locAMPERE_lat = 6; #6 = latitude [arcdeg]
locAMPERE_long = 7; #7 = longitude [arcdeg]

#==============Prepare the ISR plotting for the type of data chosen==============
if( ISR_type == 'SNR' ):
    ISR_type_dataName = 'SNP3'; #data name for SNR is SNP3
elif( ISR_type == 'POPL' ):
    ISR_type_dataName = ['POP','POPL']; #data name for POPL is POPL (I guess it could be POP too - the L seems to indicate log10(POP) )
elif( ISR_type == 'Ne' ):
    ISR_type_dataName = ['NE','NEL']; #data name for Ne is Ne (or NEL if it's the log10(NE) )
#END IF


#==============If doubleKeo is on, make sure the plot lat/long ranges are large enough==============
if( FLG_doubleKeo >= 1 ):
    # doubleKeo_latMax = np.max(doubleKeo_latLong[0][0]); #prep
    # doubleKeo_latMin = np.min(doubleKeo_latLong[0][0]); #prep
    # doubleKeo_longMax = np.max(doubleKeo_latLong[0][1]); #prep
    # doubleKeo_longMin = np.min(doubleKeo_latLong[0][1]); #prep
    # for i in range(0,len(doubleKeo_latLong)):
    #     if( np.max(doubleKeo_latLong[i][0]) > doubleKeo_latMax ):
    #         doubleKeo_latMax = np.max(doubleKeo_latLong[i][0]); #update
    #     #END IF
    #     if( np.min(doubleKeo_latLong[i][0]) < doubleKeo_latMin ):
    #         doubleKeo_latMin = np.min(doubleKeo_latLong[i][0]); #update
    #     #END IF
    #     if( np.max(doubleKeo_latLong[i][1]) > doubleKeo_longMax ):
    #         doubleKeo_longMax = np.max(doubleKeo_latLong[i][1]); #update
    #     #END IF
    #     if( np.min(doubleKeo_latLong[i][1]) < doubleKeo_longMin ):
    #         doubleKeo_longMin = np.min(doubleKeo_latLong[i][1]); #update
    #     #END IF
    # #END FOR i
    # if( doubleKeo_latMax > np.max(plotLatRange) ):
    #     print('WARNING: Plot lat range maximum of '+str(np.max(plotLatRange))+' degc is less than the double keo required max lat of '+str(doubleKeo_latMax)+' degc. Increasing plotLatRange max to match.');
    #     plotLatRange[np.where(plotLatRange == np.max(plotLatRange))[0].item()] = doubleKeo_latMax; #increase the plot range accordingly
    # #END IF
    # if( doubleKeo_latMin < np.min(plotLatRange) ):
    #     print('WARNING: Plot lat range minumum of '+str(np.min(plotLatRange))+' degc is less than the double keo required min lat of '+str(doubleKeo_latMin)+'. Increasing plotLatRange min to match.');
    #     plotLatRange[np.where(plotLatRange == np.min(plotLatRange))[0].item()] = doubleKeo_latMin; #increase the plot range accordingly
    # #END IF
    # if( doubleKeo_longMax > np.max(plotLongRange) ):
    #     print('WARNING: Plot long range maximum of '+str(np.max(plotLongRange))+' degc is less than the double keo required max long of '+str(doubleKeo_longMax)+'. Increasing plotLongRange max to match.');
    #     plotLongRange[np.where(plotLongRange == np.max(plotLongRange))[0].item()] = doubleKeo_longMax; #increase the plot range accordingly
    # #END IF
    # if( doubleKeo_longMin < np.min(plotLongRange) ):
    #     print('WARNING: Plot long range minumum of '+str(np.min(plotLongRange))+' degc is less than the double keo required min long of '+str(doubleKeo_longMin)+'. Increasing plotLongRange min to match.');
    #     plotLongRange[np.where(plotLongRange == np.min(plotLongRange))[0].item()] = doubleKeo_longMin; #increase the plot range accordingly
    # #END IF
    
    #Verify if mode 2 is possible
    if( (FLG_doubleKeo_plot == 2) | (FLG_doubleKeo_plot_timeCutout == 2) ):
        if( np.any(np.array(doubleKeo_angle_orig) == 90) | np.any(np.array(doubleKeo_angle_orig) == 0) ): #only works on 0 or 90 degrees
            if( np.all(np.array(doubleKeo_angle_orig) == doubleKeo_angle_orig[0]) == True ): #the angles have to be the same as well
                doubleKeo_latLongComb = np.empty( (len(doubleKeo_latLong),2) );
                if( np.any(np.array(doubleKeo_angle_orig) == 90) ):
                    for i in range(0,len(doubleKeo_latLong)):
                        doubleKeo_latLongComb[i,:] = doubleKeo_latLong[i][0]; #pull it out latitude
                    #END FOR i
                else:
                    for i in range(0,len(doubleKeo_latLong)):
                        doubleKeo_latLongComb[i,:] = doubleKeo_latLong[i][1]; #pull it out longitude
                    #END FOR i
                # END IF
                doubleKeo_latLongComb = np.sort(doubleKeo_latLongComb,axis=1);
                uniques, indxs, cnts = np.unique(doubleKeo_latLongComb.flatten(), return_index=True,return_counts=True);
                if( (len(doubleKeo_latLong)-1 == np.sum(cnts == 2)) & np.all(cnts[1:-1] == 2) ):
                    doubleKeo_alignments = uniques[1:-1]; #places where the lines of separation need to be drawn
                else:
                    if( FLG_doubleKeo_plot == 2 ):
                        print('WARNING: doubleKeo is set to mode 2, but the keogram [latitude or longitudes] don\'t match up. Reverting to mode 1.');
                        FLG_doubleKeo_plot = 1; #set the flag to mode 1
                    # END IF
                    if( FLG_doubleKeo_plot_timeCutout == 2 ):
                        print('WARNING: doubleKeo timeCutout is set to mode 2, but the keogram [latitude or longitudes] don\'t match up. Reverting to mode 1.');
                        FLG_doubleKeo_plot_timeCutout = 1; #set the flag to mode 1
                    # END IF
                #END IF
            else:
                if( FLG_doubleKeo_plot == 2 ):
                    print('WARNING: doubleKeo is set to mode 2, but keogram angles do not match. Reverting to mode 1.');
                    FLG_doubleKeo_plot = 1; #set the flag to mode 1
                # END IF
                if( FLG_doubleKeo_plot_timeCutout == 2 ):
                    print('WARNING: doubleKeo timeCutout is set to mode 2, but keogram angles do not match. Reverting to mode 1.');
                    FLG_doubleKeo_plot_timeCutout = 1; #set the flag to mode 1
                # END IF
            #END IF
        else:
            if( FLG_doubleKeo_plot == 2 ):
                print('WARNING: doubleKeo is set to mode 2, but keogram angles must be 0 or 90 to make mode 2 work. Reverting to mode 1.');
                FLG_doubleKeo_plot = 1; #set the flag to mode 1
            # END IF
            if( FLG_doubleKeo_plot_timeCutout == 2 ):
                print('WARNING: doubleKeo timeCutout is set to mode 2, but keogram angles must be 0 or 90 to make mode 2 work. Reverting to mode 1.');
                FLG_doubleKeo_plot_timeCutout = 1; #set the flag to mode 1
            # END IF
        #END IF
    #END IF
#END IF
# if( FLG_doubleKeo_TECnMag == 1 ):
#     doubleKeo_latMax = np.max(doubleKeo_TECnMag_TEC_latLong[0]); #prep
#     doubleKeo_latMin = np.min(doubleKeo_TECnMag_TEC_latLong[0]); #prep
#     doubleKeo_longMax = np.max(doubleKeo_TECnMag_TEC_latLong[1]); #prep
#     doubleKeo_longMin = np.min(doubleKeo_TECnMag_TEC_latLong[1]); #prep
#     if( doubleKeo_latMax > np.max(plotLatRange) ):
#         print('WARNING: Plot lat range maximum of '+str(np.max(plotLatRange))+' degc is less than the double keo required max lat of '+str(doubleKeo_latMax)+' degc. Increasing plotLatRange max to match.');
#         plotLatRange[np.where(plotLatRange == np.max(plotLatRange))[0].item()] = doubleKeo_latMax; #increase the plot range accordingly
#     #END IF
#     if( doubleKeo_latMin < np.min(plotLatRange) ):
#         print('WARNING: Plot lat range minumum of '+str(np.min(plotLatRange))+' degc is less than the double keo required min lat of '+str(doubleKeo_latMin)+'. Increasing plotLatRange min to match.');
#         plotLatRange[np.where(plotLatRange == np.min(plotLatRange))[0].item()] = doubleKeo_latMin; #increase the plot range accordingly
#     #END IF
#     if( doubleKeo_longMax > np.max(plotLongRange) ):
#         print('WARNING: Plot long range maximum of '+str(np.max(plotLongRange))+' degc is less than the double keo required max long of '+str(doubleKeo_longMax)+'. Increasing plotLongRange max to match.');
#         plotLongRange[np.where(plotLongRange == np.max(plotLongRange))[0].item()] = doubleKeo_longMax; #increase the plot range accordingly
#     #END IF
#     if( doubleKeo_longMin < np.min(plotLongRange) ):
#         print('WARNING: Plot long range minumum of '+str(np.min(plotLongRange))+' degc is less than the double keo required min long of '+str(doubleKeo_longMin)+'. Increasing plotLongRange min to match.');
#         plotLongRange[np.where(plotLongRange == np.min(plotLongRange))[0].item()] = doubleKeo_longMin; #increase the plot range accordingly
#     #END IF
# #END IF

#==============Ensure import region is large enough to cover everything==============
plotLatRange_importer = plotLatRange.copy(); #Prep a list
plotLongRange_importer = plotLongRange.copy(); #Prep a list
if( (FLG_avgPt >= 1) | (FLG_keo >= 1) ):
    for i in range(0,avgPt_coords.shape[0]):
        plotLatRange_importer.append(settings_map['site coords'][i][0]);
        plotLongRange_importer.append(settings_map['site coords'][i][1]);
    #END FOR i
#END IF
if( FLG_doubleKeo >= 1 ):
    for i in range(0,len(doubleKeo_latLong)):
        plotLatRange_importer.extend(doubleKeo_latLong[i][0]);
        plotLongRange_importer.extend(doubleKeo_latLong[i][1]);
    #END FOR i
#END IF        
if( FLG_doubleKeo_TECnMag >= 1 ):
    plotLatRange_importer.extend(doubleKeo_TECnMag_TEC_latLong[0]);
    plotLongRange_importer.extend(doubleKeo_TECnMag_TEC_latLong[1]);
#END IF
if( FLG_magicks >= 1 ):
    plotLatRange_importer.append(settings_map['site coords'][0][0]);
    plotLongRange_importer.append(settings_map['site coords'][0][1]);
#END IF
plotLatRange_importer = [np.min(np.asarray(plotLatRange_importer)), np.max(np.asarray(plotLatRange_importer))];
plotLongRange_importer = [np.min(np.asarray(plotLongRange_importer)), np.max(np.asarray(plotLongRange_importer))];
settings_TEC_import['lat range'] = plotLatRange_importer; #place in
settings_TEC_import['long range'] = plotLongRange_importer; #place in


#==============Figure out what data types are needed==============
FLG_dataTypes = np.zeros(len(dataTypes),dtype=np.int8); #prime the needed flag (supports all data types)
FLG_TECloc = dataTypes.index("TEC"); #get the index for TEC
FLG_ISRloc = dataTypes.index("ISR"); #get the index for ISR
FLG_AMPEREloc = dataTypes.index("AMPERE"); #get the index for AMPERE
FLG_Kploc = dataTypes.index("Kp"); #get the index for Kp
FLG_OMNIloc = dataTypes.index("OMNI"); #get the index for OMNI
FLG_SuperMAGloc = dataTypes.index('SuperMAG'); #get the index for SuperMAG indices
FLG_MagCANloc = dataTypes.index("MagCAN"); #get the index for MagCAN
FLG_SuperMAGstationsloc = dataTypes.index('SuperMAG stations'); #get the index for SuperMAG Mag data (not the indices, data that makes them)
#-----NOW CHOOSE WHICH DATA TYPES TO USE-----
#~~~PREDOMINANTLY TEC STUFF~~~
if( FLG_keo >= 1 ):
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
#END IF
if( FLG_keo_plot >= 1 ):
    FLG_keo = 1; #this is required for above to work
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
#END IF
if( FLG_keo_plot_timeCutout >= 1 ):
    FLG_keo = 1; #this is required for above to work
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
#END IF
if( FLG_keo_dataDensity >= 1 ):
    FLG_keo = 1; #this is required for above to work
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
#END IF
if( FLG_keo_plot_wNoise >= 1 ):
    FLG_keo = 1; #this is required for above to work
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
#END IF
if( FLG_keo_plot_noiseAllViews >= 1 ):
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
#END IF
if( FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration >= 1 ):
    FLG_keo = 1; #avg any angle is needed for this
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
#END IF
if( FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone >= 1 ):
    FLG_keo = 1; #avg any angle is needed for this
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
#END IF
if( (FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone_spectra >= 1) | (FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone_spectra_timeMatch >= 1) ):
    FLG_keo = 1; #avg any angle is needed for this
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
#END IF
if( FLG_keo_stacker >= 1 ):
    FLG_keo = 1; #avg any angle is needed for this
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
#END IF
if( FLG_keo_stackerPlot >= 1 ):
    FLG_keo = 1; #avg any angle is needed for this
    if( FLG_keo_stacker == 0 ):
        FLG_keo_stacker = 1; #need the stacker to plot the stack result
    #END IF
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
#END IF
if( FLG_doubleKeo >= 1 ):
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
#END IF
if( FLG_doubleKeo_plot >= 1 ):
    FLG_doubleKeo = 1; #needs double keo, make sure it on
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
#END IF
if( FLG_doubleKeo_plot_timeCutout >= 1 ):
    FLG_doubleKeo = 1; #needs double keo, make sure it on
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
#END IF
if( (FLG_doubleKeo_xcorr_TECnOMNIxcorr >= 1) & (FLG_doubleKeo_xcorr >= 1) ):
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( (FLG_doubleKeo_xcorr_TECnMagCANxcorr >= 1) & (FLG_doubleKeo_xcorr >= 1) ):
    FLG_dataTypes[FLG_MagCANloc] = 1; #turn on flag for getting Magnetometer data
#END IF
if( FLG_doubleKeo_xcorr >= 1 ):
    FLG_doubleKeo = 1; #needs double keo, make sure it on
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting AMPERE data
    FLG_dataTypes[FLG_SuperMAGloc] = 1; #turn on flag for getting AMPERE data
#END IF
if( FLG_doubleKeo_TECnMag >= 1 ):
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_MagCANloc] = 1; #turn on flag for getting Magnetometer data
#END IF
if( FLG_activityIndex >= 1):
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #need it
#END IF
if( FLG_dataCountIndex >= 1 ):
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
#END IF
if( FLG_avgPt >= 1 ):
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
#END IF
if( FLG_avgPt_timeMatch >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_avgPt_HP_timeMatch_plotWithISR_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_avgPt_HP_timeMatch_POPL_plotWithISR_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_avgPt_HP_timeMatch_plotWithISR_ZenithOnly_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_avgPt_HP_timeMatch_POPL_plotWithISR_ZenithOnly_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_avgPt_HP_timeMatch_scargleWithISR_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_avgPt_HP_timeMatch_POPL_scargleWithISR_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_avgPt_HP_timeMatch_POPLnOMNI_scargleORfft_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_avgPt_HP_timeMatch_POPL_CPSD_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_avgPt_HP_timeMatch_POPLnTECNOISE_CPSD_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_avgPt_HP_timeMatch_POPLnTECNOISE_FFT_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_avgPt_HP_timeMatch_POPLnOMNI_CPSD_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_avgPt_HP_timeMatch_POPLnOMNI_FFT_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_avgPt_HP_timeMatch_POPLnOMNInTECNOISE_CPSD_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_avgPt_HP_timeMatch_POPLnOMNInTECNOISE_FFT_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_avgPt_HP_timeMatch_POPLnAMPERE_plotWithISR_ZenithOnly_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #need it
#END IF
if( FLG_avgPt_HP_timeMatch_POPLnAMPERE_FFT_cutOut >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #need it
#END IF
if( FLG_avgPt_HP_timeMatch_FFTthruTime_POPLnOMNI >= 1 ):
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 1; #this reqs avg pt time match
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_FFTthruTime_KEOnAvgPtnAMPEREintegrated >= 1 ):
    FLG_keo = 1; #this reqs keo
    FLG_avgPt = 1; #this reqs avg pt
    FLG_avgPt_timeMatch = 0; #cannot time match as it is set up now
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #need it
#END IF
if( FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated >= 1 ):
    FLG_keo = 1; #this reqs keo
    # FLG_avgPt = 1; #this reqs avg pt
    # FLG_avgPt_timeMatch = 0; #cannot time match as it is set up now
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #need it
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_FFTthruTime_KEOnOMNIintegrated >= 1 ):
    FLG_keo = 1; #this reqs keo
    # FLG_avgPt = 1; #this reqs avg pt
    # FLG_avgPt_timeMatch = 0; #cannot time match as it is set up now
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( (FLG_OMNInAMPERE_correlator >= 1) | (FLG_OMNInAMPERE_correlator_walking >= 1) ):
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #need it
#END IF
if( FLG_OMNInAMPERE_Xcorrelator >= 1 ):
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #need it
#END IF
if( FLG_magicks >= 1 ):
    #TURN ON TEC
    FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    # FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    # FLG_AMPERE_integrate = True; #need it
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
    FLG_dataTypes[FLG_SuperMAGloc] = 1; #turn on flag for getting OMNI data
#END IF
if( (FLG_enable_movieSnaps >= 1) ): #movieSnaps shares the same data reqs as movieCreation
    if( (snaps_type == 0) | (snaps_type == 1) ):
        FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    elif( (snaps_type == 2) | (snaps_type == 3) ):
        FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
        FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
    elif( (snaps_type == 4) | (snaps_type == 5)| (snaps_type == 6)| (snaps_type == 7)| (snaps_type == 10) ):
        FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
        FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    elif( (snaps_type == 8) ):
        FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
        FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
    elif( (snaps_type == 9) ):
        FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
        FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
        FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    elif( (snaps_type == 11) | (snaps_type == 12) ):
        FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting ISR data
    #END IF
#END IF
if( (FLG_movieCreation_enable >= 1) ): #movieSnaps shares the same data reqs as movieCreation
    if( (movieType == 0) | (movieType == 1) | (movieType == 71) ):
        FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
    elif( (movieType == 2) | (movieType == 3) ):
        FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
        FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
    elif( (movieType == 4) | (movieType == 5)| (movieType == 6)| (movieType == 7)| (movieType == 10) ):
        FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
        FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    elif( (movieType == 8) ):
        FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
        FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
    elif( (movieType == 9) ):
        FLG_dataTypes[FLG_TECloc] = 1; #turn on flag for getting TEC data
        FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
        FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting AMPERE data
    elif( (movieType == 11) ):
        FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on flag for getting ISR data
    #END IF
#END IF
    
#~~~PREDOMINANTLY ISR STUFF~~~
if( FLG_ISR_data >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_ISR_plot_POPL_HP >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF 
if( FLG_ISR_plot_POPL_HP_cutOut >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_ISR_plot_POPL >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_ISR_plot_POPL_limited >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF  
if( FLG_ISR_plot_POPL_ScargleSet >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF  
if( FLG_ISR_plot_POPL_FFTSet >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF  
if( FLG_ISR_plot_SNR_HP >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_ISR_plot_SNR >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_ISR_plot_SNR_limited >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF  
if( FLG_ISR_plot_ScargleSet >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF  
if( FLG_ISR_plot_ionVel >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF  
if( FLG_ISR_plot_ionVel_cutOut >= 1 ): 
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
if( FLG_ISR_plot_ionVel_hp >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF 
if( FLG_ISR_plot_ionVel_hp_cutOut >= 1 ):
    #TURN ON ISR
    FLG_dataTypes[FLG_ISRloc] = 1; #turn on flag for getting ISR data
#END IF
    
#~~~PREDOMINANTLY Kp STUFF~~~
if( FLG_Kp_plot >= 1 ):
    #TURN ON Kp
    FLG_dataTypes[FLG_Kploc] = 1; #turn on flag for getting Kp data
#END IF
#~~~PREDOMINANTLY OMNI STUFF~~~
if( FLG_OMNI_plot >= 1 ):
    #TURN ON OMNI
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_OMNI_plot_scargle >= 1 ):
    #TURN ON OMNI
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_OMNI_plot_FFT >= 1 ):
    #TURN ON OMNI
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_OMNI_plot_combined >= 1 ):
    #TURN ON OMNI
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_OMNI_stacker >= 1 ):
    #TURN ON OMNI
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_OMNI_stacker_FFT >= 1 ):
    #TURN ON OMNI
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_OMNI_IMFclockAngle >= 1 ):
    #TURN ON OMNI
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
#~~~PREDOMINANTLY SuperMAG Indices STUFF~~~
if( FLG_SuperMAG_plot >= 1 ):
    FLG_dataTypes[FLG_SuperMAGloc] = 1; #turn on flag for getting SuperMAG Indices data
#END IF
if( (FLG_SuperMAGnAMPERE_correlator >= 1) | (FLG_SuperMAGnAMPERE_correlator_walking >= 1) ):
    FLG_dataTypes[FLG_SuperMAGloc] = 1; #turn on flag for getting SuperMAG Indices data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #need it
#END IF
if( FLG_SuperMAGnAMPERE_Xcorrelator >= 1 ):
    FLG_dataTypes[FLG_SuperMAGloc] = 1; #turn on flag for getting SuperMAG Indices data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #need it
#END IF
#~~~COMBO KP & OMNI & SuperMAG STUFF~~~
if( FLG_MECHACOMBO_plot >= 1 ):
    FLG_dataTypes[FLG_Kploc] = 1; #turn on flag for getting Kp data
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
    FLG_dataTypes[FLG_SuperMAGloc] = 1; #turn on flag for getting SuperMAG Indices data
    # FLG_dataTypes[FLG_SuperMAGstationsloc] = 1; #turn on flag for getting SuperMAG stations data [will call this in a reactionary way]
    FLG_dataTypes[FLG_MagCANloc] = 3; #turn on flag for getting MagCAN data
    FLG_MECHACOMBO_AMPEREcheck = np.where((strfind(FLG_MECHACOMBO_plot_names,'AMP:',opt=0) > 0) | (strfind(FLG_MECHACOMBO_plot_names,'AMPERE:',opt=0) > 0))[0];
    if( FLG_MECHACOMBO_AMPEREcheck.size > 0 ):
        #optional AMPERE data based on decorator
        # for i in range(0,FLG_MECHACOMBO_AMPEREcheck.size): #not needed since integrate in place it seems
        #     if( (strfind(FLG_MECHACOMBO_plot_names[FLG_MECHACOMBO_AMPEREcheck[i]].lower(),':int:',opt=1) > 0) | (strfind(FLG_MECHACOMBO_plot_names[FLG_MECHACOMBO_AMPEREcheck[i]].lower(),':integrate:',opt=1) > 0) ):
        #         FLG_AMPERE_integrate = True; #turn on integration
        #     #END IF
        # #END FOR i
        FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    #END IF
#END IF
#~~~PREDOMINATELY AMPERE STUFF~~~
if( FLG_AMPERE_keo >= 1 ):
    #TURN ON TEC
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
#END IF
if( FLG_AMPERE_keo_plot >= 1):
    FLG_AMPERE_keo = 1; #turn this on, it's req
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
#END IF
if( FLG_AMPERE_keo_plot_highlightIMFSouth >= 1 ):
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on the flag for getting OMNI data
#END IF
if( FLG_AMPERE_keo_plot_timeCutout >= 1):
    FLG_AMPERE_keo = 1; #turn this on, it's req
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
#END IF
if( FLG_AMPERE_keo_spectra >= 1):
    FLG_AMPERE_keo = 1; #turn this on, it's req
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
#END IF
if( FLG_AMPERE_keo_plot_wSun >= 1 ):
    FLG_AMPERE_keo = 1; #turn this on, it's req
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
#END IF
if( FLG_AMPERE_keo_plot_wSunCenter >= 1 ):
    FLG_AMPERE_keo = 1; #turn this on, it's req
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
#END IF
if( FLG_AMPERE_keo_spectra_wSunCenter >= 1 ):
    FLG_AMPERE_keo = 1; #turn this on, it's req
    FLG_AMPERE_keo_plot_wSunCenter = 1; #turn this on, it's req
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
#END IF
if( FLG_AMPERE_scatter_plot_area >= 1 ):
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
#END IF
if( FLG_AMPEREnAMPERE_correlator >= 1 ):
    #TURN ON AMPERE
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
#END IF
if( FLG_AMPERE_integrate_plot >= 1 ):
    #TURN ON AMPERE
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #turn on integration
    if( FLG_AMPERE_integrate_plot_highlightIMFSouth >= 1 ):
        FLG_dataTypes[FLG_OMNIloc] = 1; #turn on the flag for getting OMNI data
    #END IF
#END IF
if( FLG_AMPERE_integrate_area >= 1 ):
    #TURN ON AMPERE
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #turn on integration
#END IF
if( FLG_AMPERE_integrate_FFT >= 1 ):
    #TURN ON AMPERE
    FLG_dataTypes[FLG_AMPEREloc]   = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #turn on integration
#END IF
if( FLG_AMPERE_integrate_scargle >= 1 ):
    #TURN ON AMPERE
    FLG_dataTypes[FLG_AMPEREloc]   = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #turn on integration
#END IF
if( FLG_AMPERE_integrate_limArea_plot >= 1 ):
    #TURN ON AMPERE
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #turn on integration
#END IF
if( FLG_AMPERE_integrate_limArea_scargle >= 1 ):
    #TURN ON AMPERE
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #turn on integration
#END IF
if( FLG_AMPERE_integrate_stacker >= 1 ):
    #TURN ON AMPERE
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #turn on integration
#END IF
if( FLG_AMPERE_integrate_stacker_FFT >= 1 ):
    FLG_AMPERE_integrate_stacker = 1; #need integrator to run
    #TURN ON AMPERE
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #turn on integration
#END IF
if( FLG_AMPERE_integrate_andOMNI_AE_plot >= 1 ):
    #TURN ON AMPERE
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #turn on integration
    #TURN ON OMNI
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
if( FLG_AMPERE_integrate_andOMNI_AE_plot_scargle >= 1 ):
    #TURN ON AMPERE
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #turn on integration
    #TURN ON OMNI
    FLG_dataTypes[FLG_OMNIloc] = 1; #turn on flag for getting OMNI data
#END IF
#~~~PREDOMINATELY MAG STUFF~~~
if( FLG_MagCAN_viewAll_magF >= 1 ):
    #TURN ON Mag
    FLG_dataTypes[FLG_MagCANloc] = 1; #turn on the flag for getting Mag data
#END IF
if( FLG_MagCAN_viewAll_magF_FFT >= 1 ):
    #TURN ON Mag
    FLG_dataTypes[FLG_MagCANloc] = 1; #turn on the flag for getting Mag data
#END IF
if( FLG_MagCAN_geoPlot >= 1 ):
    #TURN ON Mag
    FLG_dataTypes[FLG_MagCANloc] = 1; #turn on the flag for getting Mag data
#END IF
if( FLG_MagCAN_keo >= 1 ):
    #TURN ON Mag
    FLG_dataTypes[FLG_MagCANloc] = 1; #turn on the flag for getting Mag data
#END IF
if( FLG_MagCAN_keo_plot >= 1 ):
    FLG_MagCAN_keo = 1; #keo req for the plot, make sure it's on
    #TURN ON Mag
    FLG_dataTypes[FLG_MagCANloc] = 1; #turn on the flag for getting Mag data
#END IF
if( (FLG_MagCANnAMPERE_correlator >= 1) | (FLG_MagCANnAMPERE_correlator_walking >= 1) ):
    FLG_dataTypes[FLG_MagCANloc] = 1; #turn on flag for getting MagCAN data
    FLG_dataTypes[FLG_AMPEREloc] = 1; #turn on the flag for getting AMPERE data
    FLG_AMPERE_integrate = True; #need it
#END IF

#--- saveFLG_dataTypes into settings ---
settings['data'] = {'data types': dataTypes, 'data types req': FLG_dataTypes};

#-----Avoid reloading same TEC data b/c it is slow, can be expanded to other data-----
if( (FLG_rerunner['run num'] == 1) | ('data' not in locals()) ):
    data = {}; #prep data holder
    FLG_rerunner['TEC'] = {
        'FLG_TEC_use':FLG_TEC_use,
        'plotLatRange':plotLatRange_importer,
        'plotLongRange':plotLongRange_importer,
        'dateRange':dateRange,
        'FLG_TEC_noise':FLG_TEC_noise,
        'coord type':settings_map['coord type'],
    }; #prep a TEC dict that unqiuely identifies the imported TEC data
else:
    dataTypes_temp = dataTypes.copy(); #make a copy
    for i in sorted(np.where(~FLG_dataTypes.astype('bool_') == 1)[0], reverse=True):
        del dataTypes_temp[i]; #remove
    #END FOR i
    keyz = list(data.keys()); #get a list of the current keys
    for i in range(0,len(keyz)):
        if( not keyz[i] in dataTypes_temp ):
            del data[keyz[i]]; # remove the key if it's not in the currently used list
        #END IF
    #END FOR i
    if( ('TEC' in list(data.keys())) & \
    ( (FLG_TEC_use != FLG_rerunner['TEC']['FLG_TEC_use']) | \
    (np.max(plotLatRange_importer) > np.max(FLG_rerunner['TEC']['plotLatRange'])) | \
    (np.min(plotLatRange_importer) < np.min(FLG_rerunner['TEC']['plotLatRange'])) | \
    (np.max(plotLongRange_importer) > np.max(FLG_rerunner['TEC']['plotLongRange'])) | \
    (np.min(plotLongRange_importer) < np.min(FLG_rerunner['TEC']['plotLongRange'])) | \
    (not np.array_equal(dateRange,FLG_rerunner['TEC']['dateRange'])) | \
    (FLG_TEC_noise != FLG_rerunner['TEC']['FLG_TEC_noise']) | \
    (settings_map['coord type'] != FLG_rerunner['TEC']['coord type']) ) ):
        del data['TEC']; # remove the TEC if the essential params are diff on rerun
        FLG_rerunner['TEC'] = {
            'FLG_TEC_use':FLG_TEC_use,
            'plotLatRange':plotLatRange_importer,
            'plotLongRange':plotLongRange_importer,
            'dateRange':dateRange,
            'FLG_TEC_noise':FLG_TEC_noise,
            'coord type':settings_map['coord type'],
        }; #update the TEC dict that unqiuely identifies the imported TEC data
    #END IF
    gc.collect(); #call the garbage collector to free memory
#END IF

#-----Deal with time reference issues----- 
#Support for TEC time reference  
if( (time_Reference == 'TEC') & (FLG_dataTypes[FLG_TECloc] == 0) ):
    print("WARNING: Time reference chosen was >"+time_Reference+"< but no TEC data is being imported for analysis. Switching to next avail time reference. Printing currently activated instruments:"); #print warning if time refernece won't exist
    for i in range(0,len(dataTypes)):
        print(dataTypes[i]+"\t"+str(FLG_dataTypes[i])); #report the data type and if it is on or not
    #END FOR i
    if( np.sum(FLG_dataTypes) != 0 ): #make sure at least one data type is on
        time_Reference = dataTypes[np.where(FLG_dataTypes == 1)[0][0]];
        print("Chose >"+time_Reference+"< as the new time reference.\n");
    else: #otherwise ditch it
        print("Looks like no data types are selected currently, so... Exiting.");
        # import sys #yolo
        sys.crash();
    #END IF
    data['time ref name'] = time_Reference; #record
#END IF
#Support for ISR time reference  
if( (time_Reference == 'ISR') & (FLG_dataTypes[FLG_ISRloc] == 0) ):
    print("WARNING: Time reference chosen was >"+time_Reference+"< but no ISR data is being imported for analysis. Switching to next avail time reference. Printing currently activated instruments:"); #print warning if time refernece won't exist
    for i in range(0,len(dataTypes)):
        print(dataTypes[i]+"\t"+str(FLG_dataTypes[i])); #report the data type and if it is on or not
    #END FOR i
    if( np.sum(FLG_dataTypes) != 0 ): #make sure at least one data type is on
        time_Reference = dataTypes[np.where(FLG_dataTypes == 1)[0][0]];
        print("Chose >"+time_Reference+"< as the new time reference.\n");
    else: #otherwise ditch it
        print("Looks like no data types are selected currently, so... Exiting.");
        # import sys #yolo
        sys.crash();
    #END IF
#END IF
#Support for AMPERE time reference  
if( (time_Reference == 'AMPERE') & (FLG_dataTypes[FLG_AMPEREloc] == 0) ):
    print("WARNING: Time reference chosen was >"+time_Reference+"< but no AMPERE data is being imported for analysis. Switching to next avail time reference. Printing currently activated instruments:"); #print warning if time refernece won't exist
    for i in range(0,len(dataTypes)):
        print(dataTypes[i]+"\t"+str(FLG_dataTypes[i])); #report the data type and if it is on or not
    #END FOR i
    if( np.sum(FLG_dataTypes) != 0 ): #make sure at least one data type is on
        time_Reference = dataTypes[np.where(FLG_dataTypes == 1)[0][0]];
        print("Chose >"+time_Reference+"< as the new time reference.\n");
    else: #otherwise ditch it
        print("Looks like no data types are selected currently, so... Exiting.");
        # import sys #yolo
        sys.crash();
    #END IF
#END IF
#Support for OMNI time reference  
if( (time_Reference == 'OMNI') & (FLG_dataTypes[FLG_OMNIloc] == 0) ):
    print("WARNING: Time reference chosen was >"+time_Reference+"< but no OMNI data is being imported for analysis. Switching to next avail time reference. Printing currently activated instruments:"); #print warning if time refernece won't exist
    for i in range(0,len(dataTypes)):
        print(dataTypes[i]+"\t"+str(FLG_dataTypes[i])); #report the data type and if it is on or not
    #END FOR i
    if( np.sum(FLG_dataTypes) != 0 ): #make sure at least one data type is on
        time_Reference = dataTypes[np.where(FLG_dataTypes == 1)[0][0]];
        print("Chose >"+time_Reference+"< as the new time reference.\n");
    else: #otherwise ditch it
        print("Looks like no data types are selected currently, so... Exiting.");
        # import sys #yolo
        sys.crash();
    #END IF
#END IF
#Support for Kp time reference  
if( (time_Reference == 'Kp') & (FLG_dataTypes[FLG_Kploc] == 0) ):
    print("WARNING: Time reference chosen was >"+time_Reference+"< but no Kp data is being imported for analysis. Switching to next avail time reference. Printing currently activated instruments:"); #print warning if time refernece won't exist
    for i in range(0,len(dataTypes)):
        print(dataTypes[i]+"\t"+str(FLG_dataTypes[i])); #report the data type and if it is on or not
    #END FOR i
    if( np.sum(FLG_dataTypes) != 0 ): #make sure at least one data type is on
        time_Reference = dataTypes[np.where(FLG_dataTypes == 1)[0][0]];
        print("Chose >"+time_Reference+"< as the new time reference.\n");
    else: #otherwise ditch it
        print("Looks like no data types are selected currently, so... Exiting.");
        # import sys #yolo
        sys.crash();
    #END IF
#END IF
#Support for Mag time reference  
if( (time_Reference == 'MagCAN') & (FLG_dataTypes[FLG_MagCANloc] == 0) ):
    print("WARNING: Time reference chosen was >"+time_Reference+"< but no Mag data is being imported for analysis. Switching to next avail time reference. Printing currently activated instruments:"); #print warning if time refernece won't exist
    for i in range(0,len(dataTypes)):
        print(dataTypes[i]+"\t"+str(FLG_dataTypes[i])); #report the data type and if it is on or not
    #END FOR i
    if( np.sum(FLG_dataTypes) != 0 ): #make sure at least one data type is on
        time_Reference = dataTypes[np.where(FLG_dataTypes == 1)[0][0]];
        print("Chose >"+time_Reference+"< as the new time reference.\n");
    else: #otherwise ditch it
        print("Looks like no data types are selected currently, so... Exiting.");
        # import sys #yolo
        sys.crash(); #crash it
    #END IF
#END IF


#plot help with autotick calculating
plotLongRange_autoTick = (np.max(plotLongRange) - np.min(plotLongRange))/25; #tries to split the longitude range into 25 parts (based off of 360/15+1)
if( plotLongRange_autoTick > 14 ):
    plotLongRange_autoTick = 30; #sets the tick setting to 15 arcdegrees per tick
elif( plotLongRange_autoTick > 10 ):
    plotLongRange_autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
elif( plotLongRange_autoTick > 5 ):
    plotLongRange_autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
elif( plotLongRange_autoTick > 2 ):
    plotLongRange_autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
elif( plotLongRange_autoTick > 1 ):
    plotLongRange_autoTick = 2; #sets the tick setting to 5 arcdegrees per tick
elif( plotLongRange_autoTick >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
    plotLongRange_autoTick = 1; #sets the tick setting to 1 arcdegree per tick
else:
    plotLongRange_autoTick = (np.max(plotLongRange) - np.min(plotLongRange))/15; #just goes for it if it's a super tiny range
#END IF
plotLongRange_autoTick_Crunched = (np.max(plotLongRange) - np.min(plotLongRange))/13; #tries to split the longitude range into 25 parts (based off of 360/15+1)
if( plotLongRange_autoTick_Crunched > 10 ):
    plotLongRange_autoTick_Crunched = 15; #sets the tick setting to 15 arcdegrees per tick
elif( plotLongRange_autoTick_Crunched > 5 ):
    plotLongRange_autoTick_Crunched = 10; #sets the tick setting to 10 arcdegrees per tick
elif( plotLongRange_autoTick_Crunched > 2 ):
    plotLongRange_autoTick_Crunched = 5; #sets the tick setting to 5 arcdegrees per tick
elif( plotLongRange_autoTick_Crunched > 1 ):
    plotLongRange_autoTick_Crunched = 2; #sets the tick setting to 5 arcdegrees per tick
elif( plotLongRange_autoTick_Crunched >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
    plotLongRange_autoTick_Crunched = 1; #sets the tick setting to 1 arcdegree per tick
else:
    plotLongRange_autoTick_Crunched = (np.max(plotLongRange) - np.min(plotLongRange))/13; #just goes for it if it's a super tiny range
#END IF
plotLatRange_autoTick = (np.max(plotLatRange) - np.min(plotLatRange))/13; #tries to split the latitude range into 13 parts (based off of 180/15+1)
if( plotLatRange_autoTick > 10 ):
    plotLatRange_autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
elif( plotLatRange_autoTick > 5 ):
    plotLatRange_autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
elif( plotLatRange_autoTick > 2 ):
    plotLatRange_autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
elif( plotLatRange_autoTick > 1 ):
    plotLatRange_autoTick = 2; #sets the tick setting to 2 arcdegrees per tick
elif( plotLatRange_autoTick > 0.75 ): #0.75 because 10/13 = 0.76something and it sounded good for enough 1 arcdeg ticks
    plotLatRange_autoTick = 1; #sets the tick setting to 1 arcdegree per tick
else:
    plotLatRange_autoTick = (np.max(plotLatRange) - np.min(plotLatRange))/13; #just goes for it if it's a super tiny range
#END IF
plotLatRange_autoTick_Crunched = (np.max(plotLatRange) - np.min(plotLatRange))/7; #tries to split the latitude range into 7 parts (based off of seems only 7 fits on a 2 subplot plot)
if( plotLatRange_autoTick_Crunched > 10 ):
    plotLatRange_autoTick_Crunched = 15; #sets the tick setting to 15 arcdegrees per tick
elif( plotLatRange_autoTick_Crunched > 5 ):
    plotLatRange_autoTick_Crunched = 10; #sets the tick setting to 10 arcdegrees per tick
elif( plotLatRange_autoTick_Crunched > 2 ):
    plotLatRange_autoTick_Crunched = 5; #sets the tick setting to 5 arcdegrees per tick
elif( plotLatRange_autoTick_Crunched > 1 ):
    plotLatRange_autoTick_Crunched = 2; #sets the tick setting to 2 arcdegrees per tick
elif( plotLatRange_autoTick_Crunched > 0.75 ): #0.75 because 10/13 = 0.76something and it sounded good for enough 1 arcdeg ticks
    plotLatRange_autoTick_Crunched = 1; #sets the tick setting to 1 arcdegree per tick
else:
    plotLatRange_autoTick_Crunched = (np.max(plotLatRange) - np.min(plotLatRange))/7; #just goes for it if it's a super tiny range
#END 
#--- For fancy plot, calculate new vars because the ratio is different ---
plotLatRange_autoTick_fancy = (np.max(plotLatRange) - np.min(plotLatRange))/17; #tries to split the latitude range into 13 parts (based off of 180/15+1)
if( plotLatRange_autoTick_fancy > 10 ):
    plotLatRange_autoTick_fancy = 15; #sets the tick setting to 15 arcdegrees per tick
elif( plotLatRange_autoTick_fancy > 5 ):
    plotLatRange_autoTick_fancy = 10; #sets the tick setting to 10 arcdegrees per tick
elif( plotLatRange_autoTick_fancy > 2 ):
    plotLatRange_autoTick_fancy = 5; #sets the tick setting to 5 arcdegrees per tick
elif( plotLatRange_autoTick_fancy > 1 ):
    plotLatRange_autoTick_fancy = 2; #sets the tick setting to 2 arcdegrees per tick
elif( plotLatRange_autoTick_fancy > 0.75 ): #0.75 because 10/13 = 0.76something and it sounded good for enough 1 arcdeg ticks
    plotLatRange_autoTick_fancy = 1; #sets the tick setting to 1 arcdegree per tick
else:
    plotLatRange_autoTick_fancy = (np.max(plotLatRange) - np.min(plotLatRange))/17; #just goes for it if it's a super tiny range
#END IF
plotLongRange_autoTick_fancy = (np.max(plotLongRange) - np.min(plotLongRange))/13; #tries to split the longitude range into 25 parts (based off of 360/15+1)
if( plotLongRange_autoTick_fancy > 25 ):
    plotLongRange_autoTick_fancy = 30; #sets the tick setting to 15 arcdegrees per tick
elif( plotLongRange_autoTick_fancy > 10 ):
    plotLongRange_autoTick_fancy = 15; #sets the tick setting to 15 arcdegrees per tick
elif( plotLongRange_autoTick_fancy > 5 ):
    plotLongRange_autoTick_fancy = 10; #sets the tick setting to 10 arcdegrees per tick
elif( plotLongRange_autoTick_fancy > 2 ):
    plotLongRange_autoTick_fancy = 5; #sets the tick setting to 5 arcdegrees per tick
elif( plotLongRange_autoTick_fancy > 1 ):
    plotLongRange_autoTick_fancy = 2; #sets the tick setting to 5 arcdegrees per tick
elif( plotLongRange_autoTick_fancy >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
    plotLongRange_autoTick_fancy = 1; #sets the tick setting to 1 arcdegree per tick
else:
    plotLongRange_autoTick_fancy = (np.max(plotLongRange) - np.min(plotLongRange))/13; #just goes for it if it's a super tiny range
#END IF

settings_map['lat autotick'] = plotLatRange_autoTick; #set them in the settings
settings_map['long autotick'] = plotLongRange_autoTick;
settings_map['lat autotick crunched'] = plotLatRange_autoTick_Crunched;
settings_map['long autotick crunched'] = plotLongRange_autoTick_Crunched;
settings_map['lat autotick fancy'] = plotLatRange_autoTick_fancy;
settings_map['long autotick fancy'] = plotLongRange_autoTick_fancy;

if( geoMap_projectionStyle == 'mill' ):
    settings_map['projection'] = cartopy.crs.PlateCarree(); #set the projection type to use, PlateCarree is like mill but distorts pole areas a bit less so
    settings_map['projection name'] = 'mill';
elif( geoMap_projectionStyle == 'robin' ):
    settings_map['projection'] = cartopy.crs.Robinson(); #set the projection type to use
    settings_map['projection name'] = 'robin';
elif( geoMap_projectionStyle == 'stere' ):
    settings_map['projection'] = cartopy.crs.Stereographic(); #set the projection type to use 
    settings_map['projection name'] = 'stere';
elif( geoMap_projectionStyle == 'npstere' ):
    settings_map['projection'] = cartopy.crs.NorthPolarStereo(); #set the projection type to use
    settings_map['projection name'] = 'npstere';
else:
    print('ERROR: geoMap_projectionStyle '+geoMap_projectionStyle+' not supported. Crashing, add the support. It needs to be cartopy.');
    sys.crash();
#END IF

#==============Declare Hemisphere Used (for AMPERE mostly)==============
if( (np.max(plotLatRange) <= 0) ):
    settings_map['hemi'] = 'south';
else:
    settings_map['hemi'] = 'north';
#END IF

#==============Set up the mega dicts that hold all the stuff==============
settings_plot = {
    'font smol':FONT_smol,
    'font smol FM':FONT_smolFM,
    'font axis tick':FONT_axisTick,
    'font axis tick FM':FONT_axisTickFM,
    'font axis label':FONT_axisLabel,
    'font axis label FM':FONT_axisLabelFM,
    'font title':FONT_title,
    'font title FM':FONT_titleFM,
    'font grandiose':FONT_grandiose,
    'font grandiose FM':FONT_grandioseFM,
    'line width':PLOT_lineWidth,
    'color':PLOT_color,
    'color default':['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'], #for using the default color cycle
    'line style':PLOT_lineStyle,
    'fancy plot':FLG_fancyPlot,
    'journal width 1C':journal_width_1C,
    'journal width 2C':journal_width_2C,
    'journal height max':journal_height_max,
    'journal dpi':journal_dpi,
    'save file type':plot_fileType,
    'unit L':plot_unitBracket_L,
    'unit R':plot_unitBracket_R,
    }; #plot settings

settings['paths'] = settings_paths; #path settings
settings['spectra'] = settings_spectra; #spectra settings
# settings['map'] = settings_map; #map settings
settings['plot'] = settings_plot; #plot settings
settings['TEC'] = settings_TEC; #incorporate the TEC settings
settings['TEC import'] = settings_TEC_import; #incorporate the TEC import settings
settings['movie'] = settings_movie; #incorporate movie settings

dates = {
    'date range':dateRange, #this is the start and end dates in YR/M/D
    'date range dayNum':dateRange_dayNum, #start and end dates in YR/DNum
    'date range full':dateRange_full, #full date range between the start and end dates in YR/M/D
    'date range full dayNum':dateRange_dayNum_full, #full date range between the start and end dates in YR/DNum
    'date range zero hr':dateRange_zeroHr, #the date that is set to be the 0 hr for plotting in YR/M/D
    'date range zero hr dayNum':dateRange_dayNum_zeroHr, #the date that is set to be the 0 hr for plotting in YR/DNum
    'date range zero hr month name':dateRange_zeroHr_monthName, #gets you the month name in real words
    'date range zero hr day post fix':dateRange_zeroHr_dayPostfix, #gets that good -st or -nd or -rd or -th to make words look nice
    'date range zero hr hour offset':dateRange_zeroHr_hrOffset, #the hour offset applied to get the 0 hour shited from the start of the data
    'date range zero hr hour bounds':dateRange_zeroHr_hrBounds, #the start and end dates in hours centered around the 0 hour
    'date range zero hr hours':dateRange_zeroHr_hrs, #the hour of each day change over
    'date range full padded':dateRange_full_adj, #padded both sides for any data that needs to slide
    'date range full padded dayNum':dateRange_dayNum_full_adj,
    }; 

#==============Convert things to geomagnetic coordinates if req'd==============
if( settings_map['coord type'] == 'mag' ):
    alt4mag = 325.;
    time4mag = datetime.datetime(dates['date range zero hr'][0],dates['date range zero hr'][1],dates['date range zero hr'][2]); #date time object for aacgmv2    
    [latMillstone, longMillstone, _] = aacgmv2.convert_latlon_arr(latMillstone, longMillstone, alt4mag, time4mag, method_code='G2A'); #converts from geographic to geomagnetic (AACGMv2)
    [latMillstoneMISA, longMillstoneMISA, _] = aacgmv2.convert_latlon_arr(latMillstoneMISA, longMillstoneMISA, alt4mag, time4mag, method_code='G2A'); #converts from geographic to geomagnetic (AACGMv2)
    for i in range(0,len(latLong_ref)):
        [lat_temp, long_temp, _] = aacgmv2.convert_latlon_arr(latLong_ref[i][0], latLong_ref[i][1], alt4mag, time4mag, method_code='G2A'); #converts from geographic to geomagnetic (AACGMv2)
        latLong_ref[i] = [lat_temp.item(), long_temp.item()]; #load it up
    #END FOR i
    for i in range(0,len(avgPt_coords)): #just in case different sizes, shouldn't be but never know
        [lat_temp, long_temp, _] = aacgmv2.convert_latlon_arr(avgPt_coords[i][0], avgPt_coords[i][1], alt4mag, time4mag, method_code='G2A'); #converts from geographic to geomagnetic (AACGMv2)
        avgPt_coords[i] = [lat_temp.item(), long_temp.item()]; #load it up
    #END FOR i
    settings_map['site coords'] = avgPt_coords; #set newly adjusted coords
#END IF
settings['map'] = settings_map; #map settings

#==============Import needed data sets==============
print('Data Import Beginning:');
tic = time.time();
#-----Import delta-vTEC-----
data, settings = GRITI_import_TEC_importer(data, dates, settings); # The multi-stage import process is jammed in a function (to support justChecking memory saving)
# unpack some things
if( 'justChecking' not in data['TEC'] ):
    TEC_timeUnique = data['TEC']['time unique']; #alias
    TEC_timeUniqueAligned = data['TEC']['time unique aligned']; #alias
    TEC_dataRate = data['TEC']['data rate']; #alias
else:
    TEC_timeUnique = 'justChecking'; #no time here
#END IF

# if( not 'TEC' in list(data.keys()) ):
#         #~~~IMPORT PRE-PROCESSED DATA~~~
#     if( np.any(np.asarray(FLG_TEC_use) == 0) | np.any(np.asarray(FLG_TEC_use) == 1) ):
#         if( FLG_dataTypes[FLG_TECloc] == 1):
#             print("Importing TEC");
#             # (TEC_int, TEC_float, TEC_str, FLG_dataTypes[FLG_TECloc]) = \
#             (data['TEC'], FLG_dataTypes[FLG_TECloc]) = \
#                 GRITI_import_TEC_otherSources(dateRange_dayNum_full,dateRange_dayNum_zeroHr,settings_paths,plotLatRange_importer,plotLongRange_importer, \
#                     TEC_dataRate=settings_TEC_import['TEC_dataRate'],TEC_minimumTimeGap=settings_TEC_import['TEC_minimumTimeGap'],
#                     TEC_timeTolerance=settings_TEC_import['TEC_timeTolerance']); #import pre-processed TEC data from other sources
#         #END IF
#     #END IF
#         #~~~IMPORT MADRIGAL DATA~~~
#     if( np.any(np.asarray(FLG_TEC_use) == 0) | np.any(np.asarray(FLG_TEC_use) == 2) ):    
#         if( ((FLG_dataTypes[FLG_TECloc] == 2) | np.any(np.asarray(FLG_TEC_use) == 2)) & (FLG_dataTypes[FLG_TECloc] != 0) ):
            
#             data['TEC'] = GRITI_import_TEC_Madrigal( dates, settings, FLG_justChecking=settings_TEC['justChecking'] ); #import TEC data for the date range
#             if( 'justChecking' not in data['TEC'] ):
#                 TEC_dataRate = data['TEC']['data rate']; #record the data rate for functions and stuff
#             #END IF
            
#         #END IF    
#     #END IF
#         #~~~IMPORT LISN DATA~~~
#     if( np.any(np.asarray(FLG_TEC_use) == 0) | np.any(np.asarray(FLG_TEC_use) == 3) ):    
#         if( FLG_dataTypes[FLG_TECloc] >= 1 ):
#             TEC_dataTemp = GRITI_import_TEC_LISN( dates, settings, FLG_justChecking=settings_TEC['justChecking'] ); #import TEC data for the date range
                                
#             if( 'justChecking' not in data['TEC'] ):
#                 keyz_new = list(TEC_dataTemp.keys()); #get the keys
#                 if( 'TEC' in list(data.keys()) ):
#                     tic_LISN = time.time(); #time it
#                     print('\nCombining LISN and current data together.');
#                     keyz_curr = list(data['TEC'].keys()); #get the keys
#                     TECcurr_site_unique, TECcurr_site_unique_indexes = np.unique(data['TEC']['site'] , return_inverse=True); #get unique site names and the indexes to speed up searching for where to look
#                     #inspired by https://stackoverflow.com/questions/33281957/faster-alternative-to-numpy-where
#                     TECcurr_site_unique_currentSiteArray = np.split(np.argsort(data['TEC']['site'], kind='mergesort'), np.cumsum(np.bincount(TECcurr_site_unique_indexes)[:-1])); #count how many indexes, cumulative sum, assign to sorted index as we go
#                     TECtemp_site_unique, TECtemp_site_unique_indexes = np.unique(TEC_dataTemp['site'] , return_inverse=True); #get unique site names and the indexes to speed up searching for where to look
#                     #inspired by https://stackoverflow.com/questions/33281957/faster-alternative-to-numpy-where
#                     TECtemp_site_unique_currentSiteArray = np.split(np.argsort(TEC_dataTemp['site'], kind='mergesort'), np.cumsum(np.bincount(TECtemp_site_unique_indexes)[:-1])); #count how many indexes, cumulative sum, assign to sorted index as we go
#                     TECtemp_site_isIn = np.isin(TECtemp_site_unique,TECcurr_site_unique); #precalc if it is in b/c ez
#                     TECtemp_site_maskr = np.ones(TEC_dataTemp['site'].size,dtype=np.bool_); #preallocate
#                     for j in range(0,TECtemp_site_unique.size):
#                         if( TECtemp_site_isIn[j] ): #use the isin mask (default mask value is true, so just need to do work if site is in)
#                             TECcurr_site_loc = TECcurr_site_unique_currentSiteArray[np.where(TECtemp_site_unique[j] == TECcurr_site_unique)[0].item()]; #pull it out of the pre-calc'd list of data locations for 1 site
#                             TECtemp_site_loc = TECtemp_site_unique_currentSiteArray[j]; #pull it out of the pre-calc'd list of data locations for 1 site
#                             if( TECcurr_site_loc.size == TECtemp_site_loc.size ):
#                                 TECtemp_site_maskr[TECtemp_site_loc] = False; #don't keep it b/c data is already all there
#                             else:
#                                 #otherwise check each row in the temp data to see if it is duplicated in the current data - if duplicated do not keep
#                                 #deep Q is of course how can 1 site have 2 completely different measurement lat/long at the same time in 2 diff repos - but for another day (maybe site names reused but diff actual sites??)
#                                 # TECtemp_isin = isin_row(np.vstack((TEC_dataTemp['lat'][TECtemp_site_loc],TEC_dataTemp['long'][TECtemp_site_loc],TEC_dataTemp['time'][TECtemp_site_loc])).T, np.vstack((data['TEC']['lat'][TECcurr_site_loc],data['TEC']['long'][TECcurr_site_loc],data['TEC']['time'][TECcurr_site_loc])).T); #check row-wise if temp data is in current data - keep anything that's not duplicated (the most permissive mode)
#                                 #moved to sat/satType/time instead of lat/long/time b/c assumed ionosphere altitude can differ lat/long but theoretically only 1 measurement for sat/satType/time/site should occur
#                                 TECtemp_isin = isin_row(np.vstack((TEC_dataTemp['sat'][TECtemp_site_loc],satConv_toInt_fromStr(TEC_dataTemp['satType'][TECtemp_site_loc]),TEC_dataTemp['time'][TECtemp_site_loc])).T, np.vstack((data['TEC']['sat'][TECcurr_site_loc],satConv_toInt_fromStr(data['TEC']['satType'][TECcurr_site_loc]),data['TEC']['time'][TECcurr_site_loc])).T); #check row-wise if temp data is in current data - keep anything that's not duplicated (the most permissive mode)
#                                 TECtemp_site_maskr[TECtemp_site_loc[TECtemp_isin]] = False; #don't keep it b/c data is already all there
#                             #END IF
#                         #END IF
#                     #END FOR j
#                     #now load in the temp data into the main array w/ the mask array
#                     for j in range(0,len(keyz_new)):
#                         if( keyz_new[j] in keyz_curr ):
#                             if( isinstance(data['TEC'][keyz_new[j]],(np.ndarray)) ):
#                                 data['TEC'][keyz_new[j]] = np.hstack( (data['TEC'][keyz_new[j]], TEC_dataTemp[keyz_new[j]][TECtemp_site_maskr]) ); #smack them together
#                             elif( isinstance(data['TEC'][keyz_new[j]],(list)) ):
#                                 if( TECtemp_site_maskr.size == TECtemp_site_maskr.sum() ):
#                                     data['TEC'][keyz_new[j]] += TEC_dataTemp[keyz_new[j]]; #append if list
#                                 else:
#                                     data['TEC'][keyz_new[j]] += [b for a, b in zip(TECtemp_site_maskr.tolist(), TEC_dataTemp[keyz_new[j]]) if a]; #append the data to keep w/ some list shennanigans to use the bool array
#                                 #END IF
#                             elif( np.isscalar(data['TEC'][keyz_new[j]]) ):
#                                 if( data['TEC'][keyz_new[j]] != TEC_dataTemp[keyz_new[j]]):
#                                     print('WARNING: TEC scalar numbers don\'t match but not a big deal, deal with this later\n'+\
#                                           'Orig: '+str(data['TEC'][keyz_new[j]])+'\t New: '+str(TEC_dataTemp[keyz_new[j]])); #tell it's not quite right
#                                 #END IF
#                             #END IF
#                         else:
#                             data['TEC'][keyz_new[j]] = TEC_dataTemp[keyz_new[j]]; #new addition
#                             keyz_curr = list(data['TEC'].keys()); #get the keys again
#                         #END IF
#                     #END FOR j
#                     print('Combining LISN and current data together took '+textNice(np.round(time.time()-tic_LISN,2))+' sec.');
#                 else:
#                     data['TEC'] = {}; #prep it as a dict sicne it doesn't exist
#                     for j in range(0,len(keyz_new)):
#                         data['TEC'][keyz_new[j]] = TEC_dataTemp[keyz_new[j]]; #create the dict
#                     #END FOR j
#                 #END IF
#             else:
#                 keyz_new = list(TEC_dataTemp.keys()); #get the keys
#                 if( 'TEC' not in list(data.keys()) ):
#                     data['TEC'] = {}; #prep it as a dict sicne it doesn't exist
#                     for j in range(0,len(keyz_new)):
#                         data['TEC'][keyz_new[j]] = TEC_dataTemp[keyz_new[j]]; #create the dict
#                     #END FOR j
#                 #END IF
#             #END IF
#             del TEC_dataTemp
#             gc.collect(); #clean the garbage
#         #END IF
#     #END IF
    
#     if( 'justChecking' not in data['TEC'] ):
#         if( FLG_dataTypes[FLG_TECloc] >= 1 ):
#             # TEC_timeUnique = np.unique(data['TEC']['time']); #days, get unique times (v useful)
#             tic = time.time()
#             data['TEC']['time unique'] = np.unique(data['TEC']['time']); #sec, get unique times (v useful)
#             TEC_timeUnique = data['TEC']['time unique']; #sec set it for reuse in main
#             data['TEC']['time unique aligned'] = np.unique(data['TEC']['time aligned']); #sec, get unique times (v useful) [aligned has year support and is set around the defined 0 hour]
#             TEC_timeUniqueAligned = data['TEC']['time unique aligned']; #sec set it for reuse in main
#             print('Time to unique: '+str(time.time()-tic))
#         #END IF
            
#         if( (FLG_TEC_noise >= 1) & (FLG_dataTypes[FLG_TECloc] >= 1) ): #replace the delta-vTEC data with random data OR random data with synth waves embedded
#             data['TEC']['dTEC'] = GRITI_TEC_randomSynth(data['TEC']['dTEC'].size,data['TEC']['lat'],data['TEC']['long'],data['TEC']['time'], \
#                 noise_background_mean,noise_background_stdev,Re,dateRange_zeroHr, \
#                 plotLatRange,plotLongRange,plotLatRange_autoTick,plotLongRange_autoTick, \
#                 wave_latRange,wave_longRange,wave_N,wave_angle,wave_phase,wave_waveLength,wave_period,wave_amp, \
#                 FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,TEC_plotLimValu,FLG_TEC_noise,FLG_plotStuff=1); #replace the delta-vTEC data with random data OR random data with synth waves embedded
#         #END IF
#     #END IF
# else:
#     print('Importing TEC\nTEC data still in memory from previous run. No import needed.\n');
# #END IF
# if( FLG_dataTypes[FLG_TECloc] >= 1 ):
#     if( 'justChecking' not in data['TEC'] ):
#         if( np.all(np.asarray(data['TEC']['version']) == data['TEC']['version'][0]) ):
#             settings_TEC['version'] = data['TEC']['version'][0]; #settings['TEC'] will update with these automagically since mem is shared
#             settings_TEC['keo']['version'] = data['TEC']['version'][0];
#         else:
#             print('ERROR in MAIN: TEC Data Versions ('+str(data['TEC']['version'])+') are not all the same, write some code to deal with this');
#             sys.crash();
#         #END IF
#         if( np.all(np.asarray(data['TEC']['pierceAlt']) == data['TEC']['pierceAlt'][0]) ):
#             settings_TEC['pierceAlt'] = data['TEC']['pierceAlt'][0]; #settings['TEC'] will update with these automagically since mem is shared
#             settings_TEC['keo']['pierceAlt'] = data['TEC']['pierceAlt'][0];
#         else:
#             print('ERROR in MAIN: TEC Data Versions ('+str(data['TEC']['pierceAlt'])+') are not all the same, write some code to deal with this');
#             sys.crash();
#         #END IF
#     #END IF
# #END IF

#-----TEC delta-vTEC File Layout-----
    #Integer Layout
    #0 = Satellite ID [# that corresponds to GPS sat]
    #1 = Year timestamp [years]
    
    #Float Layout
    #0 = delta-vTEC [TECU]
    #1 = current time in day format [days] - does not support years
    #2 = geodedic latitude [arcdeg]
    #3 = longitude [arcdeg]
    #4 = elevation [deg]
    
    #String Layout
    #[] = Receiver Site Name (there's no dim on this one) - use .decode('UTF-8') to make it a string again

#-----Import ISR Data-----
if( FLG_dataTypes[FLG_ISRloc] == 1):
    print("Importing ISR");
    (ISR_Mill_lat, ISR_Mill_long, Zenith_SNR, Zenith_SNR_hp, Zenith_POPL, Zenith_POPL_hp, Zenith_height, Zenith_time, \
     Zenith_vel, Zenith_vel_hp, Zenith_el, Zenith_az, Zenith_dopplar, Zenith_filtHeight, MISA_SNR, MISA_SNR_hp, MISA_POPL, MISA_POPL_hp, MISA_height, \
     MISA_time, MISA_vel,  MISA_vel_hp, MISA_el, MISA_az, MISA_dopplar, MISA_filtHeight) = \
         GRITI_import_ISR_Haystack(dateRange_dayNum_full,folder,dateRange_dayNum_zeroHr,pointAltitude,filter_cutoffPeriod=settings_spectra['filter cutoff period']); #import ISR data, process if need-be
    if( ISR_zenithMISA == 0):
        ISR_timeUnique = np.unique(Zenith_time); #days, get unique times (v useful)
    else:
        ISR_timeUnique = np.unique(MISA_time); #days, get unique times (v useful)
    #END IF
    
    (ISR_PFISR_lat, ISR_PFISR_long, PFISR_SNR, PFISR_SNR_hp, PFISR_POPL, PFISR_POPL_hp, PFISR_height, PFISR_time, PFISR_vel, PFISR_el, PFISR_az, PFISR_dopplar, PFISR_filtHeight) = \
        GRITI_import_ISR_Pokerflat(dateRange_dayNum_full,folder,dateRange_dayNum_zeroHr,pointAltitude,filter_cutoffPeriod = settings_spectra['filter cutoff period'])
#END IF

#-----Import AMPERE Data-----  
if( FLG_dataTypes[FLG_AMPEREloc] == 1):
    print("Importing AMPERE");
    settings['AMPERE']['padded'] = time_Reference != 'AMPERE'; #precalc it
    
    # data['AMPERE'], data['AMPERE'] = GRITI_import_AMPERE_preprepared(dateRange_dayNum_full,settings_paths,dateRange_dayNum_zeroHr,locAMPERE_jouleHeating,AMPERE_plotLimValu); #import pre-processed AMPERE data
    # AMPERE_timeUnique = np.unique(data['AMPERE'][:,5]); #days, get unique times (v useful)
    # data['AMPERE']['time unique'] =  np.unique(data['AMPERE']['time']); #days, get unique times (v useful)
    # data['AMPERE']['data rate'] = np.int64(np.round(np.median(np.diff(AMPERE_timeUnique)*24*60)))*60; #sec, gets the data rate
    # try:
    data['AMPERE'] = GRITI_import_AMPERE(dates,settings['paths'],settings_map['hemi'],settings['config'],
                                         AMPERE_coordType=coordType,AMPERE_desired_latLongSteps=settings['AMPERE']['lat long steps'],
                                         FLG_paddedDays=settings['AMPERE']['padded'],FLG_dataMix=1,FLG_dataPreference=0,FLG_float64=0); #import pre-processed AMPERE data
    # except:
    #     print('Preprepared AMPERE failed, trying generic AMPERE (will work if data type requested is part of the direct AMPERE dataset, mostly just field-aligned current).');
    #     from Code.GRITI_import_AMPERE_direct import GRITI_import_AMPERE_direct as GRITI_import_AMPERE
    #     data['AMPERE'] = GRITI_import_AMPERE(dates,settings_paths,dateRange_dayNum_full_adj,settings_map['hemi'],AMPERE_coordType=coordType,FLG_dataMix=1,FLG_dataPreference=0,FLG_float64=0); #import pre-processed AMPERE data
    # #END TRY
    # data['AMPERE']['time unique'] =  np.unique(data['AMPERE']['time']); #sec, get unique times (v useful)
    AMPERE_timeUnique = data['AMPERE']['time unique']; #sec, set to be the same thing
    
    #adds 
    # data['AMPERE']['FAC +'] = np.copy(data['AMPERE']['FAC']); #copy it over
    # data['AMPERE']['FAC +'][data['AMPERE']['FAC'] < 0] = np.nan; #nan stuff that's negative
    # data['AMPERE']['FAC -'] = np.copy(data['AMPERE']['FAC']); #copy it over
    # data['AMPERE']['FAC -'][data['AMPERE']['FAC'] > 0] = np.nan; #nan stuff that's positive
    # with h5py.File(settings_paths['data'] + '\\' + folder_AMPERE + '\\' + str(dateRange_full[i,0]) + '\\' + AMPERE_fileName, 'r') as AMPERE_file:
    if( FLG_AMPERE_integrate == True ):
        #only integrate if needed
        AMPERE_integrated = GRITI_AMPERE_integrator(data['AMPERE'], dates, settings['AMPERE'], plotLatRange, plotLongRange, AMPERE_integrateMethod, AMPERE_integrateMethod_val, 
                                    AMPERE_integrateMethod_coordType=AMPERE_integrateMethod_coordType, AMPERE_integrateMethod_coordType_global=settings['map']['coord type'], GRITI_import_AMPERE=GRITI_import_AMPERE, AMPERE_desired_latLongSteps=settings['AMPERE']['lat long steps'],
                                    AMPERE_import_AMPERE_hemi=settings['map']['hemi'], settings_config=settings['config'], settings_paths=settings['paths'],
                                    AMPERE_integrateMethod_log=AMPERE_integrateMethod_log, AMPERE_integrateMethod_radiusLoc=AMPERE_integrateMethod_radiusNloc[1], AMPERE_integrateMethod_radius=AMPERE_integrateMethod_radiusNloc[0]);
        data['AMPERE']['integrated'] = AMPERE_integrated; #alias
        settings['AMPERE']['labels']['integrated'] = settings['AMPERE']['labels'][settings['AMPERE']['data type']]; #alias (makes certain codes easier)
        settings['AMPERE']['units']['integrated'] = settings['AMPERE']['units'][settings['AMPERE']['data type']]; #alias (makes certain codes easier)
    #END IF
    if( (FLG_AMPERE_keo == 1) & ( \
            ((settings_AMPERE['keo']['keo coord type'] == 'geo') & (settings['map']['coord type'] == 'mag')) | \
            ((settings_AMPERE['keo']['keo coord type'] == 'mag') & (settings['map']['coord type'] == 'geo'))) ):
        data['AMPERE keo input'] = GRITI_import_AMPERE(dates,settings['paths'],settings_map['hemi'],settings['config'],
                                             AMPERE_coordType=settings_AMPERE['keo']['keo coord type'],AMPERE_desired_latLongSteps=settings['AMPERE']['lat long steps'],
                                             FLG_paddedDays=settings['AMPERE']['padded'],FLG_dataMix=1,FLG_dataPreference=0,FLG_float64=0); #import pre-processed AMPERE data
    else:
        data['AMPERE keo input'] = data['AMPERE']; #alias
    #END IF

#    data['AMPERE'][:,AMPERE_plot_index] = np.log(data['AMPERE'][:,AMPERE_plot_index]); #take the log to reduce the dynamic range
#END IF
#-----AMPERE File Layout-----
    #Float 32 layout
    #0 = Pedersen Conductance [?]
    #1 = Hall Conductance [?]
    #2 = Joule Heat [ergs/(cm^2*sec)]
    #3 = Electric Potential [?]
    #4 = Field-Algined Current [?]
    #5 = time [days] - does not support years 
    #6 = latitude [arcdeg]
    #7 = longitude [arcdeg]
    
#-----Import Kp Data-----  
if( FLG_dataTypes[FLG_Kploc] == 1):
    print("Importing Kp"); #now importing full padded days always
    # if( OMNI_delay_wrt_TEC > 0 ):
    #     dateRange_extraDaysForDelay = np.int64(np.ceil(OMNI_delay_wrt_TEC/24)); #get how many extra days are needed
    #     dateRange_dayNum_adj = np.copy(dateRange_dayNum); #copy it over
    #     dateRange_dayNum_adj[0,1] -= dateRange_extraDaysForDelay; #put this in
    #     #!! NO YEAR ROLL UNDER SUPPORT !!
    #     (_, dateRange_dayNum_full_adj) = subfun_dateORdayNum_to_fullRange(dateRange_dayNum_adj); #call fun to get fully enumerated days between range
    # else:
    #     dateRange_dayNum_full_adj = dateRange_dayNum_full.copy(); #keep it the same so code work
    # #END IF
    Kp_dataDict = GRITI_import_Kp(dates['date range full padded dayNum'], settings_paths['data']); #import Kp data from internet
    Kp_time = Kp_dataDict['time']
    Kp_data = Kp_dataDict['Kp']
    Kp_timeUnique = Kp_time; #days, same thing
    data['Kp'] = Kp_dataDict;
    data['Kp']['time unique'] = data['Kp']['time']; #same thing
#END IF
    #NOTE: Kp is every 3 hours, 0-3, 3-6, 6-9, 9-12, 12-15, 15-18, 18-21, 21-24 UT (8 of em) - assumed that data occurs on hour end (e.g. 0-3 means 3 is the data pt)
    
#-----Import OMNI Data-----  
if( FLG_dataTypes[FLG_OMNIloc] == 1):
    print("Importing OMNI");
    # if( OMNI_delay_wrt_TEC > 0 ): #now importing full padded days always
    #     dateRange_extraDaysForDelay = np.int64(np.ceil(OMNI_delay_wrt_TEC/24)); #get how many extra days are needed
    #     dateRange_dayNum_adj = np.copy(dateRange_dayNum); #copy it over
    #     dateRange_dayNum_adj[0,1] -= dateRange_extraDaysForDelay; #put this in
    #     #!! NO YEAR ROLL UNDER SUPPORT !!
    #     (_, dateRange_dayNum_full_adj) = subfun_dateORdayNum_to_fullRange(dateRange_dayNum_adj); #call fun to get fully enumerated days between range
    # else:
    #     dateRange_dayNum_full_adj = dateRange_dayNum_full.copy(); #keep it the same so code work
    # #END IF
    OMNI_data, OMNI_dict, OMNI_dictPlot = GRITI_import_OMNI(dates['date range full padded dayNum'], settings_paths); #import OMNI data from internet
    # OMNI_timeUnique = OMNI_data[:,OMNI_dict['Day Num']] + OMNI_data[:,OMNI_dict['Hour']]/24 + OMNI_data[:,OMNI_dict['Min']]/(1440); #days, get unique times (v useful) - unique times are implicit
    OMNI_timeUnique = np.int64(OMNI_data[:,OMNI_dict['Day Num']]*86400 + OMNI_data[:,OMNI_dict['Hour']]*3600 + OMNI_data[:,OMNI_dict['Min']]*60); #days, get unique times (v useful) - unique times are implicit
    #---make modern dict compliant---
    data['OMNI'] = {};
    settings_OMNI = {};
    settings_OMNI['data type'] = OMNI_plot_name; #just one
    settings_OMNI['data type for FFT'] = OMNI_plot_scargle_name; #just one
    settings_OMNI['set names'] = OMNI_plotSet_name; #many
    settings_OMNI['delay wrt TEC'] = OMNI_delay_wrt_TEC;
    settings_OMNI['delay wrt AMPERE'] = OMNI_delay_wrt_AMPERE;
    settings_OMNI['labels'] = {}; #also a dict
    settings_OMNI['units'] = {}; #also also a dict
    if( np.isclose(np.mod(np.median(np.diff(OMNI_timeUnique)),1),0) == True ):
        data['OMNI']['data rate'] = np.int64(np.median(np.diff(OMNI_timeUnique))); #sec, record OMNI data rate
    else:
        data['OMNI']['data rate'] = np.median(np.diff(OMNI_timeUnique)); #sec, record OMNI data rate
    #END IF
    data['OMNI']['time unique'] = OMNI_timeUnique;
    import copy
    OMNI_dict_keyz = list(OMNI_dict.keys()); #get the keys
    for j in range(0,len(OMNI_dict_keyz)):
        data['OMNI'][OMNI_dict_keyz[j]] = OMNI_data[:,OMNI_dict[OMNI_dict_keyz[j]]]; #pull out the data bit by bit (small so no matter its inefficient)
        label_full = OMNI_dictPlot[j]; #get full label
        label_split = label_full.find(' ['); #get where split is
        if( label_split > -1 ):
            label_just = label_full[:label_split]; #get just the label
            label_units = label_full[label_split:]; #get just hte units (w/ space)
        else:
            label_just = label_full; #get just the label
            label_units = ''; #no units
        #END IF
        settings_OMNI['labels'][OMNI_dict_keyz[j]] = copy.deepcopy(label_just); #get label
        settings_OMNI['units'][OMNI_dict_keyz[j]] = copy.deepcopy(label_units); #get units
    #END FOR j
    settings['OMNI'] = settings_OMNI;
#END IF
#-----OMNI File Layout-----
#Float 64 layout
#0 = year
#1 - day#
#2 = hr
#3 = min
#4 = Bz GSE (nT)
#5 = Flow speed (km/s)
#6 = Flow pressure (nPa)
#7 = AE Index (nT)
#8 = SYM/H Index (nT)

#-----Import SuperMAG Data-----  
if( FLG_dataTypes[FLG_SuperMAGloc] == 1):
    print("Importing SuperMAG Indices");
    # if( SuperMAG_delay_wrt_TEC > 0 ):
    #     dateRange_extraDaysForDelay = np.int64(np.ceil(SuperMAG_delay_wrt_TEC/24)); #get how many extra days are needed
    #     dateRange_dayNum_adj = np.copy(dateRange_dayNum); #copy it over
    #     dateRange_dayNum_adj[0,1] -= dateRange_extraDaysForDelay; #put this in
    #     #!! NO YEAR ROLL UNDER SUPPORT !!
    #     (_, dateRange_dayNum_full_adj) = subfun_dateORdayNum_to_fullRange(dateRange_dayNum_adj); #call fun to get fully enumerated days between range
    # else:
    #     dateRange_dayNum_full_adj = dateRange_dayNum_full.copy(); #keep it the same so code work
    # #END IF
    data['SuperMAG'] = GRITI_import_SuperMAG(dates['date range full padded dayNum'], settings['paths']); #import OMNI data from internet
#END IF

#-----Import SuperMAG stations Data-----  
if( FLG_dataTypes[FLG_SuperMAGstationsloc] == 1):
    print("Importing SuperMAG Stations");
    # if( SuperMAG_delay_wrt_TEC > 0 ):
    #     dateRange_extraDaysForDelay = np.int64(np.ceil(SuperMAG_delay_wrt_TEC/24)); #get how many extra days are needed
    #     dateRange_dayNum_adj = np.copy(dateRange_dayNum); #copy it over
    #     dateRange_dayNum_adj[0,1] -= dateRange_extraDaysForDelay; #put this in
    #     #!! NO YEAR ROLL UNDER SUPPORT !!
    #     (_, dateRange_dayNum_full_adj) = subfun_dateORdayNum_to_fullRange(dateRange_dayNum_adj); #call fun to get fully enumerated days between range
    # else:
    #     dateRange_dayNum_full_adj = dateRange_dayNum_full.copy(); #keep it the same so code work
    # #END IF
    data['SuperMAG stations'] = GRITI_import_SuperMAG_stations(dates['date range full padded dayNum'], SuperMAGstations_names, settings['paths']); #import SuperMAG station data from internet [per station, see https://supermag.jhuapl.edu/mag/ for station names]
#END IF


#-----Import Canadian Mag Data-----  
if( FLG_dataTypes[FLG_MagCANloc] >= 1):
    print("Importing Magnetometer Data");
    try:
        data['MagCAN'] = GRITI_import_Mag_NRCan(dates, settings, FLG_deleteRaw = 0, FLG_overwrite = 0); #import OMNI data from internet
        siteNames = data['MagCAN']['site names']; #get this var
        settings['MagCAN']['labels'] = {}; #prep label and unit holders (all the same, so automated)
        settings['MagCAN']['units'] = {};
        cntr = 0; #prep cntr
        cntrF = 0; #prep cntrF
        for j in range(0,len(siteNames)):
            cntr += data['MagCAN'][siteNames[j]]['mag'].shape[0]; #get the total size
            cntrF += data['MagCAN'][siteNames[j]]['magF'].size; #get the total size
            settings['MagCAN']['labels'][siteNames[j]] = siteNames[j]; #fill in some labels and units
            settings['MagCAN']['units'][siteNames[j]] = ' [nT]'; #fill in some labels and units
        #END FOR j
        Mag_time = np.zeros( cntr, dtype=np.int64); #preallocate
        Mag_timeF = np.zeros( cntrF, dtype=np.int64); #preallocate
        cntr = 0; #Prep cntr
        cntrF = 0; #prep cntrF
        for j in range(0,len(siteNames)):
            tempSize = data['MagCAN'][siteNames[j]]['mag'].shape[0]; #prep
            tempSizeF = data['MagCAN'][siteNames[j]]['magF'].size; #prep
            Mag_time[cntr:cntr+tempSize] = np.int64(data['MagCAN'][siteNames[j]]['dayNum'])*86400 + np.int64(data['MagCAN'][siteNames[j]]['sec']); #sec, get unique times (v useful)
            Mag_timeF[cntrF:cntrF+tempSizeF] = np.int64(data['MagCAN'][siteNames[j]]['dayNumF'])*86400 + np.int64(data['MagCAN'][siteNames[j]]['secF']); #sec, get unique times (v useful)
            cntr += tempSize; #increment
            cntrF += tempSizeF; #increment
        #END FOR j  
        data['MagCAN']['time unique'] = np.unique(Mag_time); #sec, get unique times (v useful)
        data['MagCAN']['data rate'] = np.median(np.diff(data['MagCAN']['time unique'])); #get the data rate
        data['MagCAN']['time unique F'] = np.unique(Mag_timeF); #sec, get unique times (v useful)
        data['MagCAN']['data rate F'] = np.median(np.diff(data['MagCAN']['time unique F'])); #get the data rate
        Mag_timeUnique = data['MagCAN']['time unique F']; #get this variable out
        data['MagCAN']['timeUniqueF_hr'] = (data['MagCAN']['time unique F'] - dates['date range zero hr dayNum'][1]*86400)/3600; #get this variable out
        data['MagCAN']['timeUnique_hr'] = (data['MagCAN']['time unique'] - dates['date range zero hr dayNum'][1]*86400)/3600; #get this variable out
       
        #now fill missing data with NaNs
        for j in range(0,len(siteNames)):
            if( data['MagCAN'][siteNames[j]]['mag'].shape[0] != data['MagCAN']['time unique'].size ):
                timeUnique_now = np.int64(data['MagCAN'][siteNames[j]]['dayNum'])*86400 + np.int64(data['MagCAN'][siteNames[j]]['sec']); #time unique now
                timeUnique_now_missing = np.in1d(data['MagCAN']['time unique'], timeUnique_now); #get the bits missing
                temp_mag = np.nan*np.empty( (data['MagCAN']['time unique'].size, 3), dtype=data['MagCAN'][siteNames[j]]['mag'].dtype); #make full sized array
                temp_mag[timeUnique_now_missing,:] = data['MagCAN'][siteNames[j]]['mag']; #jam em in
                data['MagCAN'][siteNames[j]]['mag'] = temp_mag; #overwrite now
                data['MagCAN'][siteNames[j]]['sec'] = np.mod(data['MagCAN']['time unique'] - dates['date range zero hr dayNum'][1]*86400,86400).astype(data['MagCAN'][siteNames[j]]['sec'].dtype); #now it is the same as time unique (minus the days)
                data['MagCAN'][siteNames[j]]['dayNum'] = np.int16(data['MagCAN']['time unique']/86400); #replicate the dayNum now that it's full too
            #END IF
            if( data['MagCAN'][siteNames[j]]['magF'].size != data['MagCAN']['time unique F'].size ):
                timeUnique_now = np.int64(data['MagCAN'][siteNames[j]]['dayNumF'])*86400 + np.int64(data['MagCAN'][siteNames[j]]['secF']); #time unique now
                timeUnique_now_missing = np.in1d(data['MagCAN']['time unique F'], timeUnique_now); #get the bits missing
                temp_mag = np.nan*np.empty( (data['MagCAN']['time unique F'].size), dtype=data['MagCAN'][siteNames[j]]['magF'].dtype); #make full sized array
                temp_mag[timeUnique_now_missing] = data['MagCAN'][siteNames[j]]['magF']; #jam em in
                data['MagCAN'][siteNames[j]]['magF'] = temp_mag; #overwrite now
                data['MagCAN'][siteNames[j]]['secF'] = np.mod(data['MagCAN']['time unique F'] - dates['date range zero hr dayNum'][1]*86400,86400).astype(data['MagCAN'][siteNames[j]]['secF'].dtype); #now it is the same as time unique (minus the days)
                data['MagCAN'][siteNames[j]]['dayNumF'] = np.int16(data['MagCAN']['time unique F']/86400); #replicate the dayNum now that it's full too
            #END IF
        #END FOR j
       
        #-----Get the plot lat/long ranges based on the site locations involved-----
        if( MagCAN_keo_setPlotRange == 0 ):
            siteLocs = np.zeros( (2, len(data['MagCAN']['site names'])) ); #preallocate
            for j in range(0,len(data['MagCAN']['site names'])):
                siteLocs[0,j] = data['MagCAN'][data['MagCAN']['site names'][j]]['lat'];
                siteLocs[1,j] = data['MagCAN'][data['MagCAN']['site names'][j]]['long'];
            #END FOR j
            
            Mag_plotLatRange = [np.min(siteLocs[0,:]), np.max(siteLocs[0,:])]; # get lat extent
            Mag_plotLongRange = [np.min(siteLocs[1,:]), np.max(siteLocs[1,:])]; # get long extent
            #Adjust these ranges as needed
            if( np.remainder(np.ceil(Mag_plotLatRange[1]),5) == 0 ):
                Mag_plotLatRange[1] = np.ceil(Mag_plotLatRange[1]) + 5; #keep up to a 5 degc lat boundary
            else:
                Mag_plotLatRange[1] = np.ceil(Mag_plotLatRange[1]) + (5-np.remainder(np.ceil(Mag_plotLatRange[1]),5)); #keep up to a 5 degc lat boundary
            #END IF
            if( np.remainder(np.floor(Mag_plotLatRange[0]),5) == 0 ):
                Mag_plotLatRange[0] = np.floor(Mag_plotLatRange[0]) - 5; #keep up to a 5 degc lat boundary
            else:
                Mag_plotLatRange[0] = np.floor(Mag_plotLatRange[0]) - np.remainder(np.floor(Mag_plotLatRange[0]),5); #keep up to a 5 degc lat boundary
            #END IF
            if( np.remainder(np.ceil(Mag_plotLongRange[1]),5) == 0 ):
                Mag_plotLongRange[1] = np.ceil(Mag_plotLongRange[1]) + 5; #keep up to a 5 degc lat boundary
            else:
                Mag_plotLongRange[1] = np.ceil(Mag_plotLongRange[1]) + (5-np.remainder(np.ceil(Mag_plotLongRange[1]),5)); #keep up to a 5 degc long boundary
            #END IF
            if( np.remainder(np.floor(Mag_plotLongRange[0]),5) == 0 ):
                Mag_plotLongRange[0] = np.floor(Mag_plotLongRange[0]) - 5; #keep up to a 5 degc lat boundary
            else:
                Mag_plotLongRange[0] = np.floor(Mag_plotLongRange[0]) - np.remainder(np.floor(Mag_plotLongRange[0]),5); #keep up to a 5 degc long boundary
            #END IF
            settings['MagCAN']['lat range'] = Mag_plotLatRange; #record Mag's custom lat range for when only Mag is in play
            settings['MagCAN']['long range'] = Mag_plotLongRange; #record Mag's custom long range for when only Mag is in play
        else:
            #otherwise, let user set the lat/long range at will
            settings['MagCAN']['lat range'] = MagCAN_keo_setPlotRange_range[0]; #arcdeg, set it by user
            settings['MagCAN']['long range'] = MagCAN_keo_setPlotRange_range[1]; #arcdeg, set it by user
        #END IF
    except Exception as errMsg:
        if( FLG_dataTypes[FLG_MagCANloc] == 3 ):
            print('WARNING in GRITI_import_Mag_NRCan: Failed to import but FLG_MagCANloc set to permissible that data is not there, so no prob!');
        else:
            print('ERROR in GRITI_import_Mag_NRCan or thereabouts:\n'+str(errMsg));
            sys.crash(); #crash out, it'll crash later since not permissible to miss it
        #END IF
    #END TRY
#END IF

#-----Set time reference to a variable - had to get that data first!----
if( (time_Reference == 'TEC') ):
    time_Ref = TEC_timeUnique; #set the time refernece by copying
elif( (time_Reference == 'ISR') ):
    time_Ref = ISR_timeUnique; #set the time refernece by copying
elif( (time_Reference == 'AMPERE') ):
    time_Ref = AMPERE_timeUnique; #set the time refernece by copying
elif( (time_Reference == 'OMNI') ):
    time_Ref = OMNI_timeUnique; #set the time refernece by copying
elif( (time_Reference == 'Kp') ): #Kp is a pretty awful time reference
    time_Ref = Kp_timeUnique; #set the time refernece by copying
elif( (time_Reference == 'SuperMAG') ):
    time_Ref = data['SuperMAG']['time unique']; #set the time refernece by copying
elif( (time_Reference == 'MagCAN') ):
    time_Ref = Mag_timeUnique; #set the time refernece by copying
elif( (time_Reference == 'MagSuperMAG') ):
    time_Ref = data['MagSuperMAG']['time unique']; #set the time refernece by copying
else:
    print("WARNING: Time reference chosen was >"+time_Reference+"< but that type data isn't supported. Correct this."); #print warning if time refernece won't exist
    print("Exiting.");
    import sys #yolo
    sys.crash(); #crash instead
#END IF
data['time ref'] = time_Ref; #record the data
settings['plot']['time ref'] = time_Reference; #name it

toc = time.time() - tic;
print("Data Import took: "+str(np.round(toc,2))+" sec / "+str(np.round(toc/60,2))+" min\n");


#==============Plot prep standardization variables==============
#-----Prep plot to show area being averaged-----
if( (np.round(np.min(plotLatRange)) < 0) & (geoMap_projectionStyle == 'npstere') ):
    print("WARNING: Plot projection style set to North Polar Stereographic ('npstere') but latitude range goes past the equator. Switching to Miller ('mill').");
    geoMap_projectionStyle = 'mill'; #switch to this because robin is only world plots
    settings_map['projection'] = cartopy.crs.PlateCarree(); #set the projection type to use
#END IF
if( (np.round(np.max(plotLatRange)) > 0) & (geoMap_projectionStyle == 'spstere') ):
    print("WARNING: Plot projection style set to South Polar Stereographic ('spstere') but latitude range goes past the equator. Switching to Miller ('mill').");
    geoMap_projectionStyle = 'mill'; #switch to this because robin is only world plots
    settings_map['projection'] = cartopy.crs.PlateCarree(); #set the projection type to use
#END IF

if( ((np.round(np.max(plotLongRange)) != 180) | (np.round(np.min(plotLongRange)) != -180) | \
   (np.round(np.max(plotLatRange)) != 90) | (np.round(np.min(plotLatRange)) != -90)) & (geoMap_projectionStyle == 'robin') ):
    print("WARNING: Plot projection style set to Robinson ('robin') but a non-global area is chosen. Switching to Miller ('mill').");
    geoMap_projectionStyle = 'mill'; #switch to this because robin is only world plots
    settings_map['projection'] = cartopy.crs.PlateCarree(); #set the projection type to use
#END IF

#fix for 'robin' plot having reduced room for longitude data points
if( geoMap_projectionStyle == 'robin' ):
    plotLongRange_autoTick = plotLongRange_autoTick*2; #double the tick spacing to account for smaller amount of space
#END IF
if( (geoMap_projectionStyle == 'npstere') | (geoMap_projectionStyle == 'spstere') ):
    keo_polarMode = 1; #force to 1 if polar plot styles were chosen
    if(geoMap_projectionStyle == 'npstere'):
        geoMap_projectionStyle_polar = 1; #simple flag to show north pole
    else:
        geoMap_projectionStyle_polar = 2; #simple flag to show south pole
    #END IF
else:
    geoMap_projectionStyle_polar = 0; #simple flag to show no polar is activated
#END IF

#****************************************************************TEC ANALYSIS****************************************************************
#!!!==============Analysis: Any Angle AVG (Keogram)==============!!!
if( (FLG_keo == 1) ):    
       
    if( 'justChecking' not in data['TEC'] ):
        #regular operation
        data['TEC']['keo'], settings['TEC']['keo'] = GRITI_keo_keogrammer( \
            data['TEC']['dTEC'] ,data['TEC']['time'], data['TEC']['lat'], data['TEC']['long'], \
            data['TEC']['time unique'], data['time ref'], dates, \
            settings['TEC']['keo'], settings_paths, settings_map, settings_plot, \
            FLG_fancyPlot=FLG_fancyPlot,FLG_disablePlot=0,FLG_dataDensity=FLG_keo_dataDensity,FLG_disableText=0,FLG_disableCache=1,FLG_useRightExact=1);
        #call the mecha function that runs the keo alg and makes a plot showing the averaging are
    else:
        #keogram stitching code here, should result in the bare minimum of needed stuff
        from copy import deepcopy
        dates_mirror = deepcopy(dates); #deepcopy time!
        dates_divvied = np.append(np.arange(0, dates['date range full dayNum'].shape[0], settings['TEC']['day num limit']), dates['date range full dayNum'].shape[0]);
        data_TEC_keo_holder = [None for i in range(0, dates_divvied.size-1)]; #preallocate
        data_TEC_timeUnique_holder = [None for i in range(0, dates_divvied.size-1)]; #preallocate
        data_TEC_timeUniqueAligned_holder = [None for i in range(0, dates_divvied.size-1)]; #preallocate
        for i in range(0, dates_divvied.size-1):
            # set the date range to the defined limit so we only load in a limited amount of days at a time
            dates_mirror['date range full'] = dates['date range full'][dates_divvied[i]:dates_divvied[i+1]]; #get just a bit
            dates_mirror['date range full dayNum'] = dates['date range full dayNum'][dates_divvied[i]:dates_divvied[i+1]]; #get just a bit
            dates_mirror['date range full padded'] = dates['date range full padded'][dates_divvied[i]:dates_divvied[i+1]+2]; #get just a bit more
            dates_mirror['date range full padded dayNum'] = dates['date range full padded dayNum'][dates_divvied[i]:dates_divvied[i+1]+2]; #get just a bit more
            dates_mirror['date range'] = dates_mirror['date range full'][0::settings['TEC']['day num limit']-1,:]; #stride just right
            dates_mirror['date range dayNum'] = dates_mirror['date range full dayNum'][0::settings['TEC']['day num limit']-1,:]; #stride just right

            data, settings = GRITI_import_TEC_importer(data, dates_mirror, settings, FLG_timeToCheck=True); # load in just a bit
            
            data_TEC_timeUnique_holder[i] = data['TEC']['time unique'].copy();
            data_TEC_timeUniqueAligned_holder[i] = data['TEC']['time unique aligned'].copy();
            
            data_TEC_keo_holder[i], settings_TEC_keo_return = GRITI_keo_keogrammer( \
                data['TEC']['dTEC'] ,data['TEC']['time'], data['TEC']['lat'], data['TEC']['long'], \
                data['TEC']['time unique'], data['time ref'], dates, \
                settings['TEC']['keo'], settings_paths, settings_map, settings_plot, \
                FLG_fancyPlot=FLG_fancyPlot,FLG_disablePlot=2,FLG_dataDensity=FLG_keo_dataDensity,FLG_disableText=0,FLG_disableCache=1,FLG_useRightExact=1);
            #call the mecha function that runs the keo alg and makes a plot showing the averaging are
            gc.collect(); #call the collections
        #END FOR i
        #empty partial TEC memory
        TEC_del_size = data['TEC']['dTEC'].size; #get the size to delete b/c incomplete
        keyzzz = list(data['TEC'].keys()); #gott get it once
        for keyz in keyzzz:
            if isinstance(data['TEC'][keyz],np.ndarray):
                if( data['TEC'][keyz].size == TEC_del_size ):
                    # print('Delete '+keyz)
                    del data['TEC'][keyz]
                #END IF
            elif isinstance(data['TEC'][keyz],list):
                # print('Delete '+keyz)
                del data['TEC'][keyz]
            #END IF
        #END FOR keyz
        #recreate keo and time unique as a big var
        data['TEC']['keo'] = np.vstack(data_TEC_keo_holder);
        data['TEC']['time unique'] = np.hstack(data_TEC_timeUnique_holder);
        data['TEC']['time unique aligned'] = np.hstack(data_TEC_timeUniqueAligned_holder);
        del data_TEC_keo_holder, data_TEC_timeUnique_holder, data_TEC_timeUniqueAligned_holder
        gc.collect(); #call the collections
        #fix time ref if that's needed
        if( (time_Reference == 'TEC') ):
            data['time ref'] = data['TEC']['time unique']; #now that time unique is filled in, time ref can exist
        #END IF        
        #write the (possibly) adjusted settings in at the end
        settings['TEC']['keo'] = settings_TEC_keo_return;
        #ensure justChecking is still there
        data['TEC']['justChecking'] = True; #make sure justChecking is retained in case later stuff interacts with it
    #END IF
    
    if( settings['TEC']['keo']['interpolation'] == True ):
        # vingette_high, settings['TEC']['keo'] = GRITI_keo_keogrammer( \
        #     data['TEC']['dTEC'] ,data['TEC']['time'], data['TEC']['lat'], data['TEC']['long'], \
        #     data['TEC']['time unique'], data['time ref'], dates, \
        #     settings['TEC']['keo'], settings_paths, settings_map, settings_plot, \
        #     FLG_fancyPlot=FLG_fancyPlot,FLG_disablePlot=0,FLG_dataDensity=FLG_keo_dataDensity,FLG_disableText=0,FLG_disableCache=0,FLG_useRightExact=0);
        # #call the mecha function that runs the keo alg and makes a plot showing the averaging are
        
        # settings_TEC_keo_vingette_low = deepcopy(settings['TEC']['keo']); #deep copy
        # settings_TEC_keo_vingette_low['keo N'] = settings['TEC']['keo']['keo N']//4; #reduce resolution greatly
        # vingette_low, _ = GRITI_keo_keogrammer( \
        #     data['TEC']['dTEC'] ,data['TEC']['time'], data['TEC']['lat'], data['TEC']['long'], \
        #     data['TEC']['time unique'], data['time ref'], dates, \
        #     settings['TEC']['keo'], settings_paths, settings_map, settings_plot, \
        #     FLG_fancyPlot=FLG_fancyPlot,FLG_disablePlot=2,FLG_dataDensity=FLG_keo_dataDensity,FLG_disableText=1,FLG_disableCache=0,FLG_useRightExact=0);
        # #call the mecha function that runs the keo alg and makes a plot showing the averaging are
        
        
        from scipy.interpolate import RBFInterpolator
        import joblib
        from time import time
        
        xx, yy = np.meshgrid(np.arange(0,data['TEC']['keo'].shape[1]), np.arange(0,data['TEC']['keo'].shape[0])); #mesh 1's, distance is meaningless in a grid like this (unless keogram angled, but that's a worry for l8tr)
        k_nan = np.isnan(data['TEC']['keo']); #gets reference data/data to interpolate
        k_noNan = ~k_nan; #calc this too
        
        timeSpanner = 20; #20*30=10 min
        timePadder = timeSpanner//2; #pad by 1/2 on each side
        
        timeStepper = np.arange(timeSpanner, data['TEC']['keo'].shape[0], timeSpanner);
        
        #calc up start
        #0 to timePadder <- this has no padded edge at 0
        RBF_interper = RBFInterpolator( np.vstack((xx[0:timeSpanner,:][k_noNan[0:timeSpanner,:]], yy[0:timeSpanner,:][k_noNan[0:timeSpanner,:]])).T, data['TEC']['keo'][0:timeSpanner,:][k_noNan[0:timeSpanner,:]], kernel='linear'); #RBF but has built-in neighbor limiting
        data['TEC']['keo'][0:timePadder,:][k_nan[0:timePadder,:]] = RBF_interper(np.vstack((xx[0:timePadder,:][k_nan[0:timePadder,:]], yy[0:timePadder,:][k_nan[0:timePadder,:]])).T); #linear RBF it right in
        
        #timePadder to timeSpanner <- this is padded, just a smaller span than usual (now aligns to timeStepper range!~)
        RBF_interper = RBFInterpolator( np.vstack((xx[0:timeSpanner+timePadder,:][k_noNan[0:timeSpanner+timePadder,:]], yy[0:timeSpanner+timePadder,:][k_noNan[0:timeSpanner+timePadder,:]])).T, data['TEC']['keo'][0:timeSpanner+timePadder,:][k_noNan[0:timeSpanner+timePadder,:]], kernel='linear'); #RBF but has built-in neighbor limiting
        data['TEC']['keo'][timePadder:timeSpanner,:][k_nan[timePadder:timeSpanner,:]] = RBF_interper(np.vstack((xx[timePadder:timeSpanner,:][k_nan[timePadder:timeSpanner,:]], yy[timePadder:timeSpanner,:][k_nan[timePadder:timeSpanner,:]])).T); #linear RBF it right in
        
        #calc up end
        #timeStepper[-1]+timePadder to data['TEC']['keo'].shape[0] <- this has no padded edge at data['TEC']['keo'].shape[0]
        RBF_interper = RBFInterpolator( np.vstack((xx[timeStepper[-1]:data['TEC']['keo'].shape[0],:][k_noNan[timeStepper[-1]:data['TEC']['keo'].shape[0],:]], yy[timeStepper[-1]:data['TEC']['keo'].shape[0],:][k_noNan[timeStepper[-1]:data['TEC']['keo'].shape[0],:]])).T, data['TEC']['keo'][timeStepper[-1]:data['TEC']['keo'].shape[0],:][k_noNan[timeStepper[-1]:data['TEC']['keo'].shape[0],:]], kernel='linear'); #RBF but has built-in neighbor limiting
        data['TEC']['keo'][timeStepper[-1]+timePadder:data['TEC']['keo'].shape[0],:][k_nan[timeStepper[-1]+timePadder:data['TEC']['keo'].shape[0],:]] = RBF_interper(np.vstack((xx[timeStepper[-1]+timePadder:data['TEC']['keo'].shape[0],:][k_nan[timeStepper[-1]+timePadder:data['TEC']['keo'].shape[0],:]], yy[timeStepper[-1]+timePadder:data['TEC']['keo'].shape[0],:][k_nan[timeStepper[-1]+timePadder:data['TEC']['keo'].shape[0],:]])).T); #linear RBF it right in
        
        #timeStepper[-1] to data['TEC']['keo'].shape[0]-timePadder <- this is padded, just a smaller span than usual (now aligns to timeStepper range!~)
        RBF_interper = RBFInterpolator( np.vstack((xx[timeStepper[-1]-timePadder:data['TEC']['keo'].shape[0],:][k_noNan[timeStepper[-1]-timePadder:data['TEC']['keo'].shape[0],:]], yy[timeStepper[-1]-timePadder:data['TEC']['keo'].shape[0],:][k_noNan[timeStepper[-1]-timePadder:data['TEC']['keo'].shape[0],:]])).T, data['TEC']['keo'][timeStepper[-1]-timePadder:data['TEC']['keo'].shape[0],:][k_noNan[timeStepper[-1]-timePadder:data['TEC']['keo'].shape[0],:]], kernel='linear'); #RBF but has built-in neighbor limiting
        data['TEC']['keo'][timeStepper[-1]:data['TEC']['keo'].shape[0]-timePadder,:][k_nan[timeStepper[-1]:data['TEC']['keo'].shape[0]-timePadder,:]] = RBF_interper(np.vstack((xx[timeStepper[-1]:data['TEC']['keo'].shape[0]-timePadder,:][k_nan[timeStepper[-1]:data['TEC']['keo'].shape[0]-timePadder,:]], yy[timeStepper[-1]:data['TEC']['keo'].shape[0]-timePadder,:][k_nan[timeStepper[-1]:data['TEC']['keo'].shape[0]-timePadder,:]])).T); #linear RBF it right in
        
        
        #--- pack up prep for parallel ---
        print('WARNING in GRITI_keo_TEC: interpolating in parallel, it may take a bit if there\'s many days!');
        nThread = settings['config']['parallel num threads']//3; #RBFInterpolator seems to slam 2 cores and smatter the others, so divide by 3
        if( nThread < 0 ):
            nThread = 1; #enforce 1
        #END IF
        nThread = 1; #disable parallel, joblib errors with "ValueError: assignment destination is read-only" for reasons I cannot grok
        
        timeStepper_stepperSize = np.int64(np.round(timeStepper.size/nThread)); #slice it between the threads involved
        timeStepper_stepper = np.append(np.arange(0,timeStepper.size,timeStepper_stepperSize),timeStepper.size); #cover the gamut
        timeStepper_stepper_start = timeStepper_stepper-1; #roll back
        timeStepper_stepper_start[0] = 0; #reset
        timeStepper_stepper_end = np.append(np.arange(0,timeStepper.size,timeStepper_stepperSize),timeStepper.size-1); #cover the gamut
        
        def RBF_interper_corraller(xx, yy, data_interped, k_nan, k_noNan, timeStepper, timePadder):
            #calc the middle (which can be properly padded)
            for jj in range(0, timeStepper.size-1):
                RBF_interper = RBFInterpolator( np.vstack((xx[timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:][k_noNan[timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:]], yy[timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:][k_noNan[timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:]])).T, data_interped[timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:][k_noNan[timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:]], kernel='linear'); #RBF
                data_interped[timeStepper[jj]:timeStepper[jj+1],:][k_nan[timeStepper[jj]:timeStepper[jj+1],:]] = RBF_interper(np.vstack((xx[timeStepper[jj]:timeStepper[jj+1],:][k_nan[timeStepper[jj]:timeStepper[jj+1],:]], yy[timeStepper[jj]:timeStepper[jj+1],:][k_nan[timeStepper[jj]:timeStepper[jj+1],:]])).T); #linear RBF it right in
            #END FOR jj
            
            return data_interped
        #END DEF
        
        tic = time();
        if( nThread > 1 ):
            #--- pack up parallel operation stuff ---
            parallel_list = []; #Prep
            for i in range(0,timeStepper_stepper.size-1): # Every iteration appends a list of inputs to parallel_list, each index of parallel_list will be independently run
                parallel_list.append([ xx[timeStepper[timeStepper_stepper_start[i]]-timePadder:timeStepper[timeStepper_stepper_start[i+1]]+timePadder,:], 
                                       yy[timeStepper[timeStepper_stepper_start[i]]-timePadder:timeStepper[timeStepper_stepper_start[i+1]]+timePadder,:], 
                                       data['TEC']['keo'][timeStepper[timeStepper_stepper_start[i]]-timePadder:timeStepper[timeStepper_stepper_start[i+1]]+timePadder,:].copy(),
                                       k_nan[timeStepper[timeStepper_stepper_start[i]]-timePadder:timeStepper[timeStepper_stepper_start[i+1]]+timePadder,:], 
                                       k_noNan[timeStepper[timeStepper_stepper_start[i]]-timePadder:timeStepper[timeStepper_stepper_start[i+1]]+timePadder,:], 
                                       timeStepper[timeStepper_stepper_start[i]:timeStepper_stepper[i+1]]-timeStepper[timeStepper_stepper_start[i]]+timePadder, 
                                       timePadder ]);
            #END FOR i


            parallel_results = [RBF_interper_corraller(*sublist) for sublist in parallel_list] #this is fine, why does parallel fail?
        
            # #--- apply parallel calc on function ---
            # with joblib.parallel_backend('loky'):
            #     with joblib.Parallel(n_jobs=nThread,pre_dispatch=nThread,batch_size=1) as parallel_arbiter:    
            #         parallel_results = parallel_arbiter(joblib.delayed(RBF_interper_corraller)(*sublist) for sublist in parallel_list); #parallel time
            #     #END WITH
            # #END WITH
            
            del parallel_list #save some mem
            #--- unpack parallel results ---
            for i in range(0,len(parallel_results)):
                data['TEC']['keo'][timeStepper[timeStepper_stepper_start[i]]:timeStepper[timeStepper_stepper_start[i+1]],:] = parallel_results[i][timePadder:-timePadder]; #load in the data
            #END FOR i
            del parallel_results #save some mem
            print('\nTime to interpolate NaN keogram values in parallel took: '+str(np.round((time()-tic)/60,2))+' min\n'); #extra space at end
        else:
            data['TEC']['keo'] = RBF_interper_corraller(xx, yy, data['TEC']['keo'], k_nan, k_noNan, timeStepper, timePadder); #toss it all in directly if only 1 thread works for some reason
            print('\nTime to interpolate NaN keogram values took: '+str(np.round((time()-tic)/60,2))+' min\n'); #extra space at end
        #END IF

        del xx, yy, k_nan, k_noNan #until in a function, delete
        
        # #calc the middle (which can be properly padded)
        # for jj in range(0, timeStepper.size-1):
        #     RBF_interper = RBFInterpolator( np.vstack((xx[timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:][k_noNan[timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:]], yy[timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:][k_noNan[timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:]])).T, data['TEC']['keo'][timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:][k_noNan[timeStepper[jj]-timePadder:timeStepper[jj+1]+timePadder,:]], kernel='linear'); #RBF but has built-in neighbor limiting
        #     data['TEC']['keo'][timeStepper[jj]:timeStepper[jj+1],:][k_nan[timeStepper[jj]:timeStepper[jj+1],:]] = RBF_interper(np.vstack((xx[timeStepper[jj]:timeStepper[jj+1],:][k_nan[timeStepper[jj]:timeStepper[jj+1],:]], yy[timeStepper[jj]:timeStepper[jj+1],:][k_nan[timeStepper[jj]:timeStepper[jj+1],:]])).T); #linear RBF it right in
        # #END FOR jj
    #END IF
#END IF
  
    
#==============Analysis: Plot Keograms of Any Angle AVG==============
if( (FLG_keo_plot == 1) & (FLG_keo == 1) ):
    #-----Plot TEC results as a Keogram-----
    GRITI_keo_plot(data['TEC']['keo'], data['TEC']['time unique'], data['time ref'], dates, \
        settings['TEC']['keo'] ,settings_plot, settings_paths, settings_map, \
        FLG_fancyPlot = 0, settings_config=settings['config']);
    #call the mecha function that plots the avg'd delta-vTEC
#END IF

#==============Analysis: Plot Keograms of Any Angle AVG ~fancy~==============
if( (FLG_keo_plot == 1) & (FLG_keo == 1) & (FLG_fancyPlot == 1) ):
    #-----Plot TEC results as a Keogram-----
    GRITI_keo_plot(data['TEC']['keo'], data['TEC']['time unique'], data['time ref'], dates, \
        settings['TEC']['keo'] ,settings_plot, settings_paths, settings_map, \
        FLG_fancyPlot = 1, settings_config=settings['config']);
    #call the mecha function that plots the avg'd delta-vTEC
#END IF

#==============Analysis: Plot Keograms of Any Angle AVG with day/nite plot ~fancy~==============
# if( (FLG_keo_plot == 1) & (FLG_keo == 1) & (FLG_fancyPlot == 1) ):
#     #-----Plot TEC results as a Keogram-----
#     GRITI_TEC_keo_fancyPlot_TEC_wDayNite(data['TEC']['keo'],TEC_timeUnique,TEC_plotLimValu, \
#         settings['TEC']['keo']['keo colormap'],plotLatRange,plotLongRange,latMillstone,longMillstone,dateRange_dayNum_zeroHr,time_Ref,latLong_ref, \
#         settings['TEC']['keo']['keo angle'],settings['TEC']['keo']['keo width'], \
#         settings['TEC']['keo']['keo plot latlong chunks'] ,settings['TEC']['keo']['keo plot latlong name'], \
#         'delta-vTEC','delta-vTEC [TECU]',dateRange_zeroHr,dateRange_zeroHr_monthName, \
#         dateRange_zeroHr_dayPostfix, dateRange_dayNum_full, dateRange_full,\
#         FONT_grandioseFM, FONT_titleFM,FONT_axisTick,FONT_axisLabelFM, PLOT_lineWidth, folder, journal_width_2C,journal_height_max,journal_dpi,
#         settings_plot, settings_TEC['keo']);
#     #call the mecha function that plots the avg'd delta-vTEC
# #END IF

#==============Analysis: Plot Keograms of Any Angle AVG and ISR ~fancy~==============
if( (FLG_keo_plot == 1) & (FLG_keo == 1) & (FLG_dataTypes[FLG_ISRloc] == 1) & (FLG_fancyPlot == 1) ):
    #-----Plot TEC results as a Keogram-----
    GRITI_TEC_keo_fancyPlot_TECnISR(data['TEC']['keo'],TEC_timeUnique,TEC_plotLimValu, \
        settings['TEC']['keo']['keo colormap'],plotLatRange,plotLongRange,latMillstone,longMillstone,dateRange_dayNum_zeroHr, \
        settings['TEC']['keo']['keo angle'],settings['TEC']['keo']['keo width'], \
        settings['TEC']['keo']['keo plot latlong chunks'] ,settings['TEC']['keo']['keo plot latlong name'], \
        'delta-vTEC','delta-vTEC [TECU]',dateRange_zeroHr,dateRange_zeroHr_monthName,dateRange_zeroHr_dayPostfix,\
        Zenith_time, Zenith_height, Zenith_POPL_hp, ISR_POPL_plotLimValu, ISR_RTI_heightLimValues, \
        FONT_grandioseFM,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM, PLOT_lineWidth, folder, journal_width_2C,journal_height_max,journal_dpi);
    #call the mecha function that plots the avg'd delta-vTEC
#END IF  
    
#==============Analysis: Plot Keograms of Any Angle AVG and TEC noise ~fancy~==============
if( (FLG_keo_plot_wNoise == 1) & (FLG_keo == 1) & (FLG_fancyPlot == 1) ):
    #-----Plot TEC results as a Keogram-----
    GRITI_TEC_keo_fancyPlot_TECnNoise(data['TEC']['keo'],TEC_timeUnique,TEC_plotLimValu, \
        data['TEC']['lat'], data['TEC']['long'], data['TEC']['time'], data['time ref'], \
        noise_background_mean, noise_background_stdev, Re, keo_N, keo_45vsLatLong, \
        wave_latRange, wave_longRange, wave_N, wave_angle, wave_phase, wave_waveLength, wave_period, wave_amp, \
        settings['TEC']['keo']['keo colormap'],plotLatRange,plotLongRange,latMillstone,longMillstone,dateRange_dayNum_zeroHr, \
        settings['TEC']['keo']['keo angle'],settings['TEC']['keo']['keo width'], \
        settings['TEC']['keo']['keo plot latlong chunks'] ,settings['TEC']['keo']['keo plot latlong name'], \
        'delta-vTEC','delta-vTEC [TECU]',dateRange_zeroHr,dateRange_zeroHr_monthName,dateRange_zeroHr_dayPostfix,\
        Zenith_time, \
        FONT_grandioseFM, FONT_titleFM,FONT_axisTick,FONT_axisLabelFM, PLOT_lineWidth, folder, journal_width_2C,journal_height_max,journal_dpi);
    #call the mecha function that plots the avg'd delta-vTEC
#END IF  

#==============Analysis: Plot Time Cut-out Keograms of Any Angle AVG==============
if( (FLG_keo_plot_timeCutout == 1) & (FLG_keo == 1) ):
    #-----Plot TEC results as a Keogram-----
    GRITI_keo_plot(data['TEC']['keo'], data['TEC']['time unique'], data['time ref'], dates, \
        settings['TEC']['keo'] ,settings_plot, settings_paths, settings_map, \
        timeCutout = time_cutout_range/3600, FLG_fancyPlot = 0, settings_config=settings['config']);
    if( FLG_fancyPlot >= 1 ):
        GRITI_keo_plot(data['TEC']['keo'], data['TEC']['time unique'], data['time ref'], dates, \
            settings['TEC']['keo'] ,settings_plot, settings_paths, settings_map, \
            timeCutout = time_cutout_range/3600, FLG_fancyPlot = FLG_fancyPlot, settings_config=settings['config']);
    #END IF
    #call the mecha function that plots the avg'd delta-vTEC
    
    # #-----Plot TEC results as a Keogram-----
    # time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
    #     np.where(np.min(np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    # vTECChunked_keo_cutOut = data['TEC']['keo'][time_cutout_indexes[0]:time_cutout_indexes[1]+1,:];
    # TEC_timeUnique_cutOut = TEC_timeUnique[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    # GRITI_TEC_keo_plot_TEC_cutOut(vTECChunked_keo_cutOut,TEC_timeUnique_cutOut,TEC_plotLimValu,'jet', \
    #   plotLatRange,plotLongRange,latMillstone,longMillstone, dateRange_dayNum_zeroHr, \
    #   settings['TEC']['keo']['keo angle'],settings['TEC']['keo']['keo width'], \
    #   settings['TEC']['keo']['keo plot latlong chunks'] ,settings['TEC']['keo']['keo plot latlong name'], \
    #   'delta-vTEC','delta-vTEC [TECU]',time_cutout_range, \
    #   FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
    # #call the mecha function that plots the avg'd delta-vTEC
#END IF

#==============Analysis: Plot Time Time series / keograms of TEC data replaced with noise==============
if( (FLG_keo_plot_noiseAllViews == 1) & (FLG_fancyPlot >= 1) & (plotLatRange == [-90,90]) & (plotLongRange == [-180,180]) ):
    #-----Plot TEC results as a Keogram and as a time series all in one big plot-----
    # import sys, importlib
    # importlib.reload(sys.modules['GRITI_TEC_keo_fancyPlot_TEC_noiseAllViews'])
    # from Code.GRITI_TEC_keo_fancyPlot_TEC_noiseAllViews import GRITI_TEC_keo_fancyPlot_TEC_noiseAllViews
    GRITI_TEC_keo_fancyPlot_TEC_noiseAllViews(time_Ref, Re,
        geoMap_projectionStyle, BasemapFixDir, settings['TEC']['keo']['keo colormap'],
        plotLatRange, plotLongRange,  [30,50], [-125,-60],
        plotLatRange_autoTick,plotLongRange_autoTick,plotLongRange_autoTick_Crunched, 
        TEC_timeUnique, data['TEC']['time'], data['TEC']['lat'], data['TEC']['long'], data['TEC']['dTEC'],
        TEC_plotLimValu, noise_background_mean, noise_background_stdev, avgPt_TECnoise_iterations,
        avgPt_pointRadius, keo_45vsLatLong, 'delta-vTEC [TECU]',
        gif_Millstone_Marker, gif_Millstone_Marker_Color, gif_Millstone_Marker_Size,
        dataReject, dataRejectOrig, dataRejectLimit, dataRejectLimitOrig, dataRejectMax,
        Zenith_time, Zenith_height, Zenith_POPL_hp, MISA_time, MISA_height, MISA_POPL_hp,
        pointAltitude, avgPt_ISRavgAlt, settings_spectra['filter cutoff period'],
        avgPt_coords,time_cutout_range,dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,
        dateRange_zeroHr, dateRange_zeroHr_monthName, dateRange_zeroHr_dayPostfix, \
        FONT_grandioseFM, FONT_titleFM,FONT_axisTickFM,FONT_axisTick,FONT_axisLabelFM,
        PLOT_lineWidth, folder, journal_width_2C,journal_height_max,journal_dpi);
    #call the mecha function that plots the avg'd delta-vTEC
#END IF

#==============Analysis: Plot Time Cut-out Keograms of Any Angle AVG==============
if( (FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration == 1) & (FLG_keo == 1) ):
    #-----Plot TEC results as a Keogram with AMPERE data as a 2nd-----
    GRITI_combinedPlot_keo_TEC_n_AMPERE_1Dintegration(data['TEC']['keo'],TEC_timeUnique,TEC_plotLimValu, \
         settings['TEC']['keo']['keo colormap'],data['AMPERE'],AMPERE_timeUnique,locAMPERE_time,locAMPERE_lat,locAMPERE_long,AMPERE_plot_index,AMPERE_plot_indexes, \
         AMPERE_plot_labels,FLG_AMPERE_upTo90,plotLatRange,plotLongRange,latMillstone,longMillstone,dateRange_dayNum_zeroHr,settings['TEC']['keo']['keo N'], \
         settings['TEC']['keo']['width'],settings['TEC']['keo']['keo plot latlong chunks'],settings['TEC']['keo']['keo plot latlong name'],'delta-vTEC', \
         'delta-vTEC [TECU]',time_Ref,time_Reference,dateRange,dateRange_zeroHr,dateRange_zeroHr_monthName, \
         dateRange_zeroHr_dayPostfix,AMPERE_delay_wrt_TEC,PLOT_lineWidth,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
    #call the mecha function
#END IF

if( (FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone == 1) & (FLG_keo == 1) ):
    #-----Plot TEC results as a Keogram with AMPERE data as a 2nd-----
    GRITI_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone(data['TEC']['keo'],TEC_timeUnique,TEC_plotLimValu, \
         settings['TEC']['keo']['keo colormap'],data['AMPERE'],AMPERE_timeUnique,locAMPERE_time,locAMPERE_lat,locAMPERE_long,AMPERE_plot_index,AMPERE_plot_indexes, \
         AMPERE_plot_labels,plotLatRange,plotLongRange,latMillstone,longMillstone,dateRange_dayNum_zeroHr,settings['TEC']['keo']['keo N'], \
         settings['TEC']['keo']['keo width'],settings['TEC']['keo']['keo plot latlong chunks'],settings['TEC']['keo']['keo plot latlong name'],'delta-vTEC', \
         'delta-vTEC [TECU]',time_Ref,time_Reference,dateRange,dateRange_zeroHr,dateRange_zeroHr_monthName, \
         dateRange_zeroHr_dayPostfix,AMPERE_delay_wrt_TEC,PLOT_lineWidth,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
    #call the mecha function
#END IF

if( (FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone_spectra == 1) & (FLG_keo == 1) ):
    #-----Plot TEC results as a Keogram with AMPERE data as a 2nd-----
    GRITI_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone_spectra(data['TEC']['keo'],TEC_timeUnique,TEC_plotLimValu, \
         settings['TEC']['keo']['keo colormap'],data['AMPERE'],AMPERE_timeUnique,locAMPERE_time,locAMPERE_lat,locAMPERE_long,AMPERE_plot_index,AMPERE_plot_indexes, \
         AMPERE_plot_labels,plotLatRange,plotLongRange,latMillstone,longMillstone,dateRange_dayNum_zeroHr,settings['TEC']['keo']['keo N'], \
         settings['TEC']['keo']['keo width'],settings['TEC']['keo']['keo plot latlong chunks'],settings['TEC']['keo']['keo plot latlong name'],'delta-vTEC', \
         'delta-vTEC [TECU]',time_Ref,time_Reference,dateRange,dateRange_zeroHr,dateRange_zeroHr_monthName, \
         dateRange_zeroHr_dayPostfix,AMPERE_delay_wrt_TEC,PLOT_lineWidth,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,settings,FLG_keo_Scargle_FFT);
    #call the mecha function
#END IF

if( (FLG_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone_spectra_timeMatch == 1) & (FLG_keo == 1) ):    
    #Cut AMPERE only b/c TEC is matched in-alg to AMPERE time steps (so having TEC data before/after AMPERE is good so can fill out the edge time slots - and no need to cut now)
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range+AMPERE_delay_wrt_TEC) )) == np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range+AMPERE_delay_wrt_TEC) ) )[0][0] , \
        np.where(np.min(np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range+AMPERE_delay_wrt_TEC) )) == np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range+AMPERE_delay_wrt_TEC) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    AMPERE_timeUnique_cutout = AMPERE_timeUnique[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    k = np.in1d(data['AMPERE']['time'],AMPERE_timeUnique_cutout); #get the data points to keep that have the matching times
    AMPERE_data_cutout = data['AMPERE'][settings['AMPERE']['data type']][k,:];
    
    #-----Plot TEC results as a Keogram with AMPERE data as a 2nd-----
    GRITI_combinedPlot_keo_TEC_n_AMPERE_1Dintegration_auroralZone_spectra(data['TEC']['keo'],TEC_timeUnique,TEC_plotLimValu, \
         settings['TEC']['keo']['keo colormap'],AMPERE_data_cutout,AMPERE_timeUnique_cutout,locAMPERE_time,locAMPERE_lat,locAMPERE_long,AMPERE_plot_index,AMPERE_plot_indexes, \
         AMPERE_plot_labels,plotLatRange,plotLongRange,latMillstone,longMillstone,dateRange_dayNum_zeroHr,settings['TEC']['keo']['keo N'], \
         settings['TEC']['keo']['keo width'],settings['TEC']['keo']['keo plot latlong chunks'],settings['TEC']['keo']['keo plot latlong name'],'delta-vTEC', \
         'delta-vTEC [TECU]',time_Ref,time_Reference,dateRange,dateRange_zeroHr,dateRange_zeroHr_monthName, \
         dateRange_zeroHr_dayPostfix,AMPERE_delay_wrt_TEC,PLOT_lineWidth,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,settings,FLG_keo_Scargle_FFT);
    #call the mecha function
#END IF

#==============Analysis: stacker time==============
if( FLG_keo_stacker >= 1 ):
    from Code.subfun_sunAlsoRises import sunAlsoRises
    from Code.subfun_comparator import subfun_comparator
    TEC_timeUnique_uniqueDays, TEC_timeUnique_uniqueDaysIndex, TEC_timeUnique_uniqueDayCounts = np.unique(np.int64(data['TEC']['time unique']/86400),return_inverse=True,return_counts=True); #get the unique days and the indexes that get us to them
    
    keo_stackerDaysStacked = TEC_timeUnique_uniqueDays.size; #get the number of days to stack
    keo_stackerTime = np.arange(0,86400,data['TEC']['data rate']); #sec, make a time vector to go with the stacker var
    keo_stackerHolder = np.zeros( (keo_stackerTime.size , data['TEC']['keo'].shape[1], TEC_timeUnique_uniqueDays.size) ); #preallocate
    if( FLG_keo_stacker == 2 ):
        [sunRise, sunSet, dateRange_fullPad] = sunAlsoRises(dateRange_full,latLong_ref[0][0],latLong_ref[0][1]); #get the sunrise and sunset times for the days at the loc
    #END IF
    if( FLG_keo_stacker_ignore[0] == True ):
        kCompare = subfun_comparator(FLG_keo_stacker_ignore[1], data, dates=dates); #get when is bad
        # if( not isinstance(FLG_keo_stacker_ignore[1]['data path'][0], (list, tuple)) ): #test if single path with ['dataSet','dataType'] instead of [['dataSet','dataType'],...]
        #     FLG_keo_stacker_ignore[1]['data path'] = [FLG_keo_stacker_ignore[1]['data path']]; #wrap it in a list so stuff works
        # #END IF
        # if( not isinstance(FLG_keo_stacker_ignore[1]['comparison'], (list, tuple)) ): #test if single comparison with 'do compare' instead of ['do compare',...]
        #     FLG_keo_stacker_ignore[1]['comparison'] = [FLG_keo_stacker_ignore[1]['comparison']]; #wrap it in a list so stuff works
        # #END IF
        # if( np.isscalar(FLG_keo_stacker_ignore[1]['time offset']) ): #test if scalar
        #     FLG_keo_stacker_ignore[1]['time offset'] = [FLG_keo_stacker_ignore[1]['time offset']]; #wrap it in a list so stuff works
        # #END IF
        
        # kCompare = np.zeros(data['TEC']['time unique'].size, dtype=np.bool_); #preallocate
        # for dd in range(0, len(FLG_keo_stacker_ignore[1]['data path'])):
        #     data2compare = data; #alias
        #     for jj in range(0,len(FLG_keo_stacker_ignore[1]['data path'][dd])):
        #         data2compare = data2compare[FLG_keo_stacker_ignore[1]['data path'][dd][jj]]; #drill down
        #     #END FOR jj
            
        #     if( data[FLG_keo_stacker_ignore[1]['data path'][dd][0]]['data rate'] != data['TEC']['data rate'] ):
        #         #resize!
        #         data2compare = subfun_timeMatch(data2compare, data[FLG_keo_stacker_ignore[1]['data path'][dd][0]]['time unique']+FLG_keo_stacker_ignore[1]['time offset'][dd], data['TEC']['time unique'], timeMatch_delta=data['TEC']['data rate'], FLG_removeNaNs=0, FLG_reportNaNs=False, FLG_useSum=0)[0];
        #     #END IF
        #     # data2compareTime = data['TEC']['time unique'];
        #     # data2compareRate = data['TEC']['data rate']; #aligned to TEC now
            
            
        #     kCompare_method = FLG_keo_stacker_ignore[1]['comparison'][dd].split('&'); #this allows multiple filtering methods to be chained together
        #     for jk in range(0,len(kCompare_method)):
                
                
        #         if( strfind(kCompare_method[jk],'|',opt=1) > 0 ): #check for filt info
        #             kCompare_method_specifics = kCompare_method[jk][kCompare_method[jk].find('|')+1:].split(','); #get any filt specifics
        #             kCompare_method_specifics = [strang.lower().replace('-','').replace(' ','') for strang in kCompare_method_specifics]; #reduce and standardize
        #             kCompare_method[jk] = kCompare_method[jk][:kCompare_method[jk].find('|')]; #remove the filt info
        #         else:
        #             kCompare_method_specifics = None; #no specifics
        #         #END IF
        #         kCompare_method_curr = kCompare_method[jk].lower().replace('-','').replace(' ',''); #get the current method w/o specifics and properly simplified
                
        #         #--- value comparisons require '<|0' for 0 to be the comparison value ---
        #         if( ('lessthan' == kCompare_method_curr) or ('<' == kCompare_method_curr) ):
        #             kCompare_method_specifics[0] = Decimal(kCompare_method_specifics[0]);
        #             if( (Decimal(kCompare_method_specifics[0]) % 1) == 0 ): #convert to a number to use
        #                 kCompare_method_specifics[0] = np.int64(kCompare_method_specifics[0]);
        #             else:
        #                 kCompare_method_specifics[0] = np.float64(kCompare_method_specifics[0]);
        #             #END IF
        #             kCompare = kCompare | (data2compare < kCompare_method_specifics[0]);
                    
        #         elif( ('lessthanorequal' == kCompare_method_curr) or ('<=' == kCompare_method_curr) ):
        #             kCompare_method_specifics[0] = Decimal(kCompare_method_specifics[0]);
        #             if( (Decimal(kCompare_method_specifics[0]) % 1) == 0 ): #convert to a number to use
        #                 kCompare_method_specifics[0] = np.int64(kCompare_method_specifics[0]);
        #             else:
        #                 kCompare_method_specifics[0] = np.float64(kCompare_method_specifics[0]);
        #             #END IF
        #             kCompare = kCompare | (data2compare <= kCompare_method_specifics[0]);
                    
        #         elif( ('greaterthan' == kCompare_method_curr) or ('>' == kCompare_method_curr) ):
        #             kCompare_method_specifics[0] = Decimal(kCompare_method_specifics[0]);
        #             if( (Decimal(kCompare_method_specifics[0]) % 1) == 0 ): #convert to a number to use
        #                 kCompare_method_specifics[0] = np.int64(kCompare_method_specifics[0]);
        #             else:
        #                 kCompare_method_specifics[0] = np.float64(kCompare_method_specifics[0]);
        #             #END IF
        #             kCompare = kCompare | (data2compare > kCompare_method_specifics[0]);
                    
        #         elif( ('greaterthanorequal' == kCompare_method_curr) or ('>=' == kCompare_method_curr) ):
        #             kCompare_method_specifics[0] = Decimal(kCompare_method_specifics[0]);
        #             if( (Decimal(kCompare_method_specifics[0]) % 1) == 0 ): #convert to a number to use
        #                 kCompare_method_specifics[0] = np.int64(kCompare_method_specifics[0]);
        #             else:
        #                 kCompare_method_specifics[0] = np.float64(kCompare_method_specifics[0]);
        #             #END IF
        #             kCompare = kCompare | (data2compare >= kCompare_method_specifics[0]);
                    
        #         #--- elevated requires a distance from the mean value (or auto) (kinda equiv to # of stdev from mean) in 1st spot with optional pos/neg only decorator, e.g., 'elevated|auto,neg only' ---
        #         elif( 'elevated' in kCompare_method_curr ):               
        #             kCompare_distFromMedian_noSqr = data2compare - np.nanmedian(data2compare);
        #             kCompare_distFromMedian = (kCompare_distFromMedian_noSqr)**2; #distance from the median (no sqrt, just leave it at pwr2)
        #             kCompare_medianDistFromMedian = np.nanmedian(kCompare_distFromMedian); #median of the distance from the median
                    
        #             if( (kCompare_method_specifics[0] == 'auto') | (kCompare_method_specifics[0].replace('.','',1).isdigit() == False) ):
        #                 #auto creates a comparison value via the ratio between mean and median (e.g., spikes should cause elevated mean and 
        #                 kCompare_curr = kCompare_distFromMedian > kCompare_medianDistFromMedian*np.nanmean(kCompare_distFromMedian)/kCompare_medianDistFromMedian; #comparison value here is a scalar multiplier, akin to # of standard deviations
        #             else:
        #                 kCompare_method_specifics[0] = Decimal(kCompare_method_specifics[0]);
        #                 if( (Decimal(kCompare_method_specifics[0]) % 1) == 0 ): #convert to a number to use
        #                     kCompare_method_specifics[0] = np.int64(kCompare_method_specifics[0]);
        #                 else:
        #                     kCompare_method_specifics[0] = np.float64(kCompare_method_specifics[0]);
        #                 #END IF
        #                 kCompare_curr = kCompare_distFromMedian > kCompare_medianDistFromMedian*kCompare_method_specifics[0]; #comparison value here is a scalar multiplier, akin to # of standard deviations
        #             #END IF
                    
        #             if( ('posonly' in kCompare_method_specifics[1:]) | ('positiveonly' in kCompare_method_specifics[1:]) | ('+only' in kCompare_method_specifics[1:]) ):
        #                 kCompare_curr = kCompare_curr & (kCompare_distFromMedian_noSqr > 0); #extra comparator for pos only
        #             elif( ('negonly' in kCompare_method_specifics[1:]) | ('negativeonly' in kCompare_method_specifics[1:]) | ('-only' in kCompare_method_specifics[1:]) ):
        #                 kCompare_curr = kCompare_curr & (kCompare_distFromMedian_noSqr < 0); #extra comparator for neg only
        #             #END IF
                    
        #             kCompare = kCompare | kCompare_curr; #combine in
                    
        #         #--- rate requires a distance from the mean value (or auto) (kinda equiv to # of stdev from mean) in 1st spot with optional pos/neg only decorator, e.g., 'rate|7,+ only' ---
        #         elif( 'rate' in kCompare_method_curr ):
        #             kCompare_rate = np.insert(np.diff(data2compare)/data['TEC']['data rate'], 0, 0); #get the rate, insert 0 at 0 so same size as data2compare
        #             kCompare_rate_distFromMedian_noSqr = kCompare_rate - np.nanmedian(kCompare_rate);
        #             kCompare_rate_distFromMedian = (kCompare_rate_distFromMedian_noSqr)**2; #distance from the median (no sqrt, just leave it at pwr2)
        #             kCompare_rate_medianDistFromMedian = np.nanmedian(kCompare_rate_distFromMedian); #median of the distance from the median
                    
        #             if( (kCompare_method_specifics[0] == 'auto') | (kCompare_method_specifics[0].replace('.','',1).isdigit() == False) ):
        #                 #auto creates a comparison value via the ratio between mean and median (e.g., spikes should cause elevated mean and 
        #                 kCompare_curr = kCompare_rate_distFromMedian > kCompare_rate_medianDistFromMedian*np.nanmean(kCompare_rate_distFromMedian)/kCompare_rate_medianDistFromMedian; #comparison value here is a scalar multiplier, akin to # of standard deviations
        #             else:
        #                 kCompare_method_specifics[0] = Decimal(kCompare_method_specifics[0]);
        #                 if( (Decimal(kCompare_method_specifics[0]) % 1) == 0 ): #convert to a number to use
        #                     kCompare_method_specifics[0] = np.float64(kCompare_method_specifics[0]);
        #                 else:
        #                     kCompare_method_specifics[0] = np.int64(kCompare_method_specifics[0]);
        #                 #END IF
        #                 kCompare_curr = kCompare_rate_distFromMedian > kCompare_rate_medianDistFromMedian*kCompare_method_specifics[0]; #comparison value here is a scalar multiplier, akin to # of standard deviations
        #             #END IF
                    
        #             if( ('posonly' in kCompare_method_specifics[1:]) | ('positiveonly' in kCompare_method_specifics[1:]) | ('+only' in kCompare_method_specifics[1:]) ):
        #                 kCompare_curr = kCompare_curr & (kCompare_rate_distFromMedian_noSqr > 0); #extra comparator for pos only
        #             elif( ('negonly' in kCompare_method_specifics[1:]) | ('negativeonly' in kCompare_method_specifics[1:]) | ('-only' in kCompare_method_specifics[1:]) ):
        #                 kCompare_curr = kCompare_curr & (kCompare_rate_distFromMedian_noSqr < 0); #extra comparator for neg only
        #             #END IF
                    
        #             kCompare = kCompare | kCompare_curr; #combine in
                    
        #         elif( 'nan' in kCompare_method_curr ):
        #             kCompare = kCompare | np.isnan(data2compare); #tack on nan check
                    
        #         else:
        #             print('WARNING in GRITI_keo_stackr: Bad comparison requested of "'+FLG_keo_stacker_ignore[1]['comparison'][dd]+'", not doing any comparing (unless nan is called out).');
        #         #END IF
                
        #     #END FOR jk
        # #END FOR dd
    else:
        kCompare = np.zeros(data['TEC']['time unique'].size, dtype=np.bool_); #preallocate, still need it
    #END IF
    #STACK EM
    for i in range(0,TEC_timeUnique_uniqueDays.size):
        k = np.where( TEC_timeUnique_uniqueDaysIndex == i )[0]; #get indexes with the first day
        
        if( FLG_keo_stacker == 1 ):
            keo_stackerHolder[:,:,i] = data['TEC']['keo'][k,:]; #yoink
        elif( FLG_keo_stacker == 2 ):
            keo_stackerHolder[:,:,i] = np.roll(data['TEC']['keo'][k,:],np.int64(np.round((sunRise[1]-sunRise[i+1])*86400/data['TEC']['data rate'])),axis=0); #roll to keep it approximately at the same daytime time yoink
        #END IF
        
        if( FLG_keo_stacker_clip[0] == True ):
            keo_stackerHolder[(keo_stackerHolder[:,:,i] < np.min(FLG_keo_stacker_clip[1])) | (keo_stackerHolder[:,:,i] > np.max(FLG_keo_stacker_clip[1])), i] = np.nan; #nan the clipped values
        #END IF
        
        if( FLG_keo_stacker_ignore[0] == True ):
            keo_stackerHolder[kCompare[k],:,i] = np.nan; #nan out the stuff that we don't want
        #END IF
        
        # keo_stackerHolder[:,:,i] = keo_stackerHolder[:,:,i]/np.nansum(keo_stackerHolder[:,:,i]); #normalize to sum to 1
        # kk = np.where( keo_stackerHolder[:,:,i] > np.max(settings_TEC['plot lim']));
        # keo_stackerHolder[kk[0],kk[1],i] = np.max(settings_TEC['plot lim']); #cap value
        # kk = np.where( keo_stackerHolder[:,:,i] < np.min(settings_TEC['plot lim']));
        # keo_stackerHolder[kk[0],kk[1],i] = np.min(settings_TEC['plot lim']); #cap value
        # kk = np.where( keo_stackerHolder[:,:,i] > np.max(settings_TEC['plot lim'])/2);
        # keo_stackerHolder[kk[0],kk[1],i] = np.max(settings_TEC['plot lim'])/2; #cap value
        # kk = np.where( keo_stackerHolder[:,:,i] < np.min(settings_TEC['plot lim'])/2);
        # keo_stackerHolder[kk[0],kk[1],i] = np.min(settings_TEC['plot lim'])/2; #cap value
    #END FOR i
    # keo_stacker = np.nansum(keo_stackerHolder,axis=2); #average along the 3rd axis
    # keo_stacker = np.nanmedian(keo_stackerHolder,axis=2); #average along the 3rd axis
    keo_stacker = np.nanmean(keo_stackerHolder,axis=2); #average along the 3rd axis
    
    settings_TEC_keo_stackr = deepcopy(settings['TEC']['keo']);
    settings_TEC_keo_stackr['day nite shading'] = 0; #turn off day nite shading to seee highlight better
    GRITI_keo_plot(data['TEC']['keo'], data['TEC']['time unique'], data['time ref'], dates, \
        settings_TEC_keo_stackr ,settings_plot, settings_paths, settings_map, \
        FLG_fancyPlot = 0, settings_config=settings['config'], highlighter=kCompare);
#END IF

if( FLG_keo_stackerPlot == 1 ):
    from Code.subfun_figFitter import figFitter
    #prep to plot, if the colorbar limit is 1 value, make it 2 because it's meant to be a +/-# situation.
    if( FLG_keo_stacker_clip[0] == True ):
        TEC_plotLimValu = np.array( (np.min(FLG_keo_stacker_clip[1]),np.max(FLG_keo_stacker_clip[1])) ); #make it a vector, order doesn't matter for FLG_keo_stacker_clip[1]
    else:
        if( np.isscalar(TEC_plotLimValu) == 1 ):
            TEC_plotLimValu = np.array( (np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim'])) ); #make it a vector
        #END IF
    #END IF

    #-----Plot TEC results as a Keogram-----
    #Plot just the TEC
    fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    divider = make_axes_locatable(ax); #prep to add an axis
    cax = divider.append_axes('right', size='2.0%', pad=0.35); #make a color bar axis
    
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    pltHelprX, pltHelprY = np.meshgrid( np.append(keo_stackerTime, keo_stackerTime[-1]+data['TEC']['data rate'])/3600, \
                settings['TEC']['keo']['keo plot latlong chunks']); #,vmin=np.min(settings_TEC['plot lim']), vmax=np.max(settings_TEC['plot lim'])
    im = ax.pcolormesh(pltHelprX, pltHelprY,  keo_stacker.T ,cmap=keo_TEC_colorMap); # pseudocolor plot "stretched" to the grid
    cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
    cbar.set_label(keo_TEC_dataName_wUnits); #tabel the colorbar
    cbar.ax.tick_params(labelsize=FONT_axisTick);
    # # cbar.set_clim(vmin=np.min(settings_TEC['plot lim']), vmax=np.max(settings_TEC['plot lim'])); #they changed how the code works, this doesn't work anymore
    # cbar.mappable.set_clim(vmin=np.min(settings_TEC['plot lim']), vmax=np.max(settings_TEC['plot lim'])); #now it's this
    # cax.yaxis.set_major_formatter(FormatStrFormatter('%.1f')); #force a rounded format
    # cax.yaxis.set_ticks(np.linspace(np.min(TEC_plotLimValu),np.max(TEC_plotLimValu),11)); #create useful tick marks
    if( FLG_keo_stacker_clip[0] == True ):
        cbar.mappable.set_clim(vmin=np.min(TEC_plotLimValu)/2, vmax=np.max(TEC_plotLimValu)/2); #now it's this
    else:
        cbar.mappable.set_clim(vmin=-np.nanstd(keo_stacker)*2.5, vmax=np.nanstd(keo_stacker)*2.5); #now it's this
        # cbar.mappable.set_clim(vmin=np.min(TEC_plotLimValu), vmax=np.max(TEC_plotLimValu)); #now it's this
    #END IF
    cax.yaxis.label.set_font_properties(FONT_axisLabelFM);
    
    if( FLG_keo_stacker == 2 ):
        ax.axvline(sunRise[1]*24,linestyle='--',linewidth=settings['plot']['line width']['smoller'],color='xkcd:dark magenta')
        ax.axvline(sunSet[1]*24,linestyle='--',linewidth=settings['plot']['line width']['smoller'],color='xkcd:dark turquoise')
    #END IF
    
    #    string_title = 'TEC Averaged on Angle of '+str(np.round(keo,2))+' deg and Width of '+ \
    #        str(np.round(settings['TEC']['keo']['keo width'],2))+' arcdeg, Avg Step # = '+str(keo_N)+ \
    #        ' arcdeg, Line Shows '+settings['TEC']['keo']['keo plot latlong name']+' of Millstone Hill Zenith Beam'; #create mecha title
    string_title = str(keo_stackerDaysStacked)+' Days Stacked | '+settings['TEC']['keo']['keo labels']+' Averaged on Angle of '+textNice(np.round(settings['TEC']['keo']['keo angle'],2))+' deg and Width of '+ \
        textNice(np.round(settings['TEC']['keo']['keo width'],2))+' arcdeg'; #create mecha title
    ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
    ax.set_xlabel('Relative time through a day, aligned to 0 UT [hr]',fontproperties=FONT_axisLabelFM); #set the x axis label
    ax.set_ylabel(settings['TEC']['keo']['keo plot latlong name']+' [arcdeg]',fontproperties=FONT_axisLabelFM); #set the y axis label
    
    xAxisTicks = np.arange( np.floor(np.min(keo_stackerTime/3600)), np.ceil(np.max(keo_stackerTime/3600)) + 2 , 2 ); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    
    keo_Range_Chunks_Long_Plot_autoTick = (np.ceil(np.max(settings['TEC']['keo']['keo plot latlong chunks'])) - np.floor(np.min(settings['TEC']['keo']['keo plot latlong chunks'])))/13; #tries to split the latitude range into 13 parts (based off of 180/15+1)
    if( keo_Range_Chunks_Long_Plot_autoTick > 25 ):
        keo_Range_Chunks_Long_Plot_autoTick = 30; #sets the tick setting to 15 arcdegrees per tick
    elif( keo_Range_Chunks_Long_Plot_autoTick > 10 ):
        keo_Range_Chunks_Long_Plot_autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
    elif( keo_Range_Chunks_Long_Plot_autoTick > 5 ):
        keo_Range_Chunks_Long_Plot_autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
    elif( keo_Range_Chunks_Long_Plot_autoTick > 2 ):
        keo_Range_Chunks_Long_Plot_autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
    elif( keo_Range_Chunks_Long_Plot_autoTick > 1 ):
        keo_Range_Chunks_Long_Plot_autoTick = 2; #sets the tick setting to 5 arcdegrees per tick
    elif( keo_Range_Chunks_Long_Plot_autoTick >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
        keo_Range_Chunks_Long_Plot_autoTick = 1; #                                                        sets the tick setting to 1 arcdegree per tick
    else:
        if(settings['TEC']['keo']['keo plot latlong name'] == 'Latitude'): #if Y axis is latitude, use latitude
            keo_Range_Chunks_Long_Plot_autoTick = (np.max(plotLatRange) - np.min(plotLatRange))/13; #just goes for it if it's a super tiny range
        elif(settings['TEC']['keo']['keo plot latlong name'] == 'Longitude'): #if Y axis is longitude, use longitude
            keo_Range_Chunks_Long_Plot_autoTick = (np.max(plotLongRange) - np.min(plotLongRange))/13; #just goes for it if it's a super tiny range
        #END IF
    #END IF
    yAxisTicks = np.round(np.arange( np.floor(np.min(settings['TEC']['keo']['keo plot latlong chunks'])),np.ceil(np.max(settings['TEC']['keo']['keo plot latlong chunks'])),keo_Range_Chunks_Long_Plot_autoTick ),2); #creates y ticks automagically
    ax.set_yticks(yAxisTicks); #set x axis ticks
    
    #Now drawing line of interest
    if( settings['TEC']['keo']['keo plot latlong name'] == 'Longitude' ): #if true, longitude
        if( (np.min(plotLongRange) <= longMillstone) & (np.max(plotLongRange) >= longMillstone) ): #only plot if it's in the long range specified
            ax.plot( np.linspace(np.floor(np.min(keo_stackerTime/3600)), np.ceil(np.max(keo_stackerTime/3600)), 10, endpoint=True) , #X time hr
                    np.ones(10)*longMillstone , #Y latitude OR longitude arcdeg
                    c='xkcd:black',linewidth=1); #plots a point with a black line
        #END IF
    else: #else latitude
        if( (np.min(plotLatRange) <= latMillstone) & (np.max(plotLatRange) >= latMillstone) ): #only plot if it's in the lat range specified
            ax.plot( np.linspace(np.floor(np.min(keo_stackerTime/3600)), np.ceil(np.max(keo_stackerTime/3600)), 10, endpoint=True) , #X time hr
                    np.ones(10)*latMillstone , #Y latitude OR longitude arcdeg
                    c='xkcd:black',linewidth=1); #plots a point with a black line
        #END IF
    #END IF
    
    ax.set_xlim( (np.floor(np.min(keo_stackerTime/3600)),np.ceil(np.max(keo_stackerTime/3600))) ); #force xlims
    
    figFitter(fig); #fit that fig fast
#END IF


#==============Analysis: automatic feature finder time==============
if( FLG_keo_featureFinder >= 1 ):
    sys.crash()
    from scipy.signal import fftconvolve, gaussian, argrelextrema
    from Code.GRITI_plotHelper_axisizerLatLong import GRITI_plotHelper_axisizerLatLong
    from Code.GRITI_plotHelper_axisizerTime import GRITI_plotHelper_axisizerTime
    from Code.TAS import TAS
    from skimage.filters import gaussian
    from skimage.measure import LineModelND, ransac
    from numba import jit
    
    
    # #--- create uint8 version cause that's what opencv reqs apparently ---
    # # either 1 for pos or 0 for neg
    # imgified = np.empty(data['TEC']['keo'].shape, dtype=np.bool_); #copy it, make it into bool
    # imgified[ data['TEC']['keo'] >= 0 ] = True
    # imgified[ data['TEC']['keo'] < 0 ] = False
    
    # # classify
    # imgified = np.zeros(data['TEC']['keo'].shape, dtype=np.int8); #copy it, make it into bool
    # mean = np.nanmean(data['TEC']['keo']);
    # stdev = np.nanstd(data['TEC']['keo']);
    # imgified[ data['TEC']['keo'] >= (mean+stdev*1) ] = 1
    # imgified[ data['TEC']['keo'] <= (mean-stdev*1) ] = -1
    
    # #enhance center
    imgified = np.copy(data['TEC']['keo']); #copy it
    imgified[ data['TEC']['keo'] >= 0 ] = imgified[ data['TEC']['keo'] >= 0 ]**(1/4); #enhance near-zero by ^1/4
    imgified[ data['TEC']['keo'] < 0 ] = -(np.abs(imgified[ data['TEC']['keo'] < 0 ])**(1/4)); #enhance near-zero by ^1/4
    
    # # classify enhanced
    # imgified = np.copy(data['TEC']['keo']); #copy it
    # imgified[ data['TEC']['keo'] >= 0 ] = imgified[ data['TEC']['keo'] >= 0 ]**(1/4); #enhance near-zero by ^1/4
    # imgified[ data['TEC']['keo'] < 0 ] = -(np.abs(imgified[ data['TEC']['keo'] < 0 ])**(1/4)); #enhance near-zero by ^1/4
    # mean = 0;
    # stdev = np.nanstd(imgified);
    # multr = 1;
    # imgified[ imgified >= (mean+stdev*multr) ] = 1
    # imgified[ imgified <= (mean-stdev*multr) ] = -1
    # imgified[ (imgified < (mean+stdev*multr)) & (imgified > (mean-stdev*multr)) ] = 0
    # # imgified = imgified.astype(np.int8); #convert
    
    # # deconvolve (goal to concentrate signal)
    # imgified = np.copy(data['TEC']['keo']); #copy it
    # # imgified[ data['TEC']['keo'] >= 0 ] = imgified[ data['TEC']['keo'] >= 0 ]**(1/4); #enhance near-zero by ^1/4
    # # imgified[ data['TEC']['keo'] < 0 ] = -(np.abs(imgified[ data['TEC']['keo'] < 0 ])**(1/4)); #enhance near-zero by ^1/4
    # rldIterations = 10;
    # centererSize = 11;    
    # k1d = gaussian(centererSize, std=.25).reshape(centererSize, 1)
    # centerer = np.outer(k1d, k1d)
    # # centerer = centerer[centererSize//2-2:centererSize//2+3,:]; #clip
    # # centerer = centerer[:, centererSize//2-2:centererSize//2+3]; #clip
    # # pad_up = imgified.shape[0] - centerer.shape[0]
    # # pad_down = imgified.shape[0] - centerer.shape[0]  # pad the bottom by the difference in the y dir
    # # pad_left = imgified.shape[1] - centerer.shape[1]
    # # pad_right = imgified.shape[1] - centerer.shape[1]  # pad the right by the difference in the x dir
    # # centerer = np.pad(centerer, ((np.int(np.floor(pad_up/2)), np.int(np.ceil(pad_down/2))), (np.int(np.floor(pad_left/2)), np.int(np.ceil(pad_right/2)))), 'constant',
    # #                         constant_values=0)  # pad so psf_pix is now the size of [stackSize,stackSize]
    # imgified = TAS(imgified, centerer, rldIterations, damper=0, weight=0, readout=0, factor_subsample=1);
    
    # #delta (1st deriv) in time
    # imgified = np.pad(np.diff(data['TEC']['keo'], axis=0), ((1,0),(0,0))); #diff it, re-pad with 0 at end so size is right
    # from scipy.interpolate import RBFInterpolator    
    # xx, yy = np.meshgrid(np.arange(0,imgified.shape[1]), np.arange(0,imgified.shape[0])); #mesh 1's, distance is meaningless in a grid like this (unless keogram angled, but that's a worry for l8tr)    
    # timeSpanner = 20+1; #20*30=10 min
    # RBF_interper = RBFInterpolator( np.vstack((xx[1:timeSpanner,:].ravel(), yy[1:timeSpanner,:].ravel())).T, imgified[1:timeSpanner,:].ravel(), kernel='linear'); #RBF but has built-in neighbor limiting
    # imgified[0:1,:] = RBF_interper(np.vstack((xx[0:1,:].ravel(), yy[0:1,:].ravel())).T); #linear RBF it right in
    # imgified[ imgified >= 0 ] = imgified[ imgified >= 0 ]**(1/4); #enhance near-zero by ^1/4
    # imgified[ imgified < 0 ] = -(np.abs(imgified[ imgified < 0 ])**(1/4)); #enhance near-zero by ^1/4
    
    # #delta (1st deriv) in space
    # imgified = np.pad(np.diff(data['TEC']['keo'], axis=1), ((0,0),(1,0))); #diff it, re-pad with 0 at end so size is right
    # imgified[ imgified >= 0 ] = imgified[ imgified >= 0 ]**(1/4); #enhance near-zero by ^1/4
    # imgified[ imgified < 0 ] = -(np.abs(imgified[ imgified < 0 ])**(1/4)); #enhance near-zero by ^1/4
    
    # #botched conversion, but it's interesting
    # imgified = np.copy(data['TEC']['keo']); #copy it, opencv needs 8-bit uints
    # imgified += np.min(imgified); # 0 it
    # imgified *= 255/np.max(imgified); #max out at 255
    # imgified = np.uint8(np.round(imgified)); #round then convert to uint8
    
    # # clean conversion, does a good job
    # imgified = np.copy(data['TEC']['keo']); #copy it, opencv needs 8-bit uints
    # imgified += np.abs(np.min(imgified)); # 0 it
    # imgified *= 255/np.max(imgified); #max out at 255
    # imgified = np.uint8(np.round(imgified)); #round then convert to uint8
    
    
    
    #================== become unbound =====================
    #function for checking nearby pts fast
    @jit(nopython=True,nogil=True,parallel=False,cache=True,fastmath=True) #nopython=True, nogil=True, parallel=True, cache=True , nogil=True, parallel=True ,fastmath=True
    def checking_checkers_the_bear(peaks_pos_0, peaks_pos_1, edger, close_arrayPossible, close_array):
        #important to init list in numba
        checkers_the_bear = [(peaks_pos_0, peaks_pos_1)]; #this'll hold pts to check
        while( len(checkers_the_bear) > 0 ):
            #edge check
            edger = edger & False; #0 them all
            if( checkers_the_bear[0][1]+1 < img_shape[1] ): #up
                edger[0] = True;
            #END IF
            if( checkers_the_bear[0][1]-1 >= 0 ): #down
                edger[1] = True;
            #END IF
            if( checkers_the_bear[0][0]-1 >= 0 ): #left
                edger[2] = True;
            #END IF
            if( checkers_the_bear[0][0]+1 < img_shape[0] ): #right
                edger[3] = True;
            #END IF
            
            #check all corners req'd (designed to ez pz add diagonals as well)
            if( edger[0] ):
                if( close_arrayPossible[checkers_the_bear[0][0], checkers_the_bear[0][1]+1] and (not close_array[checkers_the_bear[0][0], checkers_the_bear[0][1]+1]) ): #up
                    close_array[checkers_the_bear[0][0], checkers_the_bear[0][1]+1] = True; #good to go
                    checkers_the_bear.append((checkers_the_bear[0][0], checkers_the_bear[0][1]+1)); #note to check this new point too
                #END IF
            #END IF
            if( edger[1] ):
                if( close_arrayPossible[checkers_the_bear[0][0], checkers_the_bear[0][1]-1] and (not close_array[checkers_the_bear[0][0], checkers_the_bear[0][1]-1]) ): #down
                    close_array[checkers_the_bear[0][0], checkers_the_bear[0][1]-1] = True; #good to go
                    checkers_the_bear.append((checkers_the_bear[0][0], checkers_the_bear[0][1]-1)); #note to check this new point too
                #END IF
            #END IF
            if( edger[2] ):
                if( close_arrayPossible[checkers_the_bear[0][0]-1, checkers_the_bear[0][1]] and (not close_array[checkers_the_bear[0][0]-1, checkers_the_bear[0][1]]) ): #left
                    close_array[checkers_the_bear[0][0]-1, checkers_the_bear[0][1]] = True; #good to go
                    checkers_the_bear.append((checkers_the_bear[0][0]-1, checkers_the_bear[0][1])); #note to check this new point too
                #END IF
            #END IF
            if( edger[3] ):
                if( close_arrayPossible[checkers_the_bear[0][0]+1, checkers_the_bear[0][1]] and (not close_array[checkers_the_bear[0][0]+1, checkers_the_bear[0][1]]) ): #right
                    close_array[checkers_the_bear[0][0]+1, checkers_the_bear[0][1]] = True; #good to go
                    checkers_the_bear.append((checkers_the_bear[0][0]+1, checkers_the_bear[0][1])); #note to check this new point too
                #END IF
            #END IF
                       
            #remove pt
            checkers_the_bear.pop(0); #removes current element, once checkers_the_bear is empty while loop ends
        #END WHILE
        
        return close_array
    #END DEF
            
    #smooth it out
    imgifiedSmoothed = gaussian(imgified, 5, truncate=4, mode='reflect');
    
    # imgifiedSmoothed = imgified; #no smoothing - too jagged essentially
    # --- ride peaks to discover extent ---
    #get stats for cruising
    stdev = np.nanstd(imgifiedSmoothed);
    mean = 0; #ideally 0
    stdev_ratio = 1; #within 100% of stdev is a feature
    # imgified_maxVal = np.nanmax(imgifiedSmoothed);
    # imgified_minVal = np.nanmin(imgifiedSmoothed);
    num_pts_needed = np.int64(imgified.size*.0005); # 0.005% of size is needed at least
    num_pts_max = np.int64(imgified.size*.05); # 0.5% of size is needed at max
    
    
    temp = np.where((imgifiedSmoothed > mean+1.80*stdev) | (imgifiedSmoothed < mean-1.80*stdev)); #get pos and neg outliers
    temp_sorted = np.argsort(-np.abs(imgifiedSmoothed[temp])); #let's get this sorted so it goes biggest down
    temp = (temp[0][temp_sorted], temp[1][temp_sorted]); #rebuild the tuple but sorted, numpy doesn't dig the coords in a list instead of tuple at all
    peaks_pos = list(temp); #get pos/neg outliers first in maxima order (big fish first idea)
    #-- fill in via use extrema alg ot pick up anything else (it gets way too much but that's ok whatever) --
    temp = argrelextrema(imgifiedSmoothed, np.greater, axis=0); #greater than axis 0 (time)
    peaks_pos[0] = np.append(peaks_pos[0], temp[0]); #yeet
    peaks_pos[1] = np.append(peaks_pos[1], temp[1]); #yeet
    temp = argrelextrema(imgifiedSmoothed, np.less, axis=0); #less than axis 0 (time)
    peaks_pos[0] = np.append(peaks_pos[0], temp[0]); #yeet
    peaks_pos[1] = np.append(peaks_pos[1], temp[1]); #yeet
    temp = argrelextrema(imgifiedSmoothed, np.greater, axis=1); #greater than axis 1 (geo)
    peaks_pos[0] = np.append(peaks_pos[0], temp[0]); #yeet
    peaks_pos[1] = np.append(peaks_pos[1], temp[1]); #yeet
    temp = argrelextrema(imgifiedSmoothed, np.less, axis=1); #less than axis 1 (geo)
    peaks_pos[0] = np.append(peaks_pos[0], temp[0]); #yeet
    peaks_pos[1] = np.append(peaks_pos[1], temp[1]); #yeet
    
    # peaks_pos = [np.array( (3468,), dtype=np.int64), np.array( (110,), dtype=np.int64)]; #for testiung
    x_vals = (data['TEC']['time unique']  - dateRange_dayNum_zeroHr[1]*86400)/3600; #I don't care here
    y_vals = settings['TEC']['keo']['keo plot latlong chunks'][0:-1] + np.median(np.diff(settings['TEC']['keo']['keo plot latlong chunks']))/2; #gotta get the middles
    img_shape = imgified.shape;
    close_array = np.zeros(img_shape, dtype=np.bool_); #to cruise
    close_arrayAll = np.zeros(img_shape, dtype=np.bool_); #to remember all found places
    edger = np.zeros(4, dtype=np.bool_); #holds if edges are safe
    liner = []; #prep up
    for i in range(0, peaks_pos[0].size):
        if( close_arrayAll[peaks_pos[0][i], peaks_pos[1][i]] == False ):
            close_array = close_array & False; #0 them all
            close_array[peaks_pos[0][i], peaks_pos[1][i]] = True; #start the search
            
            #create array of possible related values
            if( imgifiedSmoothed[peaks_pos[0][i], peaks_pos[1][i]] > mean ):
                # stdev_ratio = np.abs(imgified[peaks_pos[0][i], peaks_pos[1][i]]/imgified_maxVal); #estimate stdev_ratio based on distance to max value (closer to max gets a wider margin to work with)
                close_arrayPossible = (imgifiedSmoothed >= (imgifiedSmoothed[peaks_pos[0][i], peaks_pos[1][i]] - stdev*stdev_ratio)) & (~close_arrayAll); #possible values plus areas not already something
            else:
                # stdev_ratio = np.abs(imgified[peaks_pos[0][i], peaks_pos[1][i]]/imgified_minVal); #estimate stdev_ratio based on distance to max value (closer to max gets a wider margin to work with)
                close_arrayPossible = (imgifiedSmoothed <= (imgifiedSmoothed[peaks_pos[0][i], peaks_pos[1][i]] + stdev*stdev_ratio)) & (~close_arrayAll); #possible values plus areas not already something
            #END IF
            
            #check all sides over and over
            close_array = checking_checkers_the_bear(peaks_pos[0][i], peaks_pos[1][i], edger, close_arrayPossible, close_array); #yeet
            
            #make sure pts are enough to care about
            if( (close_array.sum() > num_pts_needed) & (close_array.sum() < num_pts_max) ):
                #add to close_arrayAll
                close_arrayAll[close_array] = True; #yeet it in
                                        
                # get pts involved
                kj = np.where(close_array); #get where
                time_out = x_vals[kj[0]]; #get the times associated with the locs
                geo_out = y_vals[kj[1]]; #get the geos associated with the locs
                
                # get a good fit
                model_robust, _ = ransac(np.column_stack((time_out,geo_out)), LineModelND, min_samples=2, residual_threshold=1, max_trials=1000);
                
                #fit to where
                # polly = np.polynomial.polynomial.Polynomial.fit(time_out, geo_out, deg=1).convert().coef; #they borked this call, polyfit so much more straightforward [did not deal with outliers well enough at all sadly]
                extent = np.array( ((np.min(time_out), np.max(time_out)), (np.min(geo_out), np.max(geo_out))) ); #(X = Time, Y = Geo)
            
                x = model_robust.predict_x(extent[1]);
                y = extent[1];
                m = np.diff(y)/np.diff(x); #they give the line ifno as model_robust.params as some weird stuff, so just do some basic math to get it into slope/intercept form
                b = y[0] - m*x[0];
                polly = np.array( (b, m) );
            
                liner.append({'line coeffs':polly, 'extent':extent, 'robust fit':model_robust}); #add on a dict so I don't forget what they mean
            #END IF
        #END IF
    #END FOR i
    
    # imgified[close_array] = np.nan
    
    #--- plot ---
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    ax = [ax]; #wrap into list for ez later
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    divider = make_axes_locatable(ax[0]); #prep to add an axis
    cax = divider.append_axes('right', size='2.0%', pad=0.15); #make a color bar axis
    ax[0].set_aspect('auto');
    pltHelprX, pltHelprY = np.meshgrid( (np.append(data['TEC']['time unique'],data['TEC']['time unique'][-1]+np.median(np.diff(data['TEC']['time unique']))) - dateRange_dayNum_zeroHr[1]*86400)/3600, \
                settings['TEC']['keo']['keo plot latlong chunks']);
    im = ax[0].pcolormesh(pltHelprX, pltHelprY,  data['TEC']['keo'].T ,cmap=settings['TEC']['colormap'], linewidth=0, rasterized=False); # pseudocolor plot "stretched" to the grid

    #draw lines found on
    for i in range(0, len(liner)):
        ax[0].plot( liner[i]['extent'][0], (liner[i]['line coeffs'][0] + liner[i]['line coeffs'][1]*liner[i]['extent'][0][0], liner[i]['line coeffs'][0] + liner[i]['line coeffs'][1]*liner[i]['extent'][0][1]), linewidth=3, linestyle='--', c='xkcd:white');
    #END FOR i

    # #draw lines found on
    # for i in range(0, len(liner)):
    #     ax[0].plot( liner[i]['extent'][0], liner[i]['robust fit'].predict_y(liner[i]['extent'][0]), linewidth=3, c='xkcd:white');
    # #END FOR i

    cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
    cbar.set_label(settings['TEC']['keo']['keo labels']+settings['TEC']['keo']['keo units']); #tabel the colorbar
    for tick in cbar.ax.yaxis.get_major_ticks(): #if only I could apply the font manager directly
        tick.label2.set_fontproperties(FONT_axisTickFM); #yee
    #END FOR tick
    # cbar.mappable.set_clim(vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim'])); #now it's this
    cax.yaxis.label.set_font_properties(FONT_axisLabelFM);
    string_Title = settings['TEC']['keo']['keo labels']+' Averaged on Angle of '+textNice(np.round(keo_angle,2))+' ° and Width of '+ \
        textNice(np.round(settings['TEC']['keo']['keo width'],2))+' arc°'; #create mecha title - for debug so hardcode unit
    ax[0].set_title(string_Title,fontproperties=FONT_titleFM); #set the title
    ax[0].set_xlabel('Time in UT '+settings_plot['unit L']+'hr'+settings_plot['unit R']+' | 0 Hr on '+dateRange_zeroHr_monthName+' '+textNice(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' (Day '+textNice(dateRange_dayNum_zeroHr[1])+'), '+textNice(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM); #set the x axis label
    if( 'degree label' in settings_map ):
        latlong_unitName = settings_map['degree label']; #use supplied label
    else:
        latlong_unitName = '°';
    #END IF
    if( latlong_unitName != '' ):
        latlong_unitName_bracketed = settings_plot['unit L']+latlong_unitName+settings_plot['unit R']; #bracket it
    else:
        latlong_unitName_bracketed = ''; #nada
    #END IF
    if( 'indicate direction' in settings_map ):
        if( settings_map['indicate direction'][0] == True ):
            if(settings['TEC']['keo']['keo plot latlong name'] == 'Latitude'):
                keo_plotLatLong_dirAdder = settings_map['indicate direction'][1]['lat']; #get the lat
            else:
                keo_plotLatLong_dirAdder = settings_map['indicate direction'][1]['long']; #get the long
            #END IF
        else:
            keo_plotLatLong_dirAdder = ''; #nada
        #END IF
    else:
        keo_plotLatLong_dirAdder = ''; #nada
    #END IF
    if( coordType == 'geo' ):
        ax[0].set_ylabel(settings['TEC']['keo']['keo plot latlong name']+' '+latlong_unitName_bracketed+keo_plotLatLong_dirAdder,fontproperties=FONT_axisLabelFM); #set the y axis label
    elif( coordType == 'mag' ):
        ax[0].set_ylabel(settings['TEC']['keo']['keo plot latlong name']+' (Geomag) '+latlong_unitName_bracketed+keo_plotLatLong_dirAdder,fontproperties=FONT_axisLabelFM); #set the y axis label
    #END IF
    GRITI_plotHelper_axisizerLatLong(settings['TEC']['keo']['keo plot latlong chunks'],ax=ax[0],axDir='y',tickNumGoal=17);
    timezAxisTicks, timezAxisLims = GRITI_plotHelper_axisizerTime((data['TEC']['time unique']-dateRange_dayNum_zeroHr[1]*86400)/3600,ax=ax[0]); #automagic time ticks here
    figFitter(fig); #fit the fig fast
    plt.show()
        
    
    #remove times w/ undesired activity/near sunrise/sunset
    FLG_keo_featureFinder_ignore = [True, {'ref data path':['TEC'], 'data path':['SuperMAG','SMUs'], 'comparison':'elevated|auto,pos only & nan & sunrisesunset|'+str(latLong_ref[0][0])+','+str(latLong_ref[0][1])+',4500,4500', 'time offset':122*60}]; #True at start enables, dict is list for the data['path']['to']['data'], the comparison to make, and the comparison value (data needs to be 1D)

    kCompare = subfun_comparator(FLG_keo_featureFinder_ignore[1], data, dates=dates); #get when is bad

    #prune 
    nogoodtimes = data['TEC']['time unique aligned'][kCompare]/3600; #get em to ditch
    for i in range(len(liner)-1, -1, -1): #backwards bc python
        extent_real = np.array( ( (np.min(settings['TEC']['keo']['keo plot latlong chunks']) - liner[i]['line coeffs'][0])/liner[i]['line coeffs'][1], \
                                  (np.max(settings['TEC']['keo']['keo plot latlong chunks']) - liner[i]['line coeffs'][0])/liner[i]['line coeffs'][1]) );
        k = np.any( (np.min(extent_real) <= nogoodtimes) & (np.max(extent_real) >= nogoodtimes) );
        # k = np.any( (np.min(liner[i]['extent'][0]) <= nogoodtimes) & (np.max(liner[i]['extent'][0]) >= nogoodtimes) );
        if( k == True ):
            liner.pop(i); #yeet
        #END IF
    #END FOR i
    
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    ax = [ax]; #wrap into list for ez later
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    divider = make_axes_locatable(ax[0]); #prep to add an axis
    cax = divider.append_axes('right', size='2.0%', pad=0.15); #make a color bar axis
    ax[0].set_aspect('auto');
    pltHelprX, pltHelprY = np.meshgrid( (np.append(data['TEC']['time unique'],data['TEC']['time unique'][-1]+np.median(np.diff(data['TEC']['time unique']))) - dateRange_dayNum_zeroHr[1]*86400)/3600, \
                settings['TEC']['keo']['keo plot latlong chunks']);
    im = ax[0].pcolormesh(pltHelprX, pltHelprY,  data['TEC']['keo'].T ,cmap=settings['TEC']['colormap'], linewidth=0, rasterized=False); # pseudocolor plot "stretched" to the grid

    #draw lines found on
    for i in range(0, len(liner)):
        ax[0].plot( liner[i]['extent'][0], (liner[i]['line coeffs'][0] + liner[i]['line coeffs'][1]*liner[i]['extent'][0][0], liner[i]['line coeffs'][0] + liner[i]['line coeffs'][1]*liner[i]['extent'][0][1]), linewidth=3, linestyle='--', c='xkcd:white');
    #END FOR i

    # #draw lines found on
    # for i in range(0, len(liner)):
    #     ax[0].plot( liner[i]['extent'][0], liner[i]['robust fit'].predict_y(liner[i]['extent'][0]), linewidth=3, c='xkcd:white');
    # #END FOR i
    
    pltr_time = np.copy(data['TEC']['time unique']); #copy time
    k = np.logical_not(kCompare); #remove times not highlighted
    pltr_time = np.delete(pltr_time,k,axis=0); #delete em

    k = np.isclose(np.diff(pltr_time), np.median(np.diff(data['TEC']['time unique']))); #find contiguous time bits
    pltr_time = (pltr_time - dateRange_dayNum_zeroHr[1]*86400)/3600; #for plottin, adjust to hrs
    kj = np.where(~k)[0]+1; #add 1 for index b/c diff
    if(kj[0] != 0):
        kj = np.insert(kj, 0, 0); #insert 0
    #END IF
    if(kj[-1] != (pltr_time.size-1) ):
        kj = np.append(kj, pltr_time.size-1); #insert end size
    #END IF
    for j in range(0,kj.size-1):
        ax[0].axvspan(pltr_time[kj[j]], pltr_time[kj[j+1]-1], ymin=0, ymax=1, alpha=0.45, edgecolor='none', facecolor='xkcd:brick red');
    #END FOR j

    cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
    cbar.set_label(settings['TEC']['keo']['keo labels']+settings['TEC']['keo']['keo units']); #tabel the colorbar
    for tick in cbar.ax.yaxis.get_major_ticks(): #if only I could apply the font manager directly
        tick.label2.set_fontproperties(FONT_axisTickFM); #yee
    #END FOR tick
    # cbar.mappable.set_clim(vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim'])); #now it's this
    cax.yaxis.label.set_font_properties(FONT_axisLabelFM);
    string_Title = settings['TEC']['keo']['keo labels']+' Averaged on Angle of '+textNice(np.round(keo_angle,2))+' ° and Width of '+ \
        textNice(np.round(settings['TEC']['keo']['keo width'],2))+' arc°'; #create mecha title - for debug so hardcode unit
    ax[0].set_title(string_Title,fontproperties=FONT_titleFM); #set the title
    ax[0].set_xlabel('Time in UT '+settings_plot['unit L']+'hr'+settings_plot['unit R']+' | 0 Hr on '+dateRange_zeroHr_monthName+' '+textNice(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' (Day '+textNice(dateRange_dayNum_zeroHr[1])+'), '+textNice(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM); #set the x axis label
    if( 'degree label' in settings_map ):
        latlong_unitName = settings_map['degree label']; #use supplied label
    else:
        latlong_unitName = '°';
    #END IF
    if( latlong_unitName != '' ):
        latlong_unitName_bracketed = settings_plot['unit L']+latlong_unitName+settings_plot['unit R']; #bracket it
    else:
        latlong_unitName_bracketed = ''; #nada
    #END IF
    if( 'indicate direction' in settings_map ):
        if( settings_map['indicate direction'][0] == True ):
            if(settings['TEC']['keo']['keo plot latlong name'] == 'Latitude'):
                keo_plotLatLong_dirAdder = settings_map['indicate direction'][1]['lat']; #get the lat
            else:
                keo_plotLatLong_dirAdder = settings_map['indicate direction'][1]['long']; #get the long
            #END IF
        else:
            keo_plotLatLong_dirAdder = ''; #nada
        #END IF
    else:
        keo_plotLatLong_dirAdder = ''; #nada
    #END IF
    if( coordType == 'geo' ):
        ax[0].set_ylabel(settings['TEC']['keo']['keo plot latlong name']+' '+latlong_unitName_bracketed+keo_plotLatLong_dirAdder,fontproperties=FONT_axisLabelFM); #set the y axis label
    elif( coordType == 'mag' ):
        ax[0].set_ylabel(settings['TEC']['keo']['keo plot latlong name']+' (Geomag) '+latlong_unitName_bracketed+keo_plotLatLong_dirAdder,fontproperties=FONT_axisLabelFM); #set the y axis label
    #END IF
    GRITI_plotHelper_axisizerLatLong(settings['TEC']['keo']['keo plot latlong chunks'],ax=ax[0],axDir='y',tickNumGoal=17);
    timezAxisTicks, timezAxisLims = GRITI_plotHelper_axisizerTime((data['TEC']['time unique']-dateRange_dayNum_zeroHr[1]*86400)/3600,ax=ax[0]); #automagic time ticks here
    figFitter(fig); #fit the fig fast
    plt.show()
    
    
#END IF

#==============Analysis: delta-vTEC Double Keo w/ AMPERE==============
if( FLG_doubleKeo >= 1 ):
    from Code.subfun_timeMatch import subfun_timeMatch
    from Code.subfun_filter import subfun_filter
    import copy
    
    #----- Unpack -----
    AMPERE_timeUnique = data['AMPERE']['time unique']; #unpack
    
    #----- Repack -----
    settings['double keo'] = {}; #prep a dict
    for i in range(0,len(doubleKeo_latLong)):
        settings['double keo'][i] = copy.deepcopy(settings['TEC']['keo']); #copy a dict as a template
        settings['double keo'][i]['keo N'] = doubleKeo_N[i]; #set
        settings['double keo'][i]['keo width orig'] = doubleKeo_width_orig[i]; #set
        settings['double keo'][i]['keo angle'] = doubleKeo_angle_orig[i]; #set
        settings['double keo'][i]['keo 45 lat or long'] = doubleKeo_45vsLatLong[i]; #set
    #END FOR i
    settings_doubleKeo_map = {}; #prep a dict
    for i in range(0,len(doubleKeo_latLong)):
        settings_doubleKeo_map[i] = {}; #prep another dict
        settings_doubleKeo_map[i]['lat range'] = doubleKeo_latLong[i][0]; #set
        settings_doubleKeo_map[i]['long range'] = doubleKeo_latLong[i][1]; #set
        settings_doubleKeo_map[i]['site coords'] = settings_map['site coords']; #set
        settings_doubleKeo_map[i]['lat autotick fancy'] = settings_map['lat autotick fancy']; #set
        settings_doubleKeo_map[i]['projection'] = settings_map['projection']; #set
        settings_doubleKeo_map[i]['site marker type'] = settings_map['site marker type'];
        settings_doubleKeo_map[i]['site marker color'] = settings_map['site marker color'];
        settings_doubleKeo_map[i]['site marker size'] = settings_map['site marker size'];
        settings_doubleKeo_map[i]['coord type'] = settings_map['coord type'];
    #END FOR i
    
    #prep TEC data
    doubleKeo_keo = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_angle = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_width = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_plotSpacing = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_plotSpacingName = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    for i in range(0,len(doubleKeo_latLong)):
        (doubleKeo_keo[i], settings['double keo'][i]) = \
        GRITI_keo_keogrammer(data['TEC']['dTEC'] ,data['TEC']['time'], data['TEC']['lat'], data['TEC']['long'],
            TEC_timeUnique, TEC_timeUnique, dates, \
            settings['double keo'][i], settings_paths, settings_doubleKeo_map[i], settings_plot,
            FLG_fancyPlot=FLG_fancyPlot,FLG_disablePlot=2,FLG_disableText=1,FLG_disableCache=0);
        doubleKeo_angle[i] = settings['double keo'][i]['keo angle']; #unpack
        doubleKeo_width[i] = settings['double keo'][i]['keo width']; #unpack
        doubleKeo_plotSpacing[i] = settings['double keo'][i]['keo plot latlong chunks']; #unpack
        doubleKeo_plotSpacingName[i] = settings['double keo'][i]['keo plot latlong name']; #unpack
        # (doubleKeo_keo[i], doubleKeo_angle[i], doubleKeo_width[i], \
        # doubleKeo_plotSpacing[i], doubleKeo_plotSpacingName[i]) = \
        #     GRITI_TEC_keo(doubleKeo_latLong[i][0],doubleKeo_latLong[i][1],TEC_timeUnique,\
        #         TEC_plotLimValu,'jet',data['TEC']['dTEC'],data['TEC']['time'],data['TEC']['lat'],data['TEC']['long'],data['time ref'],doubleKeo_angle_orig[i], \
        #         doubleKeo_N[i],doubleKeo_width_orig[i],doubleKeo_45vsLatLong[i],avgPt_coords,geoMap_projectionStyle,\
        #         dateRange_dayNum_zeroHr,plotLatRange_autoTick,plotLongRange_autoTick,plotLongRange_autoTick_Crunched, gif_Millstone_Marker, gif_Millstone_Marker_Color, \
        #         gif_Millstone_Marker_Size,FONT_titleFM,FONT_axisTick,FONT_axisTickFM,FONT_axisLabelFM,BasemapFixDir,\
        #         'delta-vTEC','delta-vTEC [TECU]',FLG_fancyPlot,PLOT_lineWidth, folder, journal_width_2C,journal_height_max,journal_dpi,\
        #         keo_polarMode=0,FLG_disablePlot=2);
        #         #call the mecha function that runs the keo alg and makes a plot showing the averaging are
    #END FOR i
    
    #prep AMPERE data
    doubleKeo_AMPERE_integrated = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_AMPERE_integrated_noFilt = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_AMPERE_time = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_AMPERE_timeHr = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    sixMin_timeUnique = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    
    AMPERE_plot_label = settings['AMPERE']['labels'][AMPERE_dataType]+settings['AMPERE']['units'][AMPERE_dataType]; #get the label
    AMPERE_plot_label_noUnits = settings['AMPERE']['labels'][AMPERE_dataType]; #remove the (units)    
    
    sixMin_timeUnique_base = np.arange(dates['date range zero hr hour bounds'][0]*3600,dates['date range zero hr hour bounds'][1]*3600,data['AMPERE']['data rate']); #sec, arange time stamps in 6 minute steps [or whatever is the AMPERE data rate]
    for i in range(0,len(doubleKeo_latLong)):
        #--- Integrate AMPERE Data ---
        doubleKeo_AMPERE_integrated_noFilt[i] = GRITI_AMPERE_integrator(data['AMPERE'], dates, settings['AMPERE'], doubleKeo_latLong[i][0], doubleKeo_latLong[i][1], 
                                                                 FLG_doubleKeo_AMPERE_integrateMethod[i], doubleKeo_AMPERE_integrateMethod_val[i], 
                                                                 AMPERE_integrateMethod_coordType=doubleKeo_AMPERE_coordType, AMPERE_integrateMethod_coordType_global=settings['map']['coord type'], GRITI_import_AMPERE=GRITI_import_AMPERE, AMPERE_desired_latLongSteps=settings['AMPERE']['lat long steps'],
                                                                 AMPERE_import_AMPERE_hemi=settings_map['hemi'], settings_config=settings['config'], settings_paths=settings['paths'],
                                                                 AMPERE_integrateMethod_radiusLoc=doubleKeo_AMPERE_radiusNloc[1], AMPERE_integrateMethod_radius=doubleKeo_AMPERE_radiusNloc[0]); #integrate with the integrator function

        #--- Filter if req'd ---
        doubleKeo_AMPERE_integrated[i] = subfun_filter( doubleKeo_AMPERE_integrated_noFilt[i], FLG_doubleKeo_AMPERE_filtMethod, dataTime = AMPERE_timeUnique, dataRate = data['AMPERE']['data rate'], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
        
        #--- Adjust by the time offset ---
        #Do this before the time matching so everything is well aligned
        if( np.isclose(np.mod(doubleKeo_AMPERE_timeDelay[i]*3600,1),0.0) ):
            doubleKeo_AMPERE_time[i] = AMPERE_timeUnique + np.int32(doubleKeo_AMPERE_timeDelay[i]*3600); #it all stays integers
            sixMin_timeUnique[i] = sixMin_timeUnique_base + np.int32(doubleKeo_AMPERE_timeDelay[i]*3600); #it all stays integers
        else:
            doubleKeo_AMPERE_time[i] = np.float64(AMPERE_timeUnique) + doubleKeo_AMPERE_timeDelay[i]*3600; #it all becomes floats
            sixMin_timeUnique[i] = np.float64(sixMin_timeUnique_base) + doubleKeo_AMPERE_timeDelay[i]*3600; #it all stays integers
        #END IF
        
        # #--- Time match to 6 minutes if needed ---
        # if( np.isclose(data['AMPERE']['data rate'],360.) == False ):
        #     doubleKeo_AMPERE_integrated[i], doubleKeo_AMPERE_time[i] = subfun_timeMatch(doubleKeo_AMPERE_integrated[i], (doubleKeo_AMPERE_time[i] - dateRange_dayNum_zeroHr[1]*86400), sixMin_timeUnique[i], timeMatch_delta=360., FLG_removeNaNs=0, FLG_useSum=1); #time match alg to align to 6 minute cadence, add because it's a count (?)
        #     doubleKeo_AMPERE_timeHr[i] = doubleKeo_AMPERE_time[i]/3600; #hr, convert to hr with 0 hr at specified day
        #     doubleKeo_AMPERE_time[i] += dateRange_dayNum_zeroHr[1]*86400; #add this back in to be consistent
        # else:
        #     if( doubleKeo_AMPERE_time[i].size == sixMin_timeUnique[i].size ):
        #         if( np.all(np.isclose( (doubleKeo_AMPERE_time[i] - dateRange_dayNum_zeroHr[1]*86400),sixMin_timeUnique[i])) ):
        #             doubleKeo_AMPERE_timeHr[i] = (doubleKeo_AMPERE_time[i] - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
        #         else:
        #             doubleKeo_AMPERE_integrated[i], doubleKeo_AMPERE_time[i] = subfun_timeMatch(doubleKeo_AMPERE_integrated[i], (doubleKeo_AMPERE_time[i] - dateRange_dayNum_zeroHr[1]*86400), sixMin_timeUnique[i], timeMatch_delta=360., FLG_removeNaNs=0, FLG_useSum=1); #time match alg to align to 6 minute cadence, add because it's a count (?)
        #             doubleKeo_AMPERE_timeHr[i] = doubleKeo_AMPERE_time[i]/3600; #hr, convert to hr with 0 hr at specified day
        #             doubleKeo_AMPERE_time[i] += dateRange_dayNum_zeroHr[1]*86400; #add this back in to be consistent
        #         #END IF
        #     else:
        #         doubleKeo_AMPERE_integrated[i], doubleKeo_AMPERE_time[i] = subfun_timeMatch(doubleKeo_AMPERE_integrated[i], (doubleKeo_AMPERE_time[i] - dateRange_dayNum_zeroHr[1]*86400), sixMin_timeUnique[i], timeMatch_delta=360., FLG_removeNaNs=0, FLG_useSum=1); #time match alg to align to 6 minute cadence, add because it's a count (?)
        #         doubleKeo_AMPERE_timeHr[i] = doubleKeo_AMPERE_time[i]/3600; #hr, convert to hr with 0 hr at specified day
        #         doubleKeo_AMPERE_time[i] += dateRange_dayNum_zeroHr[1]*86400; #add this back in to be consistent
        #     #END IF
        # #END IF
        doubleKeo_AMPERE_timeHr[i] = (doubleKeo_AMPERE_time[i]-dates['date range zero hr dayNum'][1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    #END FOR i
    
    #pack for later
    data['double keo'] = {
        'keo':doubleKeo_keo,
        'time unique':TEC_timeUnique,
        'data rate':TEC_dataRate,
        'AMPERE integrated':doubleKeo_AMPERE_integrated,
        'AMPERE integrated no filter':doubleKeo_AMPERE_integrated_noFilt,
        'AMPERE time':doubleKeo_AMPERE_time,
        'AMPERE time hr':doubleKeo_AMPERE_timeHr,
        };
    settings['double keo']['keo data type'] = settings['double keo'][0]['keo data type'];
    settings['double keo']['lat long'] = doubleKeo_latLong;
    if( 'doubleKeo_latLongComb' in locals() ):
        settings['double keo']['lat long combo'] = doubleKeo_latLongComb; #only exists if plot=2 is on I think
        settings['double keo']['plot alignments'] = doubleKeo_alignments; #only exists if plot=2 is on I think
    #END IF
    settings['double keo']['angle'] = doubleKeo_angle;
    settings['double keo']['width'] = doubleKeo_width;
    settings['double keo']['plot spacing'] = doubleKeo_plotSpacing;
    settings['double keo']['plot spacing name'] = doubleKeo_plotSpacingName;
    settings['double keo']['extra line'] = FLG_doubleKeo_plot_include2ndLine;
    settings['double keo']['extra line delay hr'] = FLG_doubleKeo_plot_include2ndLine_delay;
    settings['double keo']['nite times'] = doubleKeo_niteTimes;
    settings['double keo']['arrow times'] = doubleKeo_arrowTimes;
    settings['double keo']['AMPERE integrate method'] = FLG_doubleKeo_AMPERE_integrateMethod;
    settings['double keo']['AMPERE integrate val'] = doubleKeo_AMPERE_integrateMethod_val;
    settings['double keo']['AMPERE integrate coord type'] = doubleKeo_AMPERE_coordType;
    settings['double keo']['AMPERE radius n loc'] = doubleKeo_AMPERE_radiusNloc;
    settings['double keo']['AMPERE filter method'] = FLG_doubleKeo_AMPERE_filtMethod;
    settings['double keo']['AMPERE plot lim'] = doubleKeo_AMPERE_plotLim;
    settings['double keo']['AMPERE time delay'] = doubleKeo_AMPERE_timeDelay;
    settings['double keo']['AMPERE alignments'] = doubleKeo_AMPERE_latAlign;
    settings['double keo']['AMPERE plot label'] = settings['AMPERE']['labels'][AMPERE_dataType]+settings['AMPERE']['units'][AMPERE_dataType]; #get the label
    settings['double keo']['AMPERE plot label no units'] = settings['AMPERE']['labels'][AMPERE_dataType]; #remove the (units)
#END IF

if( FLG_doubleKeo_plot == 1 ):
    from matplotlib.patches import ConnectionPatch, Rectangle
    from Code.subfun_timeMatch import subfun_timeMatch
    from Code.subfun_figFitter import figFitter
    from Code.subfun_filter import subfun_filter
    from Code.subfun_sunAlsoRises import sunAlsoRises
    from Code.subfun_date_to_dayNum import subfun_date_to_dayNum
    import copy
    
    #-----Plot TEC results as a Keogram w/ AMPERE integrated line as well-----
    #Prep the plot
    fig, ax = plt.subplots(nrows=len(doubleKeo_latLong), ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    axTwinx = []; #prep this list, holds the twinx axes, will grow as we plot
    cax = []; #prep
    caxTwinx = []; #prep
    for i in range(0,len(doubleKeo_latLong)):
        divider = make_axes_locatable(ax[i]); #prep to add an axis
        cax.append(divider.append_axes('right', size='2.0%', pad=1.75)); #make a color bar axis, append
        
        #Remove the aspect ratio from the basemap so it fills the screen better
        ax[i].set_aspect('auto');
        
        #-----Plot TEC results as a keogram-----
        pltHelprX, pltHelprY = np.meshgrid( (np.append(TEC_timeUnique,TEC_timeUnique[-1]+TEC_dataRate) - dateRange_dayNum_zeroHr[1]*86400)/3600, \
                    doubleKeo_plotSpacing[i]);
        im = ax[i].pcolormesh(pltHelprX, pltHelprY,  doubleKeo_keo[i].T ,vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim']),cmap=settings['TEC']['colormap']); # pseudocolor plot "stretched" to the grid
        cbar = fig.colorbar(im, cax=cax[i], orientation='vertical'); #create a colorbar using the prev. defined cax
        cbar.set_label(settings['TEC']['name']+settings['TEC']['units']); #tabel the colorbar
        cbar.ax.tick_params(labelsize=FONT_axisTick);
        #cbar.set_clim(vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim'])); #they changed how the code works, this doesn't work anymore
        cbar.mappable.set_clim(vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim'])); #now it's this
        cax[i].yaxis.set_ticks(np.linspace(np.min(settings['TEC']['plot lim']),np.max(settings['TEC']['plot lim']),5)); #create useful tick marks
        cax[i].yaxis.set_major_formatter(FormatStrFormatter('%.2f')); #force a rounded format
        cax[i].yaxis.label.set_font_properties(FONT_axisLabelFM);
        
        #-----Plot AMPERE results as a 1D line-----
        axTwinx.append(ax[i].twinx()); #add on the new twinx axis
        doubleKeo_AMPERE_integrated_plot = np.copy(doubleKeo_AMPERE_integrated[i]); #copy
        if( doubleKeo_AMPERE_plotLim != False ):
            doubleKeo_AMPERE_integrated_plot[ doubleKeo_AMPERE_integrated_plot > doubleKeo_AMPERE_plotLim ] = doubleKeo_AMPERE_plotLim; #cap the max val
        #END IF
        axTwinx[i].plot( doubleKeo_AMPERE_timeHr[i], doubleKeo_AMPERE_integrated_plot , linewidth=settings['plot']['line width']['regular'] , color='xkcd:violet'); #plot
        axTwinx[i].set_ylabel(AMPERE_plot_label,fontproperties=FONT_axisLabelFM); #set the y axis label
        #now adjust the ylim so the lines are about where we want them to be
        lineOfInterestLoc = (doubleKeo_AMPERE_latAlign[i]-np.min(doubleKeo_latLong[i][0]))/(np.max(doubleKeo_latLong[i][0])-np.min(doubleKeo_latLong[i][0])); #get line of interest location on TEC keogram in a form of 1 to 0
        twinx_valAtLineOfInterest = np.mean(doubleKeo_AMPERE_integrated_plot) + 1.5*np.std(doubleKeo_AMPERE_integrated_plot); #this is the value we want to align with the line of interest
        twinx_minToAlign = (lineOfInterestLoc*np.max(doubleKeo_AMPERE_integrated_plot) - twinx_valAtLineOfInterest)/(lineOfInterestLoc - 1); #calc the min to get that value at the LOI
        if( twinx_minToAlign < np.max(doubleKeo_AMPERE_integrated_plot) ):
            axTwinx[i].set_ylim( twinx_minToAlign , np.max(doubleKeo_AMPERE_integrated_plot) ); #set y axis limits
        # else:
        #     axTwinx[i].set_ylim( 0 , np.max(doubleKeo_AMPERE_integrated_plot) ); #don't try to align
        #END IF
        
        #this is to keep plotting similar
        dividerTwinx = make_axes_locatable(axTwinx[i]); #prep to add an axis
        caxTwinx.append(dividerTwinx.append_axes('right', size='2.0%', pad=1.75)); #make a color bar axis, append
        caxTwinx[i].set_visible(False); #mkae it invisible so it matches the other plots in width
        
        xAxisTicksStep = 4; #hr, hour steps between each x axis tick
        xAxisTicks = np.arange( (np.round((TEC_timeUnique[0]-dateRange_dayNum_zeroHr[1]*86400)/3600) - np.mod(np.round((TEC_timeUnique[0]-dateRange_dayNum_zeroHr[1]*86400)/3600), xAxisTicksStep)) , \
            (np.round((TEC_timeUnique[-1]-dateRange_dayNum_zeroHr[1]*86400)/3600) - np.mod(np.round((TEC_timeUnique[-1]-dateRange_dayNum_zeroHr[1]*86400)/3600),xAxisTicksStep)) + xAxisTicksStep , \
            xAxisTicksStep); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
        ax[i].set_xticks(xAxisTicks); #set x axis ticks
        ax[i].set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set x axis limits
        axTwinx[i].set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set x axis limits
        
        #adjust the tick marks
        # tickzLim = 40*np.median(doubleKeo_AMPERE_integrated[i]); #get the median*40 of the integrated JH
        tickz = axTwinx[i].get_yticks(); #get the ticks
        # tickz = tickz[ (tickz < tickzLim) & (tickz >= 0) ]; #get only the tickz we want
        tickz = tickz[ (tickz >= 0) ]; #get only the tickz we want
        axTwinx[i].set_yticks(tickz); #set the ticks
        
        #----- Plot Shading to represent 'night' -----
        if( doubleKeo_niteTimes[0] == False ):
            if( doubleKeo_plotSpacingName[i] == 'Latitude' ): #if true, latitude
                if( doubleKeo_AMPERE_latAlign[i] > 45 ):
                    latToUse = 45; #cap at 50 deg lat to keep it from getting too zesty at the poles
                else:
                    latToUse = doubleKeo_AMPERE_latAlign[i];
                #END IF
                (doubleKeo_niteTimes_sunRise, doubleKeo_niteTimes_sunSet, doubleKeo_dateRange_fullPad) = sunAlsoRises(dateRange_full,latToUse,np.mean(doubleKeo_latLong[i][1])); #call sunrise/set function
            else:
                (doubleKeo_niteTimes_sunRise, doubleKeo_niteTimes_sunSet, doubleKeo_dateRange_fullPad) = sunAlsoRises(dateRange_full,np.mean(doubleKeo_latLong[i][0]),doubleKeo_AMPERE_latAlign[i]); #call sunrise/set function
            #END IF
            doubleKeo_dateRange_dayNum_fullPad = subfun_date_to_dayNum(doubleKeo_dateRange_fullPad); #convert to dayNum
            doubleKeo_niteTimes_sunRise = (doubleKeo_niteTimes_sunRise + doubleKeo_dateRange_dayNum_fullPad[:,1] - dateRange_dayNum_zeroHr[1])*24; #hrs, center around zero hr and convert ot hrs
            doubleKeo_niteTimes_sunSet = (doubleKeo_niteTimes_sunSet + doubleKeo_dateRange_dayNum_fullPad[:,1] - dateRange_dayNum_zeroHr[1])*24; #hrs, center around zero hr and convert ot hrs
            doubleKeo_niteTimes_sunRise = doubleKeo_niteTimes_sunRise[1:]; #remove 1st
            doubleKeo_niteTimes_sunSet = doubleKeo_niteTimes_sunSet[:-1]; #remove last
            #FIFTH STEP: PLOT THIS STUFF
            for j in range(0,doubleKeo_niteTimes_sunSet.size):
                # ax[i].axvspan(doubleKeo_AMPERE_niteTimes_array[j,0], doubleKeo_AMPERE_niteTimes_array[j,1], alpha=0.25, color='xkcd:black');
                if(doubleKeo_plotSpacingName[i] == 'Latitude'): #if Y axis is latitude, use latitude
                    recta = Rectangle((doubleKeo_niteTimes_sunSet[j], np.min(doubleKeo_latLong[i][0])), doubleKeo_niteTimes_sunRise[j]-doubleKeo_niteTimes_sunSet[j], np.diff(doubleKeo_latLong[i][0]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
                    ax[i].add_patch(recta); #add on that patch
                else: #otherwise longitude
                    recta = Rectangle((doubleKeo_niteTimes_sunSet[j], np.min(doubleKeo_latLong[i][1])), doubleKeo_niteTimes_sunRise[j]-doubleKeo_niteTimes_sunSet[j], np.diff(doubleKeo_latLong[i][1]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
                    ax[i].add_patch(recta); #add on that patch
                #END IF
            #END FOR j
        else:
            for j in range(0,dates['date range zero hr hours'].size):
                doubleKeo_niteTimes_per = dates['date range zero hr hours'][j] + np.asarray(doubleKeo_niteTimes[i]); #get the nite time ranges
                if(doubleKeo_plotSpacingName[i] == 'Latitude'): #if Y axis is latitude, use latitude
                    recta = Rectangle((doubleKeo_niteTimes_per[0], np.min(doubleKeo_latLong[i][0])), np.diff(doubleKeo_niteTimes_per).item(), np.diff(doubleKeo_latLong[i][0]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
                    ax[i].add_patch(recta); #add on that patch
                else: #otherwise longitude
                    recta = Rectangle((doubleKeo_niteTimes_per[0], np.min(doubleKeo_latLong[i][1])), np.diff(doubleKeo_niteTimes_per).item(), np.diff(doubleKeo_latLong[i][1]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
                    ax[i].add_patch(recta); #add on that patch
                #END IF
            #END FOR j
        #END IF
        
        string_title = settings['TEC']['name']+' Keo Angle of '+str(np.round(doubleKeo_angle_orig[i],2))+' deg & Width of '+ \
            str(np.round(doubleKeo_width[i],2))+' arcdeg | Integrated '+AMPERE_plot_label_noUnits; #create mecha title
        if( FLG_doubleKeo_AMPERE_integrateMethod[i] == 0 ):
            string_title = string_title + ' within keo area'; #add to mecha title
        elif( FLG_doubleKeo_AMPERE_integrateMethod[i] == 1 ):
            string_title = string_title + ' within keo long & up to pole'; #add to mecha title
        elif( FLG_doubleKeo_AMPERE_integrateMethod[i] == 2 ):
            string_title = string_title + ' within keo long & up to '+str(doubleKeo_AMPERE_integrateMethod_val[i])+' degc lat'; #add to mecha title
        elif( FLG_doubleKeo_AMPERE_integrateMethod[i] == 3 ):
            if( (np.min(plotLatRange) <= 0) & (np.max(plotLatRange) >= 0) ):
                string_title = string_title + ' both Hemispheres'; #add to mecha title
            else:
                if( (np.min(plotLatRange) >= 0) & (np.max(plotLatRange) >= 0) ):
                    #northern hemisphere
                    string_title = string_title + ' Northern Hemisphere'; #add to mecha title
                else:
                    #southern hemisphere
                    string_title = string_title + ' Southern Hemisphere'; #add to mecha title
                #END IF
            #END IF
        #END IF
        string_title = string_title + ' w/ time delay of '+str(doubleKeo_AMPERE_timeDelay[i])+' hrs';
        ax[i].set_title(string_title,fontproperties=FONT_titleFM); #set the title
        if( i == len(doubleKeo_latLong)-1 ):
            ax[i].set_xlabel('Time in UT - 0 Hr on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0])+' [hr]',fontproperties=FONT_axisLabelFM); #set the x axis label
        #END IF
        ax[i].set_ylabel(doubleKeo_plotSpacingName[i]+' [arcdeg]',fontproperties=FONT_axisLabelFM); #set the y axis label
        
        autoTick = (np.ceil(np.max(doubleKeo_plotSpacing[i])) - np.floor(np.min(doubleKeo_plotSpacing[i])))/13; #tries to split the latitude range into 13 parts (based off of 180/15+1)
        if( autoTick > 25 ):
            autoTick = 30; #sets the tick setting to 15 arcdegrees per tick
        elif( autoTick > 10 ):
            autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
        elif( autoTick > 5 ):
            autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
        elif( autoTick > 2 ):
            autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
        elif( autoTick > 1 ):
            autoTick = 2; #sets the tick setting to 5 arcdegrees per tick
        elif( autoTick >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
            autoTick = 1; #                                                        sets the tick setting to 1 arcdegree per tick
        else:
            if(doubleKeo_plotSpacingName[i] == 'Latitude'): #if Y axis is latitude, use latitude
                autoTick = (np.max(doubleKeo_latLong[i][0]) - np.min(doubleKeo_latLong[i][0]))/13; #just goes for it if it's a super tiny range
            elif(doubleKeo_plotSpacingName[i] == 'Longitude'): #if Y axis is longitude, use longitude
                autoTick = (np.max(doubleKeo_latLong[i][1]) - np.min(doubleKeo_latLong[i][1]))/13; #just goes for it if it's a super tiny range
            #END IF
        #END IF
        yAxisTicks = np.round(np.arange( np.floor(np.min(doubleKeo_plotSpacing[i])),np.ceil(np.max(doubleKeo_plotSpacing[i])),autoTick ),2); #creates y ticks automagically
        ax[i].set_yticks(yAxisTicks); #set x axis ticks
        
        #Now drawing line of interest
        if( doubleKeo_plotSpacingName[i] == 'Latitude' ): #if true, latitude
            if( (np.min(doubleKeo_latLong[i][0]) <= doubleKeo_AMPERE_latAlign[i]) & (np.max(doubleKeo_latLong[i][0]) >= doubleKeo_AMPERE_latAlign[i]) ): #only plot if it's in the lat range specified
                ax[i].plot( np.linspace(np.min((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600),np.max((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600),10,endpoint=True) , #X time hr
                    np.tile(doubleKeo_AMPERE_latAlign[i],10) , #Y latitude OR longitude arcdeg
                    c='xkcd:black',linewidth=settings['plot']['line width']['smol']); #plots a point with a black line
            #END IF
        else:
            if( (np.min(doubleKeo_latLong[i][1]) <= doubleKeo_AMPERE_latAlign[i]) & (np.max(doubleKeo_latLong[i][1]) >= doubleKeo_AMPERE_latAlign[i]) ): #only plot if it's in the lat range specified
                ax[i].plot( np.linspace(np.min((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600),np.max((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600),10,endpoint=True) , #X time hr
                    np.tile(doubleKeo_AMPERE_latAlign[i],10) , #Y latitude OR longitude arcdeg
                    c='xkcd:black',linewidth=settings['plot']['line width']['smol']); #plots a point with a black line
            #END IF
        #END IF
    #END FOR i
    
    #-----Draw line from 1st TEC event to 2nd-----
    if( np.any(doubleKeo_arrowTimes[0] != False) ):
        for jj in range(0,len(doubleKeo_arrowTimes)):
            if( (doubleKeo_arrowTimes[jj][0] >= np.min((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600)) & \
                (doubleKeo_arrowTimes[jj][1] <= np.max((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600)) ):
                con = ConnectionPatch(xyA=(doubleKeo_arrowTimes[jj][0],doubleKeo_AMPERE_latAlign[0]), coordsA=ax[0].transData,
                                      xyB=(doubleKeo_arrowTimes[jj][1],doubleKeo_AMPERE_latAlign[1]), coordsB=ax[1].transData,
                                      arrowstyle="-|>", shrinkA=5, shrinkB=5,mutation_scale=20, fc="xkcd:pink",
                                      color='xkcd:pink', linewidth=settings['plot']['line width']['double plus']); #prep a line between plots
                fig.add_artist(con); #draw the line
            #END IF
        #END FOR jj
    #END IF
    
    # figFitter(fig); #fit the fig fast [title's too long for this]
    fig.subplots_adjust(left = 0.055, right = 0.935, top = 0.96, bottom = 0.075, hspace = 0.18); #sets padding to small numbers for minimal white space
#END IF

#==============Analysis: delta-vTEC Double Keo w/ AMPERE==============
if( FLG_doubleKeo_plot == 2 ): #mode 2 makes the two keograms meet at a shared latitude/longitude
    GRITI_doubleKeo_plot(data['double keo'], 'AMPERE', dates, settings, dataAll=data, timeCutout = None, FLG_fancyPlot=0);
    if( FLG_fancyPlot >= 1 ):
        GRITI_doubleKeo_plot(data['double keo'], 'AMPERE', dates, settings, dataAll=data, timeCutout = None, FLG_fancyPlot=FLG_fancyPlot);
    #END IF
#END IF

if( FLG_doubleKeo_plot_timeCutout == 1 ):
    from matplotlib.patches import ConnectionPatch, Rectangle
    from Code.subfun_timeMatch import subfun_timeMatch
    from Code.subfun_figFitter import figFitter
    from Code.subfun_filter import subfun_filter
    from Code.subfun_sunAlsoRises import sunAlsoRises
    from Code.subfun_date_to_dayNum import subfun_date_to_dayNum
    import copy
    
    #-----Plot TEC results as a Keogram w/ AMPERE integrated line as well-----
    #Prep the plot
    fig, ax = plt.subplots(nrows=len(doubleKeo_latLong), ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    axTwinx = []; #prep this list, holds the twinx axes, will grow as we plot
    cax = []; #prep
    caxTwinx = []; #prep
    
    timeCutout_TEC_indexes = np.array( ( np.where(np.min(np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    for i in range(0,len(doubleKeo_latLong)):
        timeCutout_AMPERE_indexes = np.array( ( np.where(np.min(np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
            np.where(np.min(np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
        
        divider = make_axes_locatable(ax[i]); #prep to add an axis
        cax.append(divider.append_axes('right', size='2.0%', pad=1.75)); #make a color bar axis, append
        
        #Remove the aspect ratio from the basemap so it fills the screen better
        ax[i].set_aspect('auto');
        
        #-----Plot TEC results as a keogram-----
        pltHelprX, pltHelprY = np.meshgrid( (TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1] - dateRange_dayNum_zeroHr[1]*86400)/3600, \
                    doubleKeo_plotSpacing[i]);
        im = ax[i].pcolormesh(pltHelprX, pltHelprY,  doubleKeo_keo[i][timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1,:].T ,vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim']),cmap=settings['TEC']['colormap']); # pseudocolor plot "stretched" to the grid
        cbar = fig.colorbar(im, cax=cax[i], orientation='vertical'); #create a colorbar using the prev. defined cax
        cbar.set_label(settings['TEC']['plot label']); #tabel the colorbar
        cbar.ax.tick_params(labelsize=FONT_axisTick);
        #cbar.set_clim(vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim'])); #they changed how the code works, this doesn't work anymore
        cbar.mappable.set_clim(vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim'])); #now it's this
        cax[i].yaxis.set_ticks(np.linspace(np.min(settings['TEC']['plot lim']),np.max(settings['TEC']['plot lim']),5)); #create useful tick marks
        cax[i].yaxis.set_major_formatter(FormatStrFormatter('%.2f')); #force a rounded format
        cax[i].yaxis.label.set_font_properties(FONT_axisLabelFM);
        
        #-----Plot AMPERE results as a 1D line-----
        axTwinx.append(ax[i].twinx()); #add on the new twinx axis
        doubleKeo_AMPERE_integrated_plot = np.copy(doubleKeo_AMPERE_integrated[i]); #copy
        if( doubleKeo_AMPERE_plotLim != False ):
            doubleKeo_AMPERE_integrated_plot[ doubleKeo_AMPERE_integrated_plot > doubleKeo_AMPERE_plotLim ] = doubleKeo_AMPERE_plotLim; #cap the max val
        #END IF
        axTwinx[i].plot( doubleKeo_AMPERE_timeHr[i][timeCutout_AMPERE_indexes[0]:timeCutout_AMPERE_indexes[1]+1], doubleKeo_AMPERE_integrated_plot[timeCutout_AMPERE_indexes[0]:timeCutout_AMPERE_indexes[1]+1] , linewidth=settings['plot']['line width']['regular'] , color='xkcd:violet'); #plot
        axTwinx[i].set_ylabel(AMPERE_plot_label,fontproperties=FONT_axisLabelFM); #set the y axis label
        #now adjust the ylim so the lines are about where we want them to be
        lineOfInterestLoc = (doubleKeo_AMPERE_latAlign[i]-np.min(doubleKeo_latLong[i][0]))/(np.max(doubleKeo_latLong[i][0])-np.min(doubleKeo_latLong[i][0])); #get line of interest location on TEC keogram in a form of 1 to 0
        twinx_valAtLineOfInterest = np.mean(doubleKeo_AMPERE_integrated_plot) + 1.5*np.std(doubleKeo_AMPERE_integrated_plot); #this is the value we want to align with the line of interest
        twinx_minToAlign = (lineOfInterestLoc*np.max(doubleKeo_AMPERE_integrated_plot) - twinx_valAtLineOfInterest)/(lineOfInterestLoc - 1); #calc the min to get that value at the LOI
        axTwinx[i].set_ylim( twinx_minToAlign , np.max(doubleKeo_AMPERE_integrated_plot) ); #set y axis limits
        
        #this is to keep plotting similar
        dividerTwinx = make_axes_locatable(axTwinx[i]); #prep to add an axis
        caxTwinx.append(dividerTwinx.append_axes('right', size='2.0%', pad=1.75)); #make a color bar axis, append
        caxTwinx[i].set_visible(False); #mkae it invisible so it matches the other plots in width
        
        xAxisTicksStep = 1; #hr, hour steps between each x axis tick
        xAxisTicks = np.arange( (np.round((np.min(TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1])-dateRange_dayNum_zeroHr[1]*86400)/3600) - np.mod(np.round((np.min(TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1])-dateRange_dayNum_zeroHr[1]*86400)/3600), xAxisTicksStep)) , \
            (np.round((np.max(TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1])-dateRange_dayNum_zeroHr[1]*86400)/3600) - np.mod(np.round((np.max(TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1])-dateRange_dayNum_zeroHr[1]*86400)/3600),xAxisTicksStep)) + xAxisTicksStep , \
            xAxisTicksStep); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
        ax[i].set_xticks(xAxisTicks); #set x axis ticks
        ax[i].set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set x axis limits
        axTwinx[i].set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set x axis limits
        
        #adjust the tick marks
        # tickzLim = 40*np.median(doubleKeo_AMPERE_integrated[i]); #get the median*40 of the integrated JH
        tickz = axTwinx[i].get_yticks(); #get the ticks
        # tickz = tickz[ (tickz < tickzLim) & (tickz >= 0) ]; #get only the tickz we want
        tickz = tickz[ (tickz >= 0) ]; #get only the tickz we want
        axTwinx[i].set_yticks(tickz); #set the ticks
        
        #----- Plot Shading to represent 'night' -----
        if( doubleKeo_niteTimes[0] == False ):
            if( doubleKeo_plotSpacingName[i] == 'Latitude' ): #if true, latitude
                if( doubleKeo_AMPERE_latAlign[i] > 45 ):
                    latToUse = 45; #cap at 50 deg lat to keep it from getting too zesty at the poles
                else:
                    latToUse = doubleKeo_AMPERE_latAlign[i];
                #END IF
                (doubleKeo_niteTimes_sunRise, doubleKeo_niteTimes_sunSet, doubleKeo_dateRange_fullPad) = sunAlsoRises(dateRange_full,latToUse,np.mean(doubleKeo_latLong[i][1])); #call sunrise/set function
            else:
                (doubleKeo_niteTimes_sunRise, doubleKeo_niteTimes_sunSet, doubleKeo_dateRange_fullPad) = sunAlsoRises(dateRange_full,np.mean(doubleKeo_latLong[i][0]),doubleKeo_AMPERE_latAlign[i]); #call sunrise/set function
            #END IF
            doubleKeo_dateRange_dayNum_fullPad = subfun_date_to_dayNum(doubleKeo_dateRange_fullPad); #convert to dayNum
            doubleKeo_niteTimes_sunRise = (doubleKeo_niteTimes_sunRise + doubleKeo_dateRange_dayNum_fullPad[:,1] - dateRange_dayNum_zeroHr[1])*24; #hrs, center around zero hr and convert ot hrs
            doubleKeo_niteTimes_sunSet = (doubleKeo_niteTimes_sunSet + doubleKeo_dateRange_dayNum_fullPad[:,1] - dateRange_dayNum_zeroHr[1])*24; #hrs, center around zero hr and convert ot hrs
            doubleKeo_niteTimes_sunRise = doubleKeo_niteTimes_sunRise[1:]; #remove 1st
            doubleKeo_niteTimes_sunSet = doubleKeo_niteTimes_sunSet[:-1]; #remove last
            #FIFTH STEP: PLOT THIS STUFF
            for j in range(0,doubleKeo_niteTimes_sunSet.size):
                # ax.axvspan(doubleKeo_AMPERE_niteTimes_array[j,0], doubleKeo_AMPERE_niteTimes_array[j,1], alpha=0.25, color='xkcd:black');
                if(doubleKeo_plotSpacingName[i] == 'Latitude'): #if Y axis is latitude, use latitude
                    recta = Rectangle((doubleKeo_niteTimes_sunSet[j], np.min(doubleKeo_latLong[i][0])), doubleKeo_niteTimes_sunRise[j]-doubleKeo_niteTimes_sunSet[j], np.diff(doubleKeo_latLong[i][0]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
                    ax.add_patch(recta); #add on that patch
                else: #otherwise longitude
                    recta = Rectangle((doubleKeo_niteTimes_sunSet[j], np.min(doubleKeo_latLong[i][1])), doubleKeo_niteTimes_sunRise[j]-doubleKeo_niteTimes_sunSet[j], np.diff(doubleKeo_latLong[i][1]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
                    ax.add_patch(recta); #add on that patch
                #END IF
            #END FOR j
        else:
            for j in range(0,dates['date range zero hr hours'].size):
                doubleKeo_niteTimes_per = dates['date range zero hr hours'][j] + np.asarray(doubleKeo_niteTimes[i]); #get the nite time ranges
                if(doubleKeo_plotSpacingName[i] == 'Latitude'): #if Y axis is latitude, use latitude
                    recta = Rectangle((doubleKeo_niteTimes_per[0], np.min(doubleKeo_latLong[i][0])), np.diff(doubleKeo_niteTimes_per).item(), np.diff(doubleKeo_latLong[i][0]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
                    ax.add_patch(recta); #add on that patch
                else: #otherwise longitude
                    recta = Rectangle((doubleKeo_niteTimes_per[0], np.min(doubleKeo_latLong[i][1])), np.diff(doubleKeo_niteTimes_per).item(), np.diff(doubleKeo_latLong[i][1]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
                    ax.add_patch(recta); #add on that patch
                #END IF
            #END FOR j
        #END IF
        
        string_title = settings['TEC']['plot label no units']+' Keo Angle of '+str(np.round(doubleKeo_angle_orig[i],2))+' deg & Width of '+ \
            str(np.round(doubleKeo_width[i],2))+' arcdeg | Integrated '+AMPERE_plot_label_noUnits; #create mecha title
        if( FLG_doubleKeo_AMPERE_integrateMethod[i] == 0 ):
            string_title = string_title + ' within keo area'; #add to mecha title
        elif( FLG_doubleKeo_AMPERE_integrateMethod[i] == 1 ):
            string_title = string_title + ' within keo long & up to pole'; #add to mecha title
        elif( FLG_doubleKeo_AMPERE_integrateMethod[i] == 2 ):
            string_title = string_title + ' within keo long & up to '+str(doubleKeo_AMPERE_integrateMethod_val[i])+' degc lat'; #add to mecha title
        elif( FLG_doubleKeo_AMPERE_integrateMethod[i] == 3 ):
            if( (np.min(plotLatRange) <= 0) & (np.max(plotLatRange) >= 0) ):
                string_title = string_title + ' both Hemispheres'; #add to mecha title
            else:
                if( (np.min(plotLatRange) >= 0) & (np.max(plotLatRange) >= 0) ):
                    #northern hemisphere
                    string_title = string_title + ' Northern Hemisphere'; #add to mecha title
                else:
                    #southern hemisphere
                    string_title = string_title + ' Southern Hemisphere'; #add to mecha title
                #END IF
            #END IF
        #END IF
        string_title = string_title + ' w/ time delay of '+str(doubleKeo_AMPERE_timeDelay[i])+' hrs';
        ax[i].set_title(string_title,fontproperties=FONT_titleFM); #set the title
        if( i == len(doubleKeo_latLong)-1 ):
            ax[i].set_xlabel('Time in UT - 0 Hr on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0])+' [hr]',fontproperties=FONT_axisLabelFM); #set the x axis label
        #END IF
        ax[i].set_ylabel(doubleKeo_plotSpacingName[i]+' [arcdeg]',fontproperties=FONT_axisLabelFM); #set the y axis label
        
        autoTick = (np.ceil(np.max(doubleKeo_plotSpacing[i])) - np.floor(np.min(doubleKeo_plotSpacing[i])))/13; #tries to split the latitude range into 13 parts (based off of 180/15+1)
        if( autoTick > 25 ):
            autoTick = 30; #sets the tick setting to 15 arcdegrees per tick
        elif( autoTick > 10 ):
            autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
        elif( autoTick > 5 ):
            autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
        elif( autoTick > 2 ):
            autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
        elif( autoTick > 1 ):
            autoTick = 2; #sets the tick setting to 5 arcdegrees per tick
        elif( autoTick >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
            autoTick = 1; #                                                        sets the tick setting to 1 arcdegree per tick
        else:
            if(doubleKeo_plotSpacingName[i] == 'Latitude'): #if Y axis is latitude, use latitude
                autoTick = (np.max(doubleKeo_latLong[i][0]) - np.min(doubleKeo_latLong[i][0]))/13; #just goes for it if it's a super tiny range
            elif(doubleKeo_plotSpacingName[i] == 'Longitude'): #if Y axis is longitude, use longitude
                autoTick = (np.max(doubleKeo_latLong[i][1]) - np.min(doubleKeo_latLong[i][1]))/13; #just goes for it if it's a super tiny range
            #END IF
        #END IF
        yAxisTicks = np.round(np.arange( np.floor(np.min(doubleKeo_plotSpacing[i])),np.ceil(np.max(doubleKeo_plotSpacing[i])),autoTick ),2); #creates y ticks automagically
        ax[i].set_yticks(yAxisTicks); #set x axis ticks
        
        #Now drawing line of interest
        if( doubleKeo_plotSpacingName[i] == 'Latitude' ): #if true, latitude
            if( (np.min(doubleKeo_latLong[i][0]) <= doubleKeo_AMPERE_latAlign[i]) & (np.max(doubleKeo_latLong[i][0]) >= doubleKeo_AMPERE_latAlign[i]) ): #only plot if it's in the lat range specified
                ax[i].plot( np.linspace(np.min((TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1] - dateRange_dayNum_zeroHr[1]*86400)/3600),np.max((TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1] - dateRange_dayNum_zeroHr[1]*86400)/3600),10,endpoint=True) , #X time hr
                    np.tile(doubleKeo_AMPERE_latAlign[i],10) , #Y latitude OR longitude arcdeg
                    c='xkcd:black',linewidth=settings['plot']['line width']['smol']); #plots a point with a black line
            #END IF
        else:
            if( (np.min(doubleKeo_latLong[i][1]) <= doubleKeo_AMPERE_latAlign[i]) & (np.max(doubleKeo_latLong[i][1]) >= doubleKeo_AMPERE_latAlign[i]) ): #only plot if it's in the lat range specified
                ax[i].plot( np.linspace(np.min((TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1] - dateRange_dayNum_zeroHr[1]*86400)/3600),np.max((TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1] - dateRange_dayNum_zeroHr[1]*86400)/3600),10,endpoint=True) , #X time hr
                    np.tile(doubleKeo_AMPERE_latAlign[i],10) , #Y latitude OR longitude arcdeg
                    c='xkcd:black',linewidth=settings['plot']['line width']['smol']); #plots a point with a black line
            #END IF
        #END IF
    #END FOR i
    
    #-----Draw line from 1st TEC event to 2nd-----
    if( np.any(doubleKeo_arrowTimes[0] != False) ):
        for jj in range(0,len(doubleKeo_arrowTimes)):
            if( (doubleKeo_arrowTimes[jj][0] >= np.min(time_cutout_range/3600)) & \
                (doubleKeo_arrowTimes[jj][1] <= np.max(time_cutout_range/3600)) ):
                con = ConnectionPatch(xyA=(doubleKeo_arrowTimes[jj][0],doubleKeo_AMPERE_latAlign[0]), coordsA=ax[0].transData,
                                      xyB=(doubleKeo_arrowTimes[jj][1],doubleKeo_AMPERE_latAlign[1]), coordsB=ax[1].transData,
                                      arrowstyle="-|>", shrinkA=5, shrinkB=5,mutation_scale=20, fc="xkcd:pink",
                                      color='xkcd:pink', linewidth=settings['plot']['line width']['double plus']); #prep a line between plots
                fig.add_artist(con); #draw the line
            #END IF
        #END FOR jj
    #END IF
    
    figFitter(fig); #fit the fig fast
#END IF

#==============Analysis: delta-vTEC Double Keo w/ AMPERE==============
if( FLG_doubleKeo_plot_timeCutout == 2 ): #mode 2 makes the two keograms meet at a shared latitude/longitude
    GRITI_doubleKeo_plot(data['double keo'], 'AMPERE', dates, settings, dataAll=data, timeCutout = time_cutout_range/3600, FLG_fancyPlot=0);
    if( FLG_fancyPlot >= 1 ):
        GRITI_doubleKeo_plot(data['double keo'], 'AMPERE', dates, settings, dataAll=data, timeCutout = time_cutout_range/3600, FLG_fancyPlot=FLG_fancyPlot);
    #END IF
    # from matplotlib.patches import ConnectionPatch, Rectangle
    # from Code.GRITI_plotHelper_axisizerLatLong import GRITI_plotHelper_axisizerLatLong
    # from Code.GRITI_plotHelper_axisizerTime import GRITI_plotHelper_axisizerTime
    # from Code.subfun_timeMatch import subfun_timeMatch
    # from Code.subfun_figFitter import figFitter
    # from Code.subfun_filter import subfun_filter
    # from Code.subfun_sunAlsoRises import sunAlsoRises
    # from Code.subfun_date_to_dayNum import subfun_date_to_dayNum
    # import copy
    
    # time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
    #     np.where(np.min(np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
        
    # #-----Plot TEC results as a Keogram w/ AMPERE integrated line as well-----
    # #Prep the plot
    # fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    # figManager = fig.canvas.manager; #req to maximize
    # figManager.window.showMaximized(); #force maximized
    # axTwinx = []; #prep this list, holds the twinx axes, will grow as we plot
    # # cax = []; #prep
    # caxTwinx = []; #prep
    # divider = make_axes_locatable(ax); #prep to add an axis
    # cax = divider.append_axes('right', size='2.0%', pad=1.75); #make a color bar axis, append [0.35]
    # # dividerTwinx = make_axes_locatable(axTwinx); #prep to add an axis
    # # caxTwinx = dividerTwinx.append_axes('right', size='2.0%', pad=1.75); #make a color bar axis, append
    # # caxTwinx.set_visible(False); #mkae it invisible so it matches the other plots in width
    
    # timeCutout_TEC_indexes = np.array( ( np.where(np.min(np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) )) == np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) ) )[0][0] , \
    #     np.where(np.min(np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400) - np.max(time_cutout_range) )) == np.abs( (TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400) - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    # #Remove the aspect ratio from the basemap so it fills the screen better
    # ax.set_aspect('auto');
    # for i in range(0,len(doubleKeo_latLong)):
    #     #-----Plot TEC results as a keogram-----
    #     pltHelprX, pltHelprY = np.meshgrid( (np.append(TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1],TEC_timeUnique[timeCutout_TEC_indexes[1]]+TEC_dataRate) - dateRange_dayNum_zeroHr[1]*86400)/3600, \
    #                 doubleKeo_plotSpacing[i]);
    #     im = ax.pcolormesh(pltHelprX, pltHelprY,  doubleKeo_keo[i][timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1,:].T ,vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim']),cmap=settings['TEC']['colormap'],zorder=i); # pseudocolor plot "stretched" to the grid
    # #END FOR i
        
    # cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
    # cbar.set_label(settings['TEC']['name']+settings['TEC']['units']); #tabel the colorbar
    # cbar.ax.tick_params(labelsize=FONT_axisTick);
    # #cbar.set_clim(vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim'])); #they changed how the code works, this doesn't work anymore
    # cbar.mappable.set_clim(vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim'])); #now it's this
    # # cax.yaxis.set_ticks(np.linspace(np.min(settings['TEC']['plot lim']),np.max(settings['TEC']['plot lim']),5)); #create useful tick marks
    # cax.yaxis.set_ticks(np.arange(np.min(settings['TEC']['plot lim']),np.max(settings['TEC']['plot lim'])+0.1,0.1)); #create useful tick marks
    # cax.yaxis.set_major_formatter(FormatStrFormatter('%.1f')); #force a rounded format
    # cax.yaxis.label.set_font_properties(FONT_axisLabelFM);
    
    # #----- Draw lines of separation between the keograms -----
    # doubleKeo_alignments_limits = np.empty(doubleKeo_alignments.size+2); #preallocate
    # for i in range(0,doubleKeo_alignments.size):
    #     ax.plot( np.array( (np.min((TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1] - dateRange_dayNum_zeroHr[1]*86400)/3600),np.max((TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1] - dateRange_dayNum_zeroHr[1]*86400)/3600)) ), \
    #             np.ones(2)*doubleKeo_alignments[i],
    #             c='xkcd:white',linewidth=settings['plot']['line width']['thicc'],linestyle='-'); #plots a point with a black line
    #     plt.pause(0.0001); #another pause needed to make matplotlib work
    #     doubleKeo_alignments_limits[i+1] = ax.transLimits.transform((1,doubleKeo_alignments[i]))[1]; #get the position of the split in axis units
    # #END FOR i
    # doubleKeo_alignments_limits[0] = 1; #these are known
    # doubleKeo_alignments_limits[-1] = 0; #these are known
    
    # #!! hindsight: solve this with 2 separate plots that have no spacing between them !!
    
    # for i in range(0,len(doubleKeo_latLong)):
    #     timeCutout_AMPERE_indexes = np.array( ( np.where(np.min(np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) ) )[0][0] , \
    #         np.where(np.min(np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400)- np.max(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
        
    #     # -----Plot AMPERE results as a 1D line -----
    #     axTwinx.append(ax.twinx()); #add on the new twinx axis
    #     doubleKeo_AMPERE_integrated_plot = np.copy(doubleKeo_AMPERE_integrated[i]); #copy
    #     if( doubleKeo_AMPERE_plotLim == True ):
    #         doubleKeo_AMPERE_integrated_plot[ doubleKeo_AMPERE_integrated_plot > doubleKeo_AMPERE_plotLim ] = doubleKeo_AMPERE_plotLim; #cap the max val
    #     #END IF
    #     axTwinx[i].plot( doubleKeo_AMPERE_timeHr[i][timeCutout_AMPERE_indexes[0]:timeCutout_AMPERE_indexes[1]+1], doubleKeo_AMPERE_integrated_plot[timeCutout_AMPERE_indexes[0]:timeCutout_AMPERE_indexes[1]+1] , linewidth=settings['plot']['line width']['regular'] , color='xkcd:violet',zorder=i); #plot
    #     if( i == len(doubleKeo_latLong)-1 ):
    #         axTwinx[i].set_ylabel(AMPERE_plot_label,fontproperties=FONT_axisLabelFM); #set the y axis label
    #     #END IF
        
    #     #now adjust the ylim so the lines are about where we want them to be
    #     # #--- Adjust yLim max to be at the right place --- (turns out can't do both at once since they're linked - so gotta... solve)
    #     # twinx_yFactor = 1 - (doubleKeo_alignments_limits[i] - axTwinx[i].transLimits.transform((1,np.max(doubleKeo_AMPERE_integrated[i])))[1]); #get a factor
    #     # twinx_yLims = np.array( axTwinx[i].get_ylim() ); #get the ylims
    #     # twinx_yLims[1] = np.max(doubleKeo_AMPERE_integrated[i])/doubleKeo_alignments_limits[i]-(twinx_yLims[0]*(1-doubleKeo_alignments_limits[i]))*2; #solving this is nasty I'm not big brain here
    #     # axTwinx[i].set_ylim(twinx_yLims); #apply the new ylim because it adjusts the next thing
        
    #     # #--- Adjust yLim min to align the data on the line of interest ---
    #     # lineOfInterestLoc = (doubleKeo_alignments_limits[i]-doubleKeo_alignments_limits[i+1])*(doubleKeo_AMPERE_latAlign[i]-np.min(doubleKeo_latLongComb[i]))/(np.max(doubleKeo_latLongComb[i])-np.min(doubleKeo_latLongComb[i]))+doubleKeo_alignments_limits[i+1]; #get line of interest location on TEC keogram in a form of 1 to 0 (scaled by the keogram plot-within-plots)
    #     # twinx_valAtLineOfInterest = np.mean(doubleKeo_AMPERE_integrated[i]) + 1.5*np.std(doubleKeo_AMPERE_integrated[i]); #this is the value we want to align with the line of interest
    #     # twinx_minToAlign = (lineOfInterestLoc*twinx_yLims[1] - twinx_valAtLineOfInterest)/(lineOfInterestLoc - 1); #calc the min to get that value at the LOI
    #     # axTwinx[i].set_ylim( twinx_minToAlign , twinx_yLims[1] ); #set y axis limits
        
    #     #--- I had to do actual algebra for this (combined two equations above) ---
    #     twinx_yLims = np.array( axTwinx[i].get_ylim() ); #get the ylims
    #     lim1 = doubleKeo_alignments_limits[i]; #get the upper limit in axis units
    #     yMax = np.nanmax(doubleKeo_AMPERE_integrated_plot); #get the desired yMax
    #     yMin = twinx_yLims[0]; #get the current yMin
    #     lim2 = (doubleKeo_alignments_limits[i]-doubleKeo_alignments_limits[i+1])*(doubleKeo_AMPERE_latAlign[i]-np.min(doubleKeo_latLongComb[i]))/(np.max(doubleKeo_latLongComb[i])-np.min(doubleKeo_latLongComb[i]))+doubleKeo_alignments_limits[i+1]; #get line of interest location on TEC keogram in a form of 1 to 0 (scaled by the keogram plot-within-plots)
    #     yGoal = np.nanmean(doubleKeo_AMPERE_integrated_plot) + 1.5*np.nanstd(doubleKeo_AMPERE_integrated_plot); #this is the value we want to align with the line of interest
        
    #     #--- Calc the yLim Max and Min ---
    #     twinx_yLims = np.array( axTwinx[i].get_ylim() ); #get the ylims
    #     twinx_yLims[1] = (yMax/lim1 + 2*yGoal/(lim2-1)*(1-lim1))/(1+2*lim2/(lim2-1)*(1-lim1)); #calc max limit
    #     twinx_yLims[0] = (lim2*twinx_yLims[1] - yGoal)/(lim2-1); #calc min limit
    #     axTwinx[i].set_ylim( twinx_yLims ); #set y axis limits
    #     # #alignment check
    #     # ax.transLimits.transform((1,doubleKeo_AMPERE_latAlign[i]))[1]
    #     # axTwinx[i].transLimits.transform((1,twinx_valAtLineOfInterest))[1]
        
    #     #this is to keep plotting similar
    #     dividerTwinx = make_axes_locatable(axTwinx[i]); #prep to add an axis
    #     caxTwinx.append(dividerTwinx.append_axes('right', size='2.0%', pad=1.75)); #make a color bar axis, append
    #     caxTwinx[i].set_visible(False); #mkae it invisible so it matches the other plots in width
        
    #     # xAxisTicksStep = 1; #hr, hour steps between each x axis tick
    #     # xAxisTicks = np.arange( (np.round((np.min(TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1])-dateRange_dayNum_zeroHr[1]*86400)/3600) - np.mod(np.round((np.min(TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1])-dateRange_dayNum_zeroHr[1]*86400)/3600), xAxisTicksStep)) , \
    #     #     (np.round((np.max(TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1])-dateRange_dayNum_zeroHr[1]*86400)/3600) - np.mod(np.round((np.max(TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1])-dateRange_dayNum_zeroHr[1]*86400)/3600),xAxisTicksStep)) + xAxisTicksStep , \
    #     #     xAxisTicksStep); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
    #     # ax.set_xticks(xAxisTicks); #set x axis ticks
    #     # ax.set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set x axis limits
    #     # axTwinx[i].set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set x axis limits
        
    #     GRITI_plotHelper_axisizerTime((TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1]-dateRange_dayNum_zeroHr[1]*86400)/3600,ax=axTwinx[i],unit='hr');
        
    #     #adjust the tick marks
    #     # tickzLim = 40*np.median(doubleKeo_AMPERE_integrated[i]); #get the median*40 of the integrated JH
    #     tickz = axTwinx[i].get_yticks(); #get the ticks
    #     # tickz = tickz[ (tickz < tickzLim) & (tickz >= 0) ]; #get only the tickz we want
    #     tickzPos = axTwinx[i].transLimits.transform(np.vstack( (np.ones(tickz.size), tickz) ).T)[:,1]; #get the tickz positions on the plot
    #     tickz = tickz[ (tickz >= 0) & (doubleKeo_alignments_limits[i] >= tickzPos) & (doubleKeo_alignments_limits[i+1] <= tickzPos) ]; #make sure the ticks fall within the keogram area and they're positive
    #     axTwinx[i].set_yticks(tickz); #set the ticks
        
    #     #----- Plot Shading to represent 'night' -----
    #     if( doubleKeo_niteTimes[0] == False ):
    #         if( doubleKeo_plotSpacingName[i] == 'Latitude' ): #if true, latitude
    #             if( doubleKeo_AMPERE_latAlign[i] > 45 ):
    #                 latToUse = 45; #cap at 50 deg lat to keep it from getting too zesty at the poles
    #             else:
    #                 latToUse = doubleKeo_AMPERE_latAlign[i];
    #             #END IF
    #             (doubleKeo_niteTimes_sunRise, doubleKeo_niteTimes_sunSet, doubleKeo_dateRange_fullPad) = sunAlsoRises(dateRange_full,latToUse,np.mean(doubleKeo_latLong[i][1])); #call sunrise/set function
    #         else:
    #             (doubleKeo_niteTimes_sunRise, doubleKeo_niteTimes_sunSet, doubleKeo_dateRange_fullPad) = sunAlsoRises(dateRange_full,np.mean(doubleKeo_latLong[i][0]),doubleKeo_AMPERE_latAlign[i]); #call sunrise/set function
    #         #END IF
    #         doubleKeo_dateRange_dayNum_fullPad = subfun_date_to_dayNum(doubleKeo_dateRange_fullPad); #convert to dayNum
    #         doubleKeo_niteTimes_sunRise = (doubleKeo_niteTimes_sunRise + doubleKeo_dateRange_dayNum_fullPad[:,1] - dateRange_dayNum_zeroHr[1])*24; #hrs, center around zero hr and convert ot hrs
    #         doubleKeo_niteTimes_sunSet = (doubleKeo_niteTimes_sunSet + doubleKeo_dateRange_dayNum_fullPad[:,1] - dateRange_dayNum_zeroHr[1])*24; #hrs, center around zero hr and convert ot hrs
    #         doubleKeo_niteTimes_sunRise = doubleKeo_niteTimes_sunRise[1:]; #remove 1st
    #         doubleKeo_niteTimes_sunSet = doubleKeo_niteTimes_sunSet[:-1]; #remove last
    #         #FIFTH STEP: PLOT THIS STUFF
    #         for j in range(0,doubleKeo_niteTimes_sunSet.size):
    #             # ax.axvspan(doubleKeo_AMPERE_niteTimes_array[j,0], doubleKeo_AMPERE_niteTimes_array[j,1], alpha=0.25, color='xkcd:black');
    #             if(doubleKeo_plotSpacingName[i] == 'Latitude'): #if Y axis is latitude, use latitude
    #                 recta = Rectangle((doubleKeo_niteTimes_sunSet[j], np.min(doubleKeo_latLong[i][0])), doubleKeo_niteTimes_sunRise[j]-doubleKeo_niteTimes_sunSet[j], np.diff(doubleKeo_latLong[i][0]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
    #                 ax.add_patch(recta); #add on that patch
    #             else: #otherwise longitude
    #                 recta = Rectangle((doubleKeo_niteTimes_sunSet[j], np.min(doubleKeo_latLong[i][1])), doubleKeo_niteTimes_sunRise[j]-doubleKeo_niteTimes_sunSet[j], np.diff(doubleKeo_latLong[i][1]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
    #                 ax.add_patch(recta); #add on that patch
    #             #END IF
    #         #END FOR j
    #     else:
    #         for j in range(0,dates['date range zero hr hours'].size):
    #             doubleKeo_niteTimes_per = dates['date range zero hr hours'][j] + np.asarray(doubleKeo_niteTimes[i]); #get the nite time ranges
    #             if(doubleKeo_plotSpacingName[i] == 'Latitude'): #if Y axis is latitude, use latitude
    #                 recta = Rectangle((doubleKeo_niteTimes_per[0], np.min(doubleKeo_latLong[i][0])), np.diff(doubleKeo_niteTimes_per).item(), np.diff(doubleKeo_latLong[i][0]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
    #                 ax.add_patch(recta); #add on that patch
    #             else: #otherwise longitude
    #                 recta = Rectangle((doubleKeo_niteTimes_per[0], np.min(doubleKeo_latLong[i][1])), np.diff(doubleKeo_niteTimes_per).item(), np.diff(doubleKeo_latLong[i][1]).item(), edgecolor='xkcd:black', facecolor='xkcd:black', alpha=0.25); #make that patch
    #                 ax.add_patch(recta); #add on that patch
    #             #END IF
    #         #END FOR j
    #     #END IF
        
    #     #----- Now drawing line of interest -----
    #     if( doubleKeo_plotSpacingName[i] == 'Latitude' ): #if true, latitude
    #         if( (np.min(doubleKeo_latLong[i][0]) <= doubleKeo_AMPERE_latAlign[i]) & (np.max(doubleKeo_latLong[i][0]) >= doubleKeo_AMPERE_latAlign[i]) ): #only plot if it's in the lat range specified
    #             ax.plot( np.linspace(np.min((TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1] - dateRange_dayNum_zeroHr[1]*86400)/3600),np.max((TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1] - dateRange_dayNum_zeroHr[1]*86400)/3600),10,endpoint=True) , #X time hr
    #                 np.tile(doubleKeo_AMPERE_latAlign[i],10) , #Y latitude OR longitude arcdeg
    #                 c='xkcd:black',linewidth=settings['plot']['line width']['smol']); #plots a point with a black line
    #         #END IF
    #     else:
    #         if( (np.min(doubleKeo_latLong[i][1]) <= doubleKeo_AMPERE_latAlign[i]) & (np.max(doubleKeo_latLong[i][1]) >= doubleKeo_AMPERE_latAlign[i]) ): #only plot if it's in the lat range specified
    #             ax.plot( np.linspace(np.min((TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1] - dateRange_dayNum_zeroHr[1]*86400)/3600),np.max((TEC_timeUnique[timeCutout_TEC_indexes[0]:timeCutout_TEC_indexes[1]+1] - dateRange_dayNum_zeroHr[1]*86400)/3600),10,endpoint=True) , #X time hr
    #                 np.tile(doubleKeo_AMPERE_latAlign[i],10) , #Y latitude OR longitude arcdeg
    #                 c='xkcd:black',linewidth=settings['plot']['line width']['smol']); #plots a point with a black line
    #         #END IF
    #     #END IF
    # #END FOR i
    
    # #----- Label and make it look nice -----
    # string_title = str(len(doubleKeo_latLong))+' '+settings['TEC']['name']+' Keograms on '+str(np.round(doubleKeo_angle_orig[i],2))+' deg Angle & Widths of '+ \
    #     str(np.round(doubleKeo_width,2))+' arcdeg \n Integrated '+AMPERE_plot_label_noUnits; #create mecha title
    # if( FLG_doubleKeo_AMPERE_integrateMethod[i] == 0 ):
    #     string_title = string_title + ' within keo area'; #add to mecha title
    # elif( FLG_doubleKeo_AMPERE_integrateMethod[i] == 1 ):
    #     string_title = string_title + ' within keo long & up to pole'; #add to mecha title
    # elif( FLG_doubleKeo_AMPERE_integrateMethod[i] == 2 ):
    #     string_title = string_title + ' within keo long & up to '+str(doubleKeo_AMPERE_integrateMethod_val)+' degc lat'; #add to mecha title
    # elif( FLG_doubleKeo_AMPERE_integrateMethod[i] == 3 ):
    #     if( (np.min(plotLatRange) <= 0) & (np.max(plotLatRange) >= 0) ):
    #         string_title = string_title + ' both Hemispheres'; #add to mecha title
    #     else:
    #         if( (np.min(plotLatRange) >= 0) & (np.max(plotLatRange) >= 0) ):
    #             #northern hemisphere
    #             string_title = string_title + ' Northern Hemisphere'; #add to mecha title
    #         else:
    #             #southern hemisphere
    #             string_title = string_title + ' Southern Hemisphere'; #add to mecha title
    #         #END IF
    #     #END IF
    # #END IF
    # string_title = string_title + ' w/ time delays of '+str(doubleKeo_AMPERE_timeDelay)+' hrs';
    # ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
    # if( i == len(doubleKeo_latLong)-1 ):
    #     ax.set_xlabel('Time in UT - 0 Hr on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0])+' [hr]',fontproperties=FONT_axisLabelFM); #set the x axis label
    # #END IF
    # ax.set_ylabel(doubleKeo_plotSpacingName[i]+' [arcdeg]',fontproperties=FONT_axisLabelFM); #set the y axis label
    
    # # autoTick = (np.ceil(np.max(doubleKeo_plotSpacing)) - np.floor(np.min(doubleKeo_plotSpacing)))/13; #tries to split the latitude range into 13 parts (based off of 180/15+1)
    # # if( autoTick > 25 ):
    # #     autoTick = 30; #sets the tick setting to 15 arcdegrees per tick
    # # elif( autoTick > 10 ):
    # #     autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
    # # elif( autoTick > 5 ):
    # #     autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
    # # elif( autoTick > 2 ):
    # #     autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
    # # elif( autoTick > 1 ):
    # #     autoTick = 2; #sets the tick setting to 5 arcdegrees per tick
    # # elif( autoTick >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
    # #     autoTick = 1; #                                                        sets the tick setting to 1 arcdegree per tick
    # # else:
    # #     autoTick = (np.max(doubleKeo_latLongComb) - np.min(doubleKeo_latLongComb))/13; #just goes for it if it's a super tiny range
    # # #END IF
    # # yAxisTicks = np.round(np.arange( np.floor(np.min(doubleKeo_plotSpacing)),np.ceil(np.max(doubleKeo_plotSpacing))+autoTick,autoTick ),2); #creates y ticks automagically
    # # ax.set_yticks(yAxisTicks); #set x axis ticks
    
    # GRITI_plotHelper_axisizerLatLong(doubleKeo_plotSpacing,ax=ax,axDir='y',tickNumGoal=17);
    
    # #-----Draw line from 1st TEC event to 2nd-----
    # if( (doubleKeo_arrowTimes[0] >= np.min(time_cutout_range/3600)) & \
    #     (doubleKeo_arrowTimes[1] <= np.max(time_cutout_range/3600)) ):
    #     con = ConnectionPatch(xyA=(doubleKeo_arrowTimes[0],doubleKeo_AMPERE_latAlign[0]), coordsA=ax.transData, #-11.81 #-10.54
    #                           xyB=(doubleKeo_arrowTimes[1],doubleKeo_AMPERE_latAlign[1]), coordsB=ax.transData, #-11.13 #-9.96
    #                           arrowstyle="-|>", shrinkA=5, shrinkB=5,mutation_scale=20, fc="xkcd:pink",
    #                           color='xkcd:pink', linewidth=settings['plot']['line width']['plus']); #prep a line between plots
    #     fig.add_artist(con); #draw the line
    # #END IF
    
    # figFitter(fig); #fit the fig fast
#END IF

if( FLG_doubleKeo_xcorr == 1 ):
    from scipy import signal
    from Code.subfun_filter import subfun_filter
    from Code.subfun_figFitter import figFitter
    from Code.subfun_strstr import strstr
    from Code.subfun_correlator_corraler import subfun_correlator_corraler
    from Code.GRITI_spectral_analysisPlot import GRITI_spectral_analysisPlot
    # from Code.GRITI_spectral_6minAnalysisPlot import GRITI_spectral_6minAnalysisPlot
    from Code.GRITI_keo_keogrammer import GRITI_keo_keogrammer
    from Code.GRITI_plotHelper_axisizerTime import GRITI_plotHelper_axisizerTime
    import pickle
    
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    #Unpack everything else
    doubleKeo_keo = data['double keo']['keo'];
    doubleKeo_latLong = settings['double keo']['lat long'];
    doubleKeo_angle = settings['double keo']['angle'];
    doubleKeo_width = settings['double keo']['width'];
    doubleKeo_plotSpacing = settings['double keo']['plot spacing'];
    doubleKeo_plotSpacingName =settings['double keo']['plot spacing name'];
    doubleKeo_AMPERE_integrated = data['double keo']['AMPERE integrated no filter'];
    doubleKeo_AMPERE_time = data['double keo']['AMPERE time'];
    doubleKeo_AMPERE_timeHr = data['double keo']['AMPERE time hr'];
    
    #--- Just FFTs for good measure --- ['high-pass & 0 mean','high-pass & log10 & 0 mean']
    doubleKeo_AMPERE_xcorr = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    for i in range(0,len(doubleKeo_latLong)):
        #--- Remove NaNs, replace with 0's so filtering stuff works ---
        doubleKeo_AMPERE_xcorr[i] = np.copy(doubleKeo_AMPERE_integrated[i]); #copy over for edits
        doubleKeo_AMPERE_xcorr[i][np.isnan(doubleKeo_AMPERE_xcorr[i])] = 0; #replace NaNs with 0s
    #END FOR i
    GRITI_spectral_analysisPlot([[doubleKeo_keo[i][:, np.where( np.min(np.abs(doubleKeo_plotSpacing[i] - doubleKeo_AMPERE_latAlign[i])) == np.abs(doubleKeo_plotSpacing[i] - doubleKeo_AMPERE_latAlign[i]) )[0][0]],doubleKeo_AMPERE_xcorr[i]] for i in range(0,len(doubleKeo_latLong))],
        [[(TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400) ,(AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400)] for i in range(0,len(doubleKeo_latLong))], [['sec','sec'] for i in range(0,len(doubleKeo_latLong))],
        [[TEC_dataRate,data['AMPERE']['data rate']] for i in range(0,len(doubleKeo_latLong))], [['sec','sec'] for i in range(0,len(doubleKeo_latLong))], 'min',
        [['none','none'] for i in range(0,len(doubleKeo_latLong))], [['fft','fft'] for i in range(0,len(doubleKeo_latLong))], dates, settings_spectra, settings_plot, settings_paths, 
        [[doubleKeo_namesNice[i]+' @ '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2))+' lat No Filt',settings['AMPERE']['data type']+' (Time Delay '+textNice(doubleKeo_AMPERE_timeDelay[i])+') No Filt'] for i in range(0,len(doubleKeo_latLong))],
        reduceWindow=0); #insane plot call
    
    #--- Filter and Align if Req'd ---
    doubleKeo_keo_xcorr = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_keo_xcorrNoFilt = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_keo_xcorr_time = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_AMPERE_xcorr = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_AMPERE_xcorr_time = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_keo_dataRate = TEC_dataRate; #set data rates
    doubleKeo_AMPERE_dataRate = data['AMPERE']['data rate']; #set data rates
    for i in range(0,len(doubleKeo_latLong)):
        #--- Remove NaNs, replace with 0's so filtering stuff works ---
        doubleKeo_AMPERE_xcorr[i] = np.copy(doubleKeo_AMPERE_integrated[i]); #copy over for edits
        doubleKeo_AMPERE_xcorr[i][np.isnan(doubleKeo_AMPERE_xcorr[i])] = 0; #replace NaNs with 0s
        
        #--- Filter if req'd ---
        doubleKeo_AMPERE_xcorr[i] = subfun_filter( doubleKeo_AMPERE_xcorr[i], doubleKeo_xcorr_AMPERE_filtMethod, dataTime = doubleKeo_AMPERE_time[i], dataRate = doubleKeo_AMPERE_dataRate, settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False);  #AMPERE is forced to 6 min during integration
        doubleKeo_keo_xcorr[i] = subfun_filter( doubleKeo_keo[i][:, np.where( np.min(np.abs(doubleKeo_plotSpacing[i] - doubleKeo_AMPERE_latAlign[i])) == np.abs(doubleKeo_plotSpacing[i] - doubleKeo_AMPERE_latAlign[i]) )[0][0]], 'nan & '+doubleKeo_xcorr_TEC_filtMethod, dataTime = (TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400), dataRate = TEC_dataRate, settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = True); #filter (or not)
        doubleKeo_keo_xcorrNoFilt[i] = np.copy(doubleKeo_keo[i][:, np.where( np.min(np.abs(doubleKeo_plotSpacing[i] - doubleKeo_AMPERE_latAlign[i])) == np.abs(doubleKeo_plotSpacing[i] - doubleKeo_AMPERE_latAlign[i]) )[0][0]]);
        
        #--- Determine which has a slower data rate and align to that ---
        if( data['TEC']['data rate'] > data['AMPERE']['data rate'] ):
            #TEC is the data rate to align to
            doubleKeo_keo_xcorr_time[i] = TEC_timeUnique-dateRange_dayNum_zeroHr[1]*86400; #same
            doubleKeo_AMPERE_xcorr[i], doubleKeo_AMPERE_xcorr_time[i] = subfun_timeMatch(doubleKeo_AMPERE_xcorr[i], AMPERE_timeUnique, TEC_timeUnique, timeMatch_delta=data['TEC']['data rate'], FLG_removeNaNs=0, FLG_useSum=1); #time match alg to align to 6 minute cadence, add because it's a count (?)
            if( np.isclose(np.mod(doubleKeo_AMPERE_timeDelay[i]*3600,1),0.0) ):
                doubleKeo_AMPERE_xcorr_time[i] += np.int64(doubleKeo_AMPERE_timeDelay[i]*3600); #it all stays integers
            else:
                doubleKeo_AMPERE_xcorr_time[i] = np.float64(doubleKeo_AMPERE_xcorr_time[i]) + doubleKeo_AMPERE_timeDelay[i]*3600; #it all becomes floats
            #END IF
        elif( data['TEC']['data rate'] < data['AMPERE']['data rate'] ):
            #AMPERE is the data rate to align to
            doubleKeo_AMPERE_xcorr_time[i] = np.copy(doubleKeo_AMPERE_time[i]); #same
            doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i] = subfun_timeMatch(doubleKeo_keo_xcorr[i], TEC_timeUnique, AMPERE_timeUnique, timeMatch_delta=data['AMPERE']['data rate'], FLG_removeNaNs=0, FLG_useSum=0); #time match alg to align to 6 minute cadence, add because it's a count (?)
            doubleKeo_keo_xcorr_time[i] -= dateRange_dayNum_zeroHr[1]*86400; #remove that b/c it was coded expecting that
        else:
            doubleKeo_keo_xcorr_time[i] = np.copy(TEC_timeUnique)-dateRange_dayNum_zeroHr[1]*86400; #same
            doubleKeo_AMPERE_xcorr_time[i] = np.copy(doubleKeo_AMPERE_time[i]); #same
        #END IF

        
        
        # #--- Time match to 6 minutes on TEC time frame to deal with correlation stuff ---
        # if( np.all(np.isclose((doubleKeo_AMPERE_time[i] - dateRange_dayNum_zeroHr[1]*86400),sixMin_timeUnique[i])) ):
        #     doubleKeo_AMPERE_xcorr_time[i] = doubleKeo_AMPERE_time[i]; #same
        #     # doubleKeo_AMPERE_timeHr[i] = (doubleKeo_AMPERE_time_adj - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
        # else:
        #     doubleKeo_AMPERE_xcorr[i], doubleKeo_AMPERE_xcorr_time[i] = subfun_timeMatch(doubleKeo_AMPERE_xcorr[i], doubleKeo_AMPERE_time[i], sixMin_timeUnique[i], timeMatch_delta=data['TEC']['data rate'], FLG_removeNaNs=0, FLG_useSum=1); #time match alg to align to 6 minute cadence, add because it's a count (?)
        #     doubleKeo_AMPERE_xcorr_time[i] += dateRange_dayNum_zeroHr[1]*86400; #add back in the day offset b/c it's assumed it is there
        #     # doubleKeo_AMPERE_timeHr[i] = (doubleKeo_AMPERE_time_adj - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day                #END IF
        # #END IF
    
        # #--- Time match to 6 minutes if needed ---
        # if( (np.isclose(TEC_dataRate,doubleKeo_AMPERE_dataRate) == False) ):
        #     # doubleKeo_keo_xcorrNoFilt[i], _ = subfun_timeMatch(doubleKeo_keo_xcorrNoFilt[i], (TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400), sixMin_timeUnique_base, timeMatch_delta=360., FLG_removeNaNs=0, FLG_useSum=0); #time match alg to align to 6 minute cadence, add because it's a count (?)
        #     doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i] = subfun_timeMatch(doubleKeo_keo_xcorr[i], (TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400), sixMin_timeUnique_base, timeMatch_delta=doubleKeo_AMPERE_dataRate, FLG_removeNaNs=0, FLG_useSum=0); #time match alg to align to 6 minute cadence, add because it's a count (?)
        #     # doubleKeo_keo_xcorr_time[i] = doubleKeo_keo_xcorr_time; #sec, convert to hr with 0 hr at specified day
        #     doubleKeo_keo_dataRate = doubleKeo_AMPERE_dataRate; #set new data rate
        # else:
        #     if( TEC_timeUnique.size == sixMin_timeUnique_base.size ):
        #         if( np.all(np.isclose((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400),sixMin_timeUnique_base)) ):
        #             #doubleKeo_keo_xcorr[i] = doubleKeo_keo[i][:,np.where( np.abs(np.min(doubleKeo_plotSpacing[i] - doubleKeo_AMPERE_latAlign[i])) == np.min(doubleKeo_plotSpacing[i] - doubleKeo_AMPERE_latAlign[i]) )[0][0]]
        #             doubleKeo_keo_xcorr_time[i] = (TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400); #sec, convert to hr with 0 hr at specified day
        #         else:
        #             # doubleKeo_keo_xcorrNoFilt[i], _ = subfun_timeMatch(doubleKeo_keo_xcorrNoFilt[i], (TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400), sixMin_timeUnique_base, timeMatch_delta=TEC_dataRate, FLG_useSum=0); #time match alg to align to 6 minute cadence, add because it's a count (?)
        #             doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i] = subfun_timeMatch(doubleKeo_keo_xcorr[i], (TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400), sixMin_timeUnique_base, timeMatch_delta=TEC_dataRate, FLG_useSum=0); #time match alg to align to 6 minute cadence, add because it's a count (?)
        #         #END IF
        #     else:
        #         # doubleKeo_keo_xcorrNoFilt[i], _ = subfun_timeMatch(doubleKeo_keo_xcorrNoFilt[i], (TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400), sixMin_timeUnique_base, timeMatch_delta=TEC_dataRate, FLG_useSum=0); #time match alg to align to 6 minute cadence, add because it's a count (?)
        #         doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i] = subfun_timeMatch(doubleKeo_keo_xcorr[i], (TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400), sixMin_timeUnique_base, timeMatch_delta=TEC_dataRate, FLG_useSum=0); #time match alg to align to 6 minute cadence, add because it's a count (?)
        #     #END IF
        # #END IF
    #END FOR i
    
    #--- Whole Time Comparison ---
    Pxy_TECvAMPERE = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    freqs_TECvAMPERE = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    keo_xcorr_cutOut = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    keo_xcorr_time_cutOut = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    AMPERE_xcorr_cutOut = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    AMPERE_xcorr_time_cutOut = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    pwr_TEC = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    pwr_AMPERE = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    stringer = ''; #prep
    Fs = 1/(doubleKeo_AMPERE_dataRate); #sec, time delta in freq form
    for i in range(0,len(doubleKeo_latLong)):
        if( (TEC_timeUnique[-1]-TEC_timeUnique[0]) != (AMPERE_timeUnique[-1]-AMPERE_timeUnique[0]) ): #means AMPERE and TEC aren't the same size as TEC_timeUnique (b/c they're matched from before)
            #TEC CUTOUT NOW
            time_cutout_indexes = np.array( ( np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - (TEC_timeUnique[0]-dateRange_dayNum_zeroHr[1]*86400) )) == np.abs( doubleKeo_keo_xcorr_time[i] - (TEC_timeUnique[0]-dateRange_dayNum_zeroHr[1]*86400) ) )[0][0] , \
                np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - (TEC_timeUnique[-1]-dateRange_dayNum_zeroHr[1]*86400) )) == np.abs( doubleKeo_keo_xcorr_time[i] - (TEC_timeUnique[-1]-dateRange_dayNum_zeroHr[1]*86400) ) )[0][0] ) ); #get the indexes for that time cutout range
            keo_xcorr_cutOut[i] = np.copy(doubleKeo_keo_xcorr[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]); #get out the relevant times
            keo_xcorr_time_cutOut[i] = np.copy(doubleKeo_keo_xcorr_time[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]); #get out the relevant times
            
            #AMPERE CUTOUT NOW
            time_cutout_indexes = np.array( ( np.where(np.min(np.abs( doubleKeo_AMPERE_xcorr_time[i] - TEC_timeUnique[0] )) == np.abs( doubleKeo_AMPERE_xcorr_time[i] - TEC_timeUnique[0] ) )[0][0] , \
                np.where(np.min(np.abs( doubleKeo_AMPERE_xcorr_time[i] - TEC_timeUnique[-1] )) == np.abs( doubleKeo_AMPERE_xcorr_time[i] - TEC_timeUnique[-1] ) )[0][0] ) ); #get the indexes for that time cutout range
            AMPERE_xcorr_cutOut[i] = np.copy(doubleKeo_AMPERE_xcorr[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]); #get out the relevant times
            AMPERE_xcorr_time_cutOut[i] = np.copy(doubleKeo_AMPERE_xcorr_time[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]); #get out the relevant times
            AMPERE_xcorr_cutOut[i][np.isnan(AMPERE_xcorr_cutOut[i])] = 0; #replace NaNs with 0s
        else:
            keo_xcorr_cutOut[i] = np.copy(doubleKeo_keo_xcorr[i]); #copy it over
            keo_xcorr_time_cutOut[i] = np.copy(doubleKeo_keo_xcorr_time[i]); #copy it over
            AMPERE_xcorr_cutOut[i] = np.copy(doubleKeo_AMPERE_xcorr[i]); #copy it over
            AMPERE_xcorr_time_cutOut[i] = np.copy(doubleKeo_AMPERE_xcorr_time[i]); #copy it over
            AMPERE_xcorr_cutOut[i][np.isnan(AMPERE_xcorr_cutOut[i])] = 0; #replace NaNs with 0s
        #END IF
        
        #CALC PWR
        pwr_TEC[i] = np.sqrt(1/keo_xcorr_cutOut[i].size*np.sum(keo_xcorr_cutOut[i]**2)); #estimate power of signal
        pwr_AMPERE[i] = np.sqrt(1/AMPERE_xcorr_cutOut[i].size*np.sum(AMPERE_xcorr_cutOut[i]**2)); #estimate power of signal
        
        if( np.isclose(360, doubleKeo_AMPERE_dataRate) ):
            [freqs_TECvAMPERE[i],Cxy_TECvAMPERE] = signal.csd(1/pwr_TEC[i]*keo_xcorr_cutOut[i],1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i],window=settings['spectra']['window'],noverlap=settings['spectra']['noverlap'],nfft=settings['spectra']['nfft']['6min'],fs=Fs);
        else:
            #scale as needed
            nfft = settings_spectra['nfft']['6min']*360//doubleKeo_AMPERE_dataRate;
            nooverlap = settings['spectra']['noverlap']*360//doubleKeo_AMPERE_dataRate; #adjust
            if( settings_spectra['window type'] == 'hamm' ):
                winnow = np.hamming(settings_spectra['windowLength']*360//doubleKeo_AMPERE_dataRate); #adjust
            else:
                print('ERROR: Unsupported window type \''+settings_spectra['window type']+'\', add support for it here.');
                import sys
                sys.crash();
            #END IF
            [freqs_TECvAMPERE[i],Cxy_TECvAMPERE] = signal.csd(1/pwr_TEC[i]*keo_xcorr_cutOut[i],1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i],window=winnow,noverlap=nooverlap,nfft=nfft,fs=Fs);
        #END IF
        Axy_TECvAMPERE = np.angle(Cxy_TECvAMPERE)*180/np.pi; 
        Pxy_TECvAMPERE[i] = np.abs(Cxy_TECvAMPERE);
        
        #Real quick side move to calc correlation coefficients
        R_keovsAMPERE = np.corrcoef(1/pwr_TEC[i]*keo_xcorr_cutOut[i],1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i])[0,1];
        if( i == 0 ):
            stringer += 'Corr Coeff:\n';
        #END IF
        stringer += 'Whole '+doubleKeo_namesNice[i]+' vs '+settings['AMPERE']['data type']+' #'+str(i+1)+': '+str(np.round(R_keovsAMPERE,3));
        if( i != len(doubleKeo_latLong)-1 ):
            stringer += ' | ';
        #END IF
    #END FOR i
    print(stringer); #report the coeff
    
    #--- ROLLING TIME DELAY TO FIND OPTIMAL CORR COEFF ---
    doubleKeo_AMPERE_timeDelay_shiftStep = np.max((data['TEC']['data rate'],data['AMPERE']['data rate'])); #minutes to step by
    doubleKeo_AMPERE_timeDelay_shift = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_AMPERE_timeDelay_shiftCorr = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    for i in range(0,len(doubleKeo_latLong)):
        if( doubleKeo_AMPERE_timeDelay[i] >= 0 ):
            doubleKeo_AMPERE_timeDelay_shift[i] = np.arange(0,FLG_doubleKeo_xcorr_timeLim_AMPERE*3600+doubleKeo_AMPERE_timeDelay_shiftStep,doubleKeo_AMPERE_timeDelay_shiftStep); #get some time
        else:
            doubleKeo_AMPERE_timeDelay_shift[i] = np.arange(0,-FLG_doubleKeo_xcorr_timeLim_AMPERE*3600-doubleKeo_AMPERE_timeDelay_shiftStep,-doubleKeo_AMPERE_timeDelay_shiftStep); #get some time
        #END IF
        doubleKeo_AMPERE_timeDelay_shiftCorr[i] = np.empty(doubleKeo_AMPERE_timeDelay_shift[i].size); #preallocate it
        
        for j in range(0,doubleKeo_AMPERE_timeDelay_shift[i].size):
            #--- Adjust by the time offset ---
            doubleKeo_AMPERE_time_adj = AMPERE_timeUnique + np.int64(doubleKeo_AMPERE_timeDelay_shift[i][j]); #it all stays integers

            #align as needed
            if( (TEC_timeUnique[-1]-TEC_timeUnique[0]) != (AMPERE_timeUnique[-1]-AMPERE_timeUnique[0]) ): #means AMPERE and TEC aren't the same size as TEC_timeUnique (b/c they're matched from before)
                #AMPERE CUTOUT NOW
                time_cutout_indexes = np.array( ( np.where(np.min(np.abs( doubleKeo_AMPERE_time_adj - TEC_timeUnique[0] )) == np.abs( doubleKeo_AMPERE_time_adj - TEC_timeUnique[0] ) )[0][0] , \
                    np.where(np.min(np.abs( doubleKeo_AMPERE_time_adj - TEC_timeUnique[-1] )) == np.abs( doubleKeo_AMPERE_time_adj - TEC_timeUnique[-1] ) )[0][0] ) ); #get the indexes for that time cutout range
                doubleKeo_AMPERE_xcorr_adj = np.copy(doubleKeo_AMPERE_xcorr[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]); #get out the relevant times
                doubleKeo_AMPERE_xcorr_adj[np.isnan(doubleKeo_AMPERE_xcorr_adj)] = 0; #replace NaNs with 0s
            else:
                doubleKeo_AMPERE_xcorr_adj = np.copy(doubleKeo_AMPERE_xcorr[i]); #copy it over
                doubleKeo_AMPERE_xcorr_adj[np.isnan(doubleKeo_AMPERE_xcorr_adj)] = 0; #replace NaNs with 0s
            #END IF
            
            #AMPERE CUTOUT NOW
            AMPERE_xcorr_cutOut_adj = doubleKeo_AMPERE_xcorr_adj;
            pwr_AMPERE_adj = np.sqrt(1/AMPERE_xcorr_cutOut_adj.size*np.sum(AMPERE_xcorr_cutOut_adj**2)); #estimate power of signal
            
            #Real quick side move to calc correlation coefficients
            doubleKeo_AMPERE_timeDelay_shiftCorr[i][j] = np.corrcoef(1/pwr_TEC[i]*keo_xcorr_cutOut[i],1/pwr_AMPERE_adj*AMPERE_xcorr_cutOut_adj)[0,1];
        #END FOR j
        k = np.where( np.abs(doubleKeo_AMPERE_timeDelay_shiftCorr[i]) == np.max(np.abs(doubleKeo_AMPERE_timeDelay_shiftCorr[i])))[0]; #get maximum values
        k = k[np.min(np.mod(np.round(doubleKeo_AMPERE_timeDelay_shift[i][k],10),120)) == np.mod(np.round(doubleKeo_AMPERE_timeDelay_shift[i][k],10),120)][0]; #get one closest to 2 minutes
        print('Whole '+doubleKeo_namesNice[i]+' #'+str(i+1)+' Maximum correlation possible: '+textNice(np.round(doubleKeo_AMPERE_timeDelay_shiftCorr[i][k],3))+' at time delay: '+textNice(doubleKeo_AMPERE_timeDelay_shift[i][k]/3600)+' hrs'+\
            ' Current time delay: '+textNice(doubleKeo_AMPERE_timeDelay[i])+' hrs' );#print resupts
    #END FOR i
    
    #now, noise comparisons
    Pxy_TECNvAMPERE = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    Pxy_TECvAMPEREN = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    keo_noise_xcorr_cutOut = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    AMPERE_noise_xcorr_cutOut = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    pwr_TECN = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    pwr_AMPEREN = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    TECNvAMPERE_mat = np.empty((np.int64((settings_spectra['nfft']['6min']*360//doubleKeo_AMPERE_dataRate)/2+1),avgPt_TECnoise_iterations));
    TECvAMPEREN_mat = np.empty((np.int64((settings_spectra['nfft']['6min']*360//doubleKeo_AMPERE_dataRate)/2+1),avgPt_TECnoise_iterations));
    R_keoNvsAMPERE_mat = np.empty((avgPt_TECnoise_iterations));
    R_keovsAMPEREN_mat = np.empty((avgPt_TECnoise_iterations));
    R_keoNvsAMPERE = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    R_keovsAMPEREN = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_keo_noise_xcorr = [[[] for kk in range(0,doubleKeo_xcorr_noiseIterations)] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_AMPERE_noise_xcorr = [[[] for kk in range(0,doubleKeo_xcorr_noiseIterations)] for jj in range(0,len(doubleKeo_latLong))]; #prep
    stringer = ''; #prep
    for i in range(0,len(doubleKeo_latLong)):
        noiseHash = str(doubleKeo_latLong[i])+textNice(np.round(np.float64(doubleKeo_angle[i]),2))+'_'+textNice(np.round(np.float64(doubleKeo_width[i]),2))+'_'+ \
            str(doubleKeo_N[i])+'_'+str(doubleKeo_45vsLatLong[i])+'_'+str(doubleKeo_AMPERE_latAlign[i])+'_'+ \
            doubleKeo_xcorr_TEC_filtMethod.replace(' ','').replace('-','').lower() + \
            '_'+str(doubleKeo_xcorr_noiseIterations)+'_'+textNice(TEC_dataRate)+'_'+textNice(TEC_timeUnique.size); #hash of all of the settings in string form 
            
        if( os.path.isfile(settings['paths']['cache']+'\\'+'keoTECnoise_'+noiseHash+'.pkl') == 1 ):
            #if the data already exists, load it in
            with open(settings['paths']['cache']+'\\'+'keoTECnoise_'+noiseHash+'.pkl', 'rb') as doubleKeo_filer:
                doubleKeo_keo_noise_xcorr[i] = pickle.load(doubleKeo_filer); #load in the data
            #END WITH
            FLG_doubleKeo_xcorr_makeNoise = 0; #set the flag to off, data was already made and saved
        else:
            FLG_doubleKeo_xcorr_makeNoise = 1; #set the flag to on, data needs to be made
            tic = time.time(); #prep timer
            # k = ((np.min(doubleKeo_latLong[i][0]) <= data['TEC']['lat']) & (np.max(doubleKeo_latLong[i][0]) >= data['TEC']['lat'])) & \
            #     ((np.min(doubleKeo_latLong[i][1]) <= data['TEC']['long']) & (np.max(doubleKeo_latLong[i][1]) >= data['TEC']['long'])); #get only east coast to lower calcs needed
            k = np.min(doubleKeo_latLong[i][0]) <= data['TEC']['lat']; #split for speed, only applies like this to an "&" situation
            k[k] = np.max(doubleKeo_latLong[i][0]) >= data['TEC']['lat'][k];
            k[k] = np.min(doubleKeo_latLong[i][1]) <= data['TEC']['long'][k];
            k[k] = np.max(doubleKeo_latLong[i][1]) >= data['TEC']['long'][k]; #breaking it apart is faster
            print('JSYK: Calculating '+doubleKeo_namesNice[i]+' Noise, it takes a LONG time. On '+str(i+1)+' of '+str(len(doubleKeo_latLong))+'.'); #warn
            print('Time estimate to make '+doubleKeo_namesNice[i]+' noise data (it is cached at end of calc for this specific keogram at least): '+textNice(np.round(6.628536E-8*k.sum() - 7.533271E-2,2))+' hr(s).');
        #END IF
        
        for j in range(0,doubleKeo_xcorr_noiseIterations):
            #--- TEC Noise, EXPENSIVE CALCS if not cached ---
            if( FLG_doubleKeo_xcorr_makeNoise == 1 ):
                #!exxpensive NOISE CALCS on lots of data!
                TEC_noise = GRITI_TEC_randomSynth(k.sum(),data['TEC']['lat'][k],data['TEC']['long'][k],data['TEC']['time'][k], \
                        noise_background_mean,noise_background_stdev,Re,dateRange_zeroHr, \
                        plotLatRange,plotLongRange,plotLatRange_autoTick,plotLongRange_autoTick, \
                        wave_latRange,wave_longRange,wave_N,wave_angle,wave_phase,wave_waveLength,wave_period,wave_amp, \
                        FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,TEC_plotLimValu,1,FLG_plotStuff=0); #replace the delta-vTEC data with random data 

                (doubleKeo_keo_noise, _) = \
                    GRITI_keo_keogrammer(TEC_noise ,data['TEC']['time'][k], data['TEC']['lat'][k], data['TEC']['long'][k],
                        TEC_timeUnique, TEC_timeUnique, dates, \
                        settings['double keo'][i], settings_paths, settings_doubleKeo_map[i], settings_plot,
                        FLG_fancyPlot=FLG_fancyPlot,FLG_disablePlot=2,FLG_disableText=1,FLG_disableCache=1,FLG_useRightExact=1);
                        #call the mecha function that runs the keo alg and makes a plot showing the averaging are
                    
                #--- Filter if req'd ---
                doubleKeo_keo_noise_xcorr[i][j] = subfun_filter( doubleKeo_keo_noise[:, np.where( np.min(np.abs(doubleKeo_plotSpacing[i] - doubleKeo_AMPERE_latAlign[i])) == np.abs(doubleKeo_plotSpacing[i] - doubleKeo_AMPERE_latAlign[i]) )[0][0]], 'nan & '+doubleKeo_xcorr_TEC_filtMethod, dataTime = (TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400), dataRate = TEC_dataRate, settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
            
                print('Elapsed: '+str(np.round((time.time()-tic)/60,2))+' min | ETA: '+str(np.round( ((doubleKeo_xcorr_noiseIterations-(j+1))*(time.time()-tic)/(j+1)/60 ),2))+' min');
            #END IF
            
            #--- AMPERE noise ---
            doubleKeo_AMPERE_noise_xcorr[i][j] = np.abs(np.random.normal(loc=0,scale=np.nanstd(doubleKeo_AMPERE_integrated[i]),size=doubleKeo_AMPERE_xcorr[i].size)); #create some fake data
            #--- Remove NaNs, replace with 0's so filtering stuff works ---
            doubleKeo_AMPERE_noise_xcorr[i][j][np.isnan(doubleKeo_AMPERE_noise_xcorr[i][j])] = 0; #replace NaNs with 0s
            #--- Filter if req'd ---
            doubleKeo_AMPERE_noise_xcorr[i][j] = subfun_filter( doubleKeo_AMPERE_noise_xcorr[i][j], doubleKeo_xcorr_AMPERE_filtMethod, dataTime = AMPERE_timeUnique, dataRate = data['AMPERE']['data rate'], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
            
            #--- Time avg as needed ---
            if( data['TEC']['data rate'] > data['AMPERE']['data rate'] ):
                #TEC is the data rate to align to
                keo_noise_xcorr_cutOut[i] = np.copy(doubleKeo_keo_noise_xcorr[i][j]); #copy it over
                AMPERE_noise_xcorr_cutOut[i], _ = subfun_timeMatch(doubleKeo_AMPERE_noise_xcorr[i][j], AMPERE_timeUnique, TEC_timeUnique, timeMatch_delta=data['TEC']['data rate'], FLG_removeNaNs=0, FLG_useSum=1); #time match alg to align to 6 minute cadence, add because it's a count (?)
                AMPERE_noise_xcorr_cutOut[i][np.isnan(AMPERE_noise_xcorr_cutOut[i])] = 0; #replace NaNs with 0s
            elif( data['TEC']['data rate'] < data['AMPERE']['data rate'] ):
                #AMPERE is the data rate to align to
                keo_noise_xcorr_cutOut[i], _ = subfun_timeMatch(doubleKeo_keo_noise_xcorr[i][j], TEC_timeUnique, AMPERE_timeUnique, timeMatch_delta=data['AMPERE']['data rate'], FLG_removeNaNs=0, FLG_useSum=0); #time match alg to align to 6 minute cadence, add because it's a count (?)
                AMPERE_noise_xcorr_cutOut[i] = doubleKeo_AMPERE_noise_xcorr[i][j]; #since just made don't need to worry about copies
                AMPERE_noise_xcorr_cutOut[i][np.isnan(AMPERE_noise_xcorr_cutOut[i])] = 0; #replace NaNs with 0s
            else:
                keo_noise_xcorr_cutOut[i] = np.copy(doubleKeo_keo_noise_xcorr[i][j]); #copy it over
                AMPERE_noise_xcorr_cutOut[i] = doubleKeo_AMPERE_noise_xcorr[i][j]; #since just made don't need to worry about copies
                AMPERE_noise_xcorr_cutOut[i][np.isnan(AMPERE_noise_xcorr_cutOut[i])] = 0; #replace NaNs with 0s
            #END IF
            
            if( (TEC_timeUnique[-1]-TEC_timeUnique[0]) != (AMPERE_timeUnique[-1]-AMPERE_timeUnique[0]) ): #means AMPERE and TEC aren't the same size as TEC_timeUnique (b/c they're matched from before)
                #TEC CUTOUT NOW
                time_cutout_indexes = np.array( ( np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - (TEC_timeUnique[0]-dateRange_dayNum_zeroHr[1]*86400) )) == np.abs( doubleKeo_keo_xcorr_time[i] - (TEC_timeUnique[0]-dateRange_dayNum_zeroHr[1]*86400) ) )[0][0] , \
                    np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - (TEC_timeUnique[-1]-dateRange_dayNum_zeroHr[1]*86400) )) == np.abs( doubleKeo_keo_xcorr_time[i] - (TEC_timeUnique[-1]-dateRange_dayNum_zeroHr[1]*86400) ) )[0][0] ) ); #get the indexes for that time cutout range
                keo_noise_xcorr_cutOut[i] = keo_noise_xcorr_cutOut[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]; #get out the relevant times
                
                #AMPERE CUTOUT NOW
                time_cutout_indexes = np.array( ( np.where(np.min(np.abs( doubleKeo_AMPERE_xcorr_time[i] - TEC_timeUnique[0] )) == np.abs( doubleKeo_AMPERE_xcorr_time[i] - TEC_timeUnique[0] ) )[0][0] , \
                    np.where(np.min(np.abs( doubleKeo_AMPERE_xcorr_time[i] - TEC_timeUnique[-1] )) == np.abs( doubleKeo_AMPERE_xcorr_time[i] - TEC_timeUnique[-1] ) )[0][0] ) ); #get the indexes for that time cutout range
                AMPERE_noise_xcorr_cutOut[i] = AMPERE_noise_xcorr_cutOut[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]; #get out the relevant times
            #END IF
            
            #CALC PWR
            pwr_TECN[i] = np.sqrt(1/keo_noise_xcorr_cutOut[i].size*np.sum(keo_noise_xcorr_cutOut[i]**2)); #estimate power of signal
            pwr_AMPEREN[i] = np.sqrt(1/AMPERE_noise_xcorr_cutOut[i].size*np.sum(AMPERE_noise_xcorr_cutOut[i]**2)); #estimate power of signal
            
            if( np.isclose(360, doubleKeo_AMPERE_dataRate) ):
                [_,Cxy_TECNvAMPERE] = signal.csd(1/pwr_TECN[i]*keo_noise_xcorr_cutOut[i],1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i],window=settings['spectra']['window'],noverlap=settings['spectra']['noverlap'],nfft=settings['spectra']['nfft']['6min'],fs=Fs);
                Axy_TECNvAMPERE = np.angle(Cxy_TECNvAMPERE)*180/np.pi; 
                Pxy_TECNvAMPERE[i] = np.abs(Cxy_TECNvAMPERE);
                
                [_,Cxy_TECvAMPEREN] = signal.csd(1/pwr_TEC[i]*keo_xcorr_cutOut[i],1/pwr_AMPEREN[i]*AMPERE_noise_xcorr_cutOut[i],window=settings['spectra']['window'],noverlap=settings['spectra']['noverlap'],nfft=settings['spectra']['nfft']['6min'],fs=Fs);
                Axy_TECvAMPEREN = np.angle(Cxy_TECvAMPEREN)*180/np.pi; 
                Pxy_TECvAMPEREN[i] = np.abs(Cxy_TECvAMPEREN);            
            else:
                #scale as needed
                nfft = settings_spectra['nfft']['6min']*360//doubleKeo_AMPERE_dataRate;
                nooverlap = settings['spectra']['noverlap']*360//doubleKeo_AMPERE_dataRate; #adjust
                if( settings_spectra['window type'] == 'hamm' ):
                    winnow = np.hamming(settings_spectra['windowLength']*360//doubleKeo_AMPERE_dataRate); #adjust
                else:
                    print('ERROR: Unsupported window type \''+settings_spectra['window type']+'\', add support for it here.');
                    import sys
                    sys.crash();
                #END IF
                [_,Cxy_TECNvAMPERE] = signal.csd(1/pwr_TECN[i]*keo_noise_xcorr_cutOut[i],1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i],window=winnow,noverlap=nooverlap,nfft=nfft,fs=Fs);
                Axy_TECNvAMPERE = np.angle(Cxy_TECNvAMPERE)*180/np.pi; 
                Pxy_TECNvAMPERE[i] = np.abs(Cxy_TECNvAMPERE);
                
                [_,Cxy_TECvAMPEREN] = signal.csd(1/pwr_TEC[i]*keo_xcorr_cutOut[i],1/pwr_AMPEREN[i]*AMPERE_noise_xcorr_cutOut[i],window=winnow,noverlap=nooverlap,nfft=nfft,fs=Fs);
                Axy_TECvAMPEREN = np.angle(Cxy_TECvAMPEREN)*180/np.pi; 
                Pxy_TECvAMPEREN[i] = np.abs(Cxy_TECvAMPEREN);
            #END IF
            
            #RECORD FOR POSTERITY
            TECNvAMPERE_mat[:,j] = Pxy_TECNvAMPERE[i];
            TECvAMPEREN_mat[:,j] = Pxy_TECvAMPEREN[i];
            
            #Real quick side move to calc correlation coefficients
            R_keoNvsAMPERE_mat[j] = np.corrcoef(1/pwr_TECN[i]*keo_noise_xcorr_cutOut[i],1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i])[0,1];
            R_keovsAMPEREN_mat[j] = np.corrcoef(1/pwr_TEC[i]*keo_xcorr_cutOut[i],1/pwr_AMPEREN[i]*AMPERE_noise_xcorr_cutOut[i])[0,1];
        #END FOR j
        if( FLG_doubleKeo_xcorr_makeNoise == 1 ):
            #save the noise data if it was newly made
            with open(settings['paths']['cache']+'\\'+'keoTECnoise_'+noiseHash+'.pkl', 'wb') as doubleKeo_filer:
                pickle.dump(doubleKeo_keo_noise_xcorr[i], doubleKeo_filer); #save that data
            #END WITH
            toc = time.time() - tic; #calc the time it took
            print('Time to run '+doubleKeo_namesNice[i]+' noise making: '+textNice(np.round(toc/3600,2))+' hr.');
        #END IF
        
        R_keoNvsAMPERE[i] = np.mean(R_keoNvsAMPERE_mat);
        R_keovsAMPEREN[i] = np.mean(R_keovsAMPEREN_mat);
        stringer += '\nWhole '+doubleKeo_namesNice[i]+' Noise '+str(doubleKeo_xcorr_noiseIterations)+' #'+str(i+1)+' iters vs '+settings['AMPERE']['data type']+': '+str(np.round(R_keoNvsAMPERE[i],3));
        stringer += '\nWhole '+doubleKeo_namesNice[i]+' #'+str(i+1)+' vs '+settings['AMPERE']['data type']+' Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters: '+str(np.round(R_keovsAMPEREN[i],3));
        Pxy_TECNvAMPERE[i] = np.mean(TECNvAMPERE_mat,axis=1);
        Pxy_TECvAMPEREN[i] = np.mean(TECvAMPEREN_mat,axis=1);
    #END FOR i
    print(stringer); #report the coeff
    
    #--- Start the plot ---
    fig, ax = plt.subplots(nrows=len(doubleKeo_latLong), ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    if( len(doubleKeo_latLong) == 1 ):
        ax = [ax]; #wrap it because lists 
    #END IF
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    #Remove the aspect ratio from the basemap so it fills the screen better
    cntr = 0; #prep
    for i in range(0,len(doubleKeo_latLong)):
        ax[i].set_aspect('auto');
        pZ = []; #prep
        lZ = []; #prep
        
        pT, = ax[i].plot(keo_xcorr_time_cutOut[i]/3600,1/pwr_TEC[i]*keo_xcorr_cutOut[i],color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        lZ.append(doubleKeo_namesNice[i]+' #'+str(i+1)); #add onto the legend list
        
        pT, = ax[i].plot( (AMPERE_xcorr_time_cutOut[i]-dateRange_dayNum_zeroHr[1]*86400)/3600,1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i],color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        lZ.append(settings['AMPERE']['data type']+' #'+str(i+1)); #add onto the legend list
        
        # pT, = ax[i].plot(keo_xcorr_time_cutOut[i]/3600,1/pwr_TECN[i]*keo_noise_xcorr_cutOut[i],color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        # cntr += 1; #increment
        # pZ.append(pT); #add onto the plot list
        # lZ.append('Keo Noise (Last Iteration) #'+str(i+1)); #add onto the legend list
        
        # pT, = ax[i].plot( (AMPERE_xcorr_time_cutOut[i]-dateRange_dayNum_zeroHr[1]*86400)/3600,1/pwr_AMPEREN[i]*AMPERE_noise_xcorr_cutOut[i],color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        # cntr += 1; #increment
        # pZ.append(pT); #add onto the plot list
        # lZ.append('AMPERE Noise (Last Iteration) #'+str(i+1)); #add onto the legend list
        
        ax[i].legend(pZ, lZ, loc='upper right', framealpha=0.5);
        ax[i].set_ylabel('Normalized Ampltiude',fontproperties=FONT_axisLabelFM);
        
        ax[i].set_title(doubleKeo_namesNice[i]+' at '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2))+' lat & '+settings['AMPERE']['data type']+' (Time Delay '+textNice(doubleKeo_AMPERE_timeDelay[i])+') Whole Time on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
            fontproperties=FONT_titleFM);
    #END FOR i
    ax[i].set_xlabel('Time [hr]',fontproperties=FONT_axisLabelFM);
    
    
    # xAxisTicks = np.arange( 0, settings['spectra']['period limit max']/60+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    # ax.set_xticks(xAxisTicks); #set x axis ticks
    # ax.set_xlim( (settings['spectra']['period limit min']/60, settings['spectra']['period limit max']/60) );
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    
    #--- Start the plot ---
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    fig, ax = plt.subplots(nrows=len(doubleKeo_latLong), ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    if( len(doubleKeo_latLong) == 1 ):
        ax = [ax]; #wrap it in a list for list reasons
    # END IF
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    #Remove the aspect ratio from the basemap so it fills the screen better

    cntr = 0; #prep
    for i in range(0,len(doubleKeo_latLong)):
        ax[i].set_aspect('auto');
        pZ = []; #prep
        lZ = []; #prep
        
        pT, = ax[i].plot(1/freqs_TECvAMPERE[i]/60,(Pxy_TECvAMPERE[i]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        lZ.append('Whole '+doubleKeo_namesNice[i]+' #'+str(i+1)+' vs '+settings['AMPERE']['data type']); #add onto the legend list
        
        pT, = ax[i].plot(1/freqs_TECvAMPERE[i]/60,(Pxy_TECNvAMPERE[i]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        lZ.append('Whole '+doubleKeo_namesNice[i]+' Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters vs '+settings['AMPERE']['data type']+' #'+str(i+1)); #add onto the legend list
        
        pT, = ax[i].plot(1/freqs_TECvAMPERE[i]/60,(Pxy_TECvAMPEREN[i]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        lZ.append('Whole '+doubleKeo_namesNice[i]+' #'+str(i+1)+' '+str(doubleKeo_xcorr_noiseIterations)+' iters vs '+settings['AMPERE']['data type']+' Noise'); #add onto the legend list
    
        ax[i].set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
        ax[i].set_title('CSD - '+doubleKeo_namesNice[i]+'  at '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2))+' lat & '+settings['AMPERE']['data type']+' (Time Delay '+textNice(doubleKeo_AMPERE_timeDelay[i])+') Whole Time on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
            fontproperties=FONT_titleFM);
        ax[i].legend(pZ, lZ, loc='upper right', framealpha=0.5);
        
        xAxisTicks = np.arange( 0, settings['spectra']['period limit max']/60+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
        ax[i].set_xticks(xAxisTicks); #set x axis ticks
        ax[i].set_xlim( (settings['spectra']['period limit min']/60, settings['spectra']['period limit max']/60) );
    #END FOR i
    ax[i].set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
    #--- Just FFTs for good measure --- ['high-pass & 0 mean','high-pass & log10 & 0 mean']
    GRITI_spectral_analysisPlot([[keo_xcorr_cutOut[i],AMPERE_xcorr_cutOut[i],keo_noise_xcorr_cutOut[i],AMPERE_noise_xcorr_cutOut[i]] for i in range(0,len(doubleKeo_latLong))], 
        [[keo_xcorr_time_cutOut[i],AMPERE_xcorr_time_cutOut[i],keo_xcorr_time_cutOut[i],AMPERE_xcorr_time_cutOut[i]] for i in range(0,len(doubleKeo_latLong))], 
        [['sec','sec','sec','sec'] for i in range(0,len(doubleKeo_latLong))], [[doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate] for i in range(0,len(doubleKeo_latLong))], 
        [['sec','sec','sec','sec'] for i in range(0,len(doubleKeo_latLong))], 'min',
        [['none','none','none','none'] for i in range(0,len(doubleKeo_latLong))], [['fft','fft','fft','fft'] for i in range(0,len(doubleKeo_latLong))], 
        dates, settings_spectra, settings_plot, settings_paths, 
        [[doubleKeo_namesNice[i]+'  @ '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2)),settings['AMPERE']['data type']+' (Time Lag '+textNice(doubleKeo_AMPERE_timeDelay[i])+')',doubleKeo_namesNice[i]+'  Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters @ '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2)),settings['AMPERE']['data type']+' (Time Lag '+textNice(doubleKeo_AMPERE_timeDelay[i])+') Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters'] for i in range(0,len(doubleKeo_latLong))],
        reduceWindow=0); #insane plot call
    
    #--- Cutout Time Comparison ---
    Pxy_TECvAMPERE = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    freqs_TECvAMPERE = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    keo_xcorr_cutOut = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    keo_xcorr_time_cutOut = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    AMPERE_xcorr_cutOut = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    AMPERE_xcorr_time_cutOut = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    pwr_TEC = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    pwr_AMPERE = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    stringer = ''; #prep
    Fs = 1/(doubleKeo_AMPERE_dataRate); #sec, time delta in freq form
    for i in range(0,len(doubleKeo_latLong)):
        #TEC CUTOUT NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.min(time_cutout_range) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.min(time_cutout_range) ) )[0][0] , \
            np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.max(time_cutout_range) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
        keo_xcorr_cutOut[i] = np.copy(doubleKeo_keo_xcorr[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]);
        keo_xcorr_time_cutOut[i] = doubleKeo_keo_xcorr_time[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
        #AMPERE CUTOUT NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) ) )[0][0] , \
            np.where(np.min(np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.max(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
        AMPERE_xcorr_cutOut[i] = np.copy(doubleKeo_AMPERE_xcorr[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]);
        AMPERE_xcorr_time_cutOut[i] = doubleKeo_AMPERE_xcorr_time[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
        #enforce a local 0 mean
        if( strstr(doubleKeo_xcorr_AMPERE_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
            AMPERE_xcorr_cutOut[i] = subfun_filter( AMPERE_xcorr_cutOut[i], '0 mean', dataTime = AMPERE_xcorr_time_cutOut[i], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
        #END IF
        if( strstr(doubleKeo_xcorr_TEC_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
            keo_xcorr_cutOut[i] = subfun_filter( keo_xcorr_cutOut[i], '0 mean', dataTime = keo_xcorr_time_cutOut[i], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
        #END IF
        
        #CALC PWR
        pwr_TEC[i] = np.sqrt(1/keo_xcorr_cutOut[i].size*np.sum(keo_xcorr_cutOut[i]**2)); #estimate power of signal
        pwr_AMPERE[i] = np.sqrt(1/AMPERE_xcorr_cutOut[i].size*np.sum(AMPERE_xcorr_cutOut[i]**2)); #estimate power of signal
        
        if( np.isclose(360, doubleKeo_AMPERE_dataRate) ):
            nfft = settings_spectra['nfft']['6min'];
            nooverlap = settings['spectra']['noverlap']; #keep
            winnow = settings_spectra['window']; #keep
        else:
            #scale as needed
            nfft = settings_spectra['nfft']['6min']*360//doubleKeo_AMPERE_dataRate;
            nooverlap = settings['spectra']['noverlap']*360//doubleKeo_AMPERE_dataRate; #adjust
            if( settings_spectra['window type'] == 'hamm' ):
                winnow = np.hamming(settings_spectra['windowLength']*360//doubleKeo_AMPERE_dataRate); #adjust
            else:
                print('ERROR: Unsupported window type \''+settings_spectra['window type']+'\', add support for it here.');
                import sys
                sys.crash();
            #END IF
        #END IF
        
        if( (winnow.size > keo_xcorr_cutOut[i].size) | (winnow.size  > AMPERE_xcorr_cutOut[i].size) ):
            if( keo_xcorr_cutOut[i].size < AMPERE_xcorr_cutOut[i].size ):
                winnow = np.hamming(keo_xcorr_cutOut[i].size - 1); #adjust
            else:
                winnow = np.hamming(AMPERE_xcorr_cutOut[i].size - 1); #adjust
            #END IF
            nooverlap = winnow.size - 10; #adjust
        #END IF
        
        #CALC THE XCORR
        [freqs_TECvAMPERE[i],Cxy_TECvAMPERE] = signal.csd(1/pwr_TEC[i]*keo_xcorr_cutOut[i],1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i],window=winnow,noverlap=nooverlap,nfft=nfft,fs=Fs);
        Axy_TECvAMPERE = np.angle(Cxy_TECvAMPERE)*180/np.pi; 
        Pxy_TECvAMPERE[i] = np.abs(Cxy_TECvAMPERE);
        
        #Real quick side move to calc correlation coefficients
        R_keovsAMPERE = np.corrcoef(1/pwr_TEC[i]*keo_xcorr_cutOut[i],1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i])[0,1];
        if( i == 0 ):
            stringer += 'Corr Coeff:\n';
        #END IF
        stringer += 'Cutout '+str(time_cutout_range/3600)+' '+doubleKeo_namesNice[i]+' #'+str(i+1)+' vs '+settings['AMPERE']['data type']+': '+str(np.round(R_keovsAMPERE,3));
        if( i != len(doubleKeo_latLong)-1 ):
            stringer += ' | ';
        #END IF
    #END FOR i
    print(stringer); #report the coeff
    
    #--- ROLLING TIME DELAY TO FIND OPTIMAL CORR COEFF ---
    doubleKeo_AMPERE_timeDelay_shift = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    doubleKeo_AMPERE_timeDelay_shiftCorr = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    for i in range(0,len(doubleKeo_latLong)):
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.min(time_cutout_range) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.min(time_cutout_range) ) )[0][0] , \
            np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.max(time_cutout_range) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
        keo_xcorr_cutOut_rollin = np.copy(doubleKeo_keo_xcorr[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]);
        keo_xcorr_time_cutOut_rollin = doubleKeo_keo_xcorr_time[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        # #enforce a local 0 mean
        # if( strstr(doubleKeo_xcorr_TEC_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
        #     keo_xcorr_cutOut_rollin = subfun_filter( keo_xcorr_cutOut_rollin, '0 mean'); #filter (or not)
        # #END IF
        pwr_TEC_rollin = np.sqrt(1/keo_xcorr_cutOut_rollin.size*np.sum(keo_xcorr_cutOut_rollin**2)); #estimate power of signal
        keo_xcorr_cutOut_rollin_normd = 1/pwr_TEC_rollin*keo_xcorr_cutOut_rollin; #precalc it
        
        if( doubleKeo_AMPERE_timeDelay[i] >= 0 ):
            doubleKeo_AMPERE_timeDelay_shift[i] = np.arange(0,FLG_doubleKeo_xcorr_timeLim_AMPERE*3600+doubleKeo_AMPERE_timeDelay_shiftStep,doubleKeo_AMPERE_timeDelay_shiftStep); #get some time
        else:
            doubleKeo_AMPERE_timeDelay_shift[i] = np.arange(0,-FLG_doubleKeo_xcorr_timeLim_AMPERE*3600-doubleKeo_AMPERE_timeDelay_shiftStep,-doubleKeo_AMPERE_timeDelay_shiftStep); #get some time
        #END IF
        doubleKeo_AMPERE_timeDelay_shiftCorr[i] = np.empty(doubleKeo_AMPERE_timeDelay_shift[i].size); #preallocate it
        
        #--- Integrate AMPERE Data ---
        # doubleKeo_AMPERE_integrated_static = GRITI_AMPERE_integrator(data['AMPERE'], dates, settings_AMPERE, doubleKeo_latLong[i][0], doubleKeo_latLong[i][1], FLG_doubleKeo_AMPERE_integrateMethod[i], doubleKeo_AMPERE_integrateMethod_val[i]); #integrate with the integrator function
    
        #--- Filter if req'd ---
        # doubleKeo_AMPERE_integrated_static = subfun_filter( doubleKeo_AMPERE_integrated_static, FLG_doubleKeo_AMPERE_filtMethod, dataTime = AMPERE_timeUnique, dataRate=data['AMPERE']['data rate'], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
        # doubleKeo_AMPERE_integrated_static = subfun_filter( doubleKeo_AMPERE_integrated_static, doubleKeo_xcorr_AMPERE_filtMethod, dataTime = AMPERE_timeUnique, dataRate=data['AMPERE']['data rate'], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)

        for j in range(0,doubleKeo_AMPERE_timeDelay_shift[i].size):
            #--- Adjust by the time offset ---
            #Do this before the time matching so everything is well aligned
            # if( np.isclose(np.mod(doubleKeo_AMPERE_timeDelay_shift[i][j],1),0.0) ):
            doubleKeo_AMPERE_time_adj = AMPERE_timeUnique + np.int32(doubleKeo_AMPERE_timeDelay_shift[i][j]); #it all stays integers
            # sixMin_timeUnique_adj = sixMin_timeUnique_base + np.int32(doubleKeo_AMPERE_timeDelay_shift[i][j]); #it all stays integers
            # else:
            #     doubleKeo_AMPERE_time_adj = np.float64(AMPERE_timeUnique) + doubleKeo_AMPERE_timeDelay_shift[i][j]; #it all becomes floats
            #     sixMin_timeUnique_adj = np.float64(sixMin_timeUnique_base) + doubleKeo_AMPERE_timeDelay_shift[i][j]; #it all becomes floats
            # #END IF
            
            #--- Remove NaNs, replace with 0's so filtering stuff works ---
            doubleKeo_AMPERE_xcorr_adj = np.copy(doubleKeo_AMPERE_xcorr[i]);
            # doubleKeo_AMPERE_xcorr_adj =  np.copy(doubleKeo_AMPERE_integrated_static); #copy over for edits
            # doubleKeo_AMPERE_xcorr_adj[np.isnan(doubleKeo_AMPERE_xcorr_adj)] = 0; #replace NaNs with 0s
            
            #--- Filter if req'd ---
            # doubleKeo_AMPERE_xcorr_adj = subfun_filter( doubleKeo_AMPERE_xcorr_adj, doubleKeo_xcorr_AMPERE_filtMethod, dataTime = AMPERE_timeUnique, dataRate=360., settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
            
            # #--- Time match to 6 minutes on TEC time frame to deal with correlation stuff --- (already done)
            # if( np.all(np.isclose((doubleKeo_AMPERE_time_adj - dateRange_dayNum_zeroHr[1]*86400),sixMin_timeUnique_adj)) ):
            #     pass
            #     # doubleKeo_AMPERE_xcorr_adj = np.copy(doubleKeo_AMPERE_xcorr_adj); #copy it over, no changes needed
            #     # doubleKeo_AMPERE_timeHr[i] = (doubleKeo_AMPERE_time_adj - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
            # else:
            #     doubleKeo_AMPERE_xcorr_adj, doubleKeo_AMPERE_time_adj = subfun_timeMatch(doubleKeo_AMPERE_xcorr_adj, (doubleKeo_AMPERE_time_adj - dateRange_dayNum_zeroHr[1]*86400), sixMin_timeUnique_adj, timeMatch_delta=360., FLG_removeNaNs=0, FLG_useSum=1); #time match alg to align to 6 minute cadence, add because it's a count (?)
            #     doubleKeo_AMPERE_time_adj += dateRange_dayNum_zeroHr[1]*86400; #add back in the day offset b/c it's assumed it is there
            #     # doubleKeo_AMPERE_timeHr[i] = (doubleKeo_AMPERE_time_adj - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day                #END IF
                
            #     # #enforce a local 0 mean
            #     # if( strstr(doubleKeo_xcorr_AMPERE_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
            #     #     doubleKeo_AMPERE_xcorr_adj = subfun_filter( doubleKeo_AMPERE_xcorr_adj, '0 mean'); #filter (or not)
            #     # #END IF
            # #END IF

            #--- Remove NaNs, replace with 0's so filtering stuff works ---
            # doubleKeo_AMPERE_xcorr_adj =  np.copy(doubleKeo_AMPERE_integrated_static); #copy over for edits
            doubleKeo_AMPERE_xcorr_adj[np.isnan(doubleKeo_AMPERE_xcorr_adj)] = 0; #replace NaNs with 0s
                        
            #AMPERE CUTOUT NOW
            time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (doubleKeo_AMPERE_time_adj-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_time_adj-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) ) )[0][0] , \
                np.where(np.min(np.abs( (doubleKeo_AMPERE_time_adj-dateRange_dayNum_zeroHr[1]*86400) - np.max(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_time_adj-dateRange_dayNum_zeroHr[1]*86400) - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
            AMPERE_xcorr_cutOut_adj = doubleKeo_AMPERE_xcorr_adj[time_cutout_indexes[0]:time_cutout_indexes[1]+1];

            # #enforce a local 0 mean
            # if( strstr(doubleKeo_xcorr_AMPERE_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
            #     AMPERE_xcorr_cutOut_adj = subfun_filter( AMPERE_xcorr_cutOut_adj, '0 mean'); #filter (or not)
            # #END IF

            pwr_AMPERE_adj = np.sqrt(1/AMPERE_xcorr_cutOut_adj.size*np.sum(AMPERE_xcorr_cutOut_adj**2)); #estimate power of signal
                        
            #Real quick side move to calc correlation coefficients
            doubleKeo_AMPERE_timeDelay_shiftCorr[i][j] = np.corrcoef(keo_xcorr_cutOut_rollin_normd,1/pwr_AMPERE_adj*AMPERE_xcorr_cutOut_adj)[0,1];
        #END FOR j
        k = np.where( np.abs(doubleKeo_AMPERE_timeDelay_shiftCorr[i]) == np.max(np.abs(doubleKeo_AMPERE_timeDelay_shiftCorr[i])))[0]; #get maximum values
        k = k[np.min(np.mod(np.round(doubleKeo_AMPERE_timeDelay_shift[i][k],10),120)) == np.mod(np.round(doubleKeo_AMPERE_timeDelay_shift[i][k],10),120)].item(); #get one closest to 2 minutes
        print('Cutout '+str(time_cutout_range/3600)+'#'+str(i+1)+' Maximum correlation possible: '+textNice(np.round(doubleKeo_AMPERE_timeDelay_shiftCorr[i][k],3))+' at time delay: '+textNice(doubleKeo_AMPERE_timeDelay_shift[i][k]/3600)+' hrs'+\
            ' Current time delay: '+textNice(doubleKeo_AMPERE_timeDelay[i])+' hrs' );#print resupts
    #END FOR i
    
    corrRet = [None for i in range(0,len(doubleKeo_latLong))];
    for i in range(0,len(doubleKeo_latLong)):
        #--- Integrated AMPERE Data ---
        corrRet[i] = subfun_correlator_corraler(
                [doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i]+dates['date range zero hr dayNum'][1]*86400], '!DIRECT', doubleKeo_namesNice[i], doubleKeo_namesNice[i], \
                [doubleKeo_AMPERE_xcorr[i], AMPERE_timeUnique], '!DIRECT', settings_AMPERE['labels'][settings_AMPERE['data type']], settings_AMPERE['data type'], \
                dates, settings['plot'], settings['paths'], settings['config'], \
                1, [{'mode':'range','time range':time_cutout_range} for _ in range(1)], FLG_correlator_plot = True, FLG_correlator_tabulator = FLG_doubleKeo_xcorr_tabulator, \
                FLG_correlator_shiftDir = 'both', FLG_correlator_timeLim = 3*3600, \
                filt1 = None,  filt2 = None, settings_spectra=settings['spectra'], reportDivisor=[60,'min']);
    #END FOR i
    
    corrRet = [None for i in range(0,len(doubleKeo_latLong))];
    for i in range(0,len(doubleKeo_latLong)):
        #--- OMNI ---
        corrRet[i] = subfun_correlator_corraler(
                [doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i]+dates['date range zero hr dayNum'][1]*86400], '!DIRECT', doubleKeo_namesNice[i], doubleKeo_namesNice[i], \
                data['OMNI'], settings['OMNI'], 'OMNI', OMNI_plotSet_name, \
                dates, settings['plot'], settings['paths'], settings['config'], \
                1, [{'mode':'range','time range':time_cutout_range} for _ in range(len(OMNI_plotSet_name))], FLG_correlator_plot = FLG_doubleKeo_xcorr_enableCorrPlots, FLG_correlator_tabulator = FLG_doubleKeo_xcorr_tabulator, \
                FLG_correlator_shiftDir = 'pos', FLG_correlator_timeLim = 6*3600, \
                filt1 = None,  filt2 = 'nan & '+doubleKeo_xcorr_OMNI_filtMethod, settings_spectra=settings['spectra'], reportDivisor=[60,'min']);
    # END FOR i
        
    if( (FLG_doubleKeo_xcorr_TECnOMNIxcorr >= 1) & (FLG_doubleKeo_xcorr_disableXcorr == False) ):
        from Code.subfun_Xcorrelator import subfun_Xcorrelator
        from Code.subfun_timeMatch import subfun_timeMatch
        
        XcorrRet = [None for j in range(0,len(OMNI_plotSet_name))]; #preallocate
        for i in range(0,len(doubleKeo_latLong)):
            print('\nWorking on Xcorrelator_TECnOMNI - Double Keo #'+str(i+1)+' - '+doubleKeo_namesNice[i]);
            FLG_TECnOMNI_Xcorrelator_options = [{'time shift':None,'time range':time_cutout_range,'sig1 filt':None,'sig2 filt':'nan & '+doubleKeo_xcorr_OMNI_filtMethod} for _ in range(len(OMNI_plotSet_name))]; #define here
            for j in range(0,len(OMNI_plotSet_name)):
                FLG_TECnOMNI_Xcorrelator_options[j]['time shift'] = corrRet[i][j]['time shift'].item(); #use automatically found value
                # if(OMNI_plotSet_name[j] == 'SYM/H'):
                #     FLG_TECnOMNI_Xcorrelator_options[j]['time shift'] = (doubleKeo_AMPERE_timeDelay[i]+54/60)*3600;
                # elif(OMNI_plotSet_name[j] == 'AL'):
                #     FLG_TECnOMNI_Xcorrelator_options[j]['time shift'] = (doubleKeo_AMPERE_timeDelay[i]+60/60)*3600;
                # elif(OMNI_plotSet_name[j] == 'Bz GSM'):
                #     FLG_TECnOMNI_Xcorrelator_options[j]['time shift'] = (doubleKeo_AMPERE_timeDelay[i]+54/60)*3600;
                # elif(OMNI_plotSet_name[j] == 'PC(N)'):
                #     FLG_TECnOMNI_Xcorrelator_options[j]['time shift'] = (doubleKeo_AMPERE_timeDelay[i]+30/60)*3600;
                #     FLG_TECnOMNI_Xcorrelator_options[j]['time shift'] = 336*60; #override
                # elif(OMNI_plotSet_name[j] == 'Psw'):
                #     FLG_TECnOMNI_Xcorrelator_options[j]['time shift'] = (doubleKeo_AMPERE_timeDelay[i]+222/60)*3600;
                # elif(OMNI_plotSet_name[j] == 'Vsw'):
                #     FLG_TECnOMNI_Xcorrelator_options[j]['time shift'] = (doubleKeo_AMPERE_timeDelay[i]+18/60)*3600;
                # elif(OMNI_plotSet_name[j] == 'Proton Density'):
                #     FLG_TECnOMNI_Xcorrelator_options[j]['time shift'] = (doubleKeo_AMPERE_timeDelay[i]+222/60)*3600;
                # #END IF
            #END FOR j
            if( len(FLG_TECnOMNI_Xcorrelator_options) == len(OMNI_plotSet_name) ):
                TEC_integrated_noise = np.empty((100, doubleKeo_keo_xcorr[i].size)); #get 100 iterations of noise to use
                for k in range(0,TEC_integrated_noise.shape[0]):
                    TEC_integrated_noise[k,:] = np.random.normal(loc=noise_background_mean,scale=noise_background_stdev,size=doubleKeo_keo_xcorr[i].size); #create some fake data
                #END FOR k
                kr_OMNI = (OMNI_timeUnique >= dateRange_dayNum_full[0,1]*86400) & (OMNI_timeUnique < (dateRange_dayNum_full[-1,1]+1)*86400); #get stuff outside the date range
                kr_TEC = (doubleKeo_keo_xcorr_time[i] >= (dateRange_dayNum_full[0,1]-dates['date range zero hr dayNum'][1])*86400) & (doubleKeo_keo_xcorr_time[i] < (dateRange_dayNum_full[-1,1]+1-dates['date range zero hr dayNum'][1])*86400); #get stuff outside the date range
                for j in range(0,len(OMNI_plotSet_name)):
                    OMNI_noise = np.empty((100, OMNI_data[kr_OMNI,OMNI_dict[OMNI_plotSet_name[j]]].size)); #get 100 iterations of noise to use
                    for k in range(0,OMNI_noise.shape[0]):
                        OMNI_noise[k,:] = np.random.normal(loc=np.nanmean(OMNI_data[kr_OMNI,OMNI_dict[OMNI_plotSet_name[j]]]),scale=np.nanstd(OMNI_data[kr_OMNI,OMNI_dict[OMNI_plotSet_name[j]]]),size=OMNI_data[kr_OMNI,OMNI_dict[OMNI_plotSet_name[j]]].size); #create some fake data
                    #END FOR k
                    if( FLG_doubleKeo_xcorr_TECnOMNIxcorr == 2 ):
                        sig1 = OMNI_data[kr_OMNI,OMNI_dict[OMNI_plotSet_name[j]]]; #sig1 stays static
                        sig1_noise = OMNI_noise;
                        time1 = OMNI_timeUnique[kr_OMNI]-dates['date range zero hr dayNum'][1]*86400;
                        dataRate1 = data['OMNI']['data rate'];
                        sig2 = doubleKeo_keo_xcorr[i][kr_TEC]; #sig2 moves around
                        sig2_noise = TEC_integrated_noise[:,kr_TEC];
                        time2 = doubleKeo_keo_xcorr_time[i][kr_TEC];
                        dataRate2 = doubleKeo_AMPERE_dataRate; #manual set for doubleKeo_keo_xcorr
                        plotName = OMNI_dictPlot[OMNI_dict[OMNI_plotSet_name[j]]][:OMNI_dictPlot[OMNI_dict[OMNI_plotSet_name[j]]].find(' [')]+ \
                            ' & '+doubleKeo_namesNice[i];
                    else:
                        sig1 = doubleKeo_keo_xcorr[i][kr_TEC]; #sig1 stays static
                        sig1_noise = TEC_integrated_noise[:,kr_TEC];
                        time1 = doubleKeo_keo_xcorr_time[i][kr_TEC];
                        dataRate1 = doubleKeo_AMPERE_dataRate; #manual set for doubleKeo_keo_xcorr
                        sig2 = OMNI_data[kr_OMNI,OMNI_dict[OMNI_plotSet_name[j]]]; #sig2 moves around
                        sig2_noise = OMNI_noise;
                        time2 = OMNI_timeUnique[kr_OMNI]-dates['date range zero hr dayNum'][1]*86400;
                        dataRate2 = data['OMNI']['data rate'];
                        plotName = doubleKeo_namesNice[i]+ \
                            ' & '+OMNI_dictPlot[OMNI_dict[OMNI_plotSet_name[j]]][:OMNI_dictPlot[OMNI_dict[OMNI_plotSet_name[j]]].find(' [')];
                    #END IF
                    if( np.isclose(dataRate1,dataRate2) == False ):
                        if( dataRate1 > dataRate2 ):
                            if( type(sig2_noise) is list ):
                                for k in range(0,len(sig2_noise)):
                                    if(k == len(sig2_noise)-1):
                                        sig2_noise[k], _ = subfun_timeMatch(sig2_noise[k], time2, time1, timeMatch_delta=dataRate1, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                                    else:
                                        sig2_noise[k], _ = subfun_timeMatch(sig2_noise[k], time2, time1, timeMatch_delta=dataRate1, FLG_removeNaNs=2, FLG_reportNaNs=False); #match the times to the same cadence
                                    #END IF
                                #END FOR k
                            elif( sig2_noise.ndim == 2 ):
                                sig2_noiseNew = np.empty((sig2_noise.shape[0], time1.size)); #get newly sized sig2_noise holder
                                for k in range(0,sig2_noise.shape[0]):
                                    if(k == sig2_noise.shape[0]-1):
                                        sig2_noiseNew[k,:], _ = subfun_timeMatch(sig2_noise[k,:], time2, time1, timeMatch_delta=dataRate1, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                                    else:
                                        sig2_noiseNew[k,:], _ = subfun_timeMatch(sig2_noise[k,:], time2, time1, timeMatch_delta=dataRate1, FLG_removeNaNs=2, FLG_reportNaNs=False); #match the times to the same cadence
                                    #END IF
                                #END FOR k
                                sig2_noise = sig2_noiseNew; #replace
                            else:
                                sig2_noise, _ = subfun_timeMatch(sig2_noise, time2, time1, timeMatch_delta=dataRate1, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                            #END IF
                            sig2, time2 = subfun_timeMatch(sig2, time2, time1, timeMatch_delta=dataRate1, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                            dataRate2 = dataRate1; #set it
                        else:
                            if( type(sig1_noise) is list ):
                                for k in range(0,len(sig1_noise)):
                                    if(k == len(sig1_noise)-1):
                                        sig1_noise[k], _ = subfun_timeMatch(sig1_noise[k], time1, time2, timeMatch_delta=dataRate2, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                                    else:
                                        sig1_noise[k], _ = subfun_timeMatch(sig1_noise[k], time1, time2, timeMatch_delta=dataRate2, FLG_removeNaNs=2, FLG_reportNaNs=False); #match the times to the same cadence
                                    #END IF
                                #END FOR k
                            elif( sig1_noise.ndim == 2 ):
                                sig1_noiseNew = np.empty((sig1_noise.shape[0], time2.size)); #get newly sized sig1_noise holder
                                for k in range(0,sig1_noise.shape[0]):
                                    if(k == sig1_noise.shape[0]-1):
                                        sig1_noiseNew[k,:], _ = subfun_timeMatch(sig1_noise[k,:], time1, time2, timeMatch_delta=dataRate2, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                                    else:
                                        sig1_noiseNew[k,:], _ = subfun_timeMatch(sig1_noise[k,:], time1, time2, timeMatch_delta=dataRate2, FLG_removeNaNs=2, FLG_reportNaNs=False); #match the times to the same cadence
                                    #END IF
                                #END FOR k
                                sig1_noise = sig1_noiseNew; #replace
                            else:
                                sig1_noise, _ = subfun_timeMatch(sig1_noise, time1, time2, timeMatch_delta=dataRate2, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                            #END IF
                            sig1, time1 = subfun_timeMatch(sig1, time1, time2, timeMatch_delta=dataRate2, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                            dataRate1 = dataRate2; #set it
                        #END IF
                    #END IF
                               
                    if( FLG_TECnOMNI_Xcorrelator_options[j]['time shift'] != None ):
                        time2shift = FLG_TECnOMNI_Xcorrelator_options[j]['time shift']; #set to value
                    else:
                        time2shift = OMNI_delay_wrt_AMPERE*3600; #use global value
                    #END IF
                    XcorrRet[j] = subfun_Xcorrelator(sig1, sig2, sig1_filt=FLG_TECnOMNI_Xcorrelator_options[j]['sig1 filt'], sig2_filt=FLG_TECnOMNI_Xcorrelator_options[j]['sig2 filt'], sig1_noise=sig1_noise, sig2_noise=sig2_noise, time1=time1, time2=time2, time2shift=time2shift, \
                           dataRate=dataRate1, timeRange=FLG_TECnOMNI_Xcorrelator_options[j]['time range'], settings_spectra=settings_spectra, FLG_interpGaps=True, reportDivisor=[60,'min'], reportRounder=3, \
                           FLG_plot=True, FLG_plot_onlyXcorr=False, settings_plot=settings_plot, settings_paths=settings_paths, dates=dates, plotName=plotName, FLG_fancyPlot=0);
                #END FOR j
            else:
                print('WARNING in FLG_TECnOMNI_Xcorrelator: Length of FLG_TECnOMNI_Xcorrelator_options ('+str(len(FLG_TECnOMNI_Xcorrelator_options))+') does not equal length of OMNI_plotSet_name ('+str(len(OMNI_plotSet_name))+')');
            #END IF
        #END FOR i
    #END IF
    
    SuperMAG_data = data['SuperMAG'];
    SuperMAG_timeUnique = data['SuperMAG']['time unique'];
    corrRet = [None for i in range(0,len(doubleKeo_latLong))];
    for i in range(0,len(doubleKeo_latLong)):
        corrRet[i] = subfun_correlator_corraler(
                [doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i]+dates['date range zero hr dayNum'][1]*86400], '!DIRECT', doubleKeo_namesNice[i], doubleKeo_namesNice[i], \
                data['SuperMAG'], settings['SuperMAG'], 'SuperMAG', SuperMAG_plotSet, \
                dates, settings['plot'], settings['paths'], settings['config'], \
                1, [{'mode':'range','time range':time_cutout_range} for _ in range(len(SuperMAG_plotSet))], FLG_correlator_plot = FLG_doubleKeo_xcorr_enableCorrPlots, FLG_correlator_tabulator = FLG_doubleKeo_xcorr_tabulator, \
                FLG_correlator_shiftDir = 'pos', FLG_correlator_timeLim = 21600, \
                filt1 = None,  filt2 = doubleKeo_xcorr_AMPERE_filtMethod, settings_spectra=settings['spectra'], reportDivisor=[60,'min']);
    # END FOR i
    
    corrRet = [None for i in range(0,len(doubleKeo_latLong))];
    for i in range(0,len(doubleKeo_latLong)):
        doubleKeo_xcorr_MagCAN_names = [item+'&|mag'+'$|'+str(i) for item in MagCAN_keo_setStations_names for i in range(3)]; #all 3 vectors
        doubleKeo_xcorr_MagCAN_options = [{'mode':'range','time range':time_cutout_range} for _ in range(len(doubleKeo_xcorr_MagCAN_names))]; #all options
        corrRet[i] = subfun_correlator_corraler(
                [doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i]+dates['date range zero hr dayNum'][1]*86400], '!DIRECT', doubleKeo_namesNice[i], doubleKeo_namesNice[i], \
                data['MagCAN'], settings['MagCAN'], 'MagCAN', doubleKeo_xcorr_MagCAN_names, \
                dates, settings['plot'], settings['paths'], settings['config'], \
                1, doubleKeo_xcorr_MagCAN_options, FLG_correlator_plot = FLG_doubleKeo_xcorr_enableCorrPlots, FLG_correlator_tabulator = FLG_doubleKeo_xcorr_tabulator, \
                FLG_correlator_shiftDir = 'pos', FLG_correlator_timeLim = 21600, \
                filt1 = None,  filt2 = 'nan & '+doubleKeo_xcorr_MagCAN_filtMethod, settings_spectra=settings['spectra'], reportDivisor=[60,'min']);
    #END FOR i
    if( FLG_doubleKeo_xcorr_TECnMagCANxcorr >= 1 ):
        pass; #not implemented yet
    #END IF
    
    if( FLG_doubleKeo_xcorr_walkingCorr >= 1 ):
        print('\nNOTA BENE: Running FLG_doubleKeo_xcorr_walkingCorr. Walking correlation calcs and plots will take a while.\n');
        from Code.subfun_correlator_walking import subfun_correlator_walking
        from Code.subfun_correlator_walking_plotter import subfun_correlator_walking_plotter
        showNiteTimesDict = { #prep a dict that holds nite calc'n time info
            'nite times':doubleKeo_niteTimes, #can be [False] to disable (or [False,othr,stuff] - disable only checks 1st value for False)
            'lat align':doubleKeo_AMPERE_latAlign, #list size of corrRet that has lats to align to
            'lat long range':doubleKeo_latLong, #something like [[[50, 75], [-15, 40]], [[25, 50], [-100, -60]]] for a corrRet of size 2
            'lat or long':doubleKeo_plotSpacingName}; #notes if lat align holds either latitude or longitude, put longitude if lat align holds longitude values (happens)
        
        #----- TEC & AMPERE SETTINGS -----
        time2lim = 3*3600; #time limit to check corr coeffs for
        time2span = 6*3600; #time range to cutout and check
        time2step = 1*3600; #time increment to step 
        time2shiftDir = 'both'; #shift direction (remember POS goes back in time b/c you need to add +offset to a time range to bring it forward to align w/ reference time frame)
        data2types = [settings_AMPERE['labels'][settings_AMPERE['data type']]]; #data2 (2nd set of inputs into function) types involved
        
        corrRet = [None for i in range(0,len(doubleKeo_latLong))];
        for i in range(0,len(doubleKeo_latLong)):
            #--- Integrated AMPERE Data ---
            corrRet[i], time_cutout_range_walking = subfun_correlator_walking(
                    [doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i]+dates['date range zero hr dayNum'][1]*86400], '!DIRECT', doubleKeo_namesNice[i], doubleKeo_namesNice[i], \
                    [doubleKeo_AMPERE_xcorr[i], AMPERE_timeUnique], '!DIRECT', settings_AMPERE['labels'][settings_AMPERE['data type']], settings_AMPERE['labels'][settings_AMPERE['data type']], \
                    dates, settings['plot'], settings['paths'], settings['config'], \
                    1, [{'mode':'range','time range':time_cutout_range} for _ in range(1)], FLG_correlator_plot = False, FLG_correlator_tabulator = False, \
                    FLG_correlator_shiftDir = time2shiftDir, FLG_correlator_timeLim = time2lim, \
                    filt1 = None,  filt2 = None, settings_spectra=settings['spectra'], reportDivisor=[60,'min'],
                    time2span=time2span, time2step=time2step, time2bound=None, FLG_clipData2=False, FLG_nanLimitData2=False);
        #END FOR i
        
        #--- Plot the returns up ---
        if( FLG_fancyPlot < 2 ):
            subfun_correlator_walking_plotter(corrRet, doubleKeo_namesNice, data2types, \
                time_cutout_range_walking, time2span, \
                time2step, time2lim, time2shiftDir, \
                settings['plot'], settings['paths'], dates, \
                FLG_showNiteTimes = True, showNiteTimesDict = showNiteTimesDict, \
                reportDivisor = [3600,'hr'], FLG_fancyPlot = False); #plot that up
        #END IF
        if( FLG_fancyPlot > 0 ):
            subfun_correlator_walking_plotter(corrRet, doubleKeo_namesNice, data2types, \
                time_cutout_range_walking, time2span, \
                time2step, time2lim, time2shiftDir, \
                settings['plot'], settings['paths'], dates, \
                FLG_showNiteTimes = True, showNiteTimesDict = showNiteTimesDict, \
                reportDivisor = [3600,'hr'], FLG_fancyPlot = True); #plot that up
        #END IF
        
        
        #--- --TEC & OMNI SETTINGS -----
        time2lim = 6*3600; #time limit to check corr coeffs for
        time2span = 6*3600; #time range to cutout and check
        time2step = 1*3600; #time increment to step 
        time2shiftDir = 'pos'; #shift direction (remember POS goes back in time b/c you need to add +offset to a time range to bring it forward to align w/ reference time frame)
        data2types = OMNI_plotSet_name; #data2 (2nd set of inputs into function) types involved
        
        corrRet = [None for i in range(0,len(doubleKeo_latLong))];
        for i in range(0,len(doubleKeo_latLong)):
            #--- OMNI ---
            corrRet[i], time_cutout_range_walking = subfun_correlator_walking(
                    [doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i]+dates['date range zero hr dayNum'][1]*86400], '!DIRECT', doubleKeo_namesNice[i], doubleKeo_namesNice[i], \
                    data['OMNI'], settings['OMNI'], 'OMNI', OMNI_plotSet_name, \
                    dates, settings['plot'], settings['paths'], settings['config'], \
                    1, [{'mode':'range','time range':time_cutout_range} for _ in range(len(OMNI_plotSet_name))], FLG_correlator_plot = False, FLG_correlator_tabulator = False, \
                    FLG_correlator_shiftDir = time2shiftDir, FLG_correlator_timeLim = time2lim, \
                    filt1 = None,  filt2 = 'nan & '+doubleKeo_xcorr_OMNI_filtMethod, settings_spectra=settings['spectra'], reportDivisor=[60,'min'],
                    time2span=time2span, time2step=time2step, time2bound=None, FLG_clipData2=False, FLG_nanLimitData2=False);
        # END FOR i
        
        #--- Plot the returns up ---
        if( FLG_fancyPlot < 2 ):
            subfun_correlator_walking_plotter(corrRet, doubleKeo_namesNice, data2types, \
                time_cutout_range_walking, time2span, \
                time2step, time2lim, time2shiftDir, \
                settings['plot'], settings['paths'], dates, \
                FLG_showNiteTimes = True, showNiteTimesDict = showNiteTimesDict, \
                reportDivisor = [3600,'hr'], FLG_fancyPlot = False); #plot that up
        #END IF
        if( FLG_fancyPlot > 0 ):
            subfun_correlator_walking_plotter(corrRet, doubleKeo_namesNice, data2types, \
                time_cutout_range_walking, time2span, \
                time2step, time2lim, time2shiftDir, \
                settings['plot'], settings['paths'], dates, \
                FLG_showNiteTimes = True, showNiteTimesDict = showNiteTimesDict, \
                reportDivisor = [3600,'hr'], FLG_fancyPlot = True); #plot that up
        #END IF
        
        #--- --TEC & SuperMAG SETTINGS -----
        time2lim = 6*3600; #time limit to check corr coeffs for
        time2span = 6*3600; #time range to cutout and check
        time2step = 1*3600; #time increment to step 
        time2shiftDir = 'pos'; #shift direction (remember POS goes back in time b/c you need to add +offset to a time range to bring it forward to align w/ reference time frame)
        data2types = SuperMAG_plotSet; #data2 (2nd set of inputs into function) types involved
            
        SuperMAG_data = data['SuperMAG'];
        SuperMAG_timeUnique = data['SuperMAG']['time unique'];
        corrRet = [None for i in range(0,len(doubleKeo_latLong))];
        for i in range(0,len(doubleKeo_latLong)):
            corrRet[i], time_cutout_range_walking = subfun_correlator_walking(
                    [doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i]+dates['date range zero hr dayNum'][1]*86400], '!DIRECT', doubleKeo_namesNice[i], doubleKeo_namesNice[i], \
                    data['SuperMAG'], settings['SuperMAG'], 'SuperMAG', SuperMAG_plotSet, \
                    dates, settings['plot'], settings['paths'], settings['config'], \
                    1, [{'mode':'range','time range':time_cutout_range} for _ in range(len(SuperMAG_plotSet))], FLG_correlator_plot = False, FLG_correlator_tabulator = False, \
                    FLG_correlator_shiftDir = time2shiftDir, FLG_correlator_timeLim = time2lim, \
                    filt1 = None,  filt2 = doubleKeo_xcorr_AMPERE_filtMethod, settings_spectra=settings['spectra'], reportDivisor=[60,'min'],
                    time2span=time2span, time2step=time2step, time2bound=None, FLG_clipData2=False, FLG_nanLimitData2=False);
        # END FOR i
        
        #--- Plot the returns up ---
        if( FLG_fancyPlot < 2 ):
            subfun_correlator_walking_plotter(corrRet, doubleKeo_namesNice, data2types, \
                time_cutout_range_walking, time2span, \
                time2step, time2lim, time2shiftDir, \
                settings['plot'], settings['paths'], dates, \
                FLG_showNiteTimes = True, showNiteTimesDict = showNiteTimesDict, \
                reportDivisor = [3600,'hr'], FLG_fancyPlot = False); #plot that up
        #END IF
        if( FLG_fancyPlot > 0 ):
            subfun_correlator_walking_plotter(corrRet, doubleKeo_namesNice, data2types, \
                time_cutout_range_walking, time2span, \
                time2step, time2lim, time2shiftDir, \
                settings['plot'], settings['paths'], dates, \
                FLG_showNiteTimes = True, showNiteTimesDict = showNiteTimesDict, \
                reportDivisor = [3600,'hr'], FLG_fancyPlot = True); #plot that up
        #END IF
            
            
        #--- --TEC & MagCAN SETTINGS -----
        time2lim = 3*3600; #time limit to check corr coeffs for
        time2span = 6*3600; #time range to cutout and check
        time2step = 1*3600; #time increment to step 
        time2shiftDir = 'both'; #shift direction (remember POS goes back in time b/c you need to add +offset to a time range to bring it forward to align w/ reference time frame)
        
        doubleKeo_xcorr_MagCAN_names = [item+'&|mag'+'$|'+str(j) for item in MagCAN_keo_setStations_names for j in range(3)]; #all 3 vectors
        data2types = doubleKeo_xcorr_MagCAN_names; #data2 (2nd set of inputs into function) types involved
        doubleKeo_xcorr_MagCAN_options = [{'mode':'range','time range':time_cutout_range} for _ in range(len(doubleKeo_xcorr_MagCAN_names))]; #all options
        corrRet = [None for i in range(0,len(doubleKeo_latLong))];
        for i in range(0,len(doubleKeo_latLong)):
            corrRet[i], time_cutout_range_walking = subfun_correlator_walking(
                    [doubleKeo_keo_xcorr[i], doubleKeo_keo_xcorr_time[i]+dates['date range zero hr dayNum'][1]*86400], '!DIRECT', doubleKeo_namesNice[i], doubleKeo_namesNice[i], \
                    data['MagCAN'], settings['MagCAN'], 'MagCAN', doubleKeo_xcorr_MagCAN_names, \
                    dates, settings['plot'], settings['paths'], settings['config'], \
                    1, doubleKeo_xcorr_MagCAN_options, FLG_correlator_plot = False, FLG_correlator_tabulator = False, \
                    FLG_correlator_shiftDir = time2shiftDir, FLG_correlator_timeLim = time2lim, \
                    filt1 = None,  filt2 = 'nan & '+doubleKeo_xcorr_MagCAN_filtMethod, settings_spectra=settings['spectra'], reportDivisor=[60,'min'],
                    time2span=time2span, time2step=time2step, time2bound=None, FLG_clipData2=False, FLG_nanLimitData2=False);
        #END FOR i
        
        #--- Plot the returns up ---
        if( FLG_fancyPlot < 2 ):
            subfun_correlator_walking_plotter(corrRet, doubleKeo_namesNice, data2types, \
                time_cutout_range_walking, time2span, \
                time2step, time2lim, time2shiftDir, \
                settings['plot'], settings['paths'], dates, \
                FLG_showNiteTimes = True, showNiteTimesDict = showNiteTimesDict, \
                reportDivisor = [3600,'hr'], FLG_fancyPlot = False); #plot that up
        #END IF
        if( FLG_fancyPlot > 0 ):
            subfun_correlator_walking_plotter(corrRet, doubleKeo_namesNice, data2types, \
                time_cutout_range_walking, time2span, \
                time2step, time2lim, time2shiftDir, \
                settings['plot'], settings['paths'], dates, \
                FLG_showNiteTimes = True, showNiteTimesDict = showNiteTimesDict, \
                reportDivisor = [3600,'hr'], FLG_fancyPlot = True); #plot that up
        #END IF
    #END IF
    
    #now, noise comparisons
    Pxy_TECNvAMPERE = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    keo_noise_xcorr_cutOut = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    pwr_TECN = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    TECNvAMPERE_mat = np.empty((np.int64((settings_spectra['nfft']['6min']*360//doubleKeo_AMPERE_dataRate)/2+1),avgPt_TECnoise_iterations));
    TECvAMPEREN_mat = np.empty((np.int64((settings_spectra['nfft']['6min']*360//doubleKeo_AMPERE_dataRate)/2+1),avgPt_TECnoise_iterations));
    R_keoNvsAMPERE_mat = np.empty((avgPt_TECnoise_iterations));
    R_keoNvsAMPERE = [[] for jj in range(0,len(doubleKeo_latLong))]; #prep
    stringer = ''; #prep
    for i in range(0,len(doubleKeo_latLong)):
        for j in range(0,doubleKeo_xcorr_noiseIterations):       
            #already did the exxpensive noise raytracing calcs earlier, can re-use here
                
            #TEC CUTOUT NOW
            time_cutout_indexes = np.array( ( np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.min(time_cutout_range) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.min(time_cutout_range) ) )[0][0] , \
                np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.max(time_cutout_range) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
            keo_noise_xcorr_cutOut[i] = np.copy(doubleKeo_keo_noise_xcorr[i][j][time_cutout_indexes[0]:time_cutout_indexes[1]+1]);
            keo_xcorr_time_cutOut[i] = doubleKeo_keo_xcorr_time[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
            
            #AMPERE CUTOUT NOW
            time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) ) )[0][0] , \
                np.where(np.min(np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.max(time_cutout_range) )) == np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
            AMPERE_noise_xcorr_cutOut[i] = np.copy(doubleKeo_AMPERE_noise_xcorr[i][j][time_cutout_indexes[0]:time_cutout_indexes[1]+1]);
            AMPERE_xcorr_time_cutOut[i] = doubleKeo_AMPERE_xcorr_time[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
            
            #enforce a local 0 mean
            if( strstr(doubleKeo_xcorr_TEC_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
                keo_noise_xcorr_cutOut[i] = subfun_filter( keo_noise_xcorr_cutOut[i], '0 mean', dataTime = keo_xcorr_time_cutOut[i], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
            #END IF
            if( strstr(doubleKeo_xcorr_AMPERE_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
                AMPERE_noise_xcorr_cutOut[i] = subfun_filter( AMPERE_noise_xcorr_cutOut[i], '0mean', dataTime = AMPERE_xcorr_time_cutOut[i], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
            #END IF
            
            #CALC PWR
            pwr_TECN[i] = np.sqrt(1/keo_noise_xcorr_cutOut[i].size*np.sum(keo_noise_xcorr_cutOut[i]**2)); #estimate power of signal
            pwr_AMPEREN[i] = np.sqrt(1/AMPERE_noise_xcorr_cutOut[i].size*np.sum(AMPERE_noise_xcorr_cutOut[i]**2)); #estimate power of signal
            
            if( np.isclose(360, doubleKeo_AMPERE_dataRate) ):
                nfft = settings_spectra['nfft']['6min'];
                nooverlap = settings['spectra']['noverlap']; #keep
                winnow = settings_spectra['window']; #keep
            else:
                #scale as needed
                nfft = settings_spectra['nfft']['6min']*360//doubleKeo_AMPERE_dataRate;
                nooverlap = settings['spectra']['noverlap']*360//doubleKeo_AMPERE_dataRate; #adjust
                if( settings_spectra['window type'] == 'hamm' ):
                    winnow = np.hamming(settings_spectra['windowLength']*360//doubleKeo_AMPERE_dataRate); #adjust
                else:
                    print('ERROR: Unsupported window type \''+settings_spectra['window type']+'\', add support for it here.');
                    import sys
                    sys.crash();
                #END IF
            #END IF
            
            if( (winnow.size > keo_noise_xcorr_cutOut[i].size) | (winnow.size  > AMPERE_noise_xcorr_cutOut[i].size) ):
                if( keo_noise_xcorr_cutOut[i].size < AMPERE_noise_xcorr_cutOut[i].size ):
                    winnow = np.hamming(keo_noise_xcorr_cutOut[i].size - 1); #adjust
                else:
                    winnow = np.hamming(AMPERE_noise_xcorr_cutOut[i].size - 1); #adjust
                #END IF
                nooverlap = winnow.size - 10; #adjust
            #END IF
            
            [_,Cxy_TECNvAMPERE] = signal.csd(1/pwr_TECN[i]*keo_noise_xcorr_cutOut[i],1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i],window=winnow,noverlap=nooverlap,nfft=nfft,fs=Fs);
            Axy_TECNvAMPERE = np.angle(Cxy_TECNvAMPERE)*180/np.pi; 
            Pxy_TECNvAMPERE[i] = np.abs(Cxy_TECNvAMPERE);
            
            [_,Cxy_TECvAMPEREN] = signal.csd(1/pwr_TEC[i]*keo_xcorr_cutOut[i],1/pwr_AMPEREN[i]*AMPERE_noise_xcorr_cutOut[i],window=winnow,noverlap=nooverlap,nfft=nfft,fs=Fs);
            Axy_TECvAMPEREN = np.angle(Cxy_TECvAMPEREN)*180/np.pi; 
            Pxy_TECvAMPEREN[i] = np.abs(Cxy_TECvAMPEREN);
            
            #RECORD FOR POSTERITY
            TECNvAMPERE_mat[:,j] = Pxy_TECNvAMPERE[i];
            TECvAMPEREN_mat[:,j] = Pxy_TECvAMPEREN[i];
            
            #Real quick side move to calc correlation coefficients
            R_keoNvsAMPERE_mat[j] = np.corrcoef(1/pwr_TECN[i]*keo_noise_xcorr_cutOut[i],1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i])[0,1];
            R_keovsAMPEREN_mat[j] = np.corrcoef(1/pwr_TEC[i]*keo_xcorr_cutOut[i],1/pwr_AMPEREN[i]*AMPERE_noise_xcorr_cutOut[i])[0,1];
        #END FOR j
        R_keoNvsAMPERE[i] = np.mean(R_keoNvsAMPERE_mat);
        R_keovsAMPEREN[i] = np.mean(R_keovsAMPEREN_mat);
        rounder = np.log10(np.abs(R_keovsAMPEREN[i])); #first check, reuse var
        if( rounder < 0 ):
            rounder = np.abs(np.int64(rounder))+1; #estimate number of decimal spots
            if( rounder < 3 ):
                rounder = 3; #keep it at 3 decimal spots
            #END IF
        else:
            rounder = 3; #keep it at 3 decimal spots
        #END IF
        stringer += '\nCutout '+str(time_cutout_range/3600)+' '+doubleKeo_namesNice[i]+' Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters vs '+settings['AMPERE']['data type']+' #'+str(i+1)+': '+str(np.round(R_keoNvsAMPERE[i],rounder));
        stringer += '\nCutout '+str(time_cutout_range/3600)+' '+doubleKeo_namesNice[i]+' vs '+settings['AMPERE']['data type']+' #'+str(i+1)+' Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters: '+str(np.round(R_keovsAMPEREN[i],rounder));
        Pxy_TECNvAMPERE[i] = np.mean(TECNvAMPERE_mat,axis=1);
        Pxy_TECvAMPEREN[i] = np.mean(TECvAMPEREN_mat,axis=1);
    #END FOR i
    print(stringer); #report the coeff
    
    
    #--- Start the plot ---
    fig, ax = plt.subplots(nrows=len(doubleKeo_latLong), ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    if( len(doubleKeo_latLong) == 1 ):
        ax = [ax]; #wrap it in a list for list reasons
    # END IF
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    #Remove the aspect ratio from the basemap so it fills the screen better
    cntr = 0; #prep
    for i in range(0,len(doubleKeo_latLong)):
        ax[i].set_aspect('auto');
        pZ = []; #prep
        lZ = []; #prep
        
        pT, = ax[i].plot(keo_xcorr_time_cutOut[i]/3600,1/pwr_TEC[i]*keo_xcorr_cutOut[i],color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        lZ.append('Cutout '+str(time_cutout_range/3600)+' '+doubleKeo_namesNice[i]+' #'+str(i+1)); #add onto the legend list
        
        pT, = ax[i].plot( (AMPERE_xcorr_time_cutOut[i]-dateRange_dayNum_zeroHr[1]*86400)/3600,1/pwr_AMPERE[i]*AMPERE_xcorr_cutOut[i],color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        lZ.append('Cutout '+str(time_cutout_range/3600)+' '+settings['AMPERE']['data type']+' #'+str(i+1)); #add onto the legend list
        
        pT, = ax[i].plot(keo_xcorr_time_cutOut[i]/3600,1/pwr_TEC[i]*keo_noise_xcorr_cutOut[i],color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        lZ.append('Cutout '+str(time_cutout_range/3600)+' '+doubleKeo_namesNice[i]+' Noise (Last Iter) #'+str(i+1)); #add onto the legend list
        
        pT, = ax[i].plot( (AMPERE_xcorr_time_cutOut[i]-dateRange_dayNum_zeroHr[1]*86400)/3600,1/pwr_AMPEREN[i]*AMPERE_noise_xcorr_cutOut[i],color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        lZ.append('Cutout '+str(time_cutout_range/3600)+' '+settings['AMPERE']['data type']+' Noise (Last Iter) #'+str(i+1)); #add onto the legend list
        
        ax[i].legend(pZ, lZ, loc='upper right', framealpha=0.5);
        ax[i].set_ylabel('Normalized Ampltiude',fontproperties=FONT_axisLabelFM);
        
        ax[i].set_title(doubleKeo_namesNice[i]+' at '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2))+' lat & '+settings['AMPERE']['data type']+' (Time Delay '+textNice(doubleKeo_AMPERE_timeDelay[i])+') Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
            fontproperties=FONT_titleFM);
    #END FOR i
    ax[i].set_xlabel('Time [hr]',fontproperties=FONT_axisLabelFM);
    
    
    # xAxisTicks = np.arange( 0, settings['spectra']['period limit max']/60+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    # ax.set_xticks(xAxisTicks); #set x axis ticks
    # ax.set_xlim( (settings['spectra']['period limit min']/60, settings['spectra']['period limit max']/60) );
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    FLG_fancyPlot_justHere = False;
    if( FLG_fancyPlot_justHere == 0 ):
        fig, ax = plt.subplots(nrows=len(doubleKeo_latLong), ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
        tickNumGoal = 28; #for x axis ticks
        subfig_to_axis = [len(doubleKeo_latLong)-1];
        numRows = len(doubleKeo_latLong);
        
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
    else:
        plt.ioff() #disable showing the plot as its size will be larger than the screen, which cannot happen if the plot is shown
        if( len(doubleKeo_latLong) == 4 ):
            fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(14,8.5), dpi=journal_dpi); #use instead of fig because it inits an axis too (I think I dunno)
            ax = ax.ravel(); #flatten it (ravel doesn't make a copy)
            tickNumGoal = 20; #for x axis ticks
            subfig_to_axis = [2, 3];
            numRows = 2;
        else:
            fig, ax = plt.subplots(nrows=len(doubleKeo_latLong), ncols=1, figsize=(14,8.5), dpi=journal_dpi); #use instead of fig because it inits an axis too (I think I dunno)
            tickNumGoal = 23; #for x axis ticks
            subfig_to_axis = [len(doubleKeo_latLong)-1];
            numRows = len(doubleKeo_latLong);
        #END IF
    #END IF
    if( len(doubleKeo_latLong) == 1 ):
        ax = [ax]; #wrap it in a list for list reasons
    #END IF

    cntr = 0; #prep
    for i in range(0,len(doubleKeo_latLong)):
        #Remove the aspect ratio from the basemap so it fills the screen better
        ax[i].set_aspect('auto');
        pZ = []; #prep
        lZ = []; #prep
        
        pT, = ax[i].plot(1/freqs_TECvAMPERE[i]/60,(Pxy_TECvAMPERE[i]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        if( FLG_fancyPlot_justHere == 0 ):
            lZ.append('Cutout '+textNice(time_cutout_range/3600)+' hr '+doubleKeo_namesNice[i]+' vs '+settings['AMPERE']['data type']+' #'+str(i+1)); #add onto the legend list
        else:
            lZ.append(doubleKeo_namesNice[i]+' vs '+settings['AMPERE']['data type']); #add onto the legend list
        #END IF
        
        pT, = ax[i].plot(1/freqs_TECvAMPERE[i]/60,(Pxy_TECNvAMPERE[i]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        if( FLG_fancyPlot_justHere == 0 ):
            lZ.append('Cutout '+textNice(time_cutout_range/3600)+' hr '+doubleKeo_namesNice[i]+' Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters vs '+settings['AMPERE']['data type']+' #'+str(i+1)); #add onto the legend list
        else:
            lZ.append(doubleKeo_namesNice[i]+'<N> vs '+settings['AMPERE']['data type']); #add onto the legend list
        #END IF
        pT, = ax[i].plot(1/freqs_TECvAMPERE[i]/60,(Pxy_TECvAMPEREN[i]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        if( FLG_fancyPlot_justHere == 0 ):
            lZ.append('Cutout '+textNice(time_cutout_range/3600)+' hr '+doubleKeo_namesNice[i]+' vs '+settings['AMPERE']['data type']+' Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters #'+str(i+1)); #add onto the legend list
        else:
            lZ.append(doubleKeo_namesNice[i]+' vs '+settings['AMPERE']['data type']+'<N>'); #add onto the legend list
        #END IF
        
        ax[i].set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
        if( FLG_fancyPlot_justHere == 0 ):
            ax[i].set_title('CSD - '+doubleKeo_namesNice[i]+' at '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2))+' lat & '+settings['AMPERE']['data type']+' (Time Delay '+textNice(doubleKeo_AMPERE_timeDelay[i])+') Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
                fontproperties=FONT_titleFM);
        #END IF
        ax[i].legend(pZ, lZ, loc='upper right', framealpha=0.5);
        
        if( i in subfig_to_axis ):
            FLG_removeLabels = False;
            # if( i == subfig_to_axis[-1] ):
            #     ax[i].set_xlabel('Periods ['+'min'+']'+' for Date Range '+str(dateRange[0,1])+'/'+str(dateRange[0,2])+ \
            #         '/'+str(dateRange[0,0])+' to '+str(dateRange[-1,1])+ '/'+str(dateRange[-1,2])+'/'+str(dateRange[-1,0])+ ' (M/D/Y)',fontproperties=FONT_axisLabelFM); #set the x axis label
            # else:
            ax[i].set_xlabel('Periods ['+'min'+']');
            # END IF
        else:
            FLG_removeLabels = True;
        #END IF
        GRITI_plotHelper_axisizerTime(1/freqs_TECvAMPERE[i]/60,ax=ax[i],unit='min',tickNumGoal=tickNumGoal,FLG_removeLabels=FLG_removeLabels,FLG_tickDirIn=False,FLG_manualLims=(settings_spectra['period limit min']/60, settings_spectra['period limit max']/60));
    #END FOR i

    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    if( FLG_fancyPlot_justHere != 0 ):
        fig.savefig(settings_paths['fancyPlots']+'\\'+'doubleKeo_CSD_'+' & '.join(doubleKeo_namesNice).replace(' ','_')+'_vs_'+settings['AMPERE']['data type'].replace(' ','_')+'_'+textNice(time_cutout_range[0]/3600)+'_to_'+textNice(time_cutout_range[1]/3600)+'hrs'+'.png'); #save the figure
        plt.close(); #close figure b/c it lurks apparently
        plt.ion(); #re-enable it for later stuff
    #END IF  
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
    #--- Just FFTs for good measure ---
    GRITI_spectral_analysisPlot([[keo_xcorr_cutOut[i],AMPERE_xcorr_cutOut[i],keo_noise_xcorr_cutOut[i],AMPERE_noise_xcorr_cutOut[i]] for i in range(0,len(doubleKeo_latLong))], 
        [[keo_xcorr_time_cutOut[i],AMPERE_xcorr_time_cutOut[i],keo_xcorr_time_cutOut[i],AMPERE_xcorr_time_cutOut[i]] for i in range(0,len(doubleKeo_latLong))], 
        [['sec','sec','sec','sec'] for i in range(0,len(doubleKeo_latLong))], [[doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate] for i in range(0,len(doubleKeo_latLong))], 
        [['sec','sec','sec','sec'] for i in range(0,len(doubleKeo_latLong))], 'min',
        [['none','none','none','none'] for i in range(0,len(doubleKeo_latLong))], [['fft','fft','fft','fft'] for i in range(0,len(doubleKeo_latLong))], 
        dates, settings_spectra, settings_plot, settings_paths, 
        [['TEC Keo @ '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2))+' lat',settings['AMPERE']['data type']+' (Time Lag '+textNice(doubleKeo_AMPERE_timeDelay[i])+') Time Lim to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs','TEC Keo Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters @ '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2))+' lat',settings['AMPERE']['data type']+' (Time Lag '+textNice(doubleKeo_AMPERE_timeDelay[i])+') Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters Time Lim to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs'] for i in range(0,len(doubleKeo_latLong))],
        titleOverride=None,
        reduceWindow=1,FLG_fancyPlot=0); #insane plot call
    
    if( doubleKeo_xcorr_timeRangePer[0] != False ): #apply different time cutouts per keo
        nrow_cntr = 0; #prep
        doubleKeo_xcorr_timeRangePer_namesNice = []; #prep
        for i in range(0,len(doubleKeo_latLong)): #this is a shim that lets extra times be injected easily
            if( not isinstance(doubleKeo_xcorr_timeRangePer[i][0], list) ):
                doubleKeo_xcorr_timeRangePer[i] = [doubleKeo_xcorr_timeRangePer[i]]; #wrap it up for later
            #END IF
            nrow_cntr += len(doubleKeo_xcorr_timeRangePer[i]); #increment as needed
        #END FOR i
        
        #--- Filter and Align if Req'd ---
        doubleKeo_AMPERE_xcorr_timeRangePer = [[] for jj in range(0,nrow_cntr)]; #prep
        nrow_cntr_cntr = 0; #prep cntr
        for i in range(0,len(doubleKeo_latLong)):
            for p in range(0,len(doubleKeo_xcorr_timeRangePer[i])):
                #--- Determine which has a slower data rate and align to that ---
                if( data['TEC']['data rate'] > data['AMPERE']['data rate'] ):
                    #TEC is the data rate to align to
                    _, doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr] = subfun_timeMatch(doubleKeo_AMPERE_xcorr[i], AMPERE_timeUnique, TEC_timeUnique, timeMatch_delta=data['TEC']['data rate'], FLG_removeNaNs=0, FLG_useSum=1); #time match alg to align to 6 minute cadence, add because it's a count (?)
                # elif( data['TEC']['data rate'] < data['AMPERE']['data rate'] ):
                #     #AMPERE is the data rate to align to
                #     doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr] = np.copy(AMPERE_timeUnique); #same
                else:
                    doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr] = np.copy(AMPERE_timeUnique); #same
                #END IF
                if( np.isclose(np.mod(doubleKeo_xcorr_timeRangePer_AMPERE_timeDelay[i][p]*3600,1),0.0) ):
                    doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr] += np.int64(doubleKeo_xcorr_timeRangePer_AMPERE_timeDelay[i][p]*3600); #it all stays integers
                else:
                    doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr] = np.float64(doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr]) + doubleKeo_xcorr_timeRangePer_AMPERE_timeDelay[i][p]*3600; #it all becomes floats
                #END IF
                nrow_cntr_cntr += 1; #increment
            #END FOR p
        #END FOR i        
    
        Pxy_TECvAMPERE = [[] for jj in range(0,nrow_cntr)]; #prep
        freqs_TECvAMPERE = [[] for jj in range(0,nrow_cntr)]; #prep
        keo_xcorr_cutOut = [[] for jj in range(0,nrow_cntr)]; #prep
        keo_xcorr_time_cutOut = [[] for jj in range(0,nrow_cntr)]; #prep
        AMPERE_xcorr_cutOut = [[] for jj in range(0,nrow_cntr)]; #prep
        AMPERE_xcorr_time_cutOut = [[] for jj in range(0,nrow_cntr)]; #prep
        pwr_TEC = [[] for jj in range(0,nrow_cntr)]; #prep
        pwr_AMPERE = [[] for jj in range(0,nrow_cntr)]; #prep
    
        Pxy_TECNvAMPERE = [[] for jj in range(0,nrow_cntr)]; #prep
        Pxy_TECvAMPEREN = [[] for jj in range(0,nrow_cntr)]; #prep
        keo_noise_xcorr_cutOut = [[] for jj in range(0,nrow_cntr)]; #prep
        AMPERE_noise_xcorr_cutOut = [[] for jj in range(0,nrow_cntr)]; #prep
        pwr_TECN = [[] for jj in range(0,nrow_cntr)]; #prep
        pwr_AMPEREN = [[] for jj in range(0,nrow_cntr)]; #prep
        R_keoNvsAMPERE = [[] for jj in range(0,nrow_cntr)]; #prep
        R_keovsAMPEREN = [[] for jj in range(0,nrow_cntr)]; #prep
        
        stringer = 'Multi Time Ranges Corr Coeff:\n'; #prep
        Fs = 1/(doubleKeo_AMPERE_dataRate); #sec, time delta in freq form
        nrow_cntr_cntr = 0; #prep cntr
        for i in range(0,len(doubleKeo_latLong)):
            for p in range(0,len(doubleKeo_xcorr_timeRangePer[i])):
                #TEC CUTOUT NOW
                time_cutout_indexes = np.array( ( np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.min(doubleKeo_xcorr_timeRangePer[i][p]) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.min(doubleKeo_xcorr_timeRangePer[i][p]) ) )[0][0] , \
                    np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.max(doubleKeo_xcorr_timeRangePer[i][p]) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.max(doubleKeo_xcorr_timeRangePer[i][p]) ) )[0][0] ) ); #get the indexes for that time cutout range
                keo_xcorr_cutOut[nrow_cntr_cntr] = np.copy(doubleKeo_keo_xcorr[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]);
                keo_xcorr_time_cutOut[nrow_cntr_cntr] = doubleKeo_keo_xcorr_time[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
                
                #AMPERE CUTOUT NOW
                time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr]-dateRange_dayNum_zeroHr[1]*86400) - np.min(doubleKeo_xcorr_timeRangePer[i][p]) )) == np.abs( (doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr]-dateRange_dayNum_zeroHr[1]*86400) - np.min(doubleKeo_xcorr_timeRangePer[i][p]) ) )[0][0] , \
                    np.where(np.min(np.abs( (doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr]-dateRange_dayNum_zeroHr[1]*86400) - np.max(doubleKeo_xcorr_timeRangePer[i][p]) )) == np.abs( (doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr]-dateRange_dayNum_zeroHr[1]*86400) - np.max(doubleKeo_xcorr_timeRangePer[i][p]) ) )[0][0] ) ); #get the indexes for that time cutout range
                AMPERE_xcorr_cutOut[nrow_cntr_cntr] = np.copy(doubleKeo_AMPERE_xcorr[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]);
                AMPERE_xcorr_time_cutOut[nrow_cntr_cntr] = doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
                
                #enforce a local 0 mean
                if( strstr(doubleKeo_xcorr_AMPERE_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
                    AMPERE_xcorr_cutOut[nrow_cntr_cntr] = subfun_filter( AMPERE_xcorr_cutOut[nrow_cntr_cntr], '0 mean', dataTime = AMPERE_xcorr_time_cutOut[nrow_cntr_cntr], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
                #END IF
                if( strstr(doubleKeo_xcorr_TEC_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
                    keo_xcorr_cutOut[nrow_cntr_cntr] = subfun_filter( keo_xcorr_cutOut[nrow_cntr_cntr], '0 mean', dataTime = keo_xcorr_time_cutOut[nrow_cntr_cntr], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
                #END IF
            
                #CALC PWR
                pwr_TEC[nrow_cntr_cntr] = np.sqrt(1/keo_xcorr_cutOut[nrow_cntr_cntr].size*np.sum(keo_xcorr_cutOut[nrow_cntr_cntr]**2)); #estimate power of signal
                pwr_AMPERE[nrow_cntr_cntr] = np.sqrt(1/AMPERE_xcorr_cutOut[nrow_cntr_cntr].size*np.sum(AMPERE_xcorr_cutOut[nrow_cntr_cntr]**2)); #estimate power of signal
                
                if( np.isclose(360, doubleKeo_AMPERE_dataRate) ):
                    nfft = settings_spectra['nfft']['6min'];
                    nooverlap = settings['spectra']['noverlap']; #keep
                    winnow = settings_spectra['window']; #keep
                else:
                    #scale as needed
                    nfft = settings_spectra['nfft']['6min']*360//doubleKeo_AMPERE_dataRate;
                    nooverlap = settings['spectra']['noverlap']*360//doubleKeo_AMPERE_dataRate; #adjust
                    if( settings_spectra['window type'] == 'hamm' ):
                        winnow = np.hamming(settings_spectra['windowLength']*360//doubleKeo_AMPERE_dataRate); #adjust
                    else:
                        print('ERROR: Unsupported window type \''+settings_spectra['window type']+'\', add support for it here.');
                        import sys
                        sys.crash();
                    #END IF
                #END IF
                
                if( (winnow.size > keo_xcorr_cutOut[nrow_cntr_cntr].size) | (winnow.size  > AMPERE_xcorr_cutOut[nrow_cntr_cntr].size) ):
                    if( keo_xcorr_cutOut[nrow_cntr_cntr].size < AMPERE_xcorr_cutOut[nrow_cntr_cntr].size ):
                        winnow = np.hamming(keo_xcorr_cutOut[nrow_cntr_cntr].size - 1); #adjust
                    else:
                        winnow = np.hamming(AMPERE_xcorr_cutOut[nrow_cntr_cntr].size - 1); #adjust
                    #END IF
                    nooverlap = winnow.size - 10; #adjust
                #END IF
                
                #CALC THE XCORR
                [freqs_TECvAMPERE[nrow_cntr_cntr],Cxy_TECvAMPERE] = signal.csd(1/pwr_TEC[nrow_cntr_cntr]*keo_xcorr_cutOut[nrow_cntr_cntr],1/pwr_AMPERE[nrow_cntr_cntr]*AMPERE_xcorr_cutOut[nrow_cntr_cntr],window=winnow,noverlap=nooverlap,nfft=nfft,fs=Fs);
                # Axy_TECvAMPERE = np.angle(Cxy_TECvAMPERE)*180/np.pi; 
                Pxy_TECvAMPERE[nrow_cntr_cntr] = np.abs(Cxy_TECvAMPERE);
                
                #Real quick side move to calc correlation coefficients
                R_keovsAMPERE = np.corrcoef(1/pwr_TEC[nrow_cntr_cntr]*keo_xcorr_cutOut[nrow_cntr_cntr],1/pwr_AMPERE[nrow_cntr_cntr]*AMPERE_xcorr_cutOut[nrow_cntr_cntr])[0,1];
                
                stringer += 'Cutout '+str(np.asarray(doubleKeo_xcorr_timeRangePer[i][p])/3600)+' '+doubleKeo_namesNice[i]+' vs '+settings['AMPERE']['data type']+' #'+str(i+1)+': '+str(np.round(R_keovsAMPERE,3));
                if( nrow_cntr_cntr != nrow_cntr-1 ):
                    stringer += '\n';
                #end if
                nrow_cntr_cntr += 1; #increment
            #END FOR p
        #END FOR i
        print(stringer); #report the coeff
        
        stringer = ''; #prep
        nrow_cntr_cntr = 0; #prep cntr
        for i in range(0,len(doubleKeo_latLong)):
            for p in range(0,len(doubleKeo_xcorr_timeRangePer[i])):
                for j in range(0,doubleKeo_xcorr_noiseIterations):       
                    #already did the exxpensive noise raytracing calcs earlier, can re-use here
                        
                    #TEC CUTOUT NOW
                    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.min(doubleKeo_xcorr_timeRangePer[i][p]) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.min(doubleKeo_xcorr_timeRangePer[i][p]) ) )[0][0] , \
                        np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.max(doubleKeo_xcorr_timeRangePer[i][p]) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.max(doubleKeo_xcorr_timeRangePer[i][p]) ) )[0][0] ) ); #get the indexes for that time cutout range
                    keo_noise_xcorr_cutOut[nrow_cntr_cntr] = np.copy(doubleKeo_keo_noise_xcorr[i][j][time_cutout_indexes[0]:time_cutout_indexes[1]+1]);
                    keo_xcorr_time_cutOut[nrow_cntr_cntr] = doubleKeo_keo_xcorr_time[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
                    
                    #AMPERE CUTOUT NOW
                    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr]-dateRange_dayNum_zeroHr[1]*86400) - np.min(doubleKeo_xcorr_timeRangePer[i][p]) )) == np.abs( (doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr]-dateRange_dayNum_zeroHr[1]*86400) - np.min(doubleKeo_xcorr_timeRangePer[i][p]) ) )[0][0] , \
                        np.where(np.min(np.abs( (doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr]-dateRange_dayNum_zeroHr[1]*86400) - np.max(doubleKeo_xcorr_timeRangePer[i][p]) )) == np.abs( (doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr]-dateRange_dayNum_zeroHr[1]*86400) - np.max(doubleKeo_xcorr_timeRangePer[i][p]) ) )[0][0] ) ); #get the indexes for that time cutout range
                    AMPERE_noise_xcorr_cutOut[nrow_cntr_cntr] = np.copy(doubleKeo_AMPERE_noise_xcorr[i][j][time_cutout_indexes[0]:time_cutout_indexes[1]+1]);
                    AMPERE_xcorr_time_cutOut[nrow_cntr_cntr] = doubleKeo_AMPERE_xcorr_timeRangePer[nrow_cntr_cntr][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
                    
                    #enforce a local 0 mean
                    if( strstr(doubleKeo_xcorr_TEC_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
                        keo_noise_xcorr_cutOut[nrow_cntr_cntr] = subfun_filter( keo_noise_xcorr_cutOut[nrow_cntr_cntr], '0 mean', dataTime = keo_xcorr_time_cutOut[nrow_cntr_cntr], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
                    #END IF
                    if( strstr(doubleKeo_xcorr_AMPERE_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
                        AMPERE_noise_xcorr_cutOut[nrow_cntr_cntr] = subfun_filter( AMPERE_noise_xcorr_cutOut[nrow_cntr_cntr], '0 mean', dataTime = AMPERE_xcorr_time_cutOut[nrow_cntr_cntr], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
                    #END IF
                    
                    #CALC PWR
                    pwr_TECN[nrow_cntr_cntr] = np.sqrt(1/keo_noise_xcorr_cutOut[nrow_cntr_cntr].size*np.sum(keo_noise_xcorr_cutOut[nrow_cntr_cntr]**2)); #estimate power of signal
                    pwr_AMPEREN[nrow_cntr_cntr] = np.sqrt(1/AMPERE_noise_xcorr_cutOut[nrow_cntr_cntr].size*np.sum(AMPERE_noise_xcorr_cutOut[nrow_cntr_cntr]**2)); #estimate power of signal
                    
                    if( np.isclose(360, doubleKeo_AMPERE_dataRate) ):
                        nfft = settings_spectra['nfft']['6min'];
                        nooverlap = settings['spectra']['noverlap']; #keep
                        winnow = settings_spectra['window']; #keep
                    else:
                        #scale as needed
                        nfft = settings_spectra['nfft']['6min']*360//doubleKeo_AMPERE_dataRate;
                        nooverlap = settings['spectra']['noverlap']*360//doubleKeo_AMPERE_dataRate; #adjust
                        if( settings_spectra['window type'] == 'hamm' ):
                            winnow = np.hamming(settings_spectra['windowLength']*360//doubleKeo_AMPERE_dataRate); #adjust
                        else:
                            print('ERROR: Unsupported window type \''+settings_spectra['window type']+'\', add support for it here.');
                            import sys
                            sys.crash();
                        #END IF
                    #END IF
                    
                    if( (winnow.size > keo_noise_xcorr_cutOut[nrow_cntr_cntr].size) | (winnow.size  > AMPERE_noise_xcorr_cutOut[nrow_cntr_cntr].size) ):
                        if( keo_noise_xcorr_cutOut[nrow_cntr_cntr].size < AMPERE_noise_xcorr_cutOut[nrow_cntr_cntr].size ):
                            winnow = np.hamming(keo_noise_xcorr_cutOut[nrow_cntr_cntr].size - 1); #adjust
                        else:
                            winnow = np.hamming(AMPERE_noise_xcorr_cutOut[nrow_cntr_cntr].size - 1); #adjust
                        #END IF
                        nooverlap = winnow.size - 10; #adjust
                    #END IF
                    
                    [_,Cxy_TECNvAMPERE] = signal.csd(1/pwr_TECN[nrow_cntr_cntr]*keo_noise_xcorr_cutOut[nrow_cntr_cntr],1/pwr_AMPERE[nrow_cntr_cntr]*AMPERE_xcorr_cutOut[nrow_cntr_cntr],window=winnow,noverlap=nooverlap,nfft=nfft,fs=Fs);
                    # Axy_TECNvAMPERE = np.angle(Cxy_TECNvAMPERE)*180/np.pi; 
                    Pxy_TECNvAMPERE[nrow_cntr_cntr] = np.abs(Cxy_TECNvAMPERE);
                    
                    [_,Cxy_TECvAMPEREN] = signal.csd(1/pwr_TEC[nrow_cntr_cntr]*keo_xcorr_cutOut[nrow_cntr_cntr],1/pwr_AMPEREN[nrow_cntr_cntr]*AMPERE_noise_xcorr_cutOut[nrow_cntr_cntr],window=winnow,noverlap=nooverlap,nfft=nfft,fs=Fs);
                    # Axy_TECvAMPEREN = np.angle(Cxy_TECvAMPEREN)*180/np.pi; 
                    Pxy_TECvAMPEREN[nrow_cntr_cntr] = np.abs(Cxy_TECvAMPEREN);
                    
                    #RECORD FOR POSTERITY
                    TECNvAMPERE_mat[:,j] = Pxy_TECNvAMPERE[nrow_cntr_cntr];
                    TECvAMPEREN_mat[:,j] = Pxy_TECvAMPEREN[nrow_cntr_cntr];
                    
                    #Real quick side move to calc correlation coefficients
                    R_keoNvsAMPERE_mat[j] = np.corrcoef(1/pwr_TECN[nrow_cntr_cntr]*keo_noise_xcorr_cutOut[nrow_cntr_cntr],1/pwr_AMPERE[nrow_cntr_cntr]*AMPERE_xcorr_cutOut[nrow_cntr_cntr])[0,1];
                    R_keovsAMPEREN_mat[j] = np.corrcoef(1/pwr_TEC[nrow_cntr_cntr]*keo_xcorr_cutOut[nrow_cntr_cntr],1/pwr_AMPEREN[nrow_cntr_cntr]*AMPERE_noise_xcorr_cutOut[nrow_cntr_cntr])[0,1];
                #END FOR j
                R_keoNvsAMPERE[nrow_cntr_cntr] = np.mean(R_keoNvsAMPERE_mat);
                R_keovsAMPEREN[nrow_cntr_cntr] = np.mean(R_keovsAMPEREN_mat);
                stringer += '\nCutout '+str(np.asarray(doubleKeo_xcorr_timeRangePer[i][p])/3600)+' '+doubleKeo_namesNice[i]+' Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters vs '+settings['AMPERE']['data type']+' #'+str(i+1)+': '+str(np.round(R_keoNvsAMPERE[nrow_cntr_cntr],3));
                stringer += '\nCutout '+str(np.asarray(doubleKeo_xcorr_timeRangePer[i][p])/3600)+' '+doubleKeo_namesNice[i]+' vs '+settings['AMPERE']['data type']+' #'+str(i+1)+' Noise '+str(doubleKeo_xcorr_noiseIterations)+' iters: '+str(np.round(R_keovsAMPEREN[nrow_cntr_cntr],3));
                Pxy_TECNvAMPERE[nrow_cntr_cntr] = np.mean(TECNvAMPERE_mat,axis=1);
                Pxy_TECvAMPEREN[nrow_cntr_cntr] = np.mean(TECvAMPEREN_mat,axis=1);
                
                nrow_cntr_cntr += 1; #increment
            #END FOR p
        #END FOR i
        print(stringer); #report the coeff
        
        warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
        if( nrow_cntr == 4 ):
            fig, ax = plt.subplots(nrows=2, ncols=2); #use instead of fig because it inits an axis too (I think I dunno)
            ax = ax.ravel(); #flatten it (ravel doesn't make a copy)
            subfig_to_axis = [2, 3];
            tickNumGoal = 22; #for x axis ticks
        else:
            fig, ax = plt.subplots(nrows=nrow_cntr, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
            subfig_to_axis = [nrow_cntr-1];
            tickNumGoal = 28; #for x axis ticks
        #END IF
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        cntr = 0; #prep
        nrow_cntr_cntr = 0; #prep cntr
        for i in range(0,len(doubleKeo_latLong)):
            for p in range(0,len(doubleKeo_xcorr_timeRangePer[i])):
                cntr_line = 0; #prep
                #Remove the aspect ratio from the basemap so it fills the screen better
                ax[nrow_cntr_cntr].set_aspect('auto');
                pZ = []; #prep
                lZ = []; #prep
                
                pT, = ax[nrow_cntr_cntr].plot(1/freqs_TECvAMPERE[nrow_cntr_cntr]/60,(Pxy_TECvAMPERE[nrow_cntr_cntr]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr_line]);
                cntr += 1; #increment
                cntr_line += 1; #increment
                pZ.append(pT); #add onto the plot list
                lZ.append(doubleKeo_namesNice[i]+' vs '+settings['AMPERE']['data type']); #add onto the legend list
                
                pT, = ax[nrow_cntr_cntr].plot(1/freqs_TECvAMPERE[nrow_cntr_cntr]/60,(Pxy_TECNvAMPERE[nrow_cntr_cntr]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr_line]);
                cntr += 1; #increment
                cntr_line += 1; #increment
                pZ.append(pT); #add onto the plot list
                lZ.append(doubleKeo_namesNice[i]+'<N> '+str(doubleKeo_xcorr_noiseIterations)+' iters vs '+settings['AMPERE']['data type']); #add onto the legend list
            
                pT, = ax[nrow_cntr_cntr].plot(1/freqs_TECvAMPERE[nrow_cntr_cntr]/60,(Pxy_TECvAMPEREN[nrow_cntr_cntr]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr_line]);
                cntr += 1; #increment
                cntr_line += 1; #increment
                pZ.append(pT); #add onto the plot list
                lZ.append(doubleKeo_namesNice[i]+' vs '+settings['AMPERE']['data type']+'<N> '+str(doubleKeo_xcorr_noiseIterations)+' iters'); #add onto the legend list
            
                ax[nrow_cntr_cntr].set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
                ax[nrow_cntr_cntr].set_title('CSD-'+doubleKeo_namesNice[i]+' @ '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2))+' lat &\n'+settings['AMPERE']['data type']+' (Lag '+textNice(doubleKeo_xcorr_timeRangePer_AMPERE_timeDelay[i][p])+'hr) Lim to '+textNice(np.round(doubleKeo_xcorr_timeRangePer[i][p][0]/3600,2))+' to '+textNice(np.round(doubleKeo_xcorr_timeRangePer[i][p][-1]/3600,2))+' hrs', \
                    fontproperties=FONT_titleFM);
                ax[nrow_cntr_cntr].legend(pZ, lZ, loc='upper right', framealpha=0.5);
                
                # xAxisTicks = np.arange( 0, settings['spectra']['period limit max']/60+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
                # ax[nrow_cntr_cntr].set_xticks(xAxisTicks); #set x axis ticks
                # ax[nrow_cntr_cntr].set_xlim( (settings['spectra']['period limit min']/60, settings['spectra']['period limit max']/60) );
                if( nrow_cntr_cntr in subfig_to_axis ):
                    FLG_removeLabels = False;
                    ax[nrow_cntr_cntr].set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
                    if( nrow_cntr_cntr == subfig_to_axis[-1] ):
                        ax[nrow_cntr_cntr].set_xlabel('Periods [min]'+' for Date Range '+str(dateRange[0,1])+'/'+str(dateRange[0,2])+ \
                            '/'+str(dateRange[0,0])+' to '+str(dateRange[-1,1])+ '/'+str(dateRange[-1,2])+'/'+str(dateRange[-1,0])+ ' (M/D/Y)',fontproperties=FONT_axisLabelFM); #set the x axis label
                    else:
                        ax[nrow_cntr_cntr].set_xlabel('Periods [min]');
                    # END IF
                else:
                    FLG_removeLabels = True;
                #END IF
                GRITI_plotHelper_axisizerTime(1/freqs_TECvAMPERE[nrow_cntr_cntr]/60,ax=ax[nrow_cntr_cntr],unit='min',tickNumGoal=tickNumGoal,FLG_removeLabels=FLG_removeLabels,FLG_tickDirIn=False,FLG_manualLims=(settings['spectra']['period limit min']/60, settings['spectra']['period limit max']/60));

                
                ax[nrow_cntr_cntr].text( np.min(ax[nrow_cntr_cntr].get_xlim())+np.diff(ax[nrow_cntr_cntr].get_xlim())*.005, np.max(ax[nrow_cntr_cntr].get_ylim()), chr(97+nrow_cntr_cntr)+'.', color='r', fontproperties=FONT_grandioseFM, horizontalalignment='left', verticalalignment='top'); #print the text labelling the lettering a. b. c. ect.
            
                nrow_cntr_cntr += 1; #increment
            #END FOR p
        #END FOR i     
    
        #final plot adjusting stuff
        figFitter(fig); #fit that fig fast
        
        #--- Just FFTs for good measure ---
        spectral_labels = [[] for jj in range(0,nrow_cntr)]; #prep
        spectral_titles = [[] for jj in range(0,nrow_cntr)]; #prep
        nrow_cntr_cntr = 0; #prep cntr
        for i in range(0,len(doubleKeo_latLong)):
            for p in range(0,len(doubleKeo_xcorr_timeRangePer[i])):
                spectral_labels[nrow_cntr_cntr] = \
                    [doubleKeo_namesNice[i]+' @ '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2))+' lat', \
                    settings['AMPERE']['data type']+' (Lag '+textNice(doubleKeo_xcorr_timeRangePer_AMPERE_timeDelay[i][p])+'hr)', \
                    doubleKeo_namesNice[i]+'<N> '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2))+' lat', \
                    settings['AMPERE']['data type']+' (Lag '+textNice(doubleKeo_xcorr_timeRangePer_AMPERE_timeDelay[i][p])+'hr)<N>']; #big ole thing
                spectral_titles[nrow_cntr_cntr] = \
                    'FFT-Lim to '+textNice(np.round(doubleKeo_xcorr_timeRangePer[i][p][0]/3600,2))+\
                     ' to '+textNice(np.round(doubleKeo_xcorr_timeRangePer[i][p][-1]/3600,2))+' hrs';
                nrow_cntr_cntr += 1; #increment
            #END FOR p
        #END FOR i
        GRITI_spectral_analysisPlot([[keo_xcorr_cutOut[i],AMPERE_xcorr_cutOut[i],keo_noise_xcorr_cutOut[i],AMPERE_noise_xcorr_cutOut[i]] for i in range(0,nrow_cntr)], 
            [[keo_xcorr_time_cutOut[i],AMPERE_xcorr_time_cutOut[i],keo_xcorr_time_cutOut[i],AMPERE_xcorr_time_cutOut[i]] for i in range(0,nrow_cntr)], 
            [['sec','sec','sec','sec'] for i in range(0,nrow_cntr)], [[doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate] for i in range(0,nrow_cntr)], 
            [['sec','sec','sec','sec'] for i in range(0,nrow_cntr)], 'min',
            [['none','none','none','none'] for i in range(0,nrow_cntr)], [['fft','fft','fft','fft'] for i in range(0,nrow_cntr)], 
            dates, settings_spectra, settings_plot, settings_paths, 
            spectral_labels,
            titleOverride=spectral_titles,
            reduceWindow=1,FLG_fancyPlot=0); #insane plot call
        
        if( FLG_doubleKeo_xcorr_fancyPlot == True ):
            #----Start plotting-----
            if( FLG_doubleKeo_xcorr_fancyPlot >= 1 ):
                fancyPlot_filename = 'doubleKeo_CSD_'+'&'.join(doubleKeo_namesNice).replace(' ','-')+'_vs_'+settings['AMPERE']['data type'].replace(' ','-')+'_cutout'+textNice((np.asarray(doubleKeo_xcorr_timeRangePer)/3600).tolist()).replace(',','').replace(' ','to')+'_fancyPlot';
                print('MAKING FANCY PLOT: '+fancyPlot_filename+' IN fancyPlot FOLDER'); #report since you won't see anything
            #END IF
            #Prime the plot
            if( FLG_doubleKeo_xcorr_fancyPlot == 0 ):
                if( nrow_cntr == 4 ):
                    fig, ax = plt.subplots(nrows=2, ncols=2); #use instead of fig because it inits an axis too (I think I dunno)
                    ax = ax.ravel(); #flatten it (ravel doesn't make a copy)
                    tickNumGoal = 22; #for x axis ticks
                else:
                    fig, ax = plt.subplots(nrows=nrow_cntr, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
                    tickNumGoal = 28; #for x axis ticks
                #END IF
                figManager = fig.canvas.manager; #req to maximize
                figManager.window.showMaximized(); #force maximized
            else:
                plt.ioff() #disable showing the plot as its size will be larger than the screen, which cannot happen if the plot is shown
                if( nrow_cntr == 4 ):
                    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(14,8.5), dpi=journal_dpi); #use instead of fig because it inits an axis too (I think I dunno)
                    ax = ax.ravel(); #flatten it (ravel doesn't make a copy)
                    tickNumGoal = 20; #for x axis ticks
                else:
                    fig, ax = plt.subplots(nrows=nrow_cntr, ncols=1, figsize=(14,8.5), dpi=journal_dpi); #use instead of fig because it inits an axis too (I think I dunno)
                    tickNumGoal = 23; #for x axis ticks
                #END IF
                fig.subplots_adjust(hspace=0);
            #END IF
            
            #---Plot the stuff---
            cntr = 0; #prep
            nrow_cntr_cntr = 0; #prep cntr
            for i in range(0,len(doubleKeo_latLong)):
                for p in range(0,len(doubleKeo_xcorr_timeRangePer[i])):
                    cntr_line = 0; #prep
                    #Remove the aspect ratio from the basemap so it fills the screen better
                    ax[nrow_cntr_cntr].set_aspect('auto');
                    pZ = []; #prep
                    lZ = []; #prep
                    
                    pT, = ax[nrow_cntr_cntr].plot(1/freqs_TECvAMPERE[nrow_cntr_cntr]/60,(Pxy_TECvAMPERE[nrow_cntr_cntr]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr_line]);
                    cntr += 1; #increment
                    cntr_line += 1; #increment
                    pZ.append(pT); #add onto the plot list
                    lZ.append('ΔvTEC vs '+settings['AMPERE']['data type']); #add onto the legend list
                    
                    pT, = ax[nrow_cntr_cntr].plot(1/freqs_TECvAMPERE[nrow_cntr_cntr]/60,(Pxy_TECNvAMPERE[nrow_cntr_cntr]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr_line]);
                    cntr += 1; #increment
                    cntr_line += 1; #increment
                    pZ.append(pT); #add onto the plot list
                    lZ.append('ΔvTEC<N> vs '+settings['AMPERE']['data type']); #add onto the legend list
                
                    pT, = ax[nrow_cntr_cntr].plot(1/freqs_TECvAMPERE[nrow_cntr_cntr]/60,(Pxy_TECvAMPEREN[nrow_cntr_cntr]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr_line]);
                    cntr += 1; #increment
                    cntr_line += 1; #increment
                    pZ.append(pT); #add onto the plot list
                    lZ.append('ΔvTEC vs '+settings['AMPERE']['data type']+'<N>'); #add onto the legend list
                
                    if( FLG_doubleKeo_xcorr_fancyPlot == 0 ):
                        ax[nrow_cntr_cntr].set_title('CSD - '+doubleKeo_namesNice[i]+' at '+textNice(np.round(doubleKeo_AMPERE_latAlign[i],2))+' lat & '+settings['AMPERE']['data type']+' (Time Delay '+textNice(doubleKeo_xcorr_timeRangePer_AMPERE_timeDelay[i][p])+') Time Limited to '+textNice(np.round(doubleKeo_xcorr_timeRangePer[i][p][0]/3600,2))+' to '+textNice(np.round(doubleKeo_xcorr_timeRangePer[i][p][-1]/3600,2))+' hrs on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
                            fontproperties=FONT_titleFM);
                    #END IF
                    ax[nrow_cntr_cntr].legend(pZ, lZ, loc='center right', framealpha=0.5);
                    
                    # xAxisTicks = np.arange( 0, settings['spectra']['period limit max']/60+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
                    # ax[nrow_cntr_cntr].set_xticks(xAxisTicks); #set x axis ticks
                    if( nrow_cntr == 4 ):
                        if( (nrow_cntr_cntr == 2) | (nrow_cntr_cntr == 3) ): #chooses bottom ones
                            FLG_removeLabels = False;
                            ax[nrow_cntr_cntr].set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
                        else:
                            FLG_removeLabels = True;
                        #END IF
                        if( np.mod(nrow_cntr_cntr,2) == 0): #chooses left ones
                            ax[nrow_cntr_cntr].set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
                        #END IF
                    else:
                        if( nrow_cntr_cntr == nrow_cntr-1 ):
                            FLG_removeLabels = False;
                        else:
                            FLG_removeLabels = True;
                        #END IF
                        ax[nrow_cntr_cntr].set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
                    #END IF
                    GRITI_plotHelper_axisizerTime(1/freqs_TECvAMPERE[nrow_cntr_cntr]/60,ax=ax[nrow_cntr_cntr],unit='min',tickNumGoal=tickNumGoal,FLG_removeLabels=FLG_removeLabels,FLG_tickDirIn=True,FLG_manualLims=(settings['spectra']['period limit min']/60, settings['spectra']['period limit max']/60));
                    # ax[nrow_cntr_cntr].set_xlim( (settings['spectra']['period limit min']/60, settings['spectra']['period limit max']/60) );
                    
                    #put some labels on the subplots
                    ax[nrow_cntr_cntr].text( np.min(ax[nrow_cntr_cntr].get_xlim())+np.diff(ax[nrow_cntr_cntr].get_xlim())*.005, np.max(ax[nrow_cntr_cntr].get_ylim())-np.diff(ax[nrow_cntr_cntr].get_ylim())*.009, chr(97+nrow_cntr_cntr)+'.', color='r', fontproperties=FONT_grandioseFM, horizontalalignment='left', verticalalignment='top'); #print the text labelling the lettering a. b. c. ect.
            
                    nrow_cntr_cntr += 1; #increment
                #END FOR p
            #END FOR i
            if( nrow_cntr != 4 ):
                nrow_cntr_cntr -= 1; #decrement
                ax[nrow_cntr_cntr].set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
            #END IF
            
            #---Finalize the plot---
            figFitter(fig); #fit that fig fast
            if( FLG_doubleKeo_xcorr_fancyPlot != 0 ):
                fig.savefig(os.path.join(settings_paths['fancyPlots'],fancyPlot_filename+settings_plot['save file type'])); #save the figure
                plt.close(); #close figure b/c it lurks apparently
                plt.ion(); #re-enable it for later stuff
            #END IF
            
            #--- Just FFTs for good measure ---
            spectral_labels = [[] for jj in range(0,nrow_cntr)]; #prep
            nrow_cntr_cntr = 0; #prep cntr
            for i in range(0,len(doubleKeo_latLong)):
                for p in range(0,len(doubleKeo_xcorr_timeRangePer[i])):
                    spectral_labels[nrow_cntr_cntr] = \
                        ['ΔvTEC',settings['AMPERE']['data type'],doubleKeo_namesNice[i]+'<N>',settings['AMPERE']['data type']+'<N>']; #big ole thing
                    nrow_cntr_cntr += 1; #increment
                #END FOR p
            #END FOR i
            spectral_title = 'doubleKeo_FFT_'+'&'.join(doubleKeo_namesNice).replace(' ','-')+'_vs_'+ \
                settings['AMPERE']['data type'].replace(' ','-')+'_cutout_';
            nrow_cntr_cntr = 0; #prep cntr
            for i in range(0,len(doubleKeo_latLong)):
                for p in range(0,len(doubleKeo_xcorr_timeRangePer[i])):
                    spectral_title += textNice(np.min(doubleKeo_xcorr_timeRangePer[i][p])/3600)+'to'+textNice(np.max(doubleKeo_xcorr_timeRangePer[i][p])/3600)
                    if( nrow_cntr_cntr != nrow_cntr-1 ):
                        spectral_title += '&'
                    #END IF                    
                    nrow_cntr_cntr += 1; #increment
                #END FOR p
            #END FOR i
            GRITI_spectral_analysisPlot([[keo_xcorr_cutOut[i],AMPERE_xcorr_cutOut[i],keo_noise_xcorr_cutOut[i],AMPERE_noise_xcorr_cutOut[i]] for i in range(0,nrow_cntr)], 
                [[keo_xcorr_time_cutOut[i],AMPERE_xcorr_time_cutOut[i],keo_xcorr_time_cutOut[i],AMPERE_xcorr_time_cutOut[i]] for i in range(0,nrow_cntr)], 
                [['sec','sec','sec','sec'] for i in range(0,nrow_cntr)], [[doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate] for i in range(0,nrow_cntr)], 
                [['sec','sec','sec','sec'] for i in range(0,nrow_cntr)], 'min',
                [['none','none','none','none'] for i in range(0,nrow_cntr)], [['fft','fft','fft','fft'] for i in range(0,nrow_cntr)], 
                dates, settings_spectra, settings_plot, settings_paths, 
                [['ΔvTEC',settings['AMPERE']['data type'],'ΔvTEC N.',settings['AMPERE']['data type']+' N.'] for i in range(0,nrow_cntr)],
                reduceWindow=1,titleOverride=spectral_title,
                FLG_fancyPlot=FLG_doubleKeo_xcorr_fancyPlot); #insane plot call
            #END IF
        #END IF  
        warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    #END IF
    
    if( doubleKeo_xcorr_timeRangeSlam[0] != False ): #slam together multiple keo time periods
        stringer = ''; #prep
        keo_xcorr_cutOut_combSize = np.empty(len(doubleKeo_latLong), dtype=np.int64);
        AMPERE_xcorr_cutOut_combSize = np.empty(len(doubleKeo_latLong), dtype=np.int64);
        Fs = 1/(doubleKeo_AMPERE_dataRate); #sec, time delta in freq form
        for i in range(0,len(doubleKeo_latLong)):
            #TEC CUTOUT NOW
            time_cutout_indexes = np.array( ( np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.min(doubleKeo_xcorr_timeRangeSlam[i]) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.min(doubleKeo_xcorr_timeRangeSlam[i]) ) )[0][0] , \
                np.where(np.min(np.abs( doubleKeo_keo_xcorr_time[i] - np.max(doubleKeo_xcorr_timeRangeSlam[i]) )) == np.abs( doubleKeo_keo_xcorr_time[i] - np.max(doubleKeo_xcorr_timeRangeSlam[i]) ) )[0][0] ) ); #get the indexes for that time cutout range
            keo_xcorr_cutOut[i] = np.copy(doubleKeo_keo_xcorr[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]);
            keo_xcorr_time_cutOut[i] = doubleKeo_keo_xcorr_time[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
            
            #AMPERE CUTOUT NOW
            time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.min(doubleKeo_xcorr_timeRangeSlam[i]) )) == np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.min(doubleKeo_xcorr_timeRangeSlam[i]) ) )[0][0] , \
                np.where(np.min(np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.max(doubleKeo_xcorr_timeRangeSlam[i]) )) == np.abs( (doubleKeo_AMPERE_xcorr_time[i]-dateRange_dayNum_zeroHr[1]*86400) - np.max(doubleKeo_xcorr_timeRangeSlam[i]) ) )[0][0] ) ); #get the indexes for that time cutout range
            AMPERE_xcorr_cutOut[i] = np.copy(doubleKeo_AMPERE_xcorr[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1]);
            AMPERE_xcorr_time_cutOut[i] = doubleKeo_AMPERE_xcorr_time[i][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
            
            #enforce a local 0 mean
            if( strstr(doubleKeo_xcorr_AMPERE_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
                AMPERE_xcorr_cutOut[i] = subfun_filter( AMPERE_xcorr_cutOut[i], '0 mean', dataTime = AMPERE_xcorr_time_cutOut[i], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
            #END IF
            if( strstr(doubleKeo_xcorr_TEC_filtMethod.lower().replace('-','').replace(' ',''),'0mean').size > 0 ):
                keo_xcorr_cutOut[i] = subfun_filter( keo_xcorr_cutOut[i], '0 mean', dataTime = keo_xcorr_time_cutOut[i], settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter (or not)
            #END IF
            
            #deal with shared time stamp if cut out ranges start and end at the same time
            if( i != 0 ):
                if( np.min(doubleKeo_xcorr_timeRangeSlam[i]) == np.max(doubleKeo_xcorr_timeRangeSlam[i-1]) ):
                    keo_xcorr_cutOut[i] = keo_xcorr_cutOut[i][1:]; #remove 1st entry
                    keo_xcorr_time_cutOut[i] = keo_xcorr_time_cutOut[i][1:]; #remove 1st entry
                    AMPERE_xcorr_cutOut[i] = AMPERE_xcorr_cutOut[i][1:]; #remove 1st entry
                    AMPERE_xcorr_time_cutOut[i] = AMPERE_xcorr_time_cutOut[i][1:]; #remove 1st entry
                #END IF
            #END IF            
            keo_xcorr_cutOut_combSize[i] = keo_xcorr_cutOut[i].size; #add on the total size
            AMPERE_xcorr_cutOut_combSize[i] = AMPERE_xcorr_cutOut[i].size; #add on the total size
        #END FOR i
        keo_xcorr_cutOut_comb = np.empty( keo_xcorr_cutOut_combSize.sum() ); #preallocate
        keo_xcorr_time_cutOut_comb = np.empty( keo_xcorr_cutOut_combSize.sum() ); #preallocate
        AMPERE_xcorr_cutOut_comb = np.empty( AMPERE_xcorr_cutOut_combSize.sum() ); #preallocate
        AMPERE_xcorr_time_cutOut_comb = np.empty( AMPERE_xcorr_cutOut_combSize.sum() ); #preallocate
        cntrKeo = 0; #prep
        cntrAMPERE = 0; #prep
        for i in range(0,len(doubleKeo_latLong)):
            keo_xcorr_cutOut_comb[cntrKeo:cntrKeo+keo_xcorr_cutOut_combSize[i]] = keo_xcorr_cutOut[i]; #put in the data
            keo_xcorr_time_cutOut_comb[cntrKeo:cntrKeo+keo_xcorr_cutOut_combSize[i]] = keo_xcorr_time_cutOut[i]; #put in the data
            AMPERE_xcorr_cutOut_comb[cntrAMPERE:cntrAMPERE+AMPERE_xcorr_cutOut_combSize[i]] = AMPERE_xcorr_cutOut[i]; #put in the data
            AMPERE_xcorr_time_cutOut_comb[cntrAMPERE:cntrAMPERE+AMPERE_xcorr_cutOut_combSize[i]] = AMPERE_xcorr_time_cutOut[i]; #put in the data
            cntrKeo += keo_xcorr_cutOut_combSize[i]; #increment
            cntrAMPERE += AMPERE_xcorr_cutOut_combSize[i]; #increment
        #END FOR i
            
        #CALC PWR
        pwr_TEC = np.sqrt(1/keo_xcorr_cutOut_comb.size*np.sum(keo_xcorr_cutOut_comb**2)); #estimate power of signal
        pwr_AMPERE = np.sqrt(1/AMPERE_xcorr_cutOut_comb.size*np.sum(AMPERE_xcorr_cutOut_comb**2)); #estimate power of signal
        
        if( np.isclose(360, doubleKeo_AMPERE_dataRate) ):
            nfft = settings_spectra['nfft']['6min'];
            nooverlap = settings['spectra']['noverlap']; #keep
            winnow = settings_spectra['window']; #keep
        else:
            #scale as needed
            nfft = settings_spectra['nfft']['6min']*360//doubleKeo_AMPERE_dataRate;
            nooverlap = settings['spectra']['noverlap']*360//doubleKeo_AMPERE_dataRate; #adjust
            if( settings_spectra['window type'] == 'hamm' ):
                winnow = np.hamming(settings_spectra['windowLength']*360//doubleKeo_AMPERE_dataRate); #adjust
            else:
                print('ERROR: Unsupported window type \''+settings_spectra['window type']+'\', add support for it here.');
                import sys
                sys.crash();
            #END IF
        #END IF
        
        if( (winnow.size > keo_xcorr_cutOut_comb.size) | (winnow.size  > AMPERE_xcorr_cutOut_comb.size) ):
            if( keo_xcorr_cutOut_comb.size < AMPERE_xcorr_cutOut_comb.size ):
                winnow = np.hamming(keo_xcorr_cutOut_comb.size - 1); #adjust
            else:
                winnow = np.hamming(AMPERE_xcorr_cutOut_comb.size - 1); #adjust
            #END IF
            nooverlap = winnow.size - 10; #adjust
        #END IF
        
        #CALC THE XCORR
        [freqs_TECvAMPERE,Cxy_TECvAMPERE] = signal.csd(1/pwr_TEC*keo_xcorr_cutOut_comb,1/pwr_AMPERE*AMPERE_xcorr_cutOut_comb,window=winnow,noverlap=nooverlap,nfft=nfft,fs=Fs);
        Axy_TECvAMPERE = np.angle(Cxy_TECvAMPERE)*180/np.pi; 
        Pxy_TECvAMPERE = np.abs(Cxy_TECvAMPERE);
        
        #Real quick side move to calc correlation coefficients
        R_keovsAMPERE = np.corrcoef(1/pwr_TEC*keo_xcorr_cutOut_comb,1/pwr_AMPERE*AMPERE_xcorr_cutOut_comb)[0,1];
        
        stringer += 'Corr Coeff:\nSlammed Cutout ['+str(doubleKeo_xcorr_timeRangeSlam[0][0]/3600)+'  '+str(doubleKeo_xcorr_timeRangeSlam[-1][-1]/3600)+'] Keo vs AMPERE COMBINED SLAM: '+str(np.round(R_keovsAMPERE,3));
        print(stringer); #report the coeff
        
        warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
        fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        cntr = 0; #prep
        #Remove the aspect ratio from the basemap so it fills the screen better
        ax.set_aspect('auto');
        pZ = []; #prep
        lZ = []; #prep
        
        pT, = ax.plot(1/freqs_TECvAMPERE/60,(Pxy_TECvAMPERE),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        cntr += 1; #increment
        pZ.append(pT); #add onto the plot list
        lZ.append('Slammed Cutout ['+str(doubleKeo_xcorr_timeRangeSlam[0][0]/3600)+'  '+str(doubleKeo_xcorr_timeRangeSlam[0][0]/3600)+']  Keo vs '+settings['AMPERE']['data type']+' COMBINED SLAM'); #add onto the legend list
        
        # pT, = ax.plot(1/freqs_TECvAMPERE[i]/60,(Pxy_TECNvAMPERE[i]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        # cntr += 1; #increment
        # pZ.append(pT); #add onto the plot list
        # lZ.append('Cutout '+str(time_cutout_range/3600)+' Keo Noise '+str(doubleKeo_xcorr_noiseIterations)+' iterations vs '+settings['AMPERE']['data type']+' #'+str(i+1)); #add onto the legend list
    
        # pT, = ax.plot(1/freqs_TECvAMPERE[i]/60,(Pxy_TECvAMPEREN[i]),color=settings['plot']['color'][cntr],linewidth=PLOT_lineWidthPlus, linestyle=settings['plot']['line style'][cntr]);
        # cntr += 1; #increment
        # pZ.append(pT); #add onto the plot list
        # lZ.append('Cutout '+str(time_cutout_range/3600)+' Keo vs AMPERE Noise '+str(doubleKeo_xcorr_noiseIterations)+' iterations #'+str(i+1)); #add onto the legend list
    
        ax.set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
        strang = 'CSD - Combined SLAM of ';
        for i in range(0,len(doubleKeo_latLong)):
            strang += 'Time Range '+textNice(np.round(doubleKeo_xcorr_timeRangeSlam[i][0]/3600,2))+' to '+textNice(np.round(doubleKeo_xcorr_timeRangeSlam[i][-1]/3600,2))+' hrs & ';
        #END FOR i
        strang = strang.rstrip(' & '); #remove last one of these
        ax.set_title(strang, \
            fontproperties=FONT_titleFM);
        ax.legend(pZ, lZ, loc='upper right', framealpha=0.5);
        
        xAxisTicks = np.arange( 0, settings['spectra']['period limit max']/60+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
        ax.set_xticks(xAxisTicks); #set x axis ticks
        ax.set_xlim( (settings['spectra']['period limit min']/60, settings['spectra']['period limit max']/60) );
        ax.set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    
        #final plot adjusting stuff
        figFitter(fig); #fit that fig fast
        warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
        
        #--- Just FFTs for good measure ---
        GRITI_spectral_analysisPlot([keo_xcorr_cutOut_comb,AMPERE_xcorr_cutOut_comb], 
            [keo_xcorr_time_cutOut_comb,AMPERE_xcorr_time_cutOut_comb], 
            ['sec','sec'], [doubleKeo_AMPERE_dataRate,doubleKeo_AMPERE_dataRate], 
            ['sec','sec'], 'min',
            ['none','none'], ['fft','fft'], 
            dates, settings_spectra, settings_plot, settings_paths, 
            ['TEC SLAM Time Range '+textNice(np.round(doubleKeo_xcorr_timeRangeSlam[0][0]/3600,2))+' to '+textNice(np.round(doubleKeo_xcorr_timeRangeSlam[-1][-1]/3600,2)),settings['AMPERE']['data type']+' SLAM Time Range '+textNice(np.round(doubleKeo_xcorr_timeRangeSlam[0][0]/3600,2))+' to '+textNice(np.round(doubleKeo_xcorr_timeRangeSlam[-1][-1]/3600,2))],
            reduceWindow=1); #insane plot call
        #END IF
    #END IF
#END IF

if( FLG_doubleKeo_TECnMag == 1 ):
    from matplotlib.patches import ConnectionPatch, Rectangle
    from Code.subfun_timeMatch import subfun_timeMatch
    from Code.subfun_figFitter import figFitter
    from Code.subfun_filter import subfun_filter
    from Code.GRITI_keo_keogrammer import GRITI_keo_keogrammer
    
    #prep TEC data
    (doubleKeo_TECnMag_TEC_keo, doubleKeo_TECnMag_TEC_angle, doubleKeo_TECnMag_TEC_width, \
    doubleKeo_TECnMag_TEC_plotRangeChunks, doubleKeo_TECnMag_TEC_plotRangeName) = \
        GRITI_keo_keogrammer(dates,settings,doubleKeo_TECnMag_TEC_latLong[0],doubleKeo_TECnMag_TEC_latLong[1],TEC_timeUnique,\
            TEC_plotLimValu,doubleKeo_TECnMag_TEC_colorMap,data['TEC']['dTEC'],data['TEC']['time'],data['TEC']['lat'],data['TEC']['long'],time_Ref,doubleKeo_TECnMag_TEC_angleOrig, \
            doubleKeo_TECnMag_TEC_N,doubleKeo_TECnMag_TEC_widthOrig,doubleKeo_TECnMag_TEC_45vsLatLong,avgPt_coords,geoMap_projectionStyle,\
            dateRange_dayNum_zeroHr,plotLatRange_autoTick,plotLongRange_autoTick,plotLongRange_autoTick_Crunched, gif_Millstone_Marker, gif_Millstone_Marker_Color, \
            gif_Millstone_Marker_Size,FONT_titleFM,FONT_axisTick,FONT_axisTickFM,FONT_axisLabelFM,BasemapFixDir,\
            doubleKeo_TECnMag_TEC_dataName,doubleKeo_TECnMag_TEC_dataName_wUnits,FLG_fancyPlot,PLOT_lineWidth, folder, journal_width_2C,journal_height_max,journal_dpi,\
            keo_polarMode=0,FLG_disablePlot=2);
            #call the mecha function that runs the keo alg and makes a plot showing the averaging are
    
    #Calc magnetometer keogram
    localSettings = {
        'MagCAN':{
            'delta method':doubleKeo_TECnMag_Mag_filtMethod,
            'keo plot name':'Magnitude of Magnetic Field [nT]', #label for plotting
            'keo angle':doubleKeo_TECnMag_Mag_angle, #orig b/c this can be adjusted slightly if 0 or 90
            'keo width orig':doubleKeo_TECnMag_Mag_width, #orig b/c this can be adjusted if it's bigger than the averaging area [easy way to guarantee full coverage is to set to 360]
            'keo N':doubleKeo_TECnMag_Mag_N, #number of times to split the area the keogram covers
            'keo polar mode':doubleKeo_TECnMag_Mag_polarMode,
            'keo 45 lat/long':doubleKeo_TECnMag_Mag_45vsLatLong,
            'keo colorbar':doubleKeo_TECnMag_Mag_colorMap,
            'keo normalize':doubleKeo_TECnMag_Mag_normalize,
            'keo set plot range':doubleKeo_TECnMag_Mag_setPlotRange,
            'keo set plot range range':doubleKeo_TECnMag_Mag_setPlotRange_range,
            'keo set stations':doubleKeo_TECnMag_Mag_setStations,
            'keo set stations names':doubleKeo_TECnMag_Mag_setStations_names,
            },
        'plot':settings['plot'],
        'spectra':settings['spectra'],
        'map':settings['map'],
        };
    #-----Get the plot lat/long ranges based on the site locations involved-----
    if( doubleKeo_TECnMag_Mag_setPlotRange == 0 ):
        siteLocs = np.zeros( (2, len(data['MagCAN']['site names'])) ); #preallocate
        for j in range(0,len(data['MagCAN']['site names'])):
            siteLocs[0,j] = data['MagCAN'][data['MagCAN']['site names'][j]]['lat'];
            siteLocs[1,j] = data['MagCAN'][data['MagCAN']['site names'][j]]['long'];
        #END FOR j
        
        Mag_plotLatRange = [np.min(siteLocs[0,:]), np.max(siteLocs[0,:])]; # get lat extent
        Mag_plotLongRange = [np.min(siteLocs[1,:]), np.max(siteLocs[1,:])]; # get long extent
        #Adjust these ranges as needed
        if( np.remainder(np.ceil(Mag_plotLatRange[1]),5) == 0 ):
            Mag_plotLatRange[1] = np.ceil(Mag_plotLatRange[1]) + 5; #keep up to a 5 degc lat boundary
        else:
            Mag_plotLatRange[1] = np.ceil(Mag_plotLatRange[1]) + (5-np.remainder(np.ceil(Mag_plotLatRange[1]),5)); #keep up to a 5 degc lat boundary
        #END IF
        if( np.remainder(np.floor(Mag_plotLatRange[0]),5) == 0 ):
            Mag_plotLatRange[0] = np.floor(Mag_plotLatRange[0]) - 5; #keep up to a 5 degc lat boundary
        else:
            Mag_plotLatRange[0] = np.floor(Mag_plotLatRange[0]) - np.remainder(np.floor(Mag_plotLatRange[0]),5); #keep up to a 5 degc lat boundary
        #END IF
        if( np.remainder(np.ceil(Mag_plotLongRange[1]),5) == 0 ):
            Mag_plotLongRange[1] = np.ceil(Mag_plotLongRange[1]) + 5; #keep up to a 5 degc lat boundary
        else:
            Mag_plotLongRange[1] = np.ceil(Mag_plotLongRange[1]) + (5-np.remainder(np.ceil(Mag_plotLongRange[1]),5)); #keep up to a 5 degc long boundary
        #END IF
        if( np.remainder(np.floor(Mag_plotLongRange[0]),5) == 0 ):
            Mag_plotLongRange[0] = np.floor(Mag_plotLongRange[0]) - 5; #keep up to a 5 degc lat boundary
        else:
            Mag_plotLongRange[0] = np.floor(Mag_plotLongRange[0]) - np.remainder(np.floor(Mag_plotLongRange[0]),5); #keep up to a 5 degc long boundary
        #END IF
        localSettings['MagCAN']['lat range'] = Mag_plotLatRange; #record Mag's custom lat range for when only Mag is in play
        localSettings['MagCAN']['long range'] = Mag_plotLongRange; #record Mag's custom long range for when only Mag is in play
    else:
        #otherwise, let user set the lat/long range at will
        localSettings['MagCAN']['lat range'] = doubleKeo_TECnMag_Mag_setPlotRange_range[0]; #arcdeg, set it by user
        localSettings['MagCAN']['long range'] = doubleKeo_TECnMag_Mag_setPlotRange_range[1]; #arcdeg, set it by user
    #END IF
    doubleKeo_TECnMag_Mag_latLong = [localSettings['MagCAN']['lat range'],localSettings['MagCAN']['long range']]; #make a latlong range

    (doubleKeo_TECnMag_MagCAN_keo, doubleKeo_TECnMag_Mag_time, doubleKeo_TECnMag_Mag_timeHr, \
    doubleKeo_TECnMag_Mag_angle, doubleKeo_TECnMag_Mag_width, \
    doubleKeo_TECnMag_Mag_plotRangeChunks,doubleKeo_TECnMag_Mag_plotRangeName) = \
        GRITI_MagCAN_keo(data,dates,localSettings,FLG_disablePlot=0);
    #call the mecha function that runs the keo alg and makes a plot showing the averaging area [FLG_normalize makes each site normalized to each other - the magnitude reduces as latitude drops]
    
    data['double keo TECnMag'] = {
        'TEC keo':doubleKeo_TECnMag_TEC_keo,
        'TEC lat long':doubleKeo_TECnMag_TEC_latLong,
        'TEC angle':doubleKeo_TECnMag_TEC_angle,
        'TEC width':doubleKeo_TECnMag_TEC_width,
        'TEC plot spacing':doubleKeo_TECnMag_TEC_plotRangeChunks,
        'TEC plot spacing name':doubleKeo_TECnMag_TEC_plotRangeName,
        'Mag keo':doubleKeo_TECnMag_MagCAN_keo,
        'Mag lat long':doubleKeo_TECnMag_Mag_latLong,
        'Mag time':doubleKeo_TECnMag_Mag_time,
        'Mag time hr':doubleKeo_TECnMag_Mag_timeHr,
        'Mag angle':doubleKeo_TECnMag_Mag_angle,
        'Mag width':doubleKeo_TECnMag_Mag_width,
        'Mag plot spacing':doubleKeo_TECnMag_Mag_plotRangeChunks,
        'Mag plot spacing name':doubleKeo_TECnMag_Mag_plotRangeName,
        };
    
    #-----Plot TEC results as a Keogram w/ AMPERE integrated line as well-----
    #Prep the plot
    fig, ax = plt.subplots(nrows=2, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    cax = []; #prep
    divider = []; #prep
    im = []; #prep
    cbar = []; #prep
    
    divider.append(make_axes_locatable(ax[0])); #prep to add an axis
    divider.append(make_axes_locatable(ax[1])); #prep to add an axis
    cax.append(divider[0].append_axes('right', size='2.0%', pad=1.75)); #make a color bar axis, append
    cax.append(divider[1].append_axes('right', size='2.0%', pad=1.75)); #make a color bar axis, append
    
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax[0].set_aspect('auto');
    ax[1].set_aspect('auto');
    
    #-----Plot Mag results as a keogram-----
    i = 0; #for plotting purposes
    pltHelprX, pltHelprY = np.meshgrid( data['double keo TECnMag']['Mag time hr'], \
                data['double keo TECnMag']['Mag plot spacing']);
    im.append(ax[i].pcolormesh(pltHelprX, pltHelprY,  data['double keo TECnMag']['Mag keo'].T,cmap=doubleKeo_TECnMag_Mag_colorMap)); # pseudocolor plot "stretched" to the grid
    cbar.append(fig.colorbar(im[i], cax=cax[i], orientation='vertical')); #create a colorbar using the prev. defined cax
    if( doubleKeo_TECnMag_Mag_plotLimVal != None ): 
        cax[i].yaxis.set_ticks(np.linspace(np.min(doubleKeo_TECnMag_Mag_plotLimVal),np.max(doubleKeo_TECnMag_Mag_plotLimVal),5)); #create useful tick marks
    #END IF
    # cax[i].yaxis.set_major_formatter(FormatStrFormatter('%.2f')); #force a rounded format
    cbar[i].set_label(settings['MagCAN']['keo plot name']); #tabel the colorbar
    cbar[i].ax.tick_params(labelsize=FONT_axisTick);
    if( doubleKeo_TECnMag_Mag_plotLimVal != None ): 
        #cbar[i].set_clim(vmin=np.min(doubleKeo_TECnMag_Mag_plotLimVal), vmax=np.max(doubleKeo_TECnMag_Mag_plotLimVal)); #they changed how the code works, this doesn't work anymore
        cbar[i].mappable.set_clim(vmin=np.min(doubleKeo_TECnMag_Mag_plotLimVal), vmax=np.max(doubleKeo_TECnMag_Mag_plotLimVal)); #now it's this
    #END IF
    cax[i].yaxis.label.set_font_properties(FONT_axisLabelFM);
    
    #-----Plot TEC results as a keogram-----
    i = 1; #for plotting purposes
    pltHelprX, pltHelprY = np.meshgrid( (TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600, \
                doubleKeo_TECnMag_TEC_plotRangeChunks);
    im.append(ax[i].pcolormesh(pltHelprX, pltHelprY,  doubleKeo_TECnMag_TEC_keo.T ,vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim']),cmap=settings['TEC']['colormap'])); # pseudocolor plot "stretched" to the grid
    cbar.append(fig.colorbar(im[i], cax=cax[i], orientation='vertical')); #create a colorbar using the prev. defined cax
    cax[i].yaxis.set_ticks(np.linspace(np.min(settings['TEC']['plot lim']),np.max(settings['TEC']['plot lim']),5)); #create useful tick marks
    cax[i].yaxis.set_major_formatter(FormatStrFormatter('%.2f')); #force a rounded format
    cbar[i].set_label(settings['TEC']['plot label']); #tabel the colorbar
    cbar[i].ax.tick_params(labelsize=FONT_axisTick);
    #cbar[i].set_clim(vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim'])); #they changed how the code works, this doesn't work anymore
    cbar[i].mappable.set_clim(vmin=np.min(settings['TEC']['plot lim']), vmax=np.max(settings['TEC']['plot lim'])); #now it's this
    cax[i].yaxis.label.set_font_properties(FONT_axisLabelFM);
    
    xAxisTicks = np.arange( (np.round((TEC_timeUnique[0]-dateRange_dayNum_zeroHr[1]*86400)/3600) - np.mod(np.round((TEC_timeUnique[0]-dateRange_dayNum_zeroHr[1]*86400)/3600), 4)) , \
        (np.round((TEC_timeUnique[-1]-dateRange_dayNum_zeroHr[1]*86400)/3600) - np.mod(np.round((TEC_timeUnique[-1]-dateRange_dayNum_zeroHr[1]*86400)/3600),2)) + 4 , \
        4); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
    i = 0;
    ax[i].set_xticks(xAxisTicks); #set x axis ticks
    ax[i].set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set x axis limits
    i = 1;
    ax[i].set_xticks(xAxisTicks); #set x axis ticks
    ax[i].set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set x axis limits
    fig.subplots_adjust(hspace = 0.0); #make the plots touch
        
    # #-----Plot Shading to represent 'night'-----
    # doubleKeo_AMPERE_niteTimes_array = np.zeros( (dateRange_zeroHr_hrs.size,2) );
    # for j in range(0,dateRange_zeroHr_hrs.size):
    #     doubleKeo_AMPERE_niteTimes_array[j,:] = np.array(doubleKeo_AMPERE_niteTimes[i])+dateRange_zeroHr_hrs[j];
    # #END FOR j
    # #FIFTH STEP: PLOT THIS STUFF
    # for j in range(0,doubleKeo_AMPERE_niteTimes_array.shape[0]):
    #     ax[i].axvspan(doubleKeo_AMPERE_niteTimes_array[j,0], doubleKeo_AMPERE_niteTimes_array[j,1], alpha=0.25, color='xkcd:black');
    # #END FOR j
    
    string_title = settings['MagCAN']['keo plot name'].replace(' [nT]','')+' Keo Angle of '+textNice(np.round(doubleKeo_TECnMag_Mag_angle,2))+' deg & Width of '+textNice(np.round(doubleKeo_TECnMag_Mag_width,2))+' arcdeg | '+settings['TEC']['plot label no units']+' Keo Angle of '+textNice(np.round(doubleKeo_TECnMag_TEC_angle,2))+' deg & Width of '+ \
        textNice(np.round(doubleKeo_TECnMag_TEC_width,2))+' arcdeg'; #create mecha title
    ax[0].set_title(string_title,fontproperties=FONT_titleFM); #set the title
    ax[1].set_xlabel('Time in UT - 0 Hr on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0])+' [hr]',fontproperties=FONT_axisLabelFM); #set the x axis label
    ax[0].set_ylabel(doubleKeo_TECnMag_Mag_plotRangeName+' [arcdeg]',fontproperties=FONT_axisLabelFM); #set the y axis label
    ax[1].set_ylabel(doubleKeo_TECnMag_TEC_plotRangeName+' [arcdeg]',fontproperties=FONT_axisLabelFM); #set the y axis label
    
    autoTick = (np.ceil(np.max(doubleKeo_TECnMag_Mag_plotRangeChunks)) - np.floor(np.min(doubleKeo_TECnMag_Mag_plotRangeChunks)))/13; #tries to split the latitude range into 13 parts (based off of 180/15+1)
    if( autoTick > 25 ):
        autoTick = 30; #sets the tick setting to 15 arcdegrees per tick
    elif( autoTick > 10 ):
        autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
    elif( autoTick > 5 ):
        autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
    elif( autoTick > 2 ):
        autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
    elif( autoTick > 1 ):
        autoTick = 2; #sets the tick setting to 5 arcdegrees per tick
    elif( autoTick >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
        autoTick = 1; #                                                        sets the tick setting to 1 arcdegree per tick
    else:
        if(doubleKeo_TECnMag_Mag_plotRangeName == 'Latitude'): #if Y axis is latitude, use latitude
            autoTick = (np.max(doubleKeo_TECnMag_Mag_latLong[0]) - np.min(doubleKeo_TECnMag_Mag_latLong[0]))/13; #just goes for it if it's a super tiny range
        elif(doubleKeo_TECnMag_Mag_plotRangeName == 'Longitude'): #if Y axis is longitude, use longitude
            autoTick = (np.max(doubleKeo_TECnMag_Mag_latLong[1]) - np.min(doubleKeo_TECnMag_Mag_latLong[1]))/13; #just goes for it if it's a super tiny range
        #END IF
    #END IF
    autoTickM = np.copy(autoTick).item(); #get the Mag auto tick
    autoTick = (np.ceil(np.max(doubleKeo_TECnMag_TEC_plotRangeChunks)) - np.floor(np.min(doubleKeo_TECnMag_TEC_plotRangeChunks)))/13; #tries to split the latitude range into 13 parts (based off of 180/15+1)
    if( autoTick > 25 ):
        autoTick = 30; #sets the tick setting to 15 arcdegrees per tick
    elif( autoTick > 10 ):
        autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
    elif( autoTick > 5 ):
        autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
    elif( autoTick > 2 ):
        autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
    elif( autoTick > 1 ):
        autoTick = 2; #sets the tick setting to 5 arcdegrees per tick
    elif( autoTick >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
        autoTick = 1; #                                                        sets the tick setting to 1 arcdegree per tick
    else:
        if(doubleKeo_TECnMag_TEC_plotRangeName == 'Latitude'): #if Y axis is latitude, use latitude
            autoTick = (np.max(doubleKeo_TECnMag_TEC_latLong[0]) - np.min(doubleKeo_TECnMag_TEC_latLong[0]))/13; #just goes for it if it's a super tiny range
        elif(doubleKeo_TECnMag_TEC_plotRangeName == 'Longitude'): #if Y axis is longitude, use longitude
            autoTick = (np.max(doubleKeo_TECnMag_TEC_latLong[1]) - np.min(doubleKeo_TECnMag_TEC_latLong[1]))/13; #just goes for it if it's a super tiny range
        #END IF
    #END IF
    autoTickT = np.copy(autoTick).item(); #get the TEC auto tick
    if(autoTickM > autoTickT):
        autoTick = autoTickM; #use larger one
    else:
        autoTick = autoTickT; #use larger one
    #END IF
    yAxisTicks = np.round(np.arange( np.floor(np.min(doubleKeo_TECnMag_Mag_plotRangeChunks)),np.ceil(np.max(doubleKeo_TECnMag_Mag_plotRangeChunks)),autoTick ),2); #creates y ticks automagically
    ax[0].set_yticks(yAxisTicks); #set y axis ticks
    yAxisTicks = np.round(np.arange( np.floor(np.min(doubleKeo_TECnMag_TEC_plotRangeChunks)),np.ceil(np.max(doubleKeo_TECnMag_TEC_plotRangeChunks)),autoTick ),2); #creates y ticks automagically
    ax[1].set_yticks(yAxisTicks); #set y axis ticks
    
    # #Now drawing line of interest
    # if( doubleKeo_plotSpacingName[i] == 'Latitude' ): #if true, latitude
    #     if( (np.min(doubleKeo_latLong[i][0]) <= doubleKeo_AMPERE_latAlign[i]) & (np.max(doubleKeo_latLong[i][0]) >= doubleKeo_AMPERE_latAlign[i]) ): #only plot if it's in the lat range specified
    #         ax[i].plot( np.linspace(np.min((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600),np.max((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600),10,endpoint=True) , #X time hr
    #             np.tile(doubleKeo_AMPERE_latAlign[i],10) , #Y latitude OR longitude arcdeg
    #             c='xkcd:black',linewidth=settings['plot']['line width']['smol']); #plots a point with a black line
    #     #END IF
    # else:
    #     if( (np.min(doubleKeo_latLong[i][1]) <= doubleKeo_AMPERE_latAlign[i]) & (np.max(doubleKeo_latLong[i][1]) >= doubleKeo_AMPERE_latAlign[i]) ): #only plot if it's in the lat range specified
    #         ax[i].plot( np.linspace(np.min((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600),np.max((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600),10,endpoint=True) , #X time hr
    #             np.tile(doubleKeo_AMPERE_latAlign[i],10) , #Y latitude OR longitude arcdeg
    #             c='xkcd:black',linewidth=settings['plot']['line width']['smol']); #plots a point with a black line
    #     #END IF
    # #END IF
    
    # #-----Draw line from 1st TEC event to 2nd-----
    # con = ConnectionPatch(xyA=(-11.81,doubleKeo_AMPERE_latAlign[0]), coordsA=ax[0].transData,
    #                       xyB=(-11.13,doubleKeo_AMPERE_latAlign[1]), coordsB=ax[1].transData,
    #                       arrowstyle="-|>", shrinkA=5, shrinkB=5,mutation_scale=20, fc="xkcd:pink",
    #                       color='xkcd:pink', linewidth=settings['plot']['line width']['double plus']); #prep a line between plots
    # fig.add_artist(con); #draw the line
    
    figFitter(fig); #fit the fig fast    
#END IF
    

#==============Analysis: delta-vTEC Activity Index==============
if( FLG_activityIndex == 1 ):
    from Code.subfun_figFitter import figFitter

    activityIndex_time = 6; #min, minutes to average together to caclulate activity
    
    activityIndex_zone1 = np.array( ((30,-125),(50,-125),(30,-60),(50,-60)) ); #USA
    activityIndex_zone1_name = 'USA';
    activityIndex_zone2 = np.array( ((30,-15),(75,-15),(30,40),(75,40)) ); #Europe   
    activityIndex_zone2_name = 'Europe';
    TEC_activityIndex_step = 0.05; #TECU, steps to run through
    
    activityIndex_zones = np.stack( (activityIndex_zone1,activityIndex_zone2) ,axis=2 ); #stack em up
    activityIndex_zonesNames = [activityIndex_zone1_name, activityIndex_zone2_name];
    
    activityIndex_bins = np.arange(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim'])+TEC_activityIndex_step,TEC_activityIndex_step); #make the bins
    activityIndex_time_sec = activityIndex_time*60; #sec, convert to sec
    activityIndex_timeRange = np.arange( TEC_timeUnique[0], TEC_timeUnique[-1]+activityIndex_time_sec, activityIndex_time_sec); #days, get the time range to go through
    activityIndex_timeRange_hr = (activityIndex_timeRange - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hrs
    activityIndex_mean = np.zeros( (activityIndex_zones.shape[2] , activityIndex_timeRange.size-1 ) );
    activityIndex_var = np.zeros( (activityIndex_zones.shape[2] , activityIndex_timeRange.size-1 ) );
    activityIndex_meanAbs = np.zeros( (activityIndex_zones.shape[2] , activityIndex_timeRange.size-1 ) );
    activityIndex_median = np.zeros( (activityIndex_zones.shape[2] , activityIndex_timeRange.size-1 ) );
    activityIndex_medianAbs = np.zeros( (activityIndex_zones.shape[2] , activityIndex_timeRange.size-1 ) );
    
    for irate in range(0,activityIndex_zones.shape[2]): #number of zones
        TEC_inZone = np.where( (data['TEC']['lat'] <= np.max(activityIndex_zones[:,0,irate]) ) & (data['TEC']['lat'] >= np.min(activityIndex_zones[:,0,irate]) ) & \
            (data['TEC']['long'] <= np.max(activityIndex_zones[:,1,irate]) ) & (data['TEC']['long'] >= np.min(activityIndex_zones[:,1,irate]) ) )[0];
        
        for i in range(activityIndex_timeRange.size-1):
            k = np.where( (data['TEC']['time'][TEC_inZone] < activityIndex_timeRange[i+1]) & (data['TEC']['time'][TEC_inZone] >= activityIndex_timeRange[i]) )[0]; #get where the time point is, make sure it is within the data rate window
            
            
            activityIndex_mean[irate,i] = np.mean(data['TEC']['dTEC'][TEC_inZone[k]]);
            activityIndex_var[irate,i] = np.var(data['TEC']['dTEC'][TEC_inZone[k]]);
            activityIndex_meanAbs[irate,i] = np.mean(np.abs(data['TEC']['dTEC'][TEC_inZone[k]]));
            activityIndex_medianAbs[irate,i] = np.median(np.abs(data['TEC']['dTEC'][TEC_inZone[k]]));
            activityIndex_median[irate,i] = np.median(activityIndex_median[irate,i]-np.abs(data['TEC']['dTEC'][TEC_inZone[k]]));
            
            #Histogram to check if Gaussian shaped
    #        (activityIndex, _) = np.histogram(data['TEC']['dTEC'][TEC_inZone[k]], bins=activityIndex_bins)
    #        #Start the Activity Index plot
    #        fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
    #        figManager = fig.canvas.manager; #req to maximize
    #        figManager.window.showMaximized(); #force maximized
    #        
    #        #ax.plot( activityIndex_bins[0:-1], activityIndex ); #plot
    #        ax.hist(data['TEC']['dTEC'][TEC_inZone[k]], bins=activityIndex_bins); #alternate
    #        
    #        string_title = 'Activity for '+activityIndex_zonesNames[irate]+' at '+str(activityIndex_timeRange_hr[i])+' hrs'; #create mecha title
    #        ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
    #        
    #        fig.subplots_adjust(left = 0.050, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space 
        
        #END FOR i
        
        #Start the Mean Activity Index plot
        fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        ax.plot( activityIndex_timeRange_hr[0:-1], activityIndex_mean[irate,:] ); #plot
        
        string_title = 'Mean Activity for '+activityIndex_zonesNames[irate]; #create mecha title
        ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
        
        figFitter(fig); #fit that fig fast
        # fig.subplots_adjust(left = 0.050, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
        
        #Start the Var Activity Index plot
        fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        ax.plot( activityIndex_timeRange_hr[0:-1], activityIndex_var[irate,:] ); #plot
        
        string_title = 'Var Activity for '+activityIndex_zonesNames[irate]; #create mecha title
        ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
        
        figFitter(fig); #fit that fig fast
        # fig.subplots_adjust(left = 0.050, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
        
        #Start the Abs Mean Activity Index plot
        fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        ax.plot( activityIndex_timeRange_hr[0:-1], activityIndex_meanAbs[irate,:] ); #plot
        
        string_title = 'Abs Mean Activity for '+activityIndex_zonesNames[irate]; #create mecha title
        ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
        
        figFitter(fig); #fit that fig fast
        # fig.subplots_adjust(left = 0.050, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
        
        
        #Start the Mean Activity Index plot
        fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        ax.plot( activityIndex_timeRange_hr[0:-1], activityIndex_mean[irate,:] ); #plot
        
        string_title = 'Mean Activity for '+activityIndex_zonesNames[irate]; #create mecha title
        ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
        
        figFitter(fig); #fit that fig fast
        # fig.subplots_adjust(left = 0.050, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
        
        
            #Start the Mean Activity Index plot
        fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        ax.plot( activityIndex_timeRange_hr[0:-1], activityIndex_median[irate,:] ); #plot
        
        string_title = 'Median Activity for '+activityIndex_zonesNames[irate]; #create mecha title
        ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
        
        figFitter(fig); #fit that fig fast
        # fig.subplots_adjust(left = 0.050, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
        
            #Start the Mean Activity Index plot
        fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        ax.plot( activityIndex_timeRange_hr[0:-1], activityIndex_medianAbs[irate,:] ); #plot
        
        string_title = 'Median Abs Activity for '+activityIndex_zonesNames[irate]; #create mecha title
        ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
        
        figFitter(fig); #fit that fig fast
        # fig.subplots_adjust(left = 0.050, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
    #END FOR irate
     
        
    AMPERE_timeUnique_hr = (AMPERE_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    if( np.mod(np.round(np.min(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr))+1; #is odd, make even
    #END IF
    if( np.mod(np.round(np.max(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr))-1; #is odd, make even
    #END IF
    
    OMNI_timeUnique_hr = (OMNI_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
         
    for irate in range(0,activityIndex_zones.shape[2]):
    
        #-----BEGIN THE PLOTTING!------
        if( np.min(data['AMPERE']['lat']) < 0 ):
            #that means there is southern hemisphere data
            pass;
        else:
            #otherwise only northern hemisphere data
            
            AMPERE_integrate = np.zeros( AMPERE_timeUnique_hr.size , dtype=np.float64); #prep integrated joule heating
            for i in range(AMPERE_timeUnique_hr.size):
                k = np.where(AMPERE_timeUnique[i] == data['AMPERE']['time'])[0]
                AMPERE_integrate[i] = np.sum(data['AMPERE'][k,locAMPERE_jouleHeating]); #ergs/(cm^2*sec), get the Joule Heating for the current time stamp
            #END FOR i
            
            #Start the AMPERE and OMNI AE plot
            fig, ax = plt.subplots(nrows=2, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
            figManager = fig.canvas.manager; #req to maximize
            figManager.window.showMaximized(); #force maximized
            
            #-----PLOT AMPERE-----
            ax[0].set_aspect('auto'); #Remove the aspect ratio from the basemap so it fills the screen better
            ax[0].plot( AMPERE_timeUnique_hr, AMPERE_integrate , linewidth=PLOT_lineWidth ); #plot
            
            if( (np.abs((np.min(AMPERE_timeUnique_hr)/24 + dateRange_dayNum_zeroHr[1]) - np.min(time_Ref))*24 >= 0.25) & ((time_Reference != 'Kp') & (time_Reference != 'AMPERE')) ): #as long as min Kp time is 15 min diff or more from the other time reference, plot where the time ref begins (not Kp tho)
                ax[0].plot( np.repeat( (np.min(time_Ref) - dateRange_dayNum_zeroHr[1]*86400)/3600 , 10) , np.linspace(np.min(AMPERE_integrate),np.max(AMPERE_integrate),num=10), linewidth=1.75, color='r'); #plot red lines showing ISR data time
            if( (np.abs((np.max(AMPERE_timeUnique_hr)/24 + dateRange_dayNum_zeroHr[1]) - np.max(time_Ref))*24 >= 0.25) & ((time_Reference != 'Kp') & (time_Reference != 'AMPERE')) ): #as long as max Kp time is 15 min diff or more from the other time reference, plot where the time ref ends (not Kp tho)
                ax[0].plot( np.repeat( (np.max(time_Ref) - dateRange_dayNum_zeroHr[1]*86400)/3600 , 10) , np.linspace(np.min(AMPERE_integrate),np.max(AMPERE_integrate),num=10), linewidth=1.75, color='r'); #plot red lines showing ISR data time
            #END IF
            
            xAxisTicks = np.arange(AMPERE_time_hr_axis_min,AMPERE_time_hr_axis_max+4,4); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
            ax[0].set_xticks(xAxisTicks); #set x axis ticks
            
    #        ax[0].set_xticklabels([]); #if statement to remove x axis labels except for the last line
    #        ax[0].tick_params(axis="x",direction="in");
            
            ax[0].set_xlim( AMPERE_time_hr_axis_min , AMPERE_time_hr_axis_max ); #set y axis limits
            
            ax[0].set_ylabel("Int. AMPERE JH [ergs/(cm^2*sec)]",fontproperties=FONT_axisLabelFM); #set the y axis label
            
            ax[0].set_ylim( np.min(AMPERE_integrate) , 150000 ); #set y axis limits
            
            ax[0].grid(b=True, which='major', axis='both', color='xkcd:light grey'); #sets major axis grid lines to be on                
            
            string_title = 'Integrated AMPERE Joule Heating in the Nothern Hemisphere & delta-vTEC Median over '+activityIndex_zonesNames[irate]+' for '+str(dateRange[0,1])+'/'+str(dateRange[0,2])+ \
            '/'+str(dateRange[0,0])+' to '+str(dateRange[-1,1])+ \
            '/'+str(dateRange[-1,2])+'/'+str(dateRange[-1,0])+ \
            ' (M/D/Y)'; #create mecha title
            ax[0].set_title(string_title,fontproperties=FONT_titleFM); #set the title
            
            #-----PLOT dTEC ACTIVITY MEDIAN----
            ax[1].set_aspect('auto'); #Remove the aspect ratio from the basemap so it fills the screen better
    
            ax[1].plot( activityIndex_timeRange_hr[0:-1], activityIndex_median[irate,:] ); #plot
            if( (np.abs((np.min(AMPERE_timeUnique_hr)/24 + dateRange_dayNum_zeroHr[1]) - np.min(time_Ref))*24 >= 0.25) & ((time_Reference != 'Kp') & (time_Reference != 'AMPERE')) ): #as long as min Kp time is 15 min diff or more from the other time reference, plot where the time ref begins (not Kp tho)
                ax[1].plot( np.repeat( (np.min(time_Ref) - dateRange_dayNum_zeroHr[1]*86400)/3600 , 10) , np.linspace(np.min(activityIndex_var[irate,:]),np.max(activityIndex_var[irate,:]),num=10), linewidth=1.75, color='r'); #plot red lines showing ISR data time
            if( (np.abs((np.max(AMPERE_timeUnique_hr)/24 + dateRange_dayNum_zeroHr[1]) - np.max(time_Ref))*24 >= 0.25) & ((time_Reference != 'Kp') & (time_Reference != 'AMPERE')) ): #as long as max Kp time is 15 min diff or more from the other time reference, plot where the time ref ends (not Kp tho)
                ax[1].plot( np.repeat( (np.max(time_Ref) - dateRange_dayNum_zeroHr[1]*86400)/3600 , 10) , np.linspace(np.min(activityIndex_var[irate,:]),np.max(activityIndex_var[irate,:]),num=10), linewidth=1.75, color='r'); #plot red lines showing ISR data time
            #END IF
            
            ax[1].set_xticks(xAxisTicks); #set x axis ticks
            
            ax[1].set_xlim( AMPERE_time_hr_axis_min , AMPERE_time_hr_axis_max ); #set y axis limits
            
            ax[1].set_ylabel('delta-vTEC Median',fontproperties=FONT_axisLabelFM); #set the y axis label
            
            ax[1].grid(b=True, which='major', axis='both', color='xkcd:light grey'); #sets major axis grid lines to be on                
          
            ax[1].set_ylim( 0 , 0.25 ); #set y axis limits
    
            ax[1].set_xlabel('Time in UT (hr) - 0 Hr on '+dateRange_zeroHr_monthName+' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM); #set the x axis label
            
            figFitter(fig); #fit that fig fast
            # fig.subplots_adjust(left = 0.070, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
        #END IF
    #END FOR irate
#END IF        

    
if( FLG_dataCountIndex ==  1):
    from Code.subfun_figFitter import figFitter
    
    TEC_timeUnique_ideal = np.arange(TEC_timeUnique[0],TEC_timeUnique[-1]+TEC_dataRate,TEC_dataRate);
    TEC_timeUnique_dataCount = np.empty(TEC_timeUnique_ideal.shape);
    
    for i in range(0,TEC_timeUnique_ideal.size):
        TEC_timeUnique_dataCount[i] = np.sum(TEC_timeUnique_ideal[i] == data['TEC']['time']); #count how many
    #END FOR i
    
    #Start the TEC data count plot
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    ax.plot((TEC_timeUnique_ideal - dateRange_dayNum_zeroHr[1]*86400)/3600,TEC_timeUnique_dataCount)
    
    ax.set_ylabel('delta-vTEC Data Count',fontproperties=FONT_axisLabelFM); #set the y axis label
    ax.set_xlabel('Time in UT (hr) - 0 Hr on '+dateRange_zeroHr_monthName+' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM); #set the x axis label
        
    figFitter(fig); #fit that fig fast
#END IF
    
    
#==============Analysis: average delta-vTEC at a single point==============
if( FLG_avgPt == 1 ): #average delta-vTEC around avgPt_coords in a radius of avgPt_pointRadius
    from Code.subfun_figFitter import figFitter
    pointRadiusAngular = (avgPt_pointRadius/Re)*180/np.pi; #deg, (based on s=R*theta) angular radius around the point allowed
    
    
    for i in range(0,avgPt_coords.shape[0]):
        #================THIS IS TO VIEW DATA AVG RANGE BEING TAKEN==============
        fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        divider = make_axes_locatable(ax); #prep to add an axis
        cax = divider.append_axes('right', size='2.0%', pad=0.35); #make a color bar axis
        fig.subplots_adjust(left = 0.04, right = 0.945, top = 0.96, bottom = 0.035); #sets padding to small numbers for minimal white space
        fig.canvas.flush_events(); #this is req. to get get_window_extent() to get the current window size correctly
        
        bboxFig = fig.get_window_extent().transformed(fig.dpi_scale_trans.inverted()); #get the entire figure dimensions
        bboxAx0 = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted()); #get the plot dimensions
        plot_ratio = (bboxAx0.width/bboxAx0.height); #get the plot ratio, will use it to fix up the circle
        avgPt_plotLongMax = plot_ratio*avgPt_plotLatMax; #degc, automagically scale it
        
        avgPt_plotLatRange = np.array( (avgPt_coords[i,0]-avgPt_plotLatMax,avgPt_coords[i,0]+avgPt_plotLatMax) ); #create a temporary range for this plot
        avgPt_plotLongRange = np.array( (avgPt_coords[i,1]-avgPt_plotLongMax,avgPt_coords[i,1]+avgPt_plotLongMax) ); #create a temporary range for this plot
    
        #plot help with autotick calculating - for this custom range
        plotLongRange_autoTick = (np.max(avgPt_plotLongRange) - np.min(avgPt_plotLongRange))/25; #tries to split the longitude range into 25 parts (based off of 360/15+1)
        if( plotLongRange_autoTick > 10 ):
            plotLongRange_autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
        elif( plotLongRange_autoTick > 5 ):
            plotLongRange_autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
        elif( plotLongRange_autoTick > 2 ):
            plotLongRange_autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
        elif( plotLongRange_autoTick > 1 ):
            plotLongRange_autoTick = 2; #sets the tick setting to 5 arcdegrees per tick
        elif( plotLongRange_autoTick >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
            plotLongRange_autoTick = 1; #sets the tick setting to 1 arcdegree per tick
        else:
    #        plotLongRange_autoTick = (np.max(avgPt_plotLongRange) - np.min(avgPt_plotLongRange))/15; #just goes for it if it's a super tiny range
            plotLongRange_autoTick = 1; #sets the tick setting to 1 arcdegree per tick
        #END IF
        plotLatRange_autoTick = (np.max(avgPt_plotLatRange) - np.min(avgPt_plotLatRange))/13; #tries to split the latitude range into 13 parts (based off of 180/15+1)
        if( plotLatRange_autoTick > 10 ):
            plotLatRange_autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
        elif( plotLatRange_autoTick > 5 ):
            plotLatRange_autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
        elif( plotLatRange_autoTick > 2 ):
            plotLatRange_autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
        elif( plotLatRange_autoTick > 1 ):
            plotLatRange_autoTick = 2; #sets the tick setting to 2 arcdegrees per tick
        elif( plotLatRange_autoTick > 0.75 ): #0.75 because 10/13 = 0.76something and it sounded good for enough 1 arcdeg ticks
            plotLatRange_autoTick = 1; #sets the tick setting to 1 arcdegree per tick
        else:
    #        plotLatRange_autoTick = (np.max(avgPt_plotLatRange) - np.min(avgPt_plotLatRange))/15; #just goes for it if it's a super tiny range
            plotLatRange_autoTick = 1; #sets the tick setting to 1 arcdegree per tick
        #END IF
        
        #mill for square Mercator style
        #robin for oval shape
        #mill forced here since it will always be a non-global plot
        geoMap = Basemap(projection='mill', lat_0=np.mean(avgPt_plotLatRange), lon_0=np.mean(avgPt_plotLongRange), #projection type, and I think lat_0/lon_0 are the centers?
            resolution = 'i', area_thresh = 10000, ax=ax, #resolutions I know are l, i, h - i seems good. area_thresh being big prevents it drawing lil lakes, 0.1 makes everything
            llcrnrlon=np.float32(avgPt_plotLongRange[0]), llcrnrlat=np.float32(avgPt_plotLatRange[0]), #lower left corner lat/long - MUST BE FLOAT cause CODED BY THE BEST
            urcrnrlon=np.float32(avgPt_plotLongRange[1]), urcrnrlat=np.float32(avgPt_plotLatRange[1])); #upper right corner lat/long - MUST BE FLOAT cause CODED BY THE BEST
        
        geoMap.drawcoastlines();
        #map.drawcountries()
        #map.fillcontinents(color='coral')
        #map.drawmapboundary()
        
        #Remove the aspect ratio from the basemap so it fills the screen better
        ax.set_aspect('auto');
        
        #np.linspace(startlat,endlat,5) # 5 = number of "ticks"
        geoMap.drawmeridians( np.round(np.arange(np.floor(np.min(avgPt_plotLongRange)),np.ceil(np.max(avgPt_plotLongRange))+1,plotLongRange_autoTick),2), 
            labels=[True,False,False,True], labelstyle='+/-', dashes=[6,15000], color='w' ); #adds the labels but keeps the lines invisible
        geoMap.drawparallels(np.round(np.arange(np.floor(np.min(avgPt_plotLatRange)),np.ceil(np.max(avgPt_plotLatRange))+1,plotLatRange_autoTick),2), 
            labels=[True,False,True,False], labelstyle='+/-', dashes=[6,15000], color='w' ); #adds the labels but keeps the lines invisible
        #dashes[6,15000] seems to be enough to keep the repeating dash from happening on a world plot (I think it's how wide a dash is and the dash spacing). 900 was good for 22 degc longitude, for ref.
        #labels=[left,right,top,bottom] is the order. true/false to turn them on and off. not sure why there's a top/bottom for the parallels but w/e people do it
        
        #xticks( np.round(np.arange(np.floor(np.min(avgPt_plotLongRange)),np.ceil(np.max(avgPt_plotLongRange))+1,plotLongRange_autoTick),2) ); #creates x ticks automagically
        #yticks( np.round(np.arange(np.floor(np.min(avgPt_plotLatRange)),np.ceil(np.max(avgPt_plotLatRange))+1,plotLatRange_autoTick),2) ); #creates y ticks automagically
        klatlongtimelim = (data['TEC']['lat'] <= np.max(avgPt_plotLatRange)) & (data['TEC']['lat'] >= np.min(avgPt_plotLatRange)) & (data['TEC']['long'] <= np.max(avgPt_plotLongRange)) & (data['TEC']['long'] >= np.min(avgPt_plotLongRange)); #only bother plotting stuff that'll show up
        klatlongtimelim = klatlongtimelim & (data['TEC']['time'] == data['TEC']['time'][np.where(klatlongtimelim==1)[0][0]]); #limit some more, to get a time when there's data (in case there might not be at index 0 or something)
        TEC_timeTemp = data['TEC']['time'][klatlongtimelim]; #get the temp time
        TEC_dTECTemp = data['TEC']['dTEC'][klatlongtimelim]; #get the temp time
        TEC_latTemp = data['TEC']['lat'][klatlongtimelim]; #get the temp time
        TEC_longTemp = data['TEC']['long'][klatlongtimelim]; #get the temp time
        k = np.where( TEC_timeTemp == TEC_timeTemp[0])[0]; #gets during a time period
        TEC_latLongMapped = geoMap(TEC_longTemp[k],TEC_latTemp[k]); #convert the lat/long arcdeg to the current map coordinates
        
        im = ax.scatter(TEC_latLongMapped[0],TEC_latLongMapped[1],s=20,c=TEC_dTECTemp[k],cmap='jet', vmin=np.min(settings_TEC['plot lim']), vmax=np.max(settings_TEC['plot lim']));
        cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
        cax.yaxis.set_ticks(np.linspace(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim']),5)); #create useful tick marks
        cax.yaxis.set_major_formatter(FormatStrFormatter('%.2f')); #force a rounded format
        cbar.set_label("delta-vTEC [TECU]"); #tabel the colorbar
        cbar.ax.tick_params(labelsize=FONT_axisTick) 
        cbar.mappable.set_clim(vmin=np.min(settings_TEC['plot lim']), vmax=np.max(settings_TEC['plot lim']))
        cax.yaxis.label.set_font_properties(FONT_axisLabelFM)
        string_title = 'Radius of '+str(avgPt_pointRadius)+' km around '+avgPt_coordsName[i];
        ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
        
        #draw a circle where the data will be averaged
        temp_mapCoords = geoMap( pointRadiusAngular*np.cos(np.arange(0,2*np.pi+np.pi/50,np.pi/50)) + avgPt_coords[i,1], pointRadiusAngular*np.sin(np.arange(0,2*np.pi+np.pi/50,np.pi/50)) + avgPt_coords[i,0] ); #convert to the geographic map coords
        ax.plot( temp_mapCoords[0],  #X longitude arcdeg
            temp_mapCoords[1],  #Y latitude arcdeg
            c=gif_Millstone_Marker_Color,linewidth=4);
                
        #plot a * where the averaging center is
        temp_mapCoords = geoMap(avgPt_coords[i,1],avgPt_coords[i,0]); #convert the lat/long arcdeg to the current map coordinates
        ax.plot(temp_mapCoords[0],temp_mapCoords[1],marker=gif_Millstone_Marker, color='xkcd:red orange', markersize=gif_Millstone_Marker_Size, zorder=50);
           
        figFitter(fig); #fit that fig fast
    #END FOR i
    
    
    #=======================NOW ACTUALLY CALC THE STUFF===========================
    
#    k = zeros(size(pplat)); #preallocate this
#    tempRadius = zeros(size(latPoints,2),length(pplat)); #record the radius calc'd
#    tempRadius(gg,:) = sqrt((pplat - latPoints(gg)).^2 + (pplong - longPoints(gg)).^2); #record the radius calc'd b/c why not save calc's
#    k = k | (pointRadiusAngular > tempRadius(gg,:));
    #END FOR i
    avgPt_vTEC, avgPt_vTEC_HP, avgPt_vTEC_time, _, _, _ = GRITI_TEC_avgPt(TEC_timeUnique,data['TEC']['lat'],data['TEC']['long'],data['TEC']['time'],data['TEC']['dTEC'], \
        avgPt_coords[0,:],avgPt_pointRadius,Re,dateRange_dayNum_zeroHr, \
        dataReject,dataRejectOrig,dataRejectLimit,dataRejectLimitOrig,dataRejectMax,FLG_report=1); #average points in a radius
        
    avgPt_vTEC_MISA, avgPt_vTEC_HP_MISA, avgPt_vTEC_time_MISA, _, _, _  = GRITI_TEC_avgPt(TEC_timeUnique,data['TEC']['lat'],data['TEC']['long'],data['TEC']['time'],data['TEC']['dTEC'], \
        avgPt_coords[1,:],avgPt_pointRadius,Re,dateRange_dayNum_zeroHr, \
        dataReject,dataRejectOrig,dataRejectLimit,dataRejectLimitOrig,dataRejectMax,FLG_report=1); #average points in a radius
    
    # import warnings
#     warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    # k = pointRadiusAngular**2 >= ((data['TEC']['lat'] - avgPt_coords[0])**2 + (data['TEC']['long'] - avgPt_coords[1])**2); #get all of the data pts within the radius
    # tempTime = data['TEC']['time'][k];
    # tempTEC = data['TEC']['dTEC'][k];
    
    # avgPt_vTEC = np.zeros( (TEC_timeUnique.size)); #preallocate
    # for t in range(0,TEC_timeUnique.size):
        
    #     j = tempTime == TEC_timeUnique[t]; #find the time that connect to the time we are at
        
    #     tempTempTEC = tempTEC[j]; #get the delta-vTEC involved, do some filtering
    #     if( tempTempTEC.size > 1 ):
    #         tempMean = np.mean( tempTempTEC ); #get the mean
            
    #         tempVar = np.var( tempTempTEC, ddof=1 ); #get variance, ddof=1 to reduce bias (matlab does automatically)
            
    #         #loop to prevent too much data being nixed
    #         while( (tempTempTEC.size - np.sum(((tempMean+dataReject*tempVar) > tempTempTEC) & ((tempMean-dataReject*tempVar) < tempTempTEC) ) )*100/tempTempTEC.size > dataRejectLimit ):
    #             dataReject = dataReject*1.05; #increase the data rejection ratio to include more data
    #             if( dataReject > dataRejectMax ):
    #                 dataRejectLimit = 100; #if this goes on for a bit then it is halted with this manuever
    #             #END IF
    # #             (length(tempTempTEC) - sum(((tempMean+dataReject*tempVar) > tempTempTEC) & ((tempMean-dataReject*tempVar) < tempTempTEC) ) )*100/length(tempTempTEC)
    # #             dataReject
    # #             dataRejectLimit
    #         #END WHILE
            
    #         if( dataReject <= dataRejectMax ): #if this occured leave the data, it is too sparse or too varied to deal with effectively
    #             tempTempTEC = tempTempTEC[ ((tempMean+dataReject*tempVar) > tempTempTEC) & ((tempMean-dataReject*tempVar) < tempTempTEC) ]; #delete some extraneous data
    #             #this is normal operation
    #         #END IF
            
    #         dataReject = dataRejectOrig; #reset dataReject
    #         dataRejectLimit = dataRejectLimitOrig; #reset dataRejectLimit
            
    #         avgPt_vTEC[t] = np.mean(tempTempTEC); #TECU, average of the delta-vTEC points in that radius at the same time into one value
    #     else:
    #         avgPt_vTEC[t] = np.nan; #
    #     #END IF
    # #END FOR t
    # warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
#     #now, make optional dataset that has the NaNs interpolated over
#     jk = np.where( np.isnan(avgPt_vTEC) == 1)[0]; #find NaNs existing
#     jl = np.where( np.isnan(avgPt_vTEC) != 1)[0]; #find NaNs not existing
#     #interped data unused since spectrum analysis done using Lomb-Scargle approach which doens't require consistent timing intervals
# #    avgPt_vTEC_interped = avgPt_vTEC; #save the O.G. data
# #    avgPt_vTEC_interped[jk] = np.interp(jk,jl,avgPt_vTEC[jl]); #fill in the gaps with the spline fill in
#     print('\navgPt_vTEC Calcs:\nAt lat '+str(np.round(avgPt_coords[0,0],3))+' deg/long '+str(np.round(avgPt_coords[0,1],3))+' deg w/ '+str(avgPt_pointRadius)+' km radius, '+str(np.round(jk.size/avgPt_vTEC.size*100,3))+'% of data was NaN and interpolated over.'); #report % data filled in
    
#     #purge NANs from avgPt_vTEC so it can be scargled w/o issue, also make a time var for it
#     avgPt_vTEC = avgPt_vTEC[jl]; #get rid of the NaNs
#     avgPt_vTEC_time = TEC_timeUnique[jl]; #get the times that correspond
    
#     avgPt_vTEC_HP = subfun_highpass( (avgPt_vTEC_time-dateRange_dayNum_zeroHr[1]*86400)/3600 , avgPt_vTEC); #highpass that data to boot
#END IF
    
    
#==============Analysis: Time match the point-avg'd data to the ISR and then high-pass it, also average the ISR data in altitude==============
if( FLG_avgPt_timeMatch == 1 ):
    #Match the data in the 1st input (and its time in the 2nd input) to the time scale given in the 3rd input time and return that data and that data's highpassed form
    avgPt_vTEC_timeMatch, avgPt_vTEC_timeMatch_HP, avgPt_vTEC_timeMatch_time = GRITI_TEC_avgPt_timeMatch(avgPt_vTEC,avgPt_vTEC_time,Zenith_time,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
    
    #now MISA
    avgPt_vTEC_timeMatch_MISA, avgPt_vTEC_timeMatch_HP_MISA, avgPt_vTEC_timeMatch_time_MISA = GRITI_TEC_avgPt_timeMatch(avgPt_vTEC_MISA,avgPt_vTEC_time_MISA,MISA_time,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
    
    #Now for the ISR stuff    
    Zenith_height_atISRavgAlt = np.where( np.min(np.abs( Zenith_height - pointAltitude )) == np.abs( Zenith_height - pointAltitude ) )[0][0]; #get the index of where Zenith_height is closest to pointAltitude (in km)
    Zenith_height_atISRavgAltIndexes = np.array( ( np.where(np.min(np.abs( (Zenith_height[Zenith_height_atISRavgAlt]-avgPt_ISRavgAlt) - Zenith_height)) == np.abs(Zenith_height[Zenith_height_atISRavgAlt]-avgPt_ISRavgAlt - Zenith_height) )[0][0] , \
                                    np.where(np.min(np.abs( (Zenith_height[Zenith_height_atISRavgAlt]+avgPt_ISRavgAlt) - Zenith_height)) == np.abs(Zenith_height[Zenith_height_atISRavgAlt]+avgPt_ISRavgAlt - Zenith_height) )[0][0] ) ); #get the upper and lower indexes of height to average (+/- avgPt_ISRavgAlt in km)
    Zenith_SNR_hp_altAvgd = np.mean( Zenith_SNR_hp[Zenith_height_atISRavgAltIndexes[0]:Zenith_height_atISRavgAltIndexes[1]+1,:] , axis=0 ); #average +/- avgPt_ISRavgAlt in km around the center altitude pointAltitude in km
    Zenith_POPL_hp_altAvgd = np.mean( Zenith_POPL_hp[Zenith_height_atISRavgAltIndexes[0]:Zenith_height_atISRavgAltIndexes[1]+1,:] , axis=0 ); #average +/- avgPt_ISRavgAlt in km around the center altitude pointAltitude in km
    
    MISA_height_atISRavgAlt = np.where( np.min(np.abs( MISA_height - pointAltitude )) == np.abs( MISA_height - pointAltitude ) )[0][0]; #get the index of where MISA_height is closest to pointAltitude (in km)
    MISA_height_atISRavgAltIndexes = np.array( ( np.where(np.min(np.abs( (MISA_height[MISA_height_atISRavgAlt]-avgPt_ISRavgAlt) - MISA_height)) == np.abs(MISA_height[MISA_height_atISRavgAlt]-avgPt_ISRavgAlt - MISA_height) )[0][0] , 
                                    np.where(np.min(np.abs( (MISA_height[MISA_height_atISRavgAlt]+avgPt_ISRavgAlt) - MISA_height)) == np.abs(MISA_height[MISA_height_atISRavgAlt]+avgPt_ISRavgAlt - MISA_height) )[0][0] ) ); #get the upper and lower indexes of height to average (+/- avgPt_ISRavgAlt in km)
    MISA_SNR_hp_altAvgd = np.mean( MISA_SNR_hp[MISA_height_atISRavgAltIndexes[0]:MISA_height_atISRavgAltIndexes[1]+1,:] , axis=0 ); #average +/- avgPt_ISRavgAlt in km around the center altitude pointAltitude in km
    MISA_POPL_hp_altAvgd = np.mean( MISA_POPL_hp[MISA_height_atISRavgAltIndexes[0]:MISA_height_atISRavgAltIndexes[1]+1,:] , axis=0 ); #average +/- avgPt_ISRavgAlt in km around the center altitude pointAltitude in km
    
    
    if( (FLG_avgPt_HP_timeMatch_POPLnOMNI_CPSD_cutOut == 1) | (FLG_avgPt_HP_timeMatch_POPLnOMNInTECNOISE_CPSD_cutOut == 1) | (FLG_avgPt_HP_timeMatch_POPLnOMNI_FFT_cutOut == 1) ): #now OMNI, if it being used       
        from scipy.interpolate import interp1d    
    
        #now OMNI on Zenith time
        OMNI_data_timeMatch_Zenith, OMNI_data_timeMatch_HP_Zenith, OMNI_data_timeMatch_time_Zenith = GRITI_TEC_avgPt_timeMatch(OMNI_data[:,OMNI_dict[OMNI_plot_name]],OMNI_timeUnique,Zenith_time+OMNI_delay_wrt_TEC/24,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
        
        #fix possible data-gaps
        if( Zenith_time.size != OMNI_data_timeMatch_time_Zenith.size ):
            Zenith_time_delay = Zenith_time+OMNI_delay_wrt_TEC/24; #get a temporary adjusted time reference
            interpFun = interp1d(OMNI_data_timeMatch_time_Zenith, OMNI_data_timeMatch_HP_Zenith, kind='linear', fill_value='extrapolate'); #get an interpolation function
            _, indx, _ = np.intersect1d(Zenith_time_delay, OMNI_data_timeMatch_time_Zenith,assume_unique=True, return_indices=True); #get where they intersect
            temp = np.nan*np.ones(Zenith_time.shape); #prep a full-size variable, set all to NaN
            temp[indx] = OMNI_data_timeMatch_HP_Zenith; #set the non-NaN values to their non-NaN values
            OMNI_data_timeMatch_HP_Zenith = temp; #overwrite with full-size temp
            jk = np.isnan(OMNI_data_timeMatch_HP_Zenith); #get the NaN locations
            OMNI_data_timeMatch_HP_Zenith[jk] = interpFun(Zenith_time_delay[jk]); #only interpolate at the points that were NaNs
            OMNI_data_timeMatch_time_Zenith = Zenith_time_delay; #overwrite
        #END IF
        
        #now OMNI on MISA time
        OMNI_data_timeMatch_MISA, OMNI_data_timeMatch_HP_MISA, OMNI_data_timeMatch_time_MISA = GRITI_TEC_avgPt_timeMatch(OMNI_data[:,OMNI_dict[OMNI_plot_name]],OMNI_timeUnique,MISA_time+OMNI_delay_wrt_TEC/24,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
    
        #fix possible data-gaps
        if( MISA_time.size != OMNI_data_timeMatch_time_MISA.size ):
            MISA_time_delay = MISA_time+OMNI_delay_wrt_TEC/24; #get a temporary adjusted time reference
            interpFun = interp1d(OMNI_data_timeMatch_time_MISA, OMNI_data_timeMatch_HP_MISA, kind='linear', fill_value='extrapolate'); #get an interpolation function
            _, indx, _ = np.intersect1d(MISA_time_delay, OMNI_data_timeMatch_time_MISA,assume_unique=True, return_indices=True); #get where they intersect
            temp = np.nan*np.ones(MISA_time.shape); #prep a full-size variable, set all to NaN
            temp[indx] = OMNI_data_timeMatch_HP_MISA; #set the non-NaN values to their non-NaN values
            OMNI_data_timeMatch_HP_MISA = temp; #overwrite with full-size temp
            jk = np.isnan(OMNI_data_timeMatch_HP_MISA); #get the NaN locations
            OMNI_data_timeMatch_HP_MISA[jk] = interpFun(MISA_time_delay[jk]); #only interpolate at the points that were NaNs
            OMNI_data_timeMatch_time_MISA = MISA_time_delay; #overwrite
        #END IF
    #END IF
#END IF
    
#==============Analysis: Plot the delta-vTEC point-averaged time series with the ISR SNR HP altitude-averaged time series, along with an ISR RTI plot, over a cut-out time period==============
if( FLG_avgPt_HP_timeMatch_plotWithISR_cutOut == 1 ):
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_SNR_hp_cutOut = Zenith_SNR_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_SNR_hp_altAvgd_cutOut = Zenith_SNR_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range

    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_SNR_hp_cutOut = MISA_SNR_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_SNR_hp_altAvgd_cutOut = MISA_SNR_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    GRITI_TEC_avgPt_HP_timeMatch_plotWithISR_cutOut(avgPt_vTEC_timeMatch_HP_cutOut,avgPt_vTEC_timeMatch_time_cutOut,Zenith_time_cutOut,Zenith_height,Zenith_SNR_hp_cutOut,Zenith_SNR_hp_altAvgd_cutOut,MISA_time_cutOut,MISA_height,MISA_SNR_hp_cutOut,MISA_SNR_hp_altAvgd_cutOut,settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_plotLimValu,avgPt_coords[0,:],avgPt_ISRavgAlt,pointAltitude,time_cutout_range,dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,PLOT_lineWidth);  
    
#END IF
    

#==============Analysis: Plot the delta-vTEC point-averaged time series with the ISR POPL HP altitude-averaged time series, along with an ISR RTI plot, over a cut-out time period==============
if( FLG_avgPt_HP_timeMatch_POPL_plotWithISR_cutOut == 1 ):
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range

    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    GRITI_TEC_avgPt_HP_timeMatch_POPL_plotWithISR_cutOut(avgPt_vTEC_timeMatch_HP_cutOut,avgPt_vTEC_timeMatch_time_cutOut,Zenith_time_cutOut,Zenith_height,Zenith_POPL_hp_cutOut,Zenith_POPL_hp_altAvgd_cutOut,MISA_time_cutOut,MISA_height,MISA_POPL_hp_cutOut,MISA_POPL_hp_altAvgd_cutOut,settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_POPL_plotLimValu,avgPt_coords[0,:],avgPt_ISRavgAlt,pointAltitude,time_cutout_range,dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,PLOT_lineWidth);
#END IF

#==============Analysis: Plot the delta-vTEC point-averaged time series with the ISR POPL HP altitude-averaged time series, along with an ISR RTI plot, over a cut-out time period==============
if( (FLG_avgPt_HP_timeMatch_POPL_plotWithISR_cutOut == 1) & (FLG_fancyPlot == 1) ):
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    # time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
    #     np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( MISA_time - np.min(Zenith_time_cutOut) )) == np.abs( MISA_time - np.min(Zenith_time_cutOut) ) )[0][0] , \
        np.where(np.min(np.abs( MISA_time - np.max(Zenith_time_cutOut) )) == np.abs( MISA_time - np.max(Zenith_time_cutOut) ) )[0][0] ) ); #get the indexes for that time cutout range
        #this makes the MISA match the Zenith plot when cut to the same axis limits as Zenith
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]-1:time_cutout_indexes[1]+1+1]; #EXTRA down 1 up 1 to adjust for Zenith/MISA time mismatches
    MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]-1:time_cutout_indexes[1]+1+1]; #EXTRA down 1 up 1 to adjust for Zenith/MISA time mismatches
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]-1:time_cutout_indexes[1]+1+1]; #EXTRA down 1 up 1 to adjust for Zenith/MISA time mismatches
    
    GRITI_TEC_avgPt_HP_timeMatch_POPL_fancyPlot_plotWithISR_cutOut(avgPt_vTEC_timeMatch_HP_cutOut,avgPt_vTEC_timeMatch_time_cutOut, \
        Zenith_time_cutOut,Zenith_height,Zenith_POPL_hp_cutOut,Zenith_POPL_hp_altAvgd_cutOut,MISA_time_cutOut,MISA_height, \
        MISA_POPL_hp_cutOut,MISA_POPL_hp_altAvgd_cutOut,settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_POPL_plotLimValu, \
        avgPt_coords,avgPt_ISRavgAlt,pointAltitude,time_cutout_range,dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,
        dateRange_zeroHr, dateRange_zeroHr_monthName, dateRange_zeroHr_dayPostfix, \
        FONT_grandioseFM, FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,PLOT_lineWidth, folder, journal_width_2C,journal_height_max,journal_dpi);
#END IF
    

#==============Analysis: Plot the delta-vTEC point-averaged time series with the ISR SNR HP altitude-averaged time series, along with an ISR RTI plot, over a cut-out time period==============
if( FLG_avgPt_HP_timeMatch_plotWithISR_ZenithOnly_cutOut == 1 ):
    #ZENITH ONLY - NO MISA!!!
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_SNR_hp_cutOut = Zenith_SNR_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_SNR_hp_altAvgd_cutOut = Zenith_SNR_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range

    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_SNR_hp_altAvgd_cutOut = MISA_SNR_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    GRITI_TEC_avgPt_HP_timeMatch_plotWithISR_ZenithOnly_cutOut(avgPt_vTEC_timeMatch_HP_cutOut,avgPt_vTEC_timeMatch_time_cutOut,Zenith_time_cutOut,Zenith_height,Zenith_SNR_hp_cutOut,Zenith_SNR_hp_altAvgd_cutOut,MISA_time_cutOut,MISA_height,MISA_SNR_hp_altAvgd_cutOut,settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_plotLimValu,avgPt_coords[0,:],avgPt_ISRavgAlt,pointAltitude,time_cutout_range,dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,PLOT_lineWidth);  
    
#END IF
    

#==============Analysis: Plot the delta-vTEC point-averaged time series with the ISR POPL HP altitude-averaged time series, along with an ISR RTI plot, over a cut-out time period==============
if( FLG_avgPt_HP_timeMatch_POPL_plotWithISR_ZenithOnly_cutOut == 1 ):
    #ZENITH ONLY - NO MISA!!!
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range

    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    GRITI_TEC_avgPt_HP_timeMatch_POPL_plotWithISR_ZenithOnly_cutOut(avgPt_vTEC_timeMatch_HP_cutOut,avgPt_vTEC_timeMatch_time_cutOut,Zenith_time_cutOut,Zenith_height,Zenith_POPL_hp_cutOut,Zenith_POPL_hp_altAvgd_cutOut,MISA_time_cutOut,MISA_height,MISA_POPL_hp_altAvgd_cutOut,settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_POPL_plotLimValu,avgPt_coords[0,:],avgPt_ISRavgAlt,pointAltitude,time_cutout_range,dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,PLOT_lineWidth);
    
#END IF
    
    
if( FLG_avgPt_HP_timeMatch_scargleWithISR_cutOut == 1 ):
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_SNR_hp_cutOut = Zenith_SNR_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_SNR_hp_altAvgd_cutOut = Zenith_SNR_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range

    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_SNR_hp_altAvgd_cutOut = MISA_SNR_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    GRITI_TEC_avgPt_HP_timeMatch_scargleWithISR_cutOut(avgPt_vTEC_timeMatch_HP_cutOut,avgPt_vTEC_timeMatch_time_cutOut,Zenith_time_cutOut,Zenith_SNR_hp_altAvgd_cutOut,MISA_time_cutOut,MISA_SNR_hp_altAvgd_cutOut,pointAltitude,avgPt_ISRavgAlt,time_cutout_range,settings_spectra['filter cutoff period'],avgPt_pointRadius,plot_periodLim_max,dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,PLOT_lineWidth);
    
#END IF
    
if( FLG_avgPt_HP_timeMatch_POPL_scargleWithISR_cutOut == 1 ):
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range

    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];

    GRITI_TEC_avgPt_HP_timeMatch_POPL_scargleWithISR_cutOut(avgPt_vTEC_timeMatch_HP_cutOut,avgPt_vTEC_timeMatch_time_cutOut,Zenith_time_cutOut,Zenith_POPL_hp_altAvgd_cutOut,MISA_time_cutOut,MISA_POPL_hp_altAvgd_cutOut,pointAltitude,avgPt_ISRavgAlt,time_cutout_range,settings_spectra['filter cutoff period'],avgPt_pointRadius,plot_periodLim_max,dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,PLOT_lineWidth);
#END IF

if( FLG_avgPt_HP_timeMatch_POPLnOMNI_scargleORfft_cutOut == 1 ):
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    Zenith_time_delta = np.median(np.diff(Zenith_time)); #days, delta of time between readings
    MISA_time_delta = np.median(np.diff(MISA_time)); #days, delta of time between readings
    # Zenith_time_delta = np.median(np.diff(Zenith_time)); #days, delta of time between readings
    # MISA_time_delta = np.median(np.diff(MISA_time)); #days, delta of time between readings
#    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
#        np.where(np.min(np.abs( (avgPt_vTEC_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
#    
#    avgPt_vTEC_HP_cutOut = avgPt_vTEC_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
#    avgPt_vTEC_time_cutOut = avgPt_vTEC_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #MISA NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut_MISA = avgPt_vTEC_timeMatch_HP_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut_MISA = avgPt_vTEC_timeMatch_time_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
            
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , 
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                             
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #OMNI plot prep
    OMNI_plot_label = OMNI_dictPlot[OMNI_dict[OMNI_plot_name]]; #get the label
    OMNI_plot_labelNoUnits = OMNI_plot_label[0:OMNI_plot_label.find('[')-1]; #remove the (units)
    
    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) ) )[0][0] , \
        np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    OMNI_data_timeMatch_HP_Zenith_cutOut = OMNI_data_timeMatch_HP_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    OMNI_data_timeMatch_time_Zenith_cutOut = OMNI_data_timeMatch_time_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #NON-TIME MATCH!
#    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed) )) == np.abs( (OMNI_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed) ) )[0][0] , \
#        np.where(np.min(np.abs( (OMNI_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed) )) == np.abs( (OMNI_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed) ) )[0][0] ) ); #get the indexes for that time cutout range
#    
#    OMNI_data_hp = subfun_highpass((OMNI_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600,OMNI_data[:,OMNI_plot_index],filter_cutoffPeriod=settings_spectra['filter cutoff period']); #high-pass that data
#    
#    OMNI_data_hp_cutOut = OMNI_data_hp[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
#    OMNI_data_time_cutOut = OMNI_timeUnique[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #MISA NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) ) )[0][0] , \
        np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    OMNI_data_timeMatch_HP_MISA_cutOut = OMNI_data_timeMatch_HP_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    OMNI_data_timeMatch_time_MISA_cutOut = OMNI_data_timeMatch_time_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    window = np.hamming(110);
    nooverlap = 100
    nfft = 512
    Fs_Z = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    Fs_M = 1/(MISA_time_delta*24*60); #min, MISA time delta in freq form
    Fs_OMNI = 1/(np.median(np.diff(OMNI_timeUnique))*24*60); #min, OMNI time delta in freq form
    
    from scipy import signal
    
    pwr_TEC_Z = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut**2)); #estimate power of signal
    pwr_Z = np.sqrt(1/Zenith_POPL_hp_altAvgd_cutOut.size*np.sum(Zenith_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_M = np.sqrt(1/MISA_POPL_hp_altAvgd_cutOut.size*np.sum(MISA_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_OMNI_Z = np.sqrt(1/OMNI_data_timeMatch_HP_Zenith_cutOut.size*np.sum(OMNI_data_timeMatch_HP_Zenith_cutOut**2)); #estimate power of signal    
#    pwr_OMNI = np.sqrt(1/OMNI_data_hp_cutOut.size*np.sum(OMNI_data_hp_cutOut**2)); #estimate power of signal   
#    pwr_TEC_nomatch = np.sqrt(1/avgPt_vTEC_HP_cutOut.size*np.sum(avgPt_vTEC_HP_cutOut**2)); #estimate power of signal
    
    [freqs_TEC_Z,Cxx_TEC_Z] = signal.welch(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut ,window=window,noverlap=nooverlap,nfft=nfft,fs=Fs_Z);
#    window2 = np.hamming(np.int64(110*5.5));
#    nooverlap2 = np.int64(100*5.5);
#    nfft2 = 512*4;
#    [freqs_TEC_Z,Cxx_TEC_Z] = signal.welch(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut ,window=window,noverlap=nooverlap,nfft=nfft,fs=Fs_Z);
    [freqs_Z,Cxx_Z] = signal.welch(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut ,window=window,noverlap=nooverlap,nfft=nfft,fs=Fs_Z);
    [freqs_M,Cxx_M] = signal.welch(1/pwr_M*MISA_POPL_hp_altAvgd_cutOut ,window=window,noverlap=nooverlap,nfft=nfft,fs=Fs_M);
    [freqs_OMNI_Z,Cxx_OMNI_Z] = signal.welch(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut ,window=window,noverlap=nooverlap,nfft=nfft,fs=Fs_Z);
#    window2 = np.hamming(np.int64(110*5.5));
#    nooverlap2 = np.int64(100*5.5);
#    nfft2 = 512*4;
#    [freqs_OMNI_Z,Cxx_OMNI_Z] = signal.welch(1/pwr_OMNI*OMNI_data_hp_cutOut ,window=window2,noverlap=nooverlap2,nfft=nfft2,fs=Fs_OMNI);
    
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    p1, = ax.plot(1/freqs_TEC_Z,Cxx_TEC_Z,color='xkcd:cerulean',linewidth=1.5, linestyle='-');
    p2, = ax.plot(1/freqs_Z,Cxx_Z,color='xkcd:deep red',linewidth=1.5, linestyle='--');
    p3, = ax.plot(1/freqs_M,Cxx_M,color='xkcd:goldenrod',linewidth=1.5, linestyle='-.');
    p4, = ax.plot(1/freqs_OMNI_Z,Cxx_OMNI_Z,color='xkcd:purple',linewidth=1.5, linestyle=':');
#    p4, = ax.plot(1/freqs_OMNI_Z,Cxx_OMNI_Z*OMNI_data_hp_cutOut.size/avgPt_vTEC_timeMatch_HP_cutOut.size,color='xkcd:purple',linewidth=1.5, linestyle=':');
    ax.set_xlim( (0, plot_periodLim_max) )
    ax.set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    ax.set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
    ax.set_title('Power Spectra - (TEC HP\'d) Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs at Millstone '+str(np.round(latMillstone,2))+' degc lat/'+str(np.round(longMillstone,2))+' deg long on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
        fontproperties=FONT_titleFM);
    ax.legend([p1,p2,p3,p4],['Point TEC AVG\'d to Zenith Times & HP', \
        'Zenith HP AVG\'d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        'MISA HP AVG\'d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        'OMNI '+OMNI_plot_labelNoUnits+' AVG\'d to Zenith Times & HP (Time Delayed '+str(OMNI_delay_wrt_TEC)+' hrs)'], \
        loc='upper left');
    
    xAxisTicks = np.arange( 0, plot_periodLim_max+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.065, right = 0.975, top = 0.96, bottom = 0.065 , hspace = 0.225); #sets padding to small numbers for minimal white space
    
    
    TEC_scargPeriod, TEC_scargPower, TEC_scarggf = subfun_lombscargle((avgPt_vTEC_timeMatch_time_cutOut - dateRange_dayNum_zeroHr[1]*86400)/3600*60 , 1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut); #scargle that data
#    TEC_scargPeriod, TEC_scargPower, TEC_scarggf = subfun_lombscargle((avgPt_vTEC_time_cutOut - dateRange_dayNum_zeroHr[1]*86400)/3600*60 , 1/pwr_TEC_nomatch*avgPt_vTEC_HP_cutOut); #scargle that data
    Zenith_scargPeriod, Zenith_scargPower, Zenith_scarggf = subfun_lombscargle((Zenith_time_cutOut - dateRange_dayNum_zeroHr[1]*86400)/3600*60 , 1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut); #scargle that data
    MISA_scargPeriod, MISA_scargPower, MISA_scarggf = subfun_lombscargle((MISA_time_cutOut - dateRange_dayNum_zeroHr[1]*86400)/3600*60 , 1/pwr_M*MISA_POPL_hp_altAvgd_cutOut); #scargle that data
    OMNI_scargPeriod, OMNI_scargPower, OMNI_scarggf = subfun_lombscargle((OMNI_data_timeMatch_time_Zenith_cutOut - dateRange_dayNum_zeroHr[1]*86400)/3600*60 , 1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut); #scargle that data
#    OMNI_scargPeriod, OMNI_scargPower, OMNI_scarggf = subfun_lombscargle((OMNI_data_time_cutOut - dateRange_dayNum_zeroHr[1]*86400)/3600*60 , 1/pwr_OMNI*OMNI_data_hp_cutOut); #scargle that data
    
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    p1, = ax.plot(TEC_scargPeriod,TEC_scargPower,color='xkcd:cerulean',linewidth=PLOT_lineWidthRegular, linestyle='-');
    ax.plot( TEC_scargPeriod, np.tile(TEC_scarggf,np.size(TEC_scargPeriod)) , color="xkcd:grey",linewidth=PLOT_lineWidthRegular, linestyle='-' ); #plot
    p2, = ax.plot(Zenith_scargPeriod,Zenith_scargPower,color='xkcd:deep red',linewidth=PLOT_lineWidthRegular, linestyle='--');
#    ax.plot( Zenith_scargPeriod, np.tile(Zenith_scarggf,np.size(Zenith_scargPeriod)) , color="xkcd:grey",linewidth=1.5, linestyle='--' ); #plot
    p3, = ax.plot(MISA_scargPeriod,MISA_scargPower,color='xkcd:goldenrod',linewidth=PLOT_lineWidthRegular, linestyle='-.');
#    ax.plot( MISA_scargPeriod, np.tile(MISA_scarggf,np.size(MISA_scargPeriod)) , color="xkcd:grey",linewidth=1.5, linestyle='-.' ); #plot
    p4, = ax.plot(OMNI_scargPeriod,OMNI_scargPower,color='xkcd:purple',linewidth=PLOT_lineWidthRegular, linestyle=':');
#    ax.plot( OMNI_scargPeriod, np.tile(OMNI_scarggf,np.size(OMNI_scargPeriod)) , color="xkcd:grey",linewidth=1.5, linestyle=':' ); #plot
    ax.set_xlim( (0, plot_periodLim_max) )
    ax.set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    ax.set_ylabel('Normalized Power',fontproperties=FONT_axisLabelFM);
    ax.set_title('Lomb-Scargle Periodogram - (TEC HP\'d) Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs at Millstone '+str(np.round(latMillstone,2))+' degc lat/'+str(np.round(longMillstone,2))+' deg long on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
        fontproperties=FONT_titleFM);
    ax.legend([p1,p2,p3,p4],['Point TEC AVG\'d to Zenith Times & HP', \
        'Zenith HP AVG\'d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        'MISA HP AVG\'d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        'OMNI '+OMNI_plot_label+' AVG\'d to Zenith Times & HP (Time Delayed '+str(OMNI_delay_wrt_TEC)+' hrs)'], \
        loc='upper left');
    
    xAxisTicks = np.arange( 0, plot_periodLim_max+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.065, right = 0.975, top = 0.96, bottom = 0.065 , hspace = 0.225); #sets padding to small numbers for minimal white space
#END IF

if( FLG_avgPt_HP_timeMatch_POPL_CPSD_cutOut == 1):
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    Zenith_time_delta = np.median(np.diff(Zenith_time)); #days, delta of time between readings
    MISA_time_delta = np.median(np.diff(MISA_time)); #days, delta of time between readings
    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #MISA NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut_MISA = avgPt_vTEC_timeMatch_HP_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut_MISA = avgPt_vTEC_timeMatch_time_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
            
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , 
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                             
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    from scipy import signal
#    from matplotlib import mlab
    window = np.hamming(110);
#    window= np.pad(window,(0,512-110),mode='constant')
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    
    pwr_TECZ = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut**2)); #estimate power of signal
    pwr_TECM = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut_MISA.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut_MISA**2)); #estimate power of signal
    pwr_Z = np.sqrt(1/Zenith_POPL_hp_altAvgd_cutOut.size*np.sum(Zenith_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_M = np.sqrt(1/MISA_POPL_hp_altAvgd_cutOut.size*np.sum(MISA_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    
    [freqs_TECvZ,Cxy_TECvZ] = signal.csd(1/pwr_TECZ*avgPt_vTEC_timeMatch_HP_cutOut,1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_TECvZ,freqs_TECvZ] = mlab.csd(avgPt_vTEC_timeMatch_HP_cutOut,Zenith_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_TECvZ,freqs_TECvZ] = cpsd(vTEC_5minInterped_Zenith(tmin_Zenith:tmax_Zenith),Zenith_SNR_threeHun_AVGD(tmin_Zenith:tmax_Zenith),[],[],512,Fs);
    Axy_TECvZ = np.angle(Cxy_TECvZ)*180/np.pi; 
    Pxy_TECvZ = np.abs(Cxy_TECvZ);
#    Pxy_TECvZ = np.abs(Cxy_TECvZ)/np.max(np.abs(Cxy_TECvZ))*0.8659;
    
#    [_,Cxx_TEC] = signal.welch(avgPt_vTEC_timeMatch_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
#    [_,Cxx_Z] = signal.welch(Zenith_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    
#    Pxy_TECvZ = Pxy_TECvZ / np.sqrt( np.abs(Cxx_TEC)*np.abs(Cxx_Z));
    
    #TEC (NO HIGH-PASS) VS MISA
    Fs = 1/(MISA_time_delta*24*60); #min, misa time delta in freq form
    [freqs_TECvM,Cxy_TECvM] = signal.csd(1/pwr_TECM*avgPt_vTEC_timeMatch_HP_cutOut_MISA,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_TECvM,freqs_TECvM] = mlab.csd(avgPt_vTEC_timeMatch_HP_cutOut_MISA,MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_TECvM,freqs_TECvM] = cpsd(vTEC_5minInterped_MISA(tmin_MISA:tmax_MISA),MISA_SNR_threeHun_AVGD(tmin_MISA:tmax_MISA),[],[],512,Fs);
    Axy_TECvM = np.angle(Cxy_TECvM)*180/np.pi; 
    Pxy_TECvM = np.abs(Cxy_TECvM);
#    Pxy_TECvM = np.abs(Cxy_TECvM)/np.max(np.abs(Cxy_TECvM))*0.6646;
    
    #ZENITH VS MISA
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_ZvM,Cxy_ZvM] = signal.csd(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_ZvM,freqs_ZvM] = mlab.csd(Zenith_POPL_hp_altAvgd_cutOut,MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_ZvM,freqs_ZvM] = cpsd(Zenith_SNR_threeHun_AVGD(tmin_Zenith:tmax_Zenith),MISA_SNR_threeHun_AVGD(tmin_MISA:tmax_MISA),[],[],512,Fs);
    Axy_ZvM = np.angle(Cxy_ZvM)*180/np.pi; 
    Pxy_ZvM = np.abs(Cxy_ZvM);
#    Pxy_ZvM = np.abs(Cxy_ZvM)/np.max(np.abs(Cxy_ZvM))*1.0758;
    
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    p1, = ax.plot(1/freqs_TECvZ,(Pxy_TECvZ),color='xkcd:cerulean',linewidth=PLOT_lineWidthRegular, linestyle='-');
    p2, = ax.plot(1/freqs_TECvM,(Pxy_TECvM),color='xkcd:deep red',linewidth=PLOT_lineWidthRegular, linestyle='--');
    p3, = ax.plot(1/freqs_ZvM,(Pxy_ZvM),color='xkcd:goldenrod',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    ax.set_xlim( (0, plot_periodLim_max) )
    ax.set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    ax.set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
    ax.set_title('Cross-Spectral Density - (TEC HP\'d) Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs at Millstone '+str(np.round(latMillstone,2))+' degc lat/'+str(np.round(longMillstone,2))+' deg long on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
        fontproperties=FONT_titleFM);
    ax.legend([p1,p2,p3],['Point TEC AVG''d to Zenith Times & HP vs Zenith HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        'Point TEC AVG''d to MISA Times & HP vs MISA HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        ' Zenith & MISA HP AVG''d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km'], \
        loc='upper left');
    
    xAxisTicks = np.arange( 0, plot_periodLim_max+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.065, right = 0.975, top = 0.96, bottom = 0.065 , hspace = 0.225); #sets padding to small numbers for minimal white space
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
#END IF
 
if( FLG_avgPt_HP_timeMatch_POPLnOMNI_FFT_cutOut == 1):
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    Zenith_time_delta = np.median(np.diff(Zenith_time)); #days, delta of time between readings
    MISA_time_delta = np.median(np.diff(MISA_time)); #days, delta of time between readings

    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    # Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #MISA NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut_MISA = avgPt_vTEC_timeMatch_HP_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut_MISA = avgPt_vTEC_timeMatch_time_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
            
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , 
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                             
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    # MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #OMNI plot prep
    OMNI_plot_label = OMNI_dictPlot[OMNI_dict[OMNI_plot_name]]; #get the label
    OMNI_plot_labelNoUnits = OMNI_plot_label[0:OMNI_plot_label.find('[')-1]; #remove the (units)
    
    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) ) )[0][0] , \
        np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    OMNI_data_timeMatch_HP_Zenith_cutOut = OMNI_data_timeMatch_HP_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    OMNI_data_timeMatch_time_Zenith_cutOut = OMNI_data_timeMatch_time_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #MISA NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) ) )[0][0] , \
        np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    OMNI_data_timeMatch_HP_MISA_cutOut = OMNI_data_timeMatch_HP_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    OMNI_data_timeMatch_time_MISA_cutOut = OMNI_data_timeMatch_time_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    from scipy import signal
#    from matplotlib import mlab
    window = np.hamming(110);
#    window= np.pad(window,(0,512-110),mode='constant')
    
    pwr_TEC_Z = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut**2)); #estimate power of signal
    pwr_TEC_M = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut_MISA.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut_MISA**2)); #estimate power of signal
    pwr_Z = np.sqrt(1/Zenith_POPL_hp_altAvgd_cutOut.size*np.sum(Zenith_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_M = np.sqrt(1/MISA_POPL_hp_altAvgd_cutOut.size*np.sum(MISA_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_OMNI_Z = np.sqrt(1/OMNI_data_timeMatch_HP_Zenith_cutOut.size*np.sum(OMNI_data_timeMatch_HP_Zenith_cutOut**2)); #estimate power of signal
    pwr_OMNI_M = np.sqrt(1/OMNI_data_timeMatch_HP_MISA_cutOut.size*np.sum(OMNI_data_timeMatch_HP_MISA_cutOut**2)); #estimate power of signal
    
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_TECZ,Cxx_TECZ] = signal.welch(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_Z,Cxx_Z] = signal.welch(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_OMNIZ,Cxx_OMNIZ] = signal.welch(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    
    Fs = 1/(MISA_time_delta*24*60); #min, MISA time delta in freq form
    [freqs_TECM,Cxx_TECM] = signal.welch(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_M,Cxx_M] = signal.welch(1/pwr_M*MISA_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_OMNIM,Cxx_OMNIM] = signal.welch(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    p1, = ax.plot(1/freqs_TECZ,(Cxx_TECZ),color='xkcd:cerulean',linewidth=PLOT_lineWidthRegular, linestyle='-');
    p2, = ax.plot(1/freqs_TECM,(Cxx_TECM),color='xkcd:deep red',linewidth=PLOT_lineWidthRegular, linestyle='--');
    p3, = ax.plot(1/freqs_Z,(Cxx_Z),color='xkcd:goldenrod',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p4, = ax.plot(1/freqs_M,(Cxx_M),color='xkcd:purple',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p5, = ax.plot(1/freqs_OMNIZ,(Cxx_OMNIZ),color='xkcd:forest green',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p6, = ax.plot(1/freqs_OMNIM,(Cxx_OMNIM),color='xkcd:dark gray',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    ax.set_xlim( (0, plot_periodLim_max) )
    ax.set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    ax.set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
    ax.set_title('Spectral Comparison - (TEC HP\'d) Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs at Millstone '+str(np.round(latMillstone,2))+' degc lat/'+str(np.round(longMillstone,2))+' deg long on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
        fontproperties=FONT_titleFM);
    ax.legend([p1,p2,p3,p4,p5,p6],['Point TEC AVG''d to Zenith Times & HP', \
        'Point TEC AVG''d to MISA Times & HP', \
        'Zenith HP AVG''d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        'MISA HP AVG''d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to Zenith Times & HP (Time Delayed '+str(OMNI_delay_wrt_TEC)+' hrs)', \
        'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to MISA Times & HP (Time Delayed '+str(OMNI_delay_wrt_TEC)+' hrs)'], \
        loc='upper left');
    
    xAxisTicks = np.arange( 0, plot_periodLim_max+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.065, right = 0.975, top = 0.96, bottom = 0.065 , hspace = 0.225); #sets padding to small numbers for minimal white space
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
#END IF
   
if( FLG_avgPt_HP_timeMatch_POPLnOMNI_CPSD_cutOut == 1):
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    Zenith_time_delta = np.median(np.diff(Zenith_time)); #days, delta of time between readings
    MISA_time_delta = np.median(np.diff(MISA_time)); #days, delta of time between readings

    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    # Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #MISA NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut_MISA = avgPt_vTEC_timeMatch_HP_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut_MISA = avgPt_vTEC_timeMatch_time_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
            
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , 
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                             
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    # MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #OMNI plot prep
    OMNI_plot_label = OMNI_dictPlot[OMNI_dict[OMNI_plot_name]]; #get the label
    OMNI_plot_labelNoUnits = OMNI_plot_label[0:OMNI_plot_label.find('[')-1]; #remove the (units)
    
    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) ) )[0][0] , \
        np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    OMNI_data_timeMatch_HP_Zenith_cutOut = OMNI_data_timeMatch_HP_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    OMNI_data_timeMatch_time_Zenith_cutOut = OMNI_data_timeMatch_time_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #MISA NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) ) )[0][0] , \
        np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    OMNI_data_timeMatch_HP_MISA_cutOut = OMNI_data_timeMatch_HP_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    OMNI_data_timeMatch_time_MISA_cutOut = OMNI_data_timeMatch_time_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
    #align disparate timings
    if( Zenith_time_cutOut.size > MISA_time_cutOut.size ):
        #need to snip Zenith stuff
        Zenith_time_cutOut = Zenith_time_cutOut[:-1]; #snip
        Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd_cutOut[:-1]; #snip
        avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time_cutOut[:-1]; #snip
        avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP_cutOut[:-1]; #snip
        OMNI_data_timeMatch_time_Zenith_cutOut = OMNI_data_timeMatch_time_Zenith_cutOut[:-1]; #snip
        OMNI_data_timeMatch_HP_Zenith_cutOut = OMNI_data_timeMatch_HP_Zenith_cutOut[:-1]; #snip
        if( OMNI_data_timeMatch_time_Zenith_cutOut.size > Zenith_time_cutOut.size ):
            #OMNI can have a time offset that could get extra off
            OMNI_data_timeMatch_time_Zenith_cutOut = OMNI_data_timeMatch_time_Zenith_cutOut[1:]; #snip from front this time
            OMNI_data_timeMatch_HP_Zenith_cutOut = OMNI_data_timeMatch_HP_Zenith_cutOut[1:]; #snip from front this time
        #END IF
    elif( Zenith_time_cutOut.size < MISA_time_cutOut.size ):
        #need to snip MISA stuff
        MISA_time_cutOut = MISA_time_cutOut[:-1]; #snip
        MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd_cutOut[:-1]; #snip
        avgPt_vTEC_timeMatch_time_cutOut_MISA = avgPt_vTEC_timeMatch_time_cutOut_MISA[:-1]; #snip
        avgPt_vTEC_timeMatch_HP_cutOut_MISA = avgPt_vTEC_timeMatch_HP_cutOut_MISA[:-1]; #snip
        OMNI_data_timeMatch_time_MISA_cutOut = OMNI_data_timeMatch_time_MISA_cutOut[:-1]; #snip
        OMNI_data_timeMatch_HP_MISA_cutOut = OMNI_data_timeMatch_HP_MISA_cutOut[:-1]; #snip
        if( OMNI_data_timeMatch_time_MISA_cutOut.size > MISA_time_cutOut.size ):
            #OMNI can have a time offset that could get extra off
            OMNI_data_timeMatch_time_MISA_cutOut = OMNI_data_timeMatch_time_MISA_cutOut[1:]; #snip from front this time
            OMNI_data_timeMatch_HP_MISA_cutOut = OMNI_data_timeMatch_HP_MISA_cutOut[1:]; #snip from front this time
        #END IF
    #END IF
    
    from scipy import signal
#    from matplotlib import mlab
    window = np.hamming(110);
#    window= np.pad(window,(0,512-110),mode='constant')
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    
    pwr_TEC_Z = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut**2)); #estimate power of signal
    pwr_TEC_M = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut_MISA.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut_MISA**2)); #estimate power of signal
    pwr_Z = np.sqrt(1/Zenith_POPL_hp_altAvgd_cutOut.size*np.sum(Zenith_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_M = np.sqrt(1/MISA_POPL_hp_altAvgd_cutOut.size*np.sum(MISA_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_OMNI_Z = np.sqrt(1/OMNI_data_timeMatch_HP_Zenith_cutOut.size*np.sum(OMNI_data_timeMatch_HP_Zenith_cutOut**2)); #estimate power of signal
    pwr_OMNI_M = np.sqrt(1/OMNI_data_timeMatch_HP_MISA_cutOut.size*np.sum(OMNI_data_timeMatch_HP_MISA_cutOut**2)); #estimate power of signal
    
    [freqs_TECvZ,Cxy_TECvZ] = signal.csd(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_TECvZ,freqs_TECvZ] = mlab.csd(avgPt_vTEC_timeMatch_HP_cutOut,Zenith_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_TECvZ,freqs_TECvZ] = cpsd(vTEC_5minInterped_Zenith(tmin_Zenith:tmax_Zenith),Zenith_SNR_threeHun_AVGD(tmin_Zenith:tmax_Zenith),[],[],512,Fs);
    Axy_TECvZ = np.angle(Cxy_TECvZ)*180/np.pi; 
    Pxy_TECvZ = np.abs(Cxy_TECvZ);
#    Pxy_TECvZ = np.abs(Cxy_TECvZ)/np.max(np.abs(Cxy_TECvZ))*0.8659;
    
#    [_,Cxx_TEC] = signal.welch(avgPt_vTEC_timeMatch_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
#    [_,Cxx_Z] = signal.welch(Zenith_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    
#    Pxy_TECvZ = Pxy_TECvZ / np.sqrt( np.abs(Cxx_TEC)*np.abs(Cxx_Z));
    
    #TEC (NO HIGH-PASS) VS MISA
    Fs = 1/(MISA_time_delta*24*60); #min, misa time delta in freq form
    [freqs_TECvM,Cxy_TECvM] = signal.csd(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_TECvM,freqs_TECvM] = mlab.csd(avgPt_vTEC_timeMatch_HP_cutOut_MISA,MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_TECvM,freqs_TECvM] = cpsd(vTEC_5minInterped_MISA(tmin_MISA:tmax_MISA),MISA_SNR_threeHun_AVGD(tmin_MISA:tmax_MISA),[],[],512,Fs);
    Axy_TECvM = np.angle(Cxy_TECvM)*180/np.pi; 
    Pxy_TECvM = np.abs(Cxy_TECvM);
#    Pxy_TECvM = np.abs(Cxy_TECvM)/np.max(np.abs(Cxy_TECvM))*0.6646;
    
    #ZENITH VS MISA
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_ZvM,Cxy_ZvM] = signal.csd(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_ZvM,freqs_ZvM] = mlab.csd(Zenith_POPL_hp_altAvgd_cutOut,MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_ZvM,freqs_ZvM] = cpsd(Zenith_SNR_threeHun_AVGD(tmin_Zenith:tmax_Zenith),MISA_SNR_threeHun_AVGD(tmin_MISA:tmax_MISA),[],[],512,Fs);
    Axy_ZvM = np.angle(Cxy_ZvM)*180/np.pi; 
    Pxy_ZvM = np.abs(Cxy_ZvM);
#    Pxy_ZvM = np.abs(Cxy_ZvM)/np.max(np.abs(Cxy_ZvM))*1.0758;
    
    #OMNI VS ZENITH
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_OMNIvZ,Cxy_OMNIvZ] = signal.csd(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
    Axy_OMNIvZ = np.angle(Cxy_OMNIvZ)*180/np.pi; 
    Pxy_OMNIvZ = np.abs(Cxy_OMNIvZ);\
    
#    #OMNI VS TEC (both aligned to Zenith)
#    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
#    [freqs_OMNIvTEC_Z,Cxy_OMNIvTEC_Z] = signal.csd(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    Axy_OMNIvTEC_Z = np.angle(Cxy_OMNIvTEC_Z)*180/np.pi; 
#    Pxy_OMNIvTEC_Z = np.abs(Cxy_OMNIvTEC_Z);
    
    #OMNI VS MISA
    Fs = 1/(MISA_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_OMNIvM,Cxy_OMNIvM] = signal.csd(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
    Axy_OMNIvM = np.angle(Cxy_OMNIvM)*180/np.pi; 
    Pxy_OMNIvM = np.abs(Cxy_OMNIvM);\
    
#    #OMNI VS TEC (both aligned to MISA)
#    Fs = 1/(MISA_time_delta*24*60); #min, zenith time delta in freq form
#    [freqs_OMNIvTEC_M,Cxy_OMNIvTEC_M] = signal.csd(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut,1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,window=window,noverlap=100,nfft=512,fs=Fs);
#    Axy_OMNIvTEC_M = np.angle(Cxy_OMNIvTEC_M)*180/np.pi; 
#    Pxy_OMNIvTEC_M = np.abs(Cxy_OMNIvTEC_M);


    #Real quick side move to calc correlation coefficients
    R_TECZvZ = np.corrcoef(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut)[0,1];
    R_TECMvM = np.corrcoef(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut)[0,1];
    R_ZvM = np.corrcoef(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut)[0,1];
    # Z_pos = Zenith_POPL_hp_altAvgd_cutOut+np.abs(np.min(Zenith_POPL_hp_altAvgd_cutOut)); #make it positive
    # Z_posPwr = np.sqrt(1/Z_pos.size*np.sum(Z_pos**2)); #estimate power of signal
    # M_pos = MISA_POPL_hp_altAvgd_cutOut+np.abs(np.min(MISA_POPL_hp_altAvgd_cutOut)); #make it positive
    # M_posPwr = np.sqrt(1/M_pos.size*np.sum(M_pos**2)); #estimate power of signal
    # TECZ_pos = avgPt_vTEC_timeMatch_HP_cutOut+np.abs(np.min(avgPt_vTEC_timeMatch_HP_cutOut)); #make it positive
    # TECZ_posPwr = np.sqrt(1/TECZ_pos.size*np.sum(TECZ_pos**2)); #estimate power of signal
    # TECM_pos = avgPt_vTEC_timeMatch_HP_cutOut_MISA+np.abs(np.min(avgPt_vTEC_timeMatch_HP_cutOut_MISA)); #make it positive
    # TECM_posPwr = np.sqrt(1/TECM_pos.size*np.sum(TECM_pos**2)); #estimate power of signal
    # R_OMNIvZ = np.corrcoef(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/Z_posPwr*Z_pos)[0,1];
    # R_OMNIvTECZ = np.corrcoef(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/TECZ_posPwr*TECZ_pos)[0,1];
    # R_OMNIvM = np.corrcoef(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut,1/M_posPwr*M_pos)[0,1];
    # R_OMNIvTECM = np.corrcoef(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut,1/TECM_posPwr*TECM_pos)[0,1];
    R_OMNIvZ = np.corrcoef(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut)[0,1];
    R_OMNIvTECZ = np.corrcoef(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut)[0,1];
    R_OMNIvM = np.corrcoef(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut)[0,1];
    R_OMNIvTECM = np.corrcoef(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut,1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA)[0,1];
    print('TECZvZ: '+str(np.round(R_TECZvZ,2))+' | TECMvM: '+str(np.round(R_TECMvM,2))+' | ZvM: '+str(np.round(R_ZvM,2))+' | OMNIvZ: '+str(np.round(R_OMNIvZ,2))+ \
          '\nOMNIvTECZ: '+str(np.round(R_OMNIvTECZ,2))+' | OMNIvM: '+str(np.round(R_OMNIvM,2))+' | OMNIvTECM: '+str(np.round(R_OMNIvTECM,2)));
    
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    p1, = ax.plot(1/freqs_TECvZ,(Pxy_TECvZ),color='xkcd:cerulean',linewidth=PLOT_lineWidthRegular, linestyle='-');
    p2, = ax.plot(1/freqs_TECvM,(Pxy_TECvM),color='xkcd:deep red',linewidth=PLOT_lineWidthRegular, linestyle='--');
    p3, = ax.plot(1/freqs_ZvM,(Pxy_ZvM),color='xkcd:goldenrod',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p4, = ax.plot(1/freqs_OMNIvZ,(Pxy_OMNIvZ),color='xkcd:purple',linewidth=PLOT_lineWidthRegular, linestyle='-.');
#    p6, = ax.plot(1/freqs_OMNIvTEC_Z,(Pxy_OMNIvTEC_Z),color='xkcd:forest green',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p5, = ax.plot(1/freqs_OMNIvM,(Pxy_OMNIvM),color='xkcd:dark gray',linewidth=PLOT_lineWidthRegular, linestyle='-.');
#    p7, = ax.plot(1/freqs_OMNIvTEC_M,(Pxy_OMNIvTEC_M),color='xkcd:orange',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    ax.set_xlim( (0, plot_periodLim_max) )
    ax.set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    ax.set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
    ax.set_title('Cross-Spectral Density - (TEC HP\'d) Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs at Millstone '+str(np.round(latMillstone,2))+' degc lat/'+str(np.round(longMillstone,2))+' deg long on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
        fontproperties=FONT_titleFM);
    ax.legend([p1,p2,p3,p4,p5],['Point TEC AVG''d to Zenith Times & HP vs Zenith HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        'Point TEC AVG''d to MISA Times & HP vs MISA HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        'Zenith & MISA HP AVG''d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to Zenith Times & HP (Time Delayed '+str(OMNI_delay_wrt_TEC)+' hrs) vs Zenith HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
#        'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to Zenith Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Point TEC AVG''d to Zenith Times & HP', \
        'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to MISA Times & HP (Time Delayed '+str(OMNI_delay_wrt_TEC)+' hrs) vs MISA HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km'], \
#        'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to MISA Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Point TEC AVG''d to MISA Times & HP'], \
        loc='upper left');
    
    xAxisTicks = np.arange( 0, plot_periodLim_max+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.065, right = 0.975, top = 0.96, bottom = 0.065 , hspace = 0.225); #sets padding to small numbers for minimal white space
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
#END IF

if( FLG_avgPt_HP_timeMatch_POPLnOMNInTECNOISE_CPSD_cutOut == 1):
    if( FLG_TEC_noise >= 1 ):
        print('***WARNING***: FLG_TEC_noise is '+str(FLG_TEC_noise)+' which means that the TEC comparisons are meaningless (the TEC data has been replaced with noise). Fix that and re-run for this plot to be useful!'); #report issue
    #END IF
    
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    Zenith_time_delta = np.median(np.diff(Zenith_time)); #days, delta of time between readings
    MISA_time_delta = np.median(np.diff(MISA_time)); #days, delta of time between readings
    
    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexesZ = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    
    #MISA NOW
    time_cutout_indexesM = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut_MISA = avgPt_vTEC_timeMatch_HP_MISA[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut_MISA = avgPt_vTEC_timeMatch_time_MISA[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
            
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , 
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                             
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #OMNI plot prep
    OMNI_plot_label = OMNI_dictPlot[OMNI_dict[OMNI_plot_name]]; #get the label
    OMNI_plot_labelNoUnits = OMNI_plot_label[0:OMNI_plot_label.find('[')-1]; #remove the (units)
    
    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) ) )[0][0] , \
        np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    OMNI_data_timeMatch_HP_Zenith_cutOut = OMNI_data_timeMatch_HP_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    OMNI_data_timeMatch_time_Zenith_cutOut = OMNI_data_timeMatch_time_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #MISA NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) ) )[0][0] , \
        np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    OMNI_data_timeMatch_HP_MISA_cutOut = OMNI_data_timeMatch_HP_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    OMNI_data_timeMatch_time_MISA_cutOut = OMNI_data_timeMatch_time_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    from scipy import signal
#    from matplotlib import mlab
    window = np.hamming(110);
#    window= np.pad(window,(0,512-110),mode='constant')
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    
    pwr_TEC_Z = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut**2)); #estimate power of signal
    pwr_TEC_M = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut_MISA.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut_MISA**2)); #estimate power of signal
    pwr_Z = np.sqrt(1/Zenith_POPL_hp_altAvgd_cutOut.size*np.sum(Zenith_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_M = np.sqrt(1/MISA_POPL_hp_altAvgd_cutOut.size*np.sum(MISA_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_OMNI_Z = np.sqrt(1/OMNI_data_timeMatch_HP_Zenith_cutOut.size*np.sum(OMNI_data_timeMatch_HP_Zenith_cutOut**2)); #estimate power of signal
    pwr_OMNI_M = np.sqrt(1/OMNI_data_timeMatch_HP_MISA_cutOut.size*np.sum(OMNI_data_timeMatch_HP_MISA_cutOut**2)); #estimate power of signal
    
    [freqs_TECvZ,Cxy_TECvZ] = signal.csd(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_TECvZ,freqs_TECvZ] = mlab.csd(avgPt_vTEC_timeMatch_HP_cutOut,Zenith_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_TECvZ,freqs_TECvZ] = cpsd(vTEC_5minInterped_Zenith(tmin_Zenith:tmax_Zenith),Zenith_SNR_threeHun_AVGD(tmin_Zenith:tmax_Zenith),[],[],512,Fs);
    Axy_TECvZ = np.angle(Cxy_TECvZ)*180/np.pi; 
    Pxy_TECvZ = np.abs(Cxy_TECvZ);
#    Pxy_TECvZ = np.abs(Cxy_TECvZ)/np.max(np.abs(Cxy_TECvZ))*0.8659;
    
#    [_,Cxx_TEC] = signal.welch(avgPt_vTEC_timeMatch_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
#    [_,Cxx_Z] = signal.welch(Zenith_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    
#    Pxy_TECvZ = Pxy_TECvZ / np.sqrt( np.abs(Cxx_TEC)*np.abs(Cxx_Z));
    
    #TEC (NO HIGH-PASS) VS MISA
    Fs = 1/(MISA_time_delta*24*60); #min, misa time delta in freq form
    [freqs_TECvM,Cxy_TECvM] = signal.csd(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_TECvM,freqs_TECvM] = mlab.csd(avgPt_vTEC_timeMatch_HP_cutOut_MISA,MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_TECvM,freqs_TECvM] = cpsd(vTEC_5minInterped_MISA(tmin_MISA:tmax_MISA),MISA_SNR_threeHun_AVGD(tmin_MISA:tmax_MISA),[],[],512,Fs);
    Axy_TECvM = np.angle(Cxy_TECvM)*180/np.pi; 
    Pxy_TECvM = np.abs(Cxy_TECvM);
#    Pxy_TECvM = np.abs(Cxy_TECvM)/np.max(np.abs(Cxy_TECvM))*0.6646;
    
    #ZENITH VS MISA
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_ZvM,Cxy_ZvM] = signal.csd(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_ZvM,freqs_ZvM] = mlab.csd(Zenith_POPL_hp_altAvgd_cutOut,MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_ZvM,freqs_ZvM] = cpsd(Zenith_SNR_threeHun_AVGD(tmin_Zenith:tmax_Zenith),MISA_SNR_threeHun_AVGD(tmin_MISA:tmax_MISA),[],[],512,Fs);
    Axy_ZvM = np.angle(Cxy_ZvM)*180/np.pi; 
    Pxy_ZvM = np.abs(Cxy_ZvM);
#    Pxy_ZvM = np.abs(Cxy_ZvM)/np.max(np.abs(Cxy_ZvM))*1.0758;
    
    #OMNI VS ZENITH
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_OMNIvZ,Cxy_OMNIvZ] = signal.csd(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
    Axy_OMNIvZ = np.angle(Cxy_OMNIvZ)*180/np.pi; 
    Pxy_OMNIvZ = np.abs(Cxy_OMNIvZ);\
    
#    #OMNI VS TEC (both aligned to Zenith)
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_OMNIvTEC_Z,Cxy_OMNIvTEC_Z] = signal.csd(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
    Axy_OMNIvTEC_Z = np.angle(Cxy_OMNIvTEC_Z)*180/np.pi; 
    Pxy_OMNIvTEC_Z = np.abs(Cxy_OMNIvTEC_Z);
    
    #OMNI VS MISA
    Fs = 1/(MISA_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_OMNIvM,Cxy_OMNIvM] = signal.csd(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
    Axy_OMNIvM = np.angle(Cxy_OMNIvM)*180/np.pi; 
    Pxy_OMNIvM = np.abs(Cxy_OMNIvM);\
    
#    #OMNI VS TEC (both aligned to MISA)
    Fs = 1/(MISA_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_OMNIvTEC_M,Cxy_OMNIvTEC_M] = signal.csd(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut,1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,window=window,noverlap=100,nfft=512,fs=Fs);
    Axy_OMNIvTEC_M = np.angle(Cxy_OMNIvTEC_M)*180/np.pi; 
    Pxy_OMNIvTEC_M = np.abs(Cxy_OMNIvTEC_M);
# 
    #now, noise comparisons
    TECZvTECZN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    TECMvTECMN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    ZvTECZN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    MvTECMN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    OMNIZvTECZN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    OMNIMvTECMN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    R_TECZvTECZN_mat = np.zeros([4,avgPt_TECnoise_iterations]);
    R_ZvTECZN_mat = np.zeros([4,avgPt_TECnoise_iterations]);
    R_OMNIZvTECZN_mat = np.zeros([4,avgPt_TECnoise_iterations]);
    R_TECMvTECMN_mat = np.zeros([4,avgPt_TECnoise_iterations]);
    R_MvTECMN_mat = np.zeros([4,avgPt_TECnoise_iterations]);
    R_OMNIMvTECMN_mat = np.zeros([4,avgPt_TECnoise_iterations]);
    pointRadiusAngular = (avgPt_pointRadius/Re)*180/np.pi; #get the angular radius to get a small subset of points to deal with
    k = ((avgPt_coords[0,0]-pointRadiusAngular <= data['TEC']['lat']) & (avgPt_coords[0,0]+pointRadiusAngular >= data['TEC']['lat'])) & \
        ((avgPt_coords[0,1]-pointRadiusAngular <= data['TEC']['long']) & (avgPt_coords[0,1]+pointRadiusAngular >= data['TEC']['long'])); #get only east coast to lower calcs needed
    kM = ((avgPt_coords[1,0]-pointRadiusAngular <= data['TEC']['lat']) & (avgPt_coords[1,0]+pointRadiusAngular >= data['TEC']['lat'])) & \
        ((avgPt_coords[1,1]-pointRadiusAngular <= data['TEC']['long']) & (avgPt_coords[1,1]+pointRadiusAngular >= data['TEC']['long'])); #get only east coast to lower calcs needed
    for i in range(0,avgPt_TECnoise_iterations):
        TEC_noise = GRITI_TEC_randomSynth(k.sum(),data['TEC']['lat'][k],data['TEC']['long'][k],data['TEC']['time'][k], \
            noise_background_mean,noise_background_stdev,Re,dateRange_zeroHr, \
            plotLatRange,plotLongRange,plotLatRange_autoTick,plotLongRange_autoTick, \
            wave_latRange,wave_longRange,wave_N,wave_angle,wave_phase,wave_waveLength,wave_period,wave_amp, \
            FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,TEC_plotLimValu,1,FLG_plotStuff=0); #replace the delta-vTEC data with random data 
        
        TEC_noiseM = GRITI_TEC_randomSynth(kM.sum(),data['TEC']['lat'][kM],data['TEC']['long'][kM],data['TEC']['time'][kM], \
            noise_background_mean,noise_background_stdev,Re,dateRange_zeroHr, \
            plotLatRange,plotLongRange,plotLatRange_autoTick,plotLongRange_autoTick, \
            wave_latRange,wave_longRange,wave_N,wave_angle,wave_phase,wave_waveLength,wave_period,wave_amp, \
            FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,TEC_plotLimValu,1,FLG_plotStuff=0); #replace the delta-vTEC data with random data 
        
        avgPt_TECnoise, _, avgPt_TECnoise_time, _, _, _  = \
            GRITI_TEC_avgPt(TEC_timeUnique,data['TEC']['lat'][k],data['TEC']['long'][k],data['TEC']['time'][k],TEC_noise, \
            avgPt_coords[0,:],avgPt_pointRadius,Re,dateRange_dayNum_zeroHr, \
            dataReject,dataRejectOrig,dataRejectLimit,dataRejectLimitOrig,dataRejectMax,FLG_report=0); #average points in a radius
            
        _, avgPt_TECnoise_timeMatch_HP, _ = GRITI_TEC_avgPt_timeMatch(avgPt_TECnoise,avgPt_TECnoise_time,Zenith_time,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);

        avgPt_TECnoise_timeMatch_HP_cutOut = avgPt_TECnoise_timeMatch_HP[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];

        avgPt_TECnoise_M, _, avgPt_TECnoise_time_M, _, _, _  = \
            GRITI_TEC_avgPt(TEC_timeUnique,data['TEC']['lat'][kM],data['TEC']['long'][kM],data['TEC']['time'][kM],TEC_noiseM, \
            avgPt_coords[1,:],avgPt_pointRadius,Re,dateRange_dayNum_zeroHr, \
            dataReject,dataRejectOrig,dataRejectLimit,dataRejectLimitOrig,dataRejectMax,FLG_report=0); #average points in a radius
        
        _, avgPt_TECnoise_timeMatch_HP_M, _ = GRITI_TEC_avgPt_timeMatch(avgPt_TECnoise_M,avgPt_TECnoise_time_M,MISA_time,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
        
        avgPt_TECnoise_timeMatch_HP_cutOut_M = avgPt_TECnoise_timeMatch_HP_M[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
        
        pwr_TECZN = np.sqrt(1/avgPt_TECnoise_timeMatch_HP_cutOut.size*np.sum(avgPt_TECnoise_timeMatch_HP_cutOut**2)); #estimate power of signal
        pwr_TECMN = np.sqrt(1/avgPt_TECnoise_timeMatch_HP_cutOut_M.size*np.sum(avgPt_TECnoise_timeMatch_HP_cutOut_M**2)); #estimate power of signal
        
        #ZENITH RELATED STUFF
        Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
        #TECZ VS TECZNOISE
        [freqs_TECZvTECZN,Cxy_TECZvTECZN] = signal.csd(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
        Pxy_TECZvTECZN = np.abs(Cxy_TECZvTECZN);
        #Z VS TECZNOISE
        [freqs_ZvTECZN,Cxy_ZvTECZN] = signal.csd(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
        Pxy_ZvTECZN = np.abs(Cxy_ZvTECZN);
        #OMNI VS TECZNOISE
        [freqs_OMNIZvTECZN,Cxy_OMNIZvTECZN] = signal.csd(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
        Pxy_OMNIZvTECZN = np.abs(Cxy_OMNIZvTECZN);
        #MISA RELATED STUFF
        Fs = 1/(MISA_time_delta*24*60); #min, misa time delta in freq form
        #TECM VS TECMNOISE
        [freqs_TECMvTECMN,Cxy_TECMvTECMN] = signal.csd(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M,window=window,noverlap=100,nfft=512,fs=Fs);
        Pxy_TECMvTECMN = np.abs(Cxy_TECMvTECMN);
        #M VS TECMNOISE
        [freqs_MvTECMN,Cxy_MvTECMN] = signal.csd(1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M,window=window,noverlap=100,nfft=512,fs=Fs);
        Pxy_MvTECMN = np.abs(Cxy_MvTECMN);
        #OMNI VS TECMNOISE
        [freqs_OMNIMvTECMN,Cxy_OMNIMvTECMN] = signal.csd(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut,1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M,window=window,noverlap=100,nfft=512,fs=Fs);
        Pxy_OMNIMvTECMN = np.abs(Cxy_OMNIMvTECMN);
        
        #Real quick side move to calc correlation coefficients
        R_TECZvTECZN = np.corrcoef(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut);
        R_ZvTECZN = np.corrcoef(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut);
        R_OMNIZvTECZN = np.corrcoef(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut);
        R_TECMvTECMN = np.corrcoef(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M);
        R_MvTECMN = np.corrcoef(1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M);
        R_OMNIMvTECMN = np.corrcoef(1/pwr_OMNI_M*np.concatenate( (OMNI_data_timeMatch_HP_MISA_cutOut,np.array((0,))) ),1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M);
        
        #RECORD FOR POSTERITY
        TECZvTECZN_mat[:,i] = Pxy_TECZvTECZN;
        TECMvTECMN_mat[:,i] = Pxy_TECMvTECMN;
        ZvTECZN_mat[:,i] = Pxy_ZvTECZN;
        MvTECMN_mat[:,i] = Pxy_MvTECMN;
        OMNIZvTECZN_mat[:,i] = Pxy_OMNIZvTECZN;
        OMNIMvTECMN_mat[:,i] = Pxy_OMNIMvTECMN;
        R_TECZvTECZN_mat[:,i] = R_TECZvTECZN.flatten();
        R_ZvTECZN_mat[:,i] = R_ZvTECZN.flatten();
        R_OMNIZvTECZN_mat[:,i] = R_OMNIZvTECZN.flatten();
        R_TECMvTECMN_mat[:,i] = R_TECMvTECMN.flatten();
        R_MvTECMN_mat[:,i] = R_MvTECMN.flatten();
        R_OMNIMvTECMN_mat[:,i] = R_OMNIMvTECMN.flatten();
    #END FOR i
    Pxy_TECZvTECZN = np.mean(TECZvTECZN_mat,axis=1);
    Pxy_TECMvTECMN = np.mean(TECMvTECMN_mat,axis=1);
    Pxy_ZvTECZN = np.mean(ZvTECZN_mat,axis=1);
    Pxy_MvTECMN = np.mean(MvTECMN_mat,axis=1);
    Pxy_OMNIZvTECZN = np.mean(OMNIZvTECZN_mat,axis=1);
    Pxy_OMNIMvTECMN = np.mean(OMNIMvTECMN_mat,axis=1);
    #Real quick side move to calc correlation coefficients
    R_TECZvTECZN = np.mean(R_TECZvTECZN_mat,axis=1)[1];
    R_ZvTECZN = np.mean(R_ZvTECZN_mat,axis=1)[1];
    R_OMNIZvTECZN = np.mean(R_OMNIZvTECZN_mat,axis=1)[1];
    R_TECMvTECMN = np.mean(R_TECMvTECMN_mat,axis=1)[1];
    R_MvTECMN = np.mean(R_MvTECMN_mat,axis=1)[1];
    R_OMNIMvTECMN = np.mean(R_OMNIMvTECMN_mat,axis=1)[1];
    
    #Real quick side move to calc correlation coefficients
    R_TECZvZ = np.corrcoef(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut)[0,1];
    R_TECMvM = np.corrcoef(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut)[0,1];
    R_ZvM = np.corrcoef(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut)[0,1];
    R_OMNIvZ = np.corrcoef(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut)[0,1];
    R_OMNIvTECZ = np.corrcoef(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut,1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut)[0,1];
    R_OMNIvM = np.corrcoef(1/pwr_OMNI_M*np.concatenate( (OMNI_data_timeMatch_HP_MISA_cutOut,np.array((0,))) ),1/pwr_M*MISA_POPL_hp_altAvgd_cutOut)[0,1];
    R_OMNIvTECM = np.corrcoef(1/pwr_OMNI_M*np.concatenate( (OMNI_data_timeMatch_HP_MISA_cutOut,np.array((0,))) ),1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA)[0,1];
    print('TECZvZ: '+str(np.round(R_TECZvZ,2))+' | TECMvM: '+str(np.round(R_TECMvM,2))+' | ZvM: '+str(np.round(R_ZvM,2))+' | OMNIvZ: '+str(np.round(R_OMNIvZ,2))+ \
          '\nOMNIvTECZ: '+str(np.round(R_OMNIvTECZ,2))+' | OMNIvM: '+str(np.round(R_OMNIvM,2))+' | OMNIvTECM: '+str(np.round(R_OMNIvTECM,2))+
          ' | TECZvTECZN: '+str(np.round(R_TECZvTECZN,2))+'\nZvTECZN: '+str(np.round(R_ZvTECZN,2))+' | OMNIZvTECZN: '+str(np.round(R_OMNIZvTECZN,2))+ \
          ' | TECMvTECMN: '+str(np.round(R_TECMvTECMN,2))+' | MvTECMN: '+str(np.round(R_MvTECMN,2))+' | OMNIMvTECMN: '+str(np.round(R_OMNIMvTECMN,2)));
    
    
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    p1, = ax.plot(1/freqs_TECvZ,(Pxy_TECvZ),color='xkcd:cerulean',linewidth=PLOT_lineWidthRegular, linestyle='-');
    p2, = ax.plot(1/freqs_TECvM,(Pxy_TECvM),color='xkcd:deep red',linewidth=PLOT_lineWidthRegular, linestyle='--');
    p3, = ax.plot(1/freqs_ZvM,(Pxy_ZvM),color='xkcd:goldenrod',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p4, = ax.plot(1/freqs_OMNIvZ,(Pxy_OMNIvZ),color='xkcd:purple',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p5, = ax.plot(1/freqs_OMNIvM,(Pxy_OMNIvM),color='xkcd:dark gray',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p6, = ax.plot(1/freqs_OMNIvTEC_Z,(Pxy_OMNIvTEC_Z),color='xkcd:forest green',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p7, = ax.plot(1/freqs_OMNIvTEC_M,(Pxy_OMNIvTEC_M),color='xkcd:orange',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p8, = ax.plot(1/freqs_TECZvTECZN,(Pxy_TECZvTECZN),color='xkcd:lavender',linewidth=PLOT_lineWidthRegular, linestyle='--');
    p9, = ax.plot(1/freqs_TECMvTECMN,(Pxy_TECMvTECMN),color='xkcd:lime green',linewidth=PLOT_lineWidthRegular, linestyle='--');
    p10, = ax.plot(1/freqs_ZvTECZN,(Pxy_ZvTECZN),color='xkcd:brown',linewidth=PLOT_lineWidthRegular, linestyle='--');
    p11, = ax.plot(1/freqs_MvTECMN,(Pxy_MvTECMN),color='xkcd:magenta',linewidth=PLOT_lineWidthRegular, linestyle='--');
    p12, = ax.plot(1/freqs_OMNIZvTECZN,(Pxy_OMNIZvTECZN),color='xkcd:teal',linewidth=PLOT_lineWidthRegular, linestyle='--');
    p13, = ax.plot(1/freqs_OMNIMvTECMN,(Pxy_OMNIMvTECMN),color='xkcd:green',linewidth=PLOT_lineWidthRegular, linestyle='--');
    errorMax = np.max([Pxy_TECZvTECZN.max(),Pxy_TECMvTECMN.max(),Pxy_ZvTECZN.max(),Pxy_MvTECMN.max(),
                       Pxy_OMNIZvTECZN.max(),Pxy_OMNIMvTECMN.max()]);
    pLine = ax.hlines(errorMax,np.min(1/freqs_TECvZ),plot_periodLim_max,color='xkcd:fire engine red',linewidth=PLOT_lineWidthRegular, linestyle='--');
    ax.set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    ax.set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
    ax.set_title('Cross-Spectral Density - Noise '+str(avgPt_TECnoise_iterations)+' Iteration Average Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs w/ OMNI time delayed by'+str(OMNI_delay_wrt_TEC)+' hrs on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
        fontproperties=FONT_titleFM);
    ax.legend([p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13],
        # ['Point TEC AVG''d to Zenith Times & HP vs Zenith HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'Point TEC AVG''d to MISA Times & HP vs MISA HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'Zenith & MISA HP AVG''d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        # 'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to Zenith Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Zenith HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to MISA Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs MISA HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to Zenith Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Point TEC AVG''d to Zenith Times & HP', \
        # 'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to MISA Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Point TEC AVG''d to MISA Times & HP', \
        ['TEC@Z vs Z ISR', \
        'TEC@M vs M ISR', \
        'Z ISR vs M ISR', \
        'OMNI ON Z vs Z ISR', \
        'OMNI ON M  vs M ISR', \
        'OMNI ON Z vs TEC@Z', \
        'OMNI ON M vs TEC@M', \
        'TEC@Z vs TECnoise@Z',\
        'TEC@M vs TECnoise@M',\
        'Z ISR vs TECnoise@Z',\
        'M ISR vs TECnoise@M',\
        'OMNI ON Z vs TECnoise@Z',\
        'OMNI ON M vs TECnoise@Z'], \
        loc='upper left');
    
    xAxisTicks = np.arange( 0, plot_periodLim_max+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    ax.set_xlim( (np.min(1/freqs_TECvZ), plot_periodLim_max) )
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.065, right = 0.975, top = 0.96, bottom = 0.065 , hspace = 0.225); #sets padding to small numbers for minimal white space
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
#END IF

if( (FLG_avgPt_HP_timeMatch_POPLnTECNOISE_CPSD_cutOut == 1) & (FLG_fancyPlot == 1) ):
    print('MAKING FANCY PLOT: TEC_avgPt_HP_timeMatch_POPLnTECNOISE_CPSD_cutOut IN fancyPlot FOLDER'); #report since you won't see anything
    from mpl_toolkits.axes_grid1 import make_axes_locatable
    if( FLG_TEC_noise >= 1 ):
        print('***ERROR***: FLG_TEC_noise is '+str(FLG_TEC_noise)+' which means that the TEC comparisons are meaningless (the TEC data has been replaced with noise). Fix that and re-run for this plot to be useful!'); #report issue
        sys.exit();
    #END IF
    Zenith_time_delta = np.median(np.diff(Zenith_time)); #days, delta of time between readings
    MISA_time_delta = np.median(np.diff(MISA_time)); #days, delta of time between readings
    
    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexesZ = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    
    #MISA NOW
    time_cutout_indexesM = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut_MISA = avgPt_vTEC_timeMatch_HP_MISA[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut_MISA = avgPt_vTEC_timeMatch_time_MISA[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
            
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , 
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                             
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    from scipy import signal
#    from matplotlib import mlab
    window = np.hamming(110);
#    window= np.pad(window,(0,512-110),mode='constant')
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    
    pwr_TEC_Z = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut**2)); #estimate power of signal
    pwr_TEC_M = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut_MISA.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut_MISA**2)); #estimate power of signal
    pwr_Z = np.sqrt(1/Zenith_POPL_hp_altAvgd_cutOut.size*np.sum(Zenith_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_M = np.sqrt(1/MISA_POPL_hp_altAvgd_cutOut.size*np.sum(MISA_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal

    [freqs_TECvZ,Cxy_TECvZ] = signal.csd(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_TECvZ,freqs_TECvZ] = mlab.csd(avgPt_vTEC_timeMatch_HP_cutOut,Zenith_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_TECvZ,freqs_TECvZ] = cpsd(vTEC_5minInterped_Zenith(tmin_Zenith:tmax_Zenith),Zenith_SNR_threeHun_AVGD(tmin_Zenith:tmax_Zenith),[],[],512,Fs);
    Axy_TECvZ = np.angle(Cxy_TECvZ)*180/np.pi; 
    Pxy_TECvZ = np.abs(Cxy_TECvZ);
#    Pxy_TECvZ = np.abs(Cxy_TECvZ)/np.max(np.abs(Cxy_TECvZ))*0.8659;
    
#    [_,Cxx_TEC] = signal.welch(avgPt_vTEC_timeMatch_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
#    [_,Cxx_Z] = signal.welch(Zenith_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    
#    Pxy_TECvZ = Pxy_TECvZ / np.sqrt( np.abs(Cxx_TEC)*np.abs(Cxx_Z));
    
    #TEC (NO HIGH-PASS) VS MISA
    Fs = 1/(MISA_time_delta*24*60); #min, misa time delta in freq form
    [freqs_TECvM,Cxy_TECvM] = signal.csd(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_TECvM,freqs_TECvM] = mlab.csd(avgPt_vTEC_timeMatch_HP_cutOut_MISA,MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_TECvM,freqs_TECvM] = cpsd(vTEC_5minInterped_MISA(tmin_MISA:tmax_MISA),MISA_SNR_threeHun_AVGD(tmin_MISA:tmax_MISA),[],[],512,Fs);
    Axy_TECvM = np.angle(Cxy_TECvM)*180/np.pi; 
    Pxy_TECvM = np.abs(Cxy_TECvM);
#    Pxy_TECvM = np.abs(Cxy_TECvM)/np.max(np.abs(Cxy_TECvM))*0.6646;
    
    #ZENITH VS MISA
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_ZvM,Cxy_ZvM] = signal.csd(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
#    [Cxy_ZvM,freqs_ZvM] = mlab.csd(Zenith_POPL_hp_altAvgd_cutOut,MISA_POPL_hp_altAvgd_cutOut,window=window,noverlap=100,NFFT=512,Fs=Fs);
    # [Cxy_ZvM,freqs_ZvM] = cpsd(Zenith_SNR_threeHun_AVGD(tmin_Zenith:tmax_Zenith),MISA_SNR_threeHun_AVGD(tmin_MISA:tmax_MISA),[],[],512,Fs);
    Axy_ZvM = np.angle(Cxy_ZvM)*180/np.pi; 
    Pxy_ZvM = np.abs(Cxy_ZvM);
#    Pxy_ZvM = np.abs(Cxy_ZvM)/np.max(np.abs(Cxy_ZvM))*1.0758;
    
# 
    #now, noise comparisons
    TECZvTECZN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    TECMvTECMN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    ZvTECZN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    MvTECMN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    R_TECZvTECZN_mat = np.zeros([4,avgPt_TECnoise_iterations]);
    R_ZvTECZN_mat = np.zeros([4,avgPt_TECnoise_iterations]);
    R_TECMvTECMN_mat = np.zeros([4,avgPt_TECnoise_iterations]);
    R_MvTECMN_mat = np.zeros([4,avgPt_TECnoise_iterations]);
    #compare noises
    TECZNvTECMN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    R_TECZNvTECMN_mat = np.zeros([4,avgPt_TECnoise_iterations]);
    pointRadiusAngular = (avgPt_pointRadius/Re)*180/np.pi; #get the angular radius to get a small subset of points to deal with
    k = ((avgPt_coords[0,0]-pointRadiusAngular <= data['TEC']['lat']) & (avgPt_coords[0,0]+pointRadiusAngular >= data['TEC']['lat'])) & \
        ((avgPt_coords[0,1]-pointRadiusAngular <= data['TEC']['long']) & (avgPt_coords[0,1]+pointRadiusAngular >= data['TEC']['long'])); #get only east coast to lower calcs needed
    kM = ((avgPt_coords[1,0]-pointRadiusAngular <= data['TEC']['lat']) & (avgPt_coords[1,0]+pointRadiusAngular >= data['TEC']['lat'])) & \
        ((avgPt_coords[1,1]-pointRadiusAngular <= data['TEC']['long']) & (avgPt_coords[1,1]+pointRadiusAngular >= data['TEC']['long'])); #get only east coast to lower calcs needed
    for i in range(0,avgPt_TECnoise_iterations):
        TEC_noise = GRITI_TEC_randomSynth(data['TEC']['lat'][k].size,data['TEC']['lat'][k],data['TEC']['long'][k],data['TEC']['time'][k], \
            noise_background_mean,noise_background_stdev,Re,dateRange_zeroHr, \
            plotLatRange,plotLongRange,plotLatRange_autoTick,plotLongRange_autoTick, \
            wave_latRange,wave_longRange,wave_N,wave_angle,wave_phase,wave_waveLength,wave_period,wave_amp, \
            FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,TEC_plotLimValu,1,FLG_plotStuff=0); #replace the delta-vTEC data with random data 
            
        TEC_noiseM = GRITI_TEC_randomSynth(data['TEC']['lat'][kM].size,data['TEC']['lat'][kM],data['TEC']['long'][kM],data['TEC']['time'][kM], \
            noise_background_mean,noise_background_stdev,Re,dateRange_zeroHr, \
            plotLatRange,plotLongRange,plotLatRange_autoTick,plotLongRange_autoTick, \
            wave_latRange,wave_longRange,wave_N,wave_angle,wave_phase,wave_waveLength,wave_period,wave_amp, \
            FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,TEC_plotLimValu,1,FLG_plotStuff=0); #replace the delta-vTEC data with random data 
        
        avgPt_TECnoise, _, avgPt_TECnoise_time, _, _, _  = \
            GRITI_TEC_avgPt(TEC_timeUnique,data['TEC']['lat'][k],data['TEC']['long'][k],data['TEC']['time'][k],TEC_noise, \
            avgPt_coords[0,:],avgPt_pointRadius,Re,dateRange_dayNum_zeroHr, \
            dataReject,dataRejectOrig,dataRejectLimit,dataRejectLimitOrig,dataRejectMax,FLG_report=0); #average points in a radius
            
        _, avgPt_TECnoise_timeMatch_HP, _ = GRITI_TEC_avgPt_timeMatch(avgPt_TECnoise,avgPt_TECnoise_time,Zenith_time,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);

        avgPt_TECnoise_timeMatch_HP_cutOut = avgPt_TECnoise_timeMatch_HP[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];

        avgPt_TECnoise_M, _, avgPt_TECnoise_time_M, _, _, _  = \
            GRITI_TEC_avgPt(TEC_timeUnique,data['TEC']['lat'][kM],data['TEC']['long'][kM],data['TEC']['time'][kM],TEC_noiseM, \
            avgPt_coords[1,:],avgPt_pointRadius,Re,dateRange_dayNum_zeroHr, \
            dataReject,dataRejectOrig,dataRejectLimit,dataRejectLimitOrig,dataRejectMax,FLG_report=0); #average points in a radius
        
        _, avgPt_TECnoise_timeMatch_HP_M, _ = GRITI_TEC_avgPt_timeMatch(avgPt_TECnoise_M,avgPt_TECnoise_time_M,MISA_time,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
        
        avgPt_TECnoise_timeMatch_HP_cutOut_M = avgPt_TECnoise_timeMatch_HP_M[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
        
        pwr_TECZN = np.sqrt(1/avgPt_TECnoise_timeMatch_HP_cutOut.size*np.sum(avgPt_TECnoise_timeMatch_HP_cutOut**2)); #estimate power of signal
        pwr_TECMN = np.sqrt(1/avgPt_TECnoise_timeMatch_HP_cutOut_M.size*np.sum(avgPt_TECnoise_timeMatch_HP_cutOut_M**2)); #estimate power of signal
        
        #ZENITH RELATED STUFF
        Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
        #TECZ VS TECZNOISE
        [freqs_TECZvTECZN,Cxy_TECZvTECZN] = signal.csd(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
        Pxy_TECZvTECZN = np.abs(Cxy_TECZvTECZN);
        #Z VS TECZNOISE
        [freqs_ZvTECZN,Cxy_ZvTECZN] = signal.csd(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut,window=window,noverlap=100,nfft=512,fs=Fs);
        Pxy_ZvTECZN = np.abs(Cxy_ZvTECZN);
        #MISA RELATED STUFF
        Fs = 1/(MISA_time_delta*24*60); #min, misa time delta in freq form
        #TECM VS TECMNOISE
        [freqs_TECMvTECMN,Cxy_TECMvTECMN] = signal.csd(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M,window=window,noverlap=100,nfft=512,fs=Fs);
        Pxy_TECMvTECMN = np.abs(Cxy_TECMvTECMN);
        #M VS TECMNOISE
        [freqs_MvTECMN,Cxy_MvTECMN] = signal.csd(1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M,window=window,noverlap=100,nfft=512,fs=Fs);
        Pxy_MvTECMN = np.abs(Cxy_MvTECMN);
        
        #Real quick side move to calc correlation coefficients
        R_TECZvTECZN = np.corrcoef(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut);
        R_ZvTECZN = np.corrcoef(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut);
        R_TECMvTECMN = np.corrcoef(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M);
        R_MvTECMN = np.corrcoef(1/pwr_M*MISA_POPL_hp_altAvgd_cutOut,1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M);
        
        #compare noises together, need to extrapolate probably
        #TECZNOISE VS TECMNOISE
        [freqs_TECZNvTECMN,Cxy_TECZNvTECMN] = signal.csd(1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut,1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M,window=window,noverlap=100,nfft=512,fs=Fs);
        Pxy_TECZNvTECMN = np.abs(Cxy_TECZNvTECMN);
        R_TECZNvTECMN = np.corrcoef(1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut,1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M);
        
        #RECORD FOR POSTERITY
        TECZvTECZN_mat[:,i] = Pxy_TECZvTECZN;
        TECMvTECMN_mat[:,i] = Pxy_TECMvTECMN;
        ZvTECZN_mat[:,i] = Pxy_ZvTECZN;
        MvTECMN_mat[:,i] = Pxy_MvTECMN;
        R_TECZvTECZN_mat[:,i] = R_TECZvTECZN.flatten();
        R_ZvTECZN_mat[:,i] = R_ZvTECZN.flatten();
        R_TECMvTECMN_mat[:,i] = R_TECMvTECMN.flatten();
        R_MvTECMN_mat[:,i] = R_MvTECMN.flatten();
        #compare noises
        TECZNvTECMN_mat[:,i] = Pxy_TECZNvTECMN;
        R_TECZNvTECMN_mat[:,i] = R_TECZNvTECMN.flatten();
    #END FOR i
    Pxy_TECZvTECZN = np.mean(TECZvTECZN_mat,axis=1);
    Pxy_TECMvTECMN = np.mean(TECMvTECMN_mat,axis=1);
    Pxy_ZvTECZN = np.mean(ZvTECZN_mat,axis=1);
    Pxy_MvTECMN = np.mean(MvTECMN_mat,axis=1);
    #Real quick side move to calc correlation coefficients
    R_TECZvTECZN = np.mean(R_TECZvTECZN_mat,axis=1)[1];
    R_ZvTECZN = np.mean(R_ZvTECZN_mat,axis=1)[1];
    R_TECMvTECMN = np.mean(R_TECMvTECMN_mat,axis=1)[1];
    R_MvTECMN = np.mean(R_MvTECMN_mat,axis=1)[1];
    #compare noises
    Pxy_TECZNvTECMN = np.mean(TECZNvTECMN_mat,axis=1);
    R_TECZNvTECMN = np.mean(R_TECZNvTECMN_mat,axis=1)[1];
    
    #Real quick side move to calc correlation coefficients
    R_TECZvZ = np.corrcoef(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut,1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut)[0,1];
    R_TECMvM = np.corrcoef(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut)[0,1];
    R_ZvM = np.corrcoef(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut,1/pwr_M*MISA_POPL_hp_altAvgd_cutOut)[0,1];
    print('TECZvZ: '+str(np.round(R_TECZvZ,3))+' | TECMvM: '+str(np.round(R_TECMvM,3))+' | ZvM: '+str(np.round(R_ZvM,3))+ \
          ' | TECZvTECZN: '+str(np.round(R_TECZvTECZN,3))+'\nZvTECZN: '+str(np.round(R_ZvTECZN,3))+ \
          ' | TECMvTECMN: '+str(np.round(R_TECMvTECMN,3))+' | MvTECMN: '+str(np.round(R_MvTECMN,3))+' |TECZNvTECMN: '+str(np.round(R_TECZNvTECMN,3)));
    
    #----PREP TO PRINT----
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    plt.ioff() #disable showing the plot as its size will be larger than the screen, which cannot happen if the plot is shown
    fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(14,8.5),dpi=journal_dpi); #use instead of fig because it inits an axis too (I think I dunno)
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    #----PLOT THE DATA-----
    p1, = ax.plot(1/freqs_TECvZ,(Pxy_TECvZ),color='xkcd:purple',linewidth=PLOT_lineWidthRegularPlus, linestyle='--',zorder=3);
    p2, = ax.plot(1/freqs_TECvM,(Pxy_TECvM),color='xkcd:goldenrod',linewidth=PLOT_lineWidthRegularPlus, linestyle='-', marker='o',zorder=4);
    p3, = ax.plot(1/freqs_ZvM,(Pxy_ZvM),color='xkcd:cyan',linewidth=PLOT_lineWidthRegularPlus, linestyle='-',zorder=5);
    # p4, = ax.plot(1/freqs_ZvTECZN,(Pxy_ZvTECZN),color='xkcd:forest green',linewidth=PLOT_lineWidthRegularPlus, linestyle='-.',zorder=2);
    # p5, = ax.plot(1/freqs_MvTECMN,(Pxy_MvTECMN),color='xkcd:magenta',linewidth=PLOT_lineWidthRegularPlus, linestyle='-.',zorder=1);
    p6, = ax.plot(1/freqs_TECZNvTECMN,(Pxy_TECZNvTECMN),color='xkcd:magenta',linewidth=PLOT_lineWidthRegularPlus, linestyle='-.',zorder=8);
    # errorMax = np.max([Pxy_TECZvTECZN.max(),Pxy_TECMvTECMN.max(),Pxy_ZvTECZN.max(),Pxy_MvTECMN.max()]);
    errorMax = np.max(Pxy_TECZNvTECMN);
    pLine = ax.hlines(errorMax,np.min(1/freqs_TECvZ),plot_periodLim_max,color='xkcd:fire engine red',linewidth=PLOT_lineWidthDoublePlus, linestyle='-.',zorder=6);
    ax.set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    ax.set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
    # ax.set_title('Cross-Spectral Density - Noise '+str(avgPt_TECnoise_iterations)+' Iteration Average Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs w/ OMNI time delayed by'+str(time_cutout_range_delay)+' hrs on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
    #     fontproperties=FONT_titleFM);
    ax.legend([p1,p2,p3,p6,pLine],
        # ['Point TEC AVG''d to Zenith Times & HP vs Zenith HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'Point TEC AVG''d to MISA Times & HP vs MISA HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'Zenith & MISA HP AVG''d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        # 'OMNI '+OMNI_plot_label+' AVG''d to Zenith Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Zenith HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'OMNI '+OMNI_plot_label+' AVG''d to MISA Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs MISA HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'OMNI '+OMNI_plot_label+' AVG''d to Zenith Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Point TEC AVG''d to Zenith Times & HP', \
        # 'OMNI '+OMNI_plot_label+' AVG''d to MISA Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Point TEC AVG''d to MISA Times & HP', \
        ['Delta-vTEC at Zenith & Zenith N$_{e^-}$', \
        'Delta-vTEC at MISA & MISA N$_{e^-}$', \
        'Zenith N$_e$ & MISA N$_{e^-}$', \
        # 'Noise delta-vTEC at Zenith & Zenith N$_e$',\
        # 'Noise delta-vTEC at MISA & MISA N$_e$', \
        'Noise delta-vTEC at Zenith &\n Noise delta-vTEC at MISA', \
        'Effective noise floor'], \
        loc='upper left', prop=FONT_axisLabelFM);
    
    xAxisTicks = np.arange( 0, plot_periodLim_max+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    ax.set_xlim( (0, plot_periodLim_max) )
    ax.spines['right'].set_visible(False); #turn off box lines
    ax.spines['top'].set_visible(False); #turn off box lines
    #final plot adjusting stuff
    fig.subplots_adjust(left = 0.075, right = 0.977, top = 0.990, bottom = 0.085); #sets padding to small numbers for minimal white space
    #fig.tight_layout(); #function for a tight layout, doesn't seem to do much here
    fig.savefig(folder[3]+'\\avgPt_HP_timeMatch&POPL&TECNOISE_CPSD_cutOut.png'); #save the figure
    plt.close(); #close figure b/c it lurks apparently
    plt.ion(); #re-enable it for later stuff
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
#END IF

if( (FLG_avgPt_HP_timeMatch_POPLnTECNOISE_FFT_cutOut == 1) & (FLG_fancyPlot == 1) ):
    print('MAKING FANCY PLOT: TEC_avgPt_HP_timeMatch_POPLnTECNOISE_FFT_cutOut IN fancyPlot FOLDER'); #report since you won't see anything
    from mpl_toolkits.axes_grid1 import make_axes_locatable
    if( FLG_TEC_noise >= 1 ):
        print('***ERROR***: FLG_TEC_noise is '+str(FLG_TEC_noise)+' which means that the TEC comparisons are meaningless (the TEC data has been replaced with noise). Fix that and re-run for this plot to be useful!'); #report issue
        sys.exit();
    #END IF
    Zenith_time_delta = np.median(np.diff(Zenith_time)); #days, delta of time between readings
    MISA_time_delta = np.median(np.diff(MISA_time)); #days, delta of time between readings
    
    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexesZ = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    
    #MISA NOW
    time_cutout_indexesM = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut_MISA = avgPt_vTEC_timeMatch_HP_MISA[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut_MISA = avgPt_vTEC_timeMatch_time_MISA[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
            
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , 
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                             
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    from scipy import signal
#    from matplotlib import mlab
    window = np.hamming(110);
#    window= np.pad(window,(0,512-110),mode='constant')
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    
    pwr_TEC_Z = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut**2)); #estimate power of signal
    pwr_TEC_M = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut_MISA.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut_MISA**2)); #estimate power of signal
    pwr_Z = np.sqrt(1/Zenith_POPL_hp_altAvgd_cutOut.size*np.sum(Zenith_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_M = np.sqrt(1/MISA_POPL_hp_altAvgd_cutOut.size*np.sum(MISA_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    
    #ZENITH STUFF
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_TECZ,Cxx_TECZ] = signal.welch(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_Z,Cxx_Z] = signal.welch(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    
    #MISA STUFF
    Fs = 1/(MISA_time_delta*24*60); #min, misa time delta in freq form
    [freqs_TECM,Cxx_TECM] = signal.welch(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_M,Cxx_M] = signal.welch(1/pwr_M*MISA_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    
    #now, noise comparisons
    TECZN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    TECMN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    pointRadiusAngular = (avgPt_pointRadius/Re)*180/np.pi; #get the angular radius to get a small subset of points to deal with
    k = ((avgPt_coords[0,0]-pointRadiusAngular <= data['TEC']['lat']) & (avgPt_coords[0,0]+pointRadiusAngular >= data['TEC']['lat'])) & \
        ((avgPt_coords[0,1]-pointRadiusAngular <= data['TEC']['long']) & (avgPt_coords[0,1]+pointRadiusAngular >= data['TEC']['long'])); #get only east coast to lower calcs needed
    kM = ((avgPt_coords[1,0]-pointRadiusAngular <= data['TEC']['lat']) & (avgPt_coords[1,0]+pointRadiusAngular >= data['TEC']['lat'])) & \
        ((avgPt_coords[1,1]-pointRadiusAngular <= data['TEC']['long']) & (avgPt_coords[1,1]+pointRadiusAngular >= data['TEC']['long'])); #get only east coast to lower calcs needed
    for i in range(0,avgPt_TECnoise_iterations):
        TEC_noise = GRITI_TEC_randomSynth(data['TEC']['lat'][k].size,data['TEC']['lat'][k],data['TEC']['long'][k],data['TEC']['time'][k], \
            noise_background_mean,noise_background_stdev,Re,dateRange_zeroHr, \
            plotLatRange,plotLongRange,plotLatRange_autoTick,plotLongRange_autoTick, \
            wave_latRange,wave_longRange,wave_N,wave_angle,wave_phase,wave_waveLength,wave_period,wave_amp, \
            FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,TEC_plotLimValu,1,FLG_plotStuff=0); #replace the delta-vTEC data with random data 
        
        TEC_noiseM = GRITI_TEC_randomSynth(data['TEC']['lat'][kM].size,data['TEC']['lat'][kM],data['TEC']['long'][kM],data['TEC']['time'][kM], \
            noise_background_mean,noise_background_stdev,Re,dateRange_zeroHr, \
            plotLatRange,plotLongRange,plotLatRange_autoTick,plotLongRange_autoTick, \
            wave_latRange,wave_longRange,wave_N,wave_angle,wave_phase,wave_waveLength,wave_period,wave_amp, \
            FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,TEC_plotLimValu,1,FLG_plotStuff=0); #replace the delta-vTEC data with random data 
        
        avgPt_TECnoise, _, avgPt_TECnoise_time, _, _, _  = \
            GRITI_TEC_avgPt(TEC_timeUnique,data['TEC']['lat'][k],data['TEC']['long'][k],data['TEC']['time'][k],TEC_noise, \
            avgPt_coords[0,:],avgPt_pointRadius,Re,dateRange_dayNum_zeroHr, \
            dataReject,dataRejectOrig,dataRejectLimit,dataRejectLimitOrig,dataRejectMax,FLG_report=0); #average points in a radius
            
        _, avgPt_TECnoise_timeMatch_HP, _ = GRITI_TEC_avgPt_timeMatch(avgPt_TECnoise,avgPt_TECnoise_time,Zenith_time,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);

        avgPt_TECnoise_timeMatch_HP_cutOut = avgPt_TECnoise_timeMatch_HP[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];

        avgPt_TECnoise_M, _, avgPt_TECnoise_time_M, _, _, _  = \
            GRITI_TEC_avgPt(TEC_timeUnique,data['TEC']['lat'][kM],data['TEC']['long'][kM],data['TEC']['time'][kM],TEC_noiseM, \
            avgPt_coords[1,:],avgPt_pointRadius,Re,dateRange_dayNum_zeroHr, \
            dataReject,dataRejectOrig,dataRejectLimit,dataRejectLimitOrig,dataRejectMax,FLG_report=0); #average points in a radius
        
        _, avgPt_TECnoise_timeMatch_HP_M, _ = GRITI_TEC_avgPt_timeMatch(avgPt_TECnoise_M,avgPt_TECnoise_time_M,MISA_time,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
        
        avgPt_TECnoise_timeMatch_HP_cutOut_M = avgPt_TECnoise_timeMatch_HP_M[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
        
        pwr_TECZN = np.sqrt(1/avgPt_TECnoise_timeMatch_HP_cutOut.size*np.sum(avgPt_TECnoise_timeMatch_HP_cutOut**2)); #estimate power of signal
        pwr_TECMN = np.sqrt(1/avgPt_TECnoise_timeMatch_HP_cutOut_M.size*np.sum(avgPt_TECnoise_timeMatch_HP_cutOut_M**2)); #estimate power of signal
        
        #ZENITH RELATED STUFF
        Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
        #TECZNOISE
        [freqs_TECZN,Cxx_TECZN] = signal.welch(1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
        #MISA RELATED STUFF
        Fs = 1/(MISA_time_delta*24*60); #min, misa time delta in freq form
        #TECMNOISE
        [freqs_TECMN,Cxx_TECMN] = signal.welch(1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M ,window=window,noverlap=100,nfft=512,fs=Fs);
        
        #RECORD FOR POSTERITY
        TECZN_mat[:,i] = Cxx_TECZN;
        TECMN_mat[:,i] = Cxx_TECMN;
    #END FOR i
    Cxx_TECZN = np.mean(TECZN_mat,axis=1);
    Cxx_TECMN = np.mean(TECMN_mat,axis=1);
    
    #----PREP TO PRINT----
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    plt.ioff() #disable showing the plot as its size will be larger than the screen, which cannot happen if the plot is shown
    fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(14,8.5),dpi=journal_dpi); #use instead of fig because it inits an axis too (I think I dunno)
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    #----PLOT THE DATA-----
    p1, = ax.plot(1/freqs_TECZ,(Cxx_TECZ),color='xkcd:red',linewidth=PLOT_lineWidthRegularPlus, linestyle='-', marker='o');
    p2, = ax.plot(1/freqs_TECM,(Cxx_TECM),color='xkcd:periwinkle',linewidth=PLOT_lineWidthRegularPlus, linestyle='-');
    p3, = ax.plot(1/freqs_Z,(Cxx_Z),color='xkcd:electric blue',linewidth=PLOT_lineWidthRegularPlus, linestyle='--');
    p4, = ax.plot(1/freqs_M,(Cxx_M),color='xkcd:neon green',linewidth=PLOT_lineWidthRegularPlus, linestyle='-.');
    p5, = ax.plot(1/freqs_TECZN,(Cxx_TECZN),color='xkcd:salmon',linewidth=PLOT_lineWidthRegularPlus, linestyle=':');
    p6, = ax.plot(1/freqs_TECMN,(Cxx_TECMN),color='xkcd:mauve',linewidth=PLOT_lineWidthRegularPlus, linestyle=':');
    errorMax = np.max([Cxx_TECZN.max(),Cxx_TECMN.max()]);
    pLine = ax.hlines(errorMax,np.min(1/freqs_TECZ),plot_periodLim_max,color='xkcd:fire engine red',linewidth=PLOT_lineWidthDoublePlus, linestyle='-.');
    ax.set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    ax.set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
    # ax.set_title('Power Spectra - Noise '+str(avgPt_TECnoise_iterations)+' Iteration Average Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs at Millstone '+str(np.round(latMillstone,2))+' degc lat/'+str(np.round(longMillstone,2))+' deg long on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
    #     fontproperties=FONT_titleFM);
    # ax.set_title('Cross-Spectral Density - Noise '+str(avgPt_TECnoise_iterations)+' Iteration Average Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs w/ OMNI time delayed by'+str(time_cutout_range_delay)+' hrs on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
    #     fontproperties=FONT_titleFM);
    ax.legend([p1,p2,p3,p4,p5,p6,pLine],
        # ['Point TEC AVG''d to Zenith Times & HP vs Zenith HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'Point TEC AVG''d to MISA Times & HP vs MISA HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'Zenith & MISA HP AVG''d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        # 'OMNI '+OMNI_plot_label+' AVG''d to Zenith Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Zenith HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'OMNI '+OMNI_plot_label+' AVG''d to MISA Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs MISA HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'OMNI '+OMNI_plot_label+' AVG''d to Zenith Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Point TEC AVG''d to Zenith Times & HP', \
        # 'OMNI '+OMNI_plot_label+' AVG''d to MISA Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Point TEC AVG''d to MISA Times & HP', \
        ['Delta-vTEC at Zenith', \
        'Delta-vTEC at MISA', \
        'Zenith N$_e$', \
        'MISA N$_e$', \
        'Noise delta-vTEC at Zenith',\
        'Noise delta-vTEC at MISA', \
        'Effective noise floor'], \
        loc='upper left', prop=FONT_axisLabelFM);
    
    xAxisTicks = np.arange( 0, plot_periodLim_max+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    ax.set_xlim( (0, plot_periodLim_max) )
    ax.spines['right'].set_visible(False); #turn off box lines
    ax.spines['top'].set_visible(False); #turn off box lines
    #final plot adjusting stuff
    fig.subplots_adjust(left = 0.075, right = 0.977, top = 0.990, bottom = 0.085); #sets padding to small numbers for minimal white space
    #fig.tight_layout(); #function for a tight layout, doesn't seem to do much here
    fig.savefig(folder[3]+'\\avgPt_HP_timeMatch&POPL&TECNOISE_FFT_cutOut.png'); #save the figure
    plt.close(); #close figure b/c it lurks apparently
    plt.ion(); #re-enable it for later stuff
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
#END IF
    
if( FLG_avgPt_HP_timeMatch_POPLnOMNInTECNOISE_FFT_cutOut == 1 ):
    if( FLG_TEC_noise >= 1 ):
        print('***WARNING***: FLG_TEC_noise is '+str(FLG_TEC_noise)+' which means that the TEC comparisons are meaningless (the TEC data has been replaced with noise). Fix that and re-run for this plot to be useful!'); #report issue
    #END IF
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    Zenith_time_delta = np.median(np.diff(Zenith_time)); #days, delta of time between readings
    MISA_time_delta = np.median(np.diff(MISA_time)); #days, delta of time between readings
    
    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexesZ = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
    
    #MISA NOW
    time_cutout_indexesM = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut_MISA = avgPt_vTEC_timeMatch_HP_MISA[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut_MISA = avgPt_vTEC_timeMatch_time_MISA[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
            
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , 
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                             
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #OMNI plot prep
    OMNI_plot_label = OMNI_dictPlot[OMNI_dict[OMNI_plot_name]]; #get the label
    OMNI_plot_labelNoUnits = OMNI_plot_label[0:OMNI_plot_label.find('[')-1]; #remove the (units)
    
    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) ) )[0][0] , \
        np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    OMNI_data_timeMatch_HP_Zenith_cutOut = OMNI_data_timeMatch_HP_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    OMNI_data_timeMatch_time_Zenith_cutOut = OMNI_data_timeMatch_time_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #MISA NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range_delayed_OMNI) ) )[0][0] , \
        np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range_delayed_OMNI) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    OMNI_data_timeMatch_HP_MISA_cutOut = OMNI_data_timeMatch_HP_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    OMNI_data_timeMatch_time_MISA_cutOut = OMNI_data_timeMatch_time_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    from scipy import signal
#    from matplotlib import mlab
    window = np.hamming(110);
#    window= np.pad(window,(0,512-110),mode='constant')
    
    pwr_TEC_Z = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut**2)); #estimate power of signal
    pwr_TEC_M = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut_MISA.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut_MISA**2)); #estimate power of signal
    pwr_Z = np.sqrt(1/Zenith_POPL_hp_altAvgd_cutOut.size*np.sum(Zenith_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_M = np.sqrt(1/MISA_POPL_hp_altAvgd_cutOut.size*np.sum(MISA_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_OMNI_Z = np.sqrt(1/OMNI_data_timeMatch_HP_Zenith_cutOut.size*np.sum(OMNI_data_timeMatch_HP_Zenith_cutOut**2)); #estimate power of signal
    pwr_OMNI_M = np.sqrt(1/OMNI_data_timeMatch_HP_MISA_cutOut.size*np.sum(OMNI_data_timeMatch_HP_MISA_cutOut**2)); #estimate power of signal
    
    #ZENITH STUFF
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_TECZ,Cxx_TECZ] = signal.welch(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_Z,Cxx_Z] = signal.welch(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_OMNIZ,Cxx_OMNIZ] = signal.welch(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    
    #MISA STUFF
    Fs = 1/(MISA_time_delta*24*60); #min, misa time delta in freq form
    [freqs_TECM,Cxx_TECM] = signal.welch(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_M,Cxx_M] = signal.welch(1/pwr_M*MISA_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_OMNIM,Cxx_OMNIM] = signal.welch(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);

    #now, noise comparisons
    TECZN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    TECMN_mat = np.zeros([np.int64(512/2+1),avgPt_TECnoise_iterations]);
    pointRadiusAngular = (avgPt_pointRadius/Re)*180/np.pi; #get the angular radius to get a small subset of points to deal with
    k = ((avgPt_coords[0,0]-pointRadiusAngular <= data['TEC']['lat']) & (avgPt_coords[0,0]+pointRadiusAngular >= data['TEC']['lat'])) & \
        ((avgPt_coords[0,1]-pointRadiusAngular <= data['TEC']['long']) & (avgPt_coords[0,1]+pointRadiusAngular >= data['TEC']['long'])); #get only east coast to lower calcs needed
    kM = ((avgPt_coords[1,0]-pointRadiusAngular <= data['TEC']['lat']) & (avgPt_coords[1,0]+pointRadiusAngular >= data['TEC']['lat'])) & \
        ((avgPt_coords[1,1]-pointRadiusAngular <= data['TEC']['long']) & (avgPt_coords[1,1]+pointRadiusAngular >= data['TEC']['long'])); #get only east coast to lower calcs needed
    for i in range(0,avgPt_TECnoise_iterations):
        TEC_noise = GRITI_TEC_randomSynth(data['TEC']['lat'][k].size,data['TEC']['lat'][k],data['TEC']['long'][k],data['TEC']['time'][k], \
            noise_background_mean,noise_background_stdev,Re,dateRange_zeroHr, \
            plotLatRange,plotLongRange,plotLatRange_autoTick,plotLongRange_autoTick, \
            wave_latRange,wave_longRange,wave_N,wave_angle,wave_phase,wave_waveLength,wave_period,wave_amp, \
            FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,TEC_plotLimValu,1,FLG_plotStuff=0); #replace the delta-vTEC data with random data 
            
        TEC_noiseM = GRITI_TEC_randomSynth(data['TEC']['lat'][kM].size,data['TEC']['lat'][kM],data['TEC']['long'][kM],data['TEC']['time'][kM], \
            noise_background_mean,noise_background_stdev,Re,dateRange_zeroHr, \
            plotLatRange,plotLongRange,plotLatRange_autoTick,plotLongRange_autoTick, \
            wave_latRange,wave_longRange,wave_N,wave_angle,wave_phase,wave_waveLength,wave_period,wave_amp, \
            FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,TEC_plotLimValu,1,FLG_plotStuff=0); #replace the delta-vTEC data with random data 
        
        avgPt_TECnoise, _, avgPt_TECnoise_time, _, _, _  = \
            GRITI_TEC_avgPt(TEC_timeUnique,data['TEC']['lat'][k],data['TEC']['long'][k],data['TEC']['time'][k],TEC_noise, \
            avgPt_coords[0,:],avgPt_pointRadius,Re,dateRange_dayNum_zeroHr, \
            dataReject,dataRejectOrig,dataRejectLimit,dataRejectLimitOrig,dataRejectMax,FLG_report=0); #average points in a radius
            
        _, avgPt_TECnoise_timeMatch_HP, _ = GRITI_TEC_avgPt_timeMatch(avgPt_TECnoise,avgPt_TECnoise_time,Zenith_time,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);

        avgPt_TECnoise_timeMatch_HP_cutOut = avgPt_TECnoise_timeMatch_HP[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];

        avgPt_TECnoise_M, _, avgPt_TECnoise_time_M, _, _, _  = \
            GRITI_TEC_avgPt(TEC_timeUnique,data['TEC']['lat'][kM],data['TEC']['long'][kM],data['TEC']['time'][kM],TEC_noiseM, \
            avgPt_coords[1,:],avgPt_pointRadius,Re,dateRange_dayNum_zeroHr, \
            dataReject,dataRejectOrig,dataRejectLimit,dataRejectLimitOrig,dataRejectMax,FLG_report=0); #average points in a radius
        
        _, avgPt_TECnoise_timeMatch_HP_M, _ = GRITI_TEC_avgPt_timeMatch(avgPt_TECnoise_M,avgPt_TECnoise_time_M,MISA_time,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
        
        avgPt_TECnoise_timeMatch_HP_cutOut_M = avgPt_TECnoise_timeMatch_HP_M[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
        
        pwr_TECZN = np.sqrt(1/avgPt_TECnoise_timeMatch_HP_cutOut.size*np.sum(avgPt_TECnoise_timeMatch_HP_cutOut**2)); #estimate power of signal
        pwr_TECMN = np.sqrt(1/avgPt_TECnoise_timeMatch_HP_cutOut_M.size*np.sum(avgPt_TECnoise_timeMatch_HP_cutOut_M**2)); #estimate power of signal
        
        #ZENITH RELATED STUFF
        Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
        #TECZNOISE
        [freqs_TECZN,Cxx_TECZN] = signal.welch(1/pwr_TECZN*avgPt_TECnoise_timeMatch_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
        #MISA RELATED STUFF
        Fs = 1/(MISA_time_delta*24*60); #min, misa time delta in freq form
        #TECMNOISE
        [freqs_TECMN,Cxx_TECMN] = signal.welch(1/pwr_TECMN*avgPt_TECnoise_timeMatch_HP_cutOut_M ,window=window,noverlap=100,nfft=512,fs=Fs);
        
        #RECORD FOR POSTERITY
        TECZN_mat[:,i] = Cxx_TECZN;
        TECMN_mat[:,i] = Cxx_TECMN;
    #END FOR i
    Cxx_TECZN = np.mean(TECZN_mat,axis=1);
    Cxx_TECMN = np.mean(TECMN_mat,axis=1);
    
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    p1, = ax.plot(1/freqs_TECZ,(Cxx_TECZ),color='xkcd:cerulean',linewidth=PLOT_lineWidthRegular, linestyle='-');
    p2, = ax.plot(1/freqs_TECM,(Cxx_TECM),color='xkcd:deep red',linewidth=PLOT_lineWidthRegular, linestyle='--');
    p3, = ax.plot(1/freqs_Z,(Cxx_Z),color='xkcd:goldenrod',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p4, = ax.plot(1/freqs_M,(Cxx_M),color='xkcd:purple',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p5, = ax.plot(1/freqs_OMNIZ,(Cxx_OMNIZ),color='xkcd:dark gray',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p6, = ax.plot(1/freqs_OMNIM,(Cxx_OMNIM),color='xkcd:forest green',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p7, = ax.plot(1/freqs_TECZN,(Cxx_TECZN),color='xkcd:orange',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p8, = ax.plot(1/freqs_TECMN,(Cxx_TECMN),color='xkcd:lavender',linewidth=PLOT_lineWidthRegular, linestyle='--');
    errorMax = np.max([Cxx_TECZN.max(),Cxx_TECMN.max()]);
    pLine = ax.hlines(errorMax,np.min(1/freqs_TECZ),plot_periodLim_max,color='xkcd:fire engine red',linewidth=PLOT_lineWidthRegular, linestyle='--');
    ax.set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    ax.set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
    ax.set_title('Power Spectra - Noise '+str(avgPt_TECnoise_iterations)+' Iteration Average Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs at Millstone '+str(np.round(latMillstone,2))+' degc lat/'+str(np.round(longMillstone,2))+' deg long on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
        fontproperties=FONT_titleFM);
    ax.legend([p1,p2,p3,p4,p5,p6,p7,p8],
        # ['Point TEC AVG''d to Zenith Times & HP vs Zenith HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'Point TEC AVG''d to MISA Times & HP vs MISA HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'Zenith & MISA HP AVG''d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        # 'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to Zenith Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Zenith HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to MISA Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs MISA HP AVG''d '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km', \
        # 'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to Zenith Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Point TEC AVG''d to Zenith Times & HP', \
        # 'OMNI '+OMNI_plot_labelNoUnits+' AVG''d to MISA Times & HP (Time Delayed '+str(time_cutout_range_delay)+' hrs) vs Point TEC AVG''d to MISA Times & HP', \
        ['TEC@Z', \
        'TEC@M', \
        'Z ISR', \
        'M ISR', \
        'OMNI@Z'+' '+str(OMNI_delay_wrt_TEC)+' hr', \
        'OMNI@M'+' '+str(OMNI_delay_wrt_TEC)+' hr', \
        'TECnoise@Z',\
        'TECnoise@M'],\
        loc='upper left');
    
    xAxisTicks = np.arange( 0, plot_periodLim_max+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    ax.set_xlim( (np.min(1/freqs_TECvZ), plot_periodLim_max) )
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.065, right = 0.975, top = 0.96, bottom = 0.065 , hspace = 0.225); #sets padding to small numbers for minimal white space
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
#END IF

if( FLG_avgPt_HP_timeMatch_POPLnAMPERE_FFT_cutOut == 1 ):
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    Zenith_time_delta = np.median(np.diff(Zenith_time)); #days, delta of time between readings
    MISA_time_delta = np.median(np.diff(MISA_time)); #days, delta of time between readings

    #ZENITH NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    # Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #MISA NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut_MISA = avgPt_vTEC_timeMatch_HP_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut_MISA = avgPt_vTEC_timeMatch_time_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
            
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , 
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                             
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    # MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    #AMPERE plot prep
    AMPERE_timeUnique_hr = (AMPERE_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    if( np.mod(np.round(np.min(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr))+1; #is odd, make even
    #END IF
    if( np.mod(np.round(np.max(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr))-1; #is odd, make even
    #END IF
    
    if( (np.min(plotLatRange) >= 0) & (np.max(plotLatRange) >= 0) ):
        #northern hemisphere
        kInRange = data['AMPERE']['lat'] >= 0; #get data in the range
    else:
        #southern hemisphere
        kInRange = data['AMPERE']['lat'] <= 0; #get data in the range
    #END IF
    
    AMPERE_integrate = np.zeros( AMPERE_timeUnique_hr.size , dtype=np.float64); #prep integrated joule heating
    for i in range(AMPERE_timeUnique_hr.size):
        k = AMPERE_timeUnique[i] == data['AMPERE']['time']; #get the right time
        AMPERE_integrate[i] = np.sum((data['AMPERE'][k&kInRange,AMPERE_plot_index])); #ergs/(cm^2*sec), get the Joule Heating for the current time stamp
    #END FOR i
    
    if( FLG_AMPERE_log == 1 ):
        strLog = 'Log of '; #set the string
        AMPERE_integrate = np.log10(AMPERE_integrate); #log it
        if( FLG_AMPERE_hp == 1 ):
            #want to highpass after the log, b/c negatives ruin log
            AMPERE_integrate = subfun_highpass(AMPERE_timeUnique_hr, AMPERE_integrate); #highpass the data
        #END IF
    else:
        strLog = ''; #nothing to say
        if( FLG_AMPERE_hp == 1 ):
            AMPERE_integrate = subfun_highpass(AMPERE_timeUnique_hr, AMPERE_integrate); #highpass the data
        #END IF
    #END IF
    
    AMPERE_plot_label = settings['AMPERE']['labels'][AMPERE_dataType]+settings['AMPERE']['units'][AMPERE_dataType]; #get the label
    AMPERE_plot_label_noUnits = settings['AMPERE']['labels'][AMPERE_dataType]; #remove the (units)
    
    #no time alignment yet NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( AMPERE_timeUnique_hr - np.min(time_cutout_range_delayed_AMPERE) )) == np.abs( AMPERE_timeUnique_hr - np.min(time_cutout_range_delayed_AMPERE) ) )[0][0] , \
        np.where(np.min(np.abs( AMPERE_timeUnique_hr - np.max(time_cutout_range_delayed_AMPERE) )) == np.abs( AMPERE_timeUnique_hr - np.max(time_cutout_range_delayed_AMPERE) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    AMPERE_integrate_cutOut = AMPERE_integrate[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    AMPERE_timeUnique_hr_cutOut = AMPERE_timeUnique_hr[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    
    from scipy import signal
#    from matplotlib import mlab
    window = np.hamming(110);
#    window= np.pad(window,(0,512-110),mode='constant')
    
    pwr_TEC_Z = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut**2)); #estimate power of signal
    pwr_TEC_M = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut_MISA.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut_MISA**2)); #estimate power of signal
    pwr_Z = np.sqrt(1/Zenith_POPL_hp_altAvgd_cutOut.size*np.sum(Zenith_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_M = np.sqrt(1/MISA_POPL_hp_altAvgd_cutOut.size*np.sum(MISA_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
    pwr_AMPERE = np.sqrt(1/AMPERE_integrate_cutOut.size*np.sum(AMPERE_integrate_cutOut**2)); #estimate power of signal
    
    Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
    [freqs_TECZ,Cxx_TECZ] = signal.welch(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_Z,Cxx_Z] = signal.welch(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_AMPERE,Cxx_AMPERE] = signal.welch(1/pwr_AMPERE*AMPERE_integrate_cutOut ,window=window,noverlap=100,nfft=512,fs=1/(np.median(np.diff(AMPERE_timeUnique_hr))*60));
    
    Fs = 1/(MISA_time_delta*24*60); #min, MISA time delta in freq form
    [freqs_TECM,Cxx_TECM] = signal.welch(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA ,window=window,noverlap=100,nfft=512,fs=Fs);
    [freqs_M,Cxx_M] = signal.welch(1/pwr_M*MISA_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
    
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    p1, = ax.plot(1/freqs_TECZ,(Cxx_TECZ),color='xkcd:cerulean',linewidth=PLOT_lineWidthRegular, linestyle='-');
    p2, = ax.plot(1/freqs_TECM,(Cxx_TECM),color='xkcd:deep red',linewidth=PLOT_lineWidthRegular, linestyle='--');
    p3, = ax.plot(1/freqs_Z,(Cxx_Z),color='xkcd:goldenrod',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p4, = ax.plot(1/freqs_M,(Cxx_M),color='xkcd:purple',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    p5, = ax.plot(1/freqs_AMPERE,(Cxx_AMPERE),color='xkcd:forest green',linewidth=PLOT_lineWidthRegular, linestyle='-.');
    ax.set_xlim( (0, plot_periodLim_max) )
    ax.set_xlabel('Periods [min]',fontproperties=FONT_axisLabelFM);
    ax.set_ylabel('Arb. Power',fontproperties=FONT_axisLabelFM);
    ax.set_title('Spectral Comparison - (TEC HP\'d) Time Limited to '+textNice(np.round(time_cutout_range[0]/3600,2))+' to '+textNice(np.round(time_cutout_range[-1]/3600,2))+' hrs at Millstone '+str(np.round(latMillstone,2))+' degc lat/'+str(np.round(longMillstone,2))+' deg long on Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]), \
        fontproperties=FONT_titleFM);
    ax.legend([p1,p2,p3,p4,p5],['Point TEC AVG''d to Zenith Times & HP', \
        'Point TEC AVG''d to MISA Times & HP', \
        'Zenith HP AVG''d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        'MISA HP AVG''d to '+str(pointAltitude)+' km +/-'+str(avgPt_ISRavgAlt)+' km',\
        strLog+'AMPERE '+AMPERE_plot_label_noUnits+' (Time Delayed '+str(AMPERE_delay_wrt_TEC)+' hrs)'], \
        loc='upper left');
    
    xAxisTicks = np.arange( 0, plot_periodLim_max+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.065, right = 0.975, top = 0.96, bottom = 0.065 , hspace = 0.225); #sets padding to small numbers for minimal white space
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
#END IF

#==============Analysis: Plot the delta-vTEC point-averaged time series with the ISR POPL HP altitude-averaged time series, along with an ISR RTI plot, over a cut-out time period==============
if( FLG_avgPt_HP_timeMatch_POPLnAMPERE_plotWithISR_ZenithOnly_cutOut == 1 ):
    #ZENITH ONLY - NO MISA!!!
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range

    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
        #AMPERE plot prep
    AMPERE_timeUnique_hr = (AMPERE_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    if( np.mod(np.round(np.min(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr))+1; #is odd, make even
    #END IF
    if( np.mod(np.round(np.max(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr))-1; #is odd, make even
    #END IF
    
    if( (np.min(plotLatRange) >= 0) & (np.max(plotLatRange) >= 0) ):
        #northern hemisphere
        kInRange = data['AMPERE']['lat'] >= 0; #get data in the range
    else:
        #southern hemisphere
        kInRange = data['AMPERE']['lat'] <= 0; #get data in the range
    #END IF
    
    AMPERE_integrate = np.zeros( AMPERE_timeUnique_hr.size , dtype=np.float64); #prep integrated joule heating
    for i in range(AMPERE_timeUnique_hr.size):
        k = AMPERE_timeUnique[i] == data['AMPERE']['time']; #get the right time
        AMPERE_integrate[i] = np.sum((data['AMPERE'][k&kInRange,AMPERE_plot_index])); #ergs/(cm^2*sec), get the Joule Heating for the current time stamp
    #END FOR i
    
    if( FLG_AMPERE_log == 1 ):
        strLog = 'Log of '; #set the string
        AMPERE_integrate = np.log10(AMPERE_integrate); #log it
        if( FLG_AMPERE_hp == 1 ):
            #want to highpass after the log, b/c negatives ruin log
            AMPERE_integrate = subfun_highpass(AMPERE_timeUnique_hr, AMPERE_integrate); #highpass the data
        #END IF
    else:
        strLog = ''; #nothing to say
        if( FLG_AMPERE_hp == 1 ):
            AMPERE_integrate = subfun_highpass(AMPERE_timeUnique_hr, AMPERE_integrate); #highpass the data
        #END IF
    #END IF
    
    AMPERE_plot_label = settings['AMPERE']['labels'][AMPERE_dataType]+settings['AMPERE']['units'][AMPERE_dataType]; #get the label
    AMPERE_plot_label_noUnits = settings['AMPERE']['labels'][AMPERE_dataType]; #remove the (units)
    
    #no time alignment yet NOW
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( AMPERE_timeUnique_hr - np.min(time_cutout_range_delayed_AMPERE) )) == np.abs( AMPERE_timeUnique_hr - np.min(time_cutout_range_delayed_AMPERE) ) )[0][0] , \
        np.where(np.min(np.abs( AMPERE_timeUnique_hr - np.max(time_cutout_range_delayed_AMPERE) )) == np.abs( AMPERE_timeUnique_hr - np.max(time_cutout_range_delayed_AMPERE) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    AMPERE_integrate_cutOut = AMPERE_integrate[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( AMPERE_timeUnique_hr - np.min(time_cutout_range) )) == np.abs( AMPERE_timeUnique_hr - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( AMPERE_timeUnique_hr - np.max(time_cutout_range) )) == np.abs( AMPERE_timeUnique_hr - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    AMPERE_timeUnique_hr_cutOut = AMPERE_timeUnique_hr[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    GRITI_TEC_avgPt_HP_timeMatch_POPLnAMPERE_plotWithISR_ZenithOnly_cutOut(avgPt_vTEC_timeMatch_HP_cutOut,avgPt_vTEC_timeMatch_time_cutOut, \
        Zenith_time_cutOut,Zenith_height,Zenith_POPL_hp_cutOut,Zenith_POPL_hp_altAvgd_cutOut,MISA_time_cutOut,MISA_height,MISA_POPL_hp_altAvgd_cutOut, \
        AMPERE_integrate_cutOut, AMPERE_timeUnique_hr_cutOut, AMPERE_plot_label, AMPERE_plot_label_noUnits, FLG_AMPERE_log, FLG_AMPERE_hp, \
        settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_POPL_plotLimValu,avgPt_coords[0,:],avgPt_ISRavgAlt,pointAltitude,time_cutout_range, AMPERE_delay_wrt_TEC, \
        dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM,PLOT_lineWidth);
#END IF


if( FLG_avgPt_HP_timeMatch_FFTthruTime_POPLnOMNI == 1 ):
    from scipy import signal
#    from matplotlib import mlab
    window = np.hamming(110);
#    window= np.pad(window,(0,512-110),mode='constant')
    Zenith_time_delta = np.median(np.diff(Zenith_time)); #days, delta of time between readings
    MISA_time_delta = np.median(np.diff(MISA_time)); #days, delta of time between readings
    
    #OMNI plot prep
    OMNI_plot_label = OMNI_dictPlot[OMNI_dict[OMNI_plot_name]]; #get the label
    OMNI_plot_labelNoUnits = OMNI_plot_label[0:OMNI_plot_label.find('[')-1]; #remove the (units)
    
    time_range = np.array( ((time_Ref[0]-dateRange_dayNum_zeroHr[1]*86400)/3600 , (time_Ref[-1]-dateRange_dayNum_zeroHr[1]*86400)/3600) ); #make a time range based on the reference time
    time_rangeRound = np.int64(np.floor(np.abs(time_range))*(time_range/np.abs(time_range))); #get the absolute hours - absolute shennanigans are to get floor to floor -11.3 -> -11 and not -12
    thruTime_num = np.int64((np.diff(time_rangeRound).item()-thruTime_width)/thruTime_step)+1; #number of times the time_rangeRound can be split into the required width and step size
    thruTime = np.zeros( (thruTime_num,2) ); #prep array
    for i in range(0,thruTime_num):
        thruTime[i,0] = time_rangeRound[0]+i*thruTime_step; #get the starting time
        thruTime[i,1] = thruTime[i,0] + thruTime_width; #get the ending time
    #END FOR i
    
    thruTime_spectral = np.zeros([6,thruTime_num,np.int64(512/2+1)]); #prep a holder for the spectral info
    for i in range(0,thruTime_num):
        #ZENITH NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) ) )[0][0] , \
            np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) )) == np.abs( (avgPt_vTEC_timeMatch_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) ) )[0][0] ) ); #get the indexes for that time cutout range
        
        avgPt_vTEC_timeMatch_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        avgPt_vTEC_timeMatch_time_cutOut = avgPt_vTEC_timeMatch_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
        time_cutout_indexesZ = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) ) )[0][0] , \
            np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) ) )[0][0] ) ); #get the indexes for that time cutout range
        
        Zenith_time_cutOut = Zenith_time[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
        Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
        Zenith_POPL_hp_altAvgd_cutOut = Zenith_POPL_hp_altAvgd[time_cutout_indexesZ[0]:time_cutout_indexesZ[1]+1];
        
        #MISA NOW
        time_cutout_indexesM = np.array( ( np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) ) )[0][0] , \
            np.where(np.min(np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) )) == np.abs( (avgPt_vTEC_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) ) )[0][0] ) ); #get the indexes for that time cutout range
        
        avgPt_vTEC_timeMatch_HP_cutOut_MISA = avgPt_vTEC_timeMatch_HP_MISA[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
        avgPt_vTEC_timeMatch_time_cutOut_MISA = avgPt_vTEC_timeMatch_time_MISA[time_cutout_indexesM[0]:time_cutout_indexesM[1]+1];
                
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) ) )[0][0] , 
            np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) ) )[0][0] ) ); #get the indexes for that time cutout range
                                 
        MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        MISA_POPL_hp_altAvgd_cutOut = MISA_POPL_hp_altAvgd[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
        #ZENITH NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]+OMNI_delay_wrt_TEC) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]+OMNI_delay_wrt_TEC) ) )[0][0] , \
            np.where(np.min(np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]+OMNI_delay_wrt_TEC) )) == np.abs( (OMNI_data_timeMatch_time_Zenith-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]+OMNI_delay_wrt_TEC) ) )[0][0] ) ); #get the indexes for that time cutout range
        
        OMNI_data_timeMatch_HP_Zenith_cutOut = OMNI_data_timeMatch_HP_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        OMNI_data_timeMatch_time_Zenith_cutOut = OMNI_data_timeMatch_time_Zenith[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
        #MISA NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]+OMNI_delay_wrt_TEC) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]+OMNI_delay_wrt_TEC) ) )[0][0] , \
            np.where(np.min(np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]+OMNI_delay_wrt_TEC) )) == np.abs( (OMNI_data_timeMatch_time_MISA-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]+OMNI_delay_wrt_TEC) ) )[0][0] ) ); #get the indexes for that time cutout range
        
        OMNI_data_timeMatch_HP_MISA_cutOut = OMNI_data_timeMatch_HP_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        OMNI_data_timeMatch_time_MISA_cutOut = OMNI_data_timeMatch_time_MISA[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
        #do some spectral analysis on this
        pwr_TEC_Z = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut**2)); #estimate power of signal
        pwr_TEC_M = np.sqrt(1/avgPt_vTEC_timeMatch_HP_cutOut_MISA.size*np.sum(avgPt_vTEC_timeMatch_HP_cutOut_MISA**2)); #estimate power of signal
        pwr_Z = np.sqrt(1/Zenith_POPL_hp_altAvgd_cutOut.size*np.sum(Zenith_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
        pwr_M = np.sqrt(1/MISA_POPL_hp_altAvgd_cutOut.size*np.sum(MISA_POPL_hp_altAvgd_cutOut**2)); #estimate power of signal
        pwr_OMNI_Z = np.sqrt(1/OMNI_data_timeMatch_HP_Zenith_cutOut.size*np.sum(OMNI_data_timeMatch_HP_Zenith_cutOut**2)); #estimate power of signal
        pwr_OMNI_M = np.sqrt(1/OMNI_data_timeMatch_HP_MISA_cutOut.size*np.sum(OMNI_data_timeMatch_HP_MISA_cutOut**2)); #estimate power of signal
        
        #ZENITH STUFF
        Fs = 1/(Zenith_time_delta*24*60); #min, zenith time delta in freq form
        [freqs_TECZ,Cxx_TECZ] = signal.welch(1/pwr_TEC_Z*avgPt_vTEC_timeMatch_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
        [freqs_Z,Cxx_Z] = signal.welch(1/pwr_Z*Zenith_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
        [freqs_OMNIZ,Cxx_OMNIZ] = signal.welch(1/pwr_OMNI_Z*OMNI_data_timeMatch_HP_Zenith_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
        
        #MISA STUFF
        Fs = 1/(MISA_time_delta*24*60); #min, misa time delta in freq form
        [freqs_TECM,Cxx_TECM] = signal.welch(1/pwr_TEC_M*avgPt_vTEC_timeMatch_HP_cutOut_MISA ,window=window,noverlap=100,nfft=512,fs=Fs);
        [freqs_M,Cxx_M] = signal.welch(1/pwr_M*MISA_POPL_hp_altAvgd_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
        [freqs_OMNIM,Cxx_OMNIM] = signal.welch(1/pwr_OMNI_M*OMNI_data_timeMatch_HP_MISA_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
        
        thruTime_spectral[0,i,:] = Cxx_TECZ; #record
        thruTime_spectral[3,i,:] = Cxx_TECM; #record
        thruTime_spectral[1,i,:] = Cxx_Z; #record
        thruTime_spectral[4,i,:] = Cxx_M; #record
        thruTime_spectral[2,i,:] = Cxx_OMNIZ; #record
        thruTime_spectral[5,i,:] = Cxx_OMNIM; #record
    #END FOR i
    
    
    #PLOT IT UP
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    FLG_sameColorLimits = 0; #if 0 different, if 1 samesies
    xAxisTicks = np.arange( np.round(np.min(1/freqs_TECZ)/10)*10, plot_periodLim_max+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    fig, ax = plt.subplots(nrows=2, ncols=3); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    if( np.max(thruTime_spectral[:,:,1/freqs_TECZ <= plot_periodLim_max]) > 200 ):
        rounder = 50; #set to round to every 50
    else:
        rounder = 25; #set to round to every 25
    #END IF
    vMax = np.ceil(np.max(thruTime_spectral[:,:,1/freqs_TECZ <= plot_periodLim_max])/rounder)*rounder; #get the overall max - FLG_sameColorLimits=0 overrides this
    for i in range(0,ax.shape[0]): #helps automagically plot
        for j in range(0,ax.shape[1]):
            if( FLG_sameColorLimits == 0 ):
                if( np.max(thruTime_spectral[i*ax.shape[1]+j,:,:]) > 200 ):
                    rounder = 50; #set to round to every 50
                else:
                    rounder = 25; #set to round to every 25
                #END IF
                vMax = np.ceil(np.max(thruTime_spectral[i*ax.shape[1]+j,:,:])/rounder)*rounder; #get the max for the plot itself
            #END IF
            #prep colorbar
            divider = make_axes_locatable(ax[i,j]); #prep to add an axis
            cax = divider.append_axes('right', size='2.0%', pad=0.15); #make a color bar axis
            #Remove the aspect ratio from the basemap so it fills the screen better
            ax[i,j].set_aspect('auto');
            
            pltHelprX, pltHelprY = np.meshgrid( thruTime[:,0], 1/freqs_TECZ);
            #gotta catch inf
            pltHelprY[np.isinf(pltHelprY)] = np.max(pltHelprY[~np.isinf(pltHelprY)])*2; #remove the infs
            im = ax[i,j].pcolormesh(pltHelprX, pltHelprY,  thruTime_spectral[i*ax.shape[1]+j,:,:].T , \
                vmin=0, vmax=vMax, cmap='nipy_spectral'); # pseudocolor plot "stretched" to the grid
            cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
            # cax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.1f')); #force a rounded format
            cbar.ax.tick_params(labelsize=FONT_axisTick);
            cbar.mappable.set_clim(vmin=0, vmax=vMax);
            # cax.yaxis.set_ticks(np.linspace(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim']),11)); #create useful tick marks
            ax[i,j].set_title('Power Spectra for TEC at Zenith - '+str(thruTime_width)+' hr width', \
                fontproperties=FONT_titleFM);
            ax[i,j].set_yticks(xAxisTicks); #set y axis ticks
            ax[i,j].set_ylim( (np.min(1/freqs_TECvZ), plot_periodLim_max) ); #set the axis limit
            
            if( i == ax.shape[0]-1 and j == np.int64((ax.shape[1]-1)/2) ):
                ax[i,j].set_xlabel('Start Hour - Time in UT [hr] - 0 Hr on '+dateRange_zeroHr_monthName+ \
                    ' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+ \
                    str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM);
            #END IF
            if( j == 0 ):
                ax[i,j].set_ylabel('Periods [min]',fontproperties=FONT_axisLabelFM);
            elif( j == ax.shape[1]-1 ):
                cbar.set_label('Arb. Power'); #tabel the colorbar
                cax.yaxis.label.set_font_properties(FONT_axisLabelFM);
            #END IF
            if( i == 0 and j == 0 ):
                ax[i,j].set_title('TEC at Zenith', fontproperties=FONT_titleFM);
            elif( i == 0 and j == 1 ):
                ax[i,j].set_title('Zenith ISR', fontproperties=FONT_titleFM);
            elif( i == 0 and j == 2 ):
                ax[i,j].set_title(OMNI_plot_labelNoUnits+' on Zenith ['+str(OMNI_delay_wrt_TEC)+' hr]', fontproperties=FONT_titleFM);
            elif( i == 1 and j == 0 ):
                ax[i,j].set_title('TEC at MISA', fontproperties=FONT_titleFM);
            elif( i == 1 and j == 1 ):
                ax[i,j].set_title('MISA ISR', fontproperties=FONT_titleFM);
            elif( i == 1 and j == 2 ):
                ax[i,j].set_title(OMNI_plot_labelNoUnits+' on MISA ['+str(OMNI_delay_wrt_TEC)+' hr]', fontproperties=FONT_titleFM);
            #END IF
        #END FOR j
    #END FOR i
    
    
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.060, right = 0.945, top = 0.96, bottom = 0.075 , hspace = 0.175, wspace = 0.275); #sets padding to small numbers for minimal white space
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
#END IF

if( FLG_FFTthruTime_KEOnAvgPtnAMPEREintegrated == 1 ):
    from scipy import signal
    from scipy.signal import savgol_filter
    from scipy.interpolate import interp1d
    from Code.subfun_timeMatch import subfun_timeMatch
    from Code.subfun_highpass import subfun_highpass
    from Code.subfun_textNice import textNice
#    from matplotlib import mlab
    window = np.hamming(110);
    
    #got a few things going
    #TEC on its own time
    #AMPERE on its own time
    #avgPt_vTEC_HP, avgPt_vTEC_time
    
#    window= np.pad(window,(0,512-110),mode='constant')
    # TEC_time_delta = TEC_dataRate/86400; #days, delta of time between readings
    AMPERE_time_delta = np.median(np.diff(AMPERE_timeUnique)); #days, delta of time between readings
    
    time_range = np.array( ((time_Ref[0]-dateRange_dayNum_zeroHr[1]*86400)/3600 , (time_Ref[-1]-dateRange_dayNum_zeroHr[1]*86400)/3600) ); #make a time range based on the reference time
    time_rangeRound = np.int64(np.floor(np.abs(time_range))*(time_range/np.abs(time_range))); #get the absolute hours - absolute shennanigans are to get floor to floor -11.3 -> -11 and not -12
    thruTime_num = np.int64((np.diff(time_rangeRound).item()-thruTime_width)/thruTime_step)+1; #number of times the time_rangeRound can be split into the required width and step size
    thruTime = np.zeros( (thruTime_num,2) ); #prep array
    for i in range(0,thruTime_num):
        thruTime[i,0] = time_rangeRound[0]+i*thruTime_step; #get the starting time
        thruTime[i,1] = thruTime[i,0] + thruTime_width; #get the ending time
    #END FOR i
    
    #----PREP TEC KEO STUFF----
    if( settings['TEC']['keo']['keo plot latlong name'] == 'Latitude' ):
        vTECChunked_keo_index = np.where( np.min(np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,0])) == np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,0]))[0].item(); #get index nearest to the data we want
    else:
        vTECChunked_keo_index = np.where( np.min(np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,1])) == np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,1]))[0].item(); #get index nearest to the data we want
    #END IF
    vTECChunked_keo_lined = np.nanmean(data['TEC']['keo'][:,vTECChunked_keo_index-3:vTECChunked_keo_index+3],axis=1); #get some extra pts as well to make it steadier
    
    #-----Plot AMPERE results as a 1D line-----
    AMPERE_timeUnique_hr = (AMPERE_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    if( np.mod(np.round(np.min(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr))+1; #is odd, make even
    #END IF
    if( np.mod(np.round(np.max(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr))-1; #is odd, make even
    #END IF
    AMPERE_dataRate_timeMatch = 360; #overwrite
    
    if( (np.min(plotLatRange) >= 0) & (np.max(plotLatRange) >= 0) ):
        #northern hemisphere
        kInRange = data['AMPERE']['lat'] >= 0; #get data in the range
    else:
        #southern hemisphere
        kInRange = data['AMPERE']['lat'] <= 0; #get data in the range
    #END IF
    
    AMPERE_integrate = np.zeros( AMPERE_timeUnique_hr.size , dtype=np.float64); #prep integrated joule heating
    for i in range(AMPERE_timeUnique_hr.size):
        k = AMPERE_timeUnique[i] == data['AMPERE']['time']; #get the right time
        AMPERE_integrate[i] = np.sum((data['AMPERE'][AMPERE_dataType][k&kInRange])); #ergs/(cm^2*sec), get the Joule Heating for the current time stamp
    #END FOR i
    #Can't log 0's, interpolate over them
    k = np.where( AMPERE_integrate == 0 )[0]; #get where 0's are
    AMPERE_integrate[k] = 1; #set to 1 to prevent error
    AMPERE_integrate = np.log10(AMPERE_integrate); #log it
    
    #make sure FFT can happen if it is on
    #if there are data gaps, data needs to be scargled
    # FLG_keo_Scargle_FFT = 0;
    #also NaNs need to be yeeted
    # if( np.isnan(AMPERE_integrate).sum() > 0 ):
    #     k = np.logical_not(np.isnan(AMPERE_integrate));
    #     AMPERE_integrate = AMPERE_integrate[k]; #remove NaNs
    #     AMPERE_timeUnique_hr = AMPERE_timeUnique_hr[k]; #remove NaNs
    # elif( np.isnan(vTECChunked_keo_lined).sum() > 0 ):
    #     k = np.logical_not(np.isnan(vTECChunked_keo_lined));
    #     vTECChunked_keo_lined = vTECChunked_keo_lined[k]; #remove NaNs
    #     TEC_timeUnique = TEC_timeUnique[k]; #remove NaNs
    # #END IF
    
    #Force TEC onto AMPERE data cadence
    if( np.isclose(np.median(np.diff(TEC_timeUnique)),np.median(np.diff(AMPERE_timeUnique))) == False ):
        #Match the data in the 1st input (and its time in the 2nd input) to the time scale given in the 3rd input time and return that data and that data's highpassed form
        # _, vTECChunked_keo_lined_timeMatch_HP, TEC_timeUnique_timeMatch = GRITI_TEC_avgPt_timeMatch(vTECChunked_keo_lined,TEC_timeUnique,AMPERE_timeUnique,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
        vTECChunked_keo_lined_timeMatch, TEC_timeUnique_timeMatch = subfun_timeMatch(vTECChunked_keo_lined, TEC_timeUnique, AMPERE_timeUnique, timeMatch_delta=None, FLG_removeNaNs=2, FLG_useSum=0); #time match
        vTECChunked_keo_lined_timeMatch_HP = subfun_highpass( TEC_timeUnique_timeMatch, vTECChunked_keo_lined_timeMatch, filter_cutoffPeriod=settings_spectra['filter cutoff period'], filter_order=settings_spectra['filter order'], windowType=settings_spectra['window type']); #highpass that data to boot
        # _, avgPt_vTEC_timeMatch_HP, TEC_timeUnique_timeMatch = GRITI_TEC_avgPt_timeMatch(avgPt_vTEC,TEC_timeUnique,AMPERE_timeUnique,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']); 
        avgPt_vTEC_timeMatch, TEC_timeUnique_timeMatch = subfun_timeMatch(avgPt_vTEC, TEC_timeUnique, AMPERE_timeUnique, timeMatch_delta=None, FLG_removeNaNs=2, FLG_useSum=0); #time match
        avgPt_vTEC_timeMatch_HP = subfun_highpass( TEC_timeUnique_timeMatch, avgPt_vTEC_timeMatch, filter_cutoffPeriod=settings_spectra['filter cutoff period'], filter_order=settings_spectra['filter order'], windowType=settings_spectra['window type']); #highpass that data to boot
    else:
        #-----Highpass the data to keep the power within the period range we want-----
        vTECChunked_keo_lined_timeMatch_HP = subfun_highpass(TEC_timeUnique, vTECChunked_keo_lined, filter_cutoffPeriod=settings_spectra['filter cutoff period'], filter_order=settings_spectra['filter order'], windowType=settings_spectra['window type']);
        avgPt_vTEC_timeMatch_HP = subfun_highpass(TEC_timeUnique, avgPt_vTEC, filter_cutoffPeriod=settings_spectra['filter cutoff period'], filter_order=settings_spectra['filter order'], windowType=settings_spectra['window type']);
    #END IF
    
    #prep the Sav-Gol filter for debiasing
    windowLen_savGol = np.int64(np.round(settings_TEC_import['filter_savGolPeriod']/(AMPERE_time_delta))); #window length, 60 minutes, converted to seconds, and divided by sample rate (plus 1 because odd is required) gets 121 for an hour window length (frame length)
    #from conversations with AC ^
    if( np.remainder(windowLen_savGol,2) == 0 ): #if there's no remainder, it's even. Gotta add 1 cause Sovitsky-Golay filter needs an odd window length
        windowLen_savGol = windowLen_savGol + 1; #add 1 so it's odd
    #END IF
    polyYvals = savgol_filter(AMPERE_integrate,windowLen_savGol, settings_TEC_import['order_savGol'] ); #filter it up
    AMPERE_integrate_HP = AMPERE_integrate - polyYvals;
    
    #-----Highpass the data to keep the power within the period range we want-----
    # AMPERE_integrate_HP = subfun_highpass(AMPERE_timeUnique_hr, AMPERE_integrate, filter_cutoffPeriod=settings_spectra['filter cutoff period'], filter_order=settings_spectra['filter order'], windowType=settings_spectra['window type'], axisToUse=1)
    
    AMPERE_plot_label = settings['AMPERE']['labels'][AMPERE_dataType]+settings['AMPERE']['units'][AMPERE_dataType]; #get the label
    AMPERE_plot_label_noUnits = settings['AMPERE']['labels'][AMPERE_dataType]; #remove the (units)
    
    thruTime_spectral = np.zeros([3,thruTime_num,np.int64(512/2+1)]); #prep a holder for the spectral info
    thruTime_freq = np.zeros([3,thruTime_num,np.int64(512/2+1)]); #prep a holder for the spectral info
    for i in range(0,thruTime_num):
        #TEC NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) )) == np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) ) )[0][0] , \
            np.where(np.min(np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) )) == np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) ) )[0][0] ) ); #get the indexes for that time cutout range
        
        vTECChunked_keo_cutOut = vTECChunked_keo_lined_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        avgPt_vTEC_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        TEC_timeUnique_cutOut = TEC_timeUnique_timeMatch[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
        #AMPERE NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) )) == np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) ) )[0][0] , \
            np.where(np.min(np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) )) == np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) ) )[0][0] ) ); #get the indexes for that time cutout range
        
        AMPERE_timeUnique_cutOut = AMPERE_timeUnique[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        AMPERE_integrate_HP_cutOut = AMPERE_integrate_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
        #do some spectral analysis on this
        pwr_TEC_pt = np.sqrt(1/avgPt_vTEC_HP_cutOut.size*np.sum(avgPt_vTEC_HP_cutOut**2)); #estimate power of signal
        pwr_TEC_keo = np.sqrt(1/vTECChunked_keo_cutOut.size*np.sum(vTECChunked_keo_cutOut**2)); #estimate power of signal
        pwr_AMPERE = np.sqrt(1/AMPERE_integrate_HP_cutOut.size*np.sum(AMPERE_integrate_HP_cutOut**2)); #estimate power of signal
        
        #TEC STUFF
        # Fs = 1/(TEC_dataRate/60); #min, zenith time delta in freq form [TEC is on AMPERE data rate now]
        Fs = 1/(AMPERE_time_delta); #sec, misa time delta in freq form
        [freqs_TECpt,Cxx_TECpt] = signal.welch(1/pwr_TEC_pt*avgPt_vTEC_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
        [freqs_TECkeo,Cxx_TECkeo] = signal.welch(1/pwr_TEC_keo*vTECChunked_keo_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
        
        #AMPERE STUFF
        Fs = 1/(AMPERE_time_delta); #sec, misa time delta in freq form
        [freqs_AMPERE,Cxx_AMPERE] = signal.welch(1/pwr_AMPERE*AMPERE_integrate_HP_cutOut ,window=window,noverlap=100,nfft=512,fs=Fs);
        # Cxx_AMPERE, freqs_AMPERE = subfun_spectra( AMPERE_integrate_HP_cutOut, AMPERE_timeUnique_cutOut, 'fft', settings_spectra, dataRate = AMPERE_dataRate_timeMatch, reduceWindow = 0, returnFreqs = 1); #calc spectra
        
        thruTime_spectral[0,i,:] = Cxx_TECpt; #record
        thruTime_spectral[1,i,:] = Cxx_TECkeo; #record
        thruTime_spectral[2,i,:] = Cxx_AMPERE; #record
        thruTime_freq[0,i,:] = freqs_TECpt; #record
        thruTime_freq[1,i,:] = freqs_TECkeo; #record
        thruTime_freq[2,i,:] = freqs_AMPERE; #record
    #END FOR i
    
    
    #PLOT IT UP
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    FLG_sameColorLimits = 0; #if 0 different, if 1 samesies
    yAxisTicks = np.arange( np.round(np.min(1/freqs_TECkeo/60)/10)*10, plot_periodLim_max/60+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    fig, ax = plt.subplots(nrows=1, ncols=3); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    if( np.nanmax(thruTime_spectral[:,:,1/freqs_TECkeo <= plot_periodLim_max]/60) > 200 ): #/60 to scale power from sec->min
        rounder = 50; #set to round to every 50
    else:
        rounder = 25; #set to round to every 25
    #END IF
    vMax = np.ceil(np.nanmax(thruTime_spectral[:,:,1/freqs_TECkeo <= plot_periodLim_max]/60)/rounder)*rounder; #get the overall max - FLG_sameColorLimits=0 overrides this
    for i in range(0,ax.shape[0]): #helps automagically plot
        if( FLG_sameColorLimits == 0 ):
            if( np.nanmax(thruTime_spectral[i,:,:]/60) > 200 ):
                rounder = 50; #set to round to every 50
            else:
                rounder = 25; #set to round to every 25
            #END IF
            vMax = np.ceil(np.nanmax(thruTime_spectral[i,:,:]/60)/rounder)*rounder; #get the max for the plot itself
        #END IF
        #prep colorbar
        divider = make_axes_locatable(ax[i]); #prep to add an axis
        cax = divider.append_axes('right', size='2.0%', pad=0.15); #make a color bar axis
        #Remove the aspect ratio from the basemap so it fills the screen better
        ax[i].set_aspect('auto');
        
        tempTime = np.copy(thruTime[:,0]);
        if( i == 2 ):
            tempTime = tempTime + AMPERE_delay_wrt_TEC; #shift by this
        #END IF
        
        pltHelprX, pltHelprY = np.meshgrid( tempTime, 1/thruTime_freq[i,0,:]/60);
        #gotta catch inf
        pltHelprY[np.isinf(pltHelprY)] = np.max(pltHelprY[~np.isinf(pltHelprY)])*2; #remove the infs
        #thruTime_spectral[i,:,:]/60 to scale power from sec->min
        im = ax[i].pcolormesh(pltHelprX, pltHelprY,  (thruTime_spectral[i,:,:]/60).T , \
            vmin=0, vmax=vMax, cmap='nipy_spectral'); # pseudocolor plot "stretched" to the grid
        cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
        # cax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.1f')); #force a rounded format
        cbar.ax.tick_params(labelsize=FONT_axisTick);
        cbar.mappable.set_clim(vmin=0, vmax=vMax);
        # cax.yaxis.set_ticks(np.linspace(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim']),11)); #create useful tick marks
        # ax[i].set_title('Power Spectra for TEC at Zenith - '+str(thruTime_width)+' hr width', \
        #     fontproperties=FONT_titleFM);
        ax[i].set_yticks(yAxisTicks); #set y axis ticks
        ax[i].set_ylim( (np.min(1/thruTime_freq[i,0,:]/60), plot_periodLim_max/60) ); #set the axis limit
        ax[i].set_xticks(np.arange( np.min(thruTime[:,0]), np.max(thruTime[:,0]), 8 )); #set y axis ticks
        ax[i].set_xlim( (np.min(thruTime[:,0]), np.max(thruTime[:,0])) ); #set the axis limit
        
        if( i == 1 ):
            ax[i].set_xlabel('Start Hour - Time in UT [hr] - 0 Hr on '+dateRange_zeroHr_monthName+ \
                ' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+ \
                str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM);
        #END IF
        if( i == 0 ):
            ax[i].set_ylabel('Periods [min]',fontproperties=FONT_axisLabelFM);
        elif( i == 2 ):
            cbar.set_label('Arb. Power'); #tabel the colorbar
            cax.yaxis.label.set_font_properties(FONT_axisLabelFM);
        #END IF
        if( i == 0 ):
            ax[i].set_title('TEC Pt Avg', fontproperties=FONT_titleFM);
        elif( i == 1 ):
            ax[i].set_title('TEC Keo Avg', fontproperties=FONT_titleFM);
        elif( i == 2 ):
            ax[i].set_title(AMPERE_plot_label_noUnits+' offset by '+textNice(AMPERE_delay_wrt_TEC)+' hrs', fontproperties=FONT_titleFM);
        #END IF
    #END FOR i
    
    
    #final plot adjusting stuff
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.060, right = 0.945, top = 0.96, bottom = 0.075 , hspace = 0.175, wspace = 0.275); #sets padding to small numbers for minimal white space
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
#END IF


if( FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated == 1 ):
    from scipy import signal
    from scipy.signal import savgol_filter
    from Code.subfun_timeMatch import subfun_timeMatch
    from Code.subfun_filter import subfun_filter
    from Code.subfun_spectra import subfun_spectra
    from Code.subfun_figFitter import figFitter
    from Code.subfun_textNice import textNice
    
    #got a few things going
    #TEC on its own time
    #AMPERE on its own time
    #avgPt_vTEC_HP, avgPt_vTEC_time
    
#    window= np.pad(window,(0,512-110),mode='constant')
    # TEC_time_delta = TEC_dataRate/86400; #days, delta of time between readings
    OMNI_time_delta = np.median(np.diff(OMNI_timeUnique)); #sec, delta of time between readings
    
    time_range = np.array( ((time_Ref[0]-dateRange_dayNum_zeroHr[1]*86400)/3600 , (time_Ref[-1]-dateRange_dayNum_zeroHr[1]*86400)/3600) ); #make a time range based on the reference time
    time_rangeRound = np.int64(np.floor(np.abs(time_range))*(time_range/np.abs(time_range))); #get the absolute hours - absolute shennanigans are to get floor to floor -11.3 -> -11 and not -12
    thruTime_num = np.int64((np.diff(time_rangeRound).item()-thruTime_width)/(thruTime_step))+1; #number of times the time_rangeRound can be split into the required width and step size
    thruTime = np.zeros( (thruTime_num,2) ); #prep array
    for i in range(0,thruTime_num):
        thruTime[i,0] = time_rangeRound[0]+i*thruTime_step; #get the starting time
        thruTime[i,1] = thruTime[i,0] + thruTime_width; #get the ending time
    #END FOR i
    
    #----PREP TEC KEO STUFF----
    if( settings['TEC']['keo']['keo plot latlong name'] == 'Latitude' ):
        vTECChunked_keo_index = np.where( np.min(np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,0])) == np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,0]))[0].item(); #get index nearest to the data we want
    else:
        vTECChunked_keo_index = np.where( np.min(np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,1])) == np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,1]))[0].item(); #get index nearest to the data we want
    #END IF
    vTECChunked_keo_lined = np.nanmean(data['TEC']['keo'][:,vTECChunked_keo_index-3:vTECChunked_keo_index+3],axis=1); #get some extra pts as well to make it steadier
    
    #-----Plot AMPERE results as a 1D line-----
    AMPERE_timeUnique_hr = (AMPERE_timeUnique -AMPERE_delay_wrt_TEC*3600 - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day (already done w/ AMPERE)
    
    if( np.mod(np.round(np.min(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr))+1; #is odd, make even
    #END IF
    if( np.mod(np.round(np.max(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr))-1; #is odd, make even
    #END IF
    
    #prep to plot
    # AMPERE_integrate = GRITI_AMPERE_integrator(data['AMPERE'], dates, settings['AMPERE'], plotLatRange, plotLongRange, FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_upTo90, FFTthruTime_KEOnAMPEREnOMNIintegrated_AMPERE_upToVal, AMPERE_integrateMethod_log=0); #Integrate w/ function
    
    #-----Plot OMNI results as a 1D line-----
    OMNI_timeUnique_hr = (OMNI_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    if( np.mod(np.round(np.min(OMNI_timeUnique_hr)),2) == 0 ):
        OMNI_time_hr_axis_min = np.round(np.min(OMNI_timeUnique_hr)); #is even, good to go
    else:
        OMNI_time_hr_axis_min = np.round(np.min(OMNI_timeUnique_hr))+1; #is odd, make even
    #END IF
    if( np.mod(np.round(np.max(OMNI_timeUnique_hr)),2) == 0 ):
        OMNI_time_hr_axis_max = np.round(np.max(OMNI_timeUnique_hr)); #is even, good to go
    else:
        OMNI_time_hr_axis_max = np.round(np.max(OMNI_timeUnique_hr))-1; #is odd, make even
    #END IF
    

    #make sure FFT can happen if it is on
    #if there are data gaps, data needs to be scargled
    # FLG_keo_Scargle_FFT = 0;
    #also NaNs need to be yeeted
    # if( np.isnan(OMNI_jouleHeating_integrate).sum() > 0 ):
    #     k = np.logical_not(np.isnan(OMNI_jouleHeating_integrate));
    #     OMNI_jouleHeating_integrate = OMNI_jouleHeating_integrate[k]; #remove NaNs
    #     OMNI_timeUnique_hr = OMNI_timeUnique_hr[k]; #remove NaNs
    # elif( np.isnan(vTECChunked_keo_lined).sum() > 0 ):
    #     k = np.logical_not(np.isnan(vTECChunked_keo_lined));
    #     vTECChunked_keo_lined = vTECChunked_keo_lined[k]; #remove NaNs
    #     TEC_timeUnique = TEC_timeUnique[k]; #remove NaNs
    #END IF
    
    #Force TEC and OMNI onto 6 min data cadance [which is used by ISR/AMPERE] !!note that their orig data rates cause too much spread-spectrum noise for this type of plot!!
    #---TEC---
    if( np.abs(TEC_dataRate-360) > 0.05 ):
        sixMin_timeUnique_abs = np.arange(0,dateRange_dayNum_full.shape[0]*86400,360); #sec, arange time stamps
        # sixMin_timeUnique = sixMin_timeUnique - dates['date range zero hr hour offset']*3600; #sec, align to 0 hour
        sixMin_timeUnique_abs = sixMin_timeUnique_abs + dates['date range dayNum'][0,1]*86400; #sec, align to date range
        #Match the data in the 1st input (and its time in the 2nd input) to the time scale given in the 3rd input time and return that data and that data's highpassed form
        # _, vTECChunked_keo_lined_timeMatch_HP, TEC_timeUnique_timeMatch = GRITI_TEC_avgPt_timeMatch(vTECChunked_keo_lined,TEC_timeUnique,sixMin_timeUnique_abs,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
        vTECChunked_keo_lined_timeMatch, TEC_timeUnique_timeMatch = subfun_timeMatch(vTECChunked_keo_lined, TEC_timeUnique, sixMin_timeUnique_abs, timeMatch_delta=360., FLG_removeNaNs=0); #match to 6 min time step
        vTECChunked_keo_lined_timeMatch_HP = subfun_filter( vTECChunked_keo_lined_timeMatch, FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_filtMethod['TEC'], dataTime = TEC_timeUnique_timeMatch, dataRate = 360, settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #high-pass filter
        TEC_dataRate_timeMatch = 360; #overwrite
    else:
    #-----Highpass the data to keep the power within the period range we want-----
        # vTECChunked_keo_lined_timeMatch_HP = subfun_highpass((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600, vTECChunked_keo_lined, filter_cutoffPeriod=settings_spectra['filter cutoff period'], filter_order=settings_spectra['filter order'], windowType=settings_spectra['window type'], axisToUse=1);
        vTECChunked_keo_lined_timeMatch_HP = subfun_filter( vTECChunked_keo_lined, FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_filtMethod['TEC'], dataTime = TEC_timeUnique, dataRate = 360, settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #high-pass filter
        TEC_timeUnique_timeMatch = TEC_timeUnique; #set so no errors
        TEC_dataRate_timeMatch = 360; #overwrite
    #END IF
    #---AMPERE---
    if( np.abs(data['AMPERE']['data rate']-360) > 0.05 ):
        sixMin_timeUnique_abs = np.arange(0,dateRange_dayNum_full.shape[0]*86400,360)-AMPERE_delay_wrt_TEC*3600; #sec, arange time stamps
        # sixMin_timeUnique_abs = sixMin_timeUnique_abs - dates['date range zero hr hour offset']*3600; #sec, align to 0 hour
        sixMin_timeUnique_abs = sixMin_timeUnique_abs + dates['date range dayNum'][0,1]*86400; #sec, align to date range
        #Match the data in the 1st input (and its time in the 2nd input) to the time scale given in the 3rd input time and return that data and that data's highpassed form
        # AMPERE_integrate_timeMatch, _, AMPERE_timeUnique_timeMatch = GRITI_TEC_avgPt_timeMatch(AMPERE_integrate,AMPERE_timeUnique,sixMin_timeUnique_abs,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
        AMPERE_integrate_timeMatch, AMPERE_timeUnique_timeMatch = subfun_timeMatch(AMPERE_integrate, AMPERE_timeUnique, sixMin_timeUnique_abs, timeMatch_delta=360., FLG_removeNaNs=0); #match to 6 min time step
        AMPERE_dataRate_timeMatch = 360; #overwrite
    else:
    #-----Highpass the data to keep the power within the period range we want-----
        AMPERE_integrate_timeMatch = AMPERE_integrate; #set so no errors
        AMPERE_timeUnique_timeMatch = AMPERE_timeUnique; #set so no errors
        AMPERE_dataRate_timeMatch = 360; #overwrite
    #END IF
    #---OMNI---
    if( np.abs(OMNI_time_delta-360) > 0.05 ):
        sixMin_timeUnique_abs = np.arange(0,dateRange_dayNum_full.shape[0]*86400,360); #sec, arange time stamps
        # sixMin_timeUnique_abs = sixMin_timeUnique_abs - dates['date range zero hr hour offset']*3600; #sec, align to 0 hour
        sixMin_timeUnique_abs = sixMin_timeUnique_abs + dates['date range dayNum'][0,1]*86400-OMNI_delay_wrt_TEC*3600; #sec, align to date range
        #adjust OMNI too
        OMNI_data_timeMatch = [[] for i in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes))]; #prep a holder
        for i in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)):
            # OMNI_data_timeMatch[i], _, OMNI_timeUnique_timeMatch = GRITI_TEC_avgPt_timeMatch(OMNI_data[:,OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]],OMNI_timeUnique,sixMin_timeUnique_abs,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
            OMNI_data_timeMatch[i], OMNI_timeUnique_timeMatch = subfun_timeMatch(OMNI_data[:,OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]], OMNI_timeUnique, sixMin_timeUnique_abs, timeMatch_delta=360., FLG_removeNaNs=2, FLG_reportNaNs=False); #match to 6 min time step
        #END FOR i
        OMNI_dataRate_timeMatch = 360; #overwrite
    else:
         #fix so it works good
        OMNI_data_timeMatch = [[] for i in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes))]; #prep a holder
        for i in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)):
            OMNI_data_timeMatch[i] = OMNI_data[:,OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]]; #set so no errors
        #END FOR i
        OMNI_timeUnique_timeMatch = OMNI_timeUnique; #set so no errors
        OMNI_dataRate_timeMatch = 360; #overwrite
    #END IF

    #prep the Sav-Gol filter for debiasing
    #---AMPERE---
    AMPERE_integrate_timeMatch_HP = subfun_filter( AMPERE_integrate_timeMatch, FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_filtMethod['AMPERE'], dataTime = AMPERE_timeUnique_timeMatch, dataRate = AMPERE_dataRate_timeMatch, settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter
    #-----Highpass the data to keep the power within the period range we want-----
    # AMPERE_integrate_HP = subfun_highpass(AMPERE_timeUnique_timeMatch*24, AMPERE_integrate_timeMatch, filter_cutoffPeriod=settings_spectra['filter cutoff period'], filter_order=settings_spectra['filter order'], windowType=settings_spectra['window type'], axisToUse=1)
    
    AMPERE_plot_label = settings['AMPERE']['labels'][AMPERE_dataType]+settings['AMPERE']['units'][AMPERE_dataType]; #get the label
    AMPERE_plot_label_noUnits = settings['AMPERE']['labels'][AMPERE_dataType]; #remove the (units)
    
    #prep the Sav-Gol filter for debiasing
    #---OMNI---
    #roll through every OMNI needed
    OMNI_dataFilt = np.zeros( [OMNI_timeUnique_timeMatch.size , len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)] ); #preallocate
    OMNI_plot_labelSet = []; #prep empty list
    OMNI_plot_labelSet_noUnits = []; #prep empty list
    for i in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)):
        OMNI_dataFilt[:,i] = subfun_filter( OMNI_data_timeMatch[i], FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_filtMethod['OMNI'], dataTime = OMNI_timeUnique_timeMatch, dataRate = OMNI_dataRate_timeMatch, settings_spectra = settings_spectra, reduceWindow = 0, FLG_reportNaNs = False); #filter
        # OMNI_dataFilt[:,i] = subfun_highpass(OMNI_timeUnique_hr, OMNI_dataFilt[:,i], filter_cutoffPeriod=settings_spectra['filter cutoff period'], filter_order=settings_spectra['filter order'], windowType=settings_spectra['window type'], axisToUse=1);
    
        #also get plot labels
        OMNI_plot_labelSet.append(OMNI_dictPlot[OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]]); #get the label
        OMNI_plot_labelSet_noUnits.append(OMNI_dictPlot[OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]][0:OMNI_dictPlot[OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]].find('[')-1]); #remove the (units)
    #END FOR i
    
    thruTime_spectral = [[] for i in range(0,2+len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes))]; #prep a holder for the spectral info
    thruTime_freq = [[] for i in range(0,2+len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes))]; #prep a holder for the spectral info
    for i in range(0,2):
        #TEC
        thruTime_spectral[i] = np.zeros([thruTime_num,np.int64(settings_spectra['nfft']['6min']/2+1)]); #preallocate in the list
        thruTime_freq[i] = np.zeros([thruTime_num,np.int64(settings_spectra['nfft']['6min']/2+1)]); #preallocate in the list
    #END FOR i
    for i in range(1,2+len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)):
        #OMNI
        thruTime_spectral[i] = np.zeros([thruTime_num,np.int64(settings_spectra['nfft']['6min']/2+1)]); #preallocate in the list
        thruTime_freq[i] = np.zeros([thruTime_num,np.int64(settings_spectra['nfft']['6min']/2+1)]); #preallocate in the list
    #END FOR i
    for i in range(0,thruTime_num):
        #TEC NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) )) == np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) ) )[0][0] , \
            np.where(np.min(np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) )) == np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) ) )[0][0] ) ); #get the indexes for that time cutout range
        
        vTECChunked_keo_cutOut = vTECChunked_keo_lined_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        # avgPt_vTEC_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        TEC_timeUnique_cutOut = TEC_timeUnique_timeMatch[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
        #do some spectral analysis on this
        Cxx_TECkeo, freqs_TECkeo = subfun_spectra( vTECChunked_keo_cutOut, TEC_timeUnique_cutOut, 'fft', settings_spectra, dataRate = TEC_dataRate_timeMatch, reduceWindow = 0, returnFreqs = 1); #calc spectra
                        
        thruTime_spectral[0][i,:] = Cxx_TECkeo; #record (scale down by sec -> min conversion to get pwr wrt min which is lower so it is easier to plot)
        thruTime_freq[0][i,:] = freqs_TECkeo; #record
        
        #AMPERE NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (AMPERE_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.min(thruTime[i,:])-AMPERE_delay_wrt_TEC) )) == np.abs( (AMPERE_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.min(thruTime[i,:])-AMPERE_delay_wrt_TEC) ) )[0][0] , \
            np.where(np.min(np.abs( (AMPERE_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.max(thruTime[i,:])-AMPERE_delay_wrt_TEC) )) == np.abs( (AMPERE_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.max(thruTime[i,:])-AMPERE_delay_wrt_TEC) ) )[0][0] ) ); #get the indexes for that time cutout range
        # time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (AMPERE_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) )) == np.abs( (AMPERE_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) ) )[0][0] , \
        #     np.where(np.min(np.abs( (AMPERE_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) )) == np.abs( (AMPERE_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) ) )[0][0] ) ); #get the indexes for that time cutout range
        
        AMPERE_timeUnique_cutOut = AMPERE_timeUnique_timeMatch[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        AMPERE_integrate_HP_cutOut = AMPERE_integrate_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
        Cxx_AMPERE, freqs_AMPERE = subfun_spectra( AMPERE_integrate_HP_cutOut, AMPERE_timeUnique_cutOut, 'fft', settings_spectra, dataRate = AMPERE_dataRate_timeMatch, reduceWindow = 0, returnFreqs = 1); #calc spectra
        
        thruTime_spectral[1][i,:] = Cxx_AMPERE; #record (scale down by sec -> min conversion to get pwr wrt min which is lower so it is easier to plot)
        thruTime_freq[1][i,:] = freqs_AMPERE; #record
        
        #OMNI NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.min(thruTime[i,:])-OMNI_delay_wrt_TEC) )) == np.abs( (OMNI_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.min(thruTime[i,:])-OMNI_delay_wrt_TEC) ) )[0][0] , \
            np.where(np.min(np.abs( (OMNI_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.max(thruTime[i,:])-OMNI_delay_wrt_TEC) )) == np.abs( (OMNI_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.max(thruTime[i,:])-OMNI_delay_wrt_TEC) ) )[0][0] ) ); #get the indexes for that time cutout range
        OMNI_timeUnique_cutOut = OMNI_timeUnique_timeMatch[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        for j in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)):

            OMNI_dataFilt_cutOut = OMNI_dataFilt[time_cutout_indexes[0]:time_cutout_indexes[1]+1,j];
            
            #do some spectral analysis on this
            Cxx_OMNI, freqs_OMNI = subfun_spectra( OMNI_dataFilt_cutOut, OMNI_timeUnique_cutOut, 'fft', settings_spectra, dataRate = OMNI_dataRate_timeMatch, reduceWindow = 0, returnFreqs = 1); #calc spectra        

            thruTime_spectral[j+2][i,:] = Cxx_OMNI; #record (scale down by sec -> min conversion to get pwr wrt min which is lower so it is easier to plot)
            thruTime_freq[j+2][i,:] = freqs_OMNI; #record
        #END FOR j
    #END FOR i
    
    
    #PLOT IT UP
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    FLG_sameColorLimits = 0; #if 0 different, if 1 samesies
    yAxisTicks = np.arange( np.round(np.min(1/freqs_TECkeo)/60/20)*20, settings_spectra['period limit max']/60+20, 20); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    fig, ax = plt.subplots(nrows=2, ncols=3); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    # if( np.max(thruTime_spectral[:,:,1/freqs_TECkeo <= settings_spectra['period limit max']]) > 200 ):
    #     rounder = 50; #set to round to every 50
    # else:
    #     rounder = 25; #set to round to every 25
    # #END IF
    # vMax = np.ceil(np.max(thruTime_spectral[:,:,1/freqs_TECkeo <= settings_spectra['period limit max']])/rounder)*rounder; #get the overall max - FLG_sameColorLimits=0 overrides this
    cntr = -1; #start cntr
    for i in range(0,ax.shape[0]): #helps automagically plot
        for j in range(0,ax.shape[1]): #helps automagically plot
            cntr += 1; #for counting continuously
            if( FLG_sameColorLimits == 0 ):
                if( np.nanmax(thruTime_spectral[cntr][:,:]/60) > 200 ): #/60 to scale power from sec->min
                    rounder = 50; #set to round to every 50
                elif( np.nanmax(thruTime_spectral[cntr][:,:]/60) < 0.5 ):
                    rounder = 0.5; #set to round to every 50
                else:
                    rounder = 25; #set to round to every 25
                #END IF
                vMax = np.ceil(np.max(thruTime_spectral[cntr][:,:]/60)/rounder)*rounder; #get the max for the plot itself
            #END IF
            #prep colorbar
            divider = make_axes_locatable(ax[i,j]); #prep to add an axis
            cax = divider.append_axes('right', size='2.0%', pad=0.15); #make a color bar axis
            #Remove the aspect ratio from the basemap so it fills the screen better
            ax[i,j].set_aspect('auto');
            
            tempTime = np.copy(thruTime[:,0]);
            # if( (i == 0) & (j == 1) ):
            #     tempTime = tempTime + AMPERE_delay_wrt_TEC*3600; #shift by this
            # #END IF
            
            pltHelprX, pltHelprY = np.meshgrid( tempTime, 1/thruTime_freq[cntr][0,:]/60);
            #gotta catch inf
            pltHelprY[np.isinf(pltHelprY)] = np.max(pltHelprY[~np.isinf(pltHelprY)])*2; #remove the infs
            #thruTime_spectral[cntr][:,:]/60 to scale power from sec->min
            im = ax[i,j].pcolormesh(pltHelprX, pltHelprY,  (thruTime_spectral[cntr][:,:]/60).T , \
                vmin=0, vmax=vMax, cmap='nipy_spectral'); # pseudocolor plot "stretched" to the grid
            cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
            # cax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.1f')); #force a rounded format
            cbar.ax.tick_params(labelsize=FONT_axisTick);
            cbar.mappable.set_clim(vmin=0, vmax=vMax);
            # cax.yaxis.set_ticks(np.linspace(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim']),11)); #create useful tick marks
            # ax[i,j].set_title('Power Spectra for TEC at Zenith - '+str(thruTime_width)+' hr width', \
            #     fontproperties=FONT_titleFM);
            ax[i,j].set_yticks(yAxisTicks); #set y axis ticks
            ax[i,j].set_ylim( (np.min(1/thruTime_freq[cntr][0,:])/60, settings_spectra['period limit max']/60) ); #set the axis limit
            ax[i,j].set_xticks(np.arange( np.min(thruTime[:,0]), np.max(thruTime[:,0]), 8 )); #set y axis ticks
            ax[i,j].set_xlim( (np.min(thruTime[:,0]), np.max(thruTime[:,0])) ); #set the axis limit
            
            if( (i == (ax.shape[0]-1) ) & (j == (ax.shape[1]-1)//2) ):
                ax[i,j].set_xlabel('Start Hour - Time in UT [hr] - 0 Hr on '+dateRange_zeroHr_monthName+ \
                    ' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+ \
                    str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM);
            #END IF
            if( j == 0 ):
                ax[i,j].set_ylabel('Periods [min]',fontproperties=FONT_axisLabelFM);
            elif( j == (ax.shape[1] - 1) ):
                cbar.set_label('Arb. Power'); #tabel the colorbar
                cax.yaxis.label.set_font_properties(FONT_axisLabelFM);
            #END IF
            if( (i == 0) & (j == 0) ):
                ax[i,j].set_title('TEC Keo', fontproperties=FONT_titleFM);
            elif( (i == 0) & (j == 1) ):
                ax[i,j].set_title(AMPERE_plot_label_noUnits+' offset by '+textNice(AMPERE_delay_wrt_TEC)+' hrs', fontproperties=FONT_titleFM);
            else:
                ax[i,j].set_title(OMNI_plot_labelSet_noUnits[cntr-2]+' offset by '+textNice(OMNI_delay_wrt_TEC)+' hrs', fontproperties=FONT_titleFM);
            #END IF
        #END FOR j
    #END FOR i
    
    #final plot adjusting stuff
    fig.subplots_adjust(hspace = 0.175, wspace = 0.275); #pad the plot spacing correctly
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.060, right = 0.945, top = 0.96, bottom = 0.075 , hspace = 0.175, wspace = 0.275); #sets padding to small numbers for minimal white space
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
#END IF

if( FLG_FFTthruTime_KEOnOMNIintegrated == 1 ):
    from scipy import signal
    from scipy.signal import savgol_filter
    from Code.subfun_timeMatch import subfun_timeMatch
    from Code.subfun_filter import subfun_filter
    from Code.subfun_spectra import subfun_spectra
    from Code.subfun_figFitter import figFitter
    
    #got a few things going
    #TEC on its own time
    #AMPERE on its own time
    #avgPt_vTEC_HP, avgPt_vTEC_time
    
#    window= np.pad(window,(0,512-110),mode='constant')
    # TEC_time_delta = TEC_dataRate/86400; #days, delta of time between readings
    OMNI_time_delta = np.median(np.diff(OMNI_timeUnique)); #sec, delta of time between readings
    
    time_range = np.array( ((time_Ref[0]-dateRange_dayNum_zeroHr[1]*86400)/3600 , (time_Ref[-1]-dateRange_dayNum_zeroHr[1]*86400)/3600) ); #make a time range based on the reference time
    time_rangeRound = np.int64(np.floor(np.abs(time_range))*(time_range/np.abs(time_range))); #get the absolute hours - absolute shennanigans are to get floor to floor -11.3 -> -11 and not -12
    thruTime_num = np.int64((np.diff(time_rangeRound).item()-thruTime_width*3600)/(thruTime_step*3600))+1; #number of times the time_rangeRound can be split into the required width and step size
    thruTime = np.zeros( (thruTime_num,2) ); #prep array
    for i in range(0,thruTime_num):
        thruTime[i,0] = time_rangeRound[0]+i*thruTime_step*3600; #get the starting time
        thruTime[i,1] = thruTime[i,0] + thruTime_width*3600; #get the ending time
    #END FOR i
    
    #----PREP TEC KEO STUFF----
    if( settings['TEC']['keo']['keo plot latlong name'] == 'Latitude' ):
        vTECChunked_keo_index = np.where( np.min(np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,0])) == np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,0]))[0].item(); #get index nearest to the data we want
    else:
        vTECChunked_keo_index = np.where( np.min(np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,1])) == np.abs(settings['TEC']['keo']['keo plot latlong chunks'] - avgPt_coords[0,1]))[0].item(); #get index nearest to the data we want
    #END IF
    vTECChunked_keo_lined = np.nanmean(data['TEC']['keo'][:,vTECChunked_keo_index-3:vTECChunked_keo_index+3],axis=1); #get some extra pts as well to make it steadier
        
    #-----Plot OMNI results as a 1D line-----
    OMNI_timeUnique_hr = (OMNI_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    if( np.mod(np.round(np.min(OMNI_timeUnique_hr)),2) == 0 ):
        OMNI_time_hr_axis_min = np.round(np.min(OMNI_timeUnique_hr)); #is even, good to go
    else:
        OMNI_time_hr_axis_min = np.round(np.min(OMNI_timeUnique_hr))+1; #is odd, make even
    #END IF
    if( np.mod(np.round(np.max(OMNI_timeUnique_hr)),2) == 0 ):
        OMNI_time_hr_axis_max = np.round(np.max(OMNI_timeUnique_hr)); #is even, good to go
    else:
        OMNI_time_hr_axis_max = np.round(np.max(OMNI_timeUnique_hr))-1; #is odd, make even
    #END IF
    
    #make sure FFT can happen if it is on
    #if there are data gaps, data needs to be scargled
    # FLG_keo_Scargle_FFT = 0;
    #also NaNs need to be yeeted
    # if( np.isnan(OMNI_jouleHeating_integrate).sum() > 0 ):
    #     k = np.logical_not(np.isnan(OMNI_jouleHeating_integrate));
    #     OMNI_jouleHeating_integrate = OMNI_jouleHeating_integrate[k]; #remove NaNs
    #     OMNI_timeUnique_hr = OMNI_timeUnique_hr[k]; #remove NaNs
    # elif( np.isnan(vTECChunked_keo_lined).sum() > 0 ):
    #     k = np.logical_not(np.isnan(vTECChunked_keo_lined));
    #     vTECChunked_keo_lined = vTECChunked_keo_lined[k]; #remove NaNs
    #     TEC_timeUnique = TEC_timeUnique[k]; #remove NaNs
    #END IF
    
    #Force TEC and OMNI onto 6 min data cadance [which is used by ISR/AMPERE] !!note that their orig data rates cause too much spread-spectrum noise for this type of plot!!
    #---TEC---
    if( np.abs(TEC_dataRate-360) > 0.05 ):
        sixMin_timeUnique_abs = np.arange(0,dateRange_dayNum_full.shape[0]*86400,360); #sec, arange time stamps
        # sixMin_timeUnique_abs = sixMin_timeUnique_abs - dates['date range zero hr hour offset']*3600; #sec, align to 0 hour
        sixMin_timeUnique_abs = sixMin_timeUnique_abs + dates['date range dayNum'][0,1]*86400; #sec, align to date range
        #Match the data in the 1st input (and its time in the 2nd input) to the time scale given in the 3rd input time and return that data and that data's highpassed form
        # _, vTECChunked_keo_lined_timeMatch_HP, TEC_timeUnique_timeMatch = GRITI_TEC_avgPt_timeMatch(vTECChunked_keo_lined,TEC_timeUnique,sixMin_timeUnique_abs,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
        vTECChunked_keo_lined_timeMatch, TEC_timeUnique_timeMatch = subfun_timeMatch(vTECChunked_keo_lined, TEC_timeUnique, sixMin_timeUnique_abs, timeMatch_delta=360., FLG_removeNaNs=0); #match to 6 min time step
        vTECChunked_keo_lined_timeMatch_HP = subfun_filter( vTECChunked_keo_lined_timeMatch, TEC_timeUnique_timeMatch, 'high-pass', settings_spectra, dataRate = 360., reduceWindow = 0); #high-pass filter
        TEC_dataRate_timeMatch = 360; #overwrite
    else:
    #-----Highpass the data to keep the power within the period range we want-----
        # vTECChunked_keo_lined_timeMatch_HP = subfun_highpass((TEC_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600, vTECChunked_keo_lined, filter_cutoffPeriod=settings_spectra['filter cutoff period'], filter_order=settings_spectra['filter order'], windowType=settings_spectra['window type'], axisToUse=1);
        vTECChunked_keo_lined_timeMatch_HP = subfun_filter( vTECChunked_keo_lined, TEC_timeUnique, 'high-pass', settings_spectra, dataRate = 360., reduceWindow = 0); #high-pass filter
        TEC_timeUnique_timeMatch = TEC_timeUnique; #set so no errors
        TEC_dataRate_timeMatch = 360; #overwrite
    #END IF
    #---OMNI---
    if( np.abs(OMNI_time_delta-360) > 0.05 ):
        sixMin_timeUnique_abs = np.arange(0,dateRange_dayNum_full.shape[0]*86400,360); #sec, arange time stamps
        # sixMin_timeUnique_abs = sixMin_timeUnique_abs - dates['date range zero hr hour offset']*3600; #sec, align to 0 hour
        sixMin_timeUnique_abs = sixMin_timeUnique_abs + dates['date range dayNum'][0,1]*86400-OMNI_delay_wrt_TEC*3600; #sec, align to date range
        #adjust OMNI too
        OMNI_data_timeMatch = [[] for i in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes))]; #prep a holder
        for i in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)):
            # OMNI_data_timeMatch[i], _, OMNI_timeUnique_timeMatch = GRITI_TEC_avgPt_timeMatch(OMNI_data[:,OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]],OMNI_timeUnique,sixMin_timeUnique_abs,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
            OMNI_data_timeMatch[i], OMNI_timeUnique_timeMatch = subfun_timeMatch(OMNI_data[:,OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]], OMNI_timeUnique, sixMin_timeUnique_abs, timeMatch_delta=360., FLG_removeNaNs=2); #match to 6 min time step
        #END FOR i
        OMNI_dataRate_timeMatch = 360; #overwrite
    else:
         #fix so it works good
        OMNI_data_timeMatch = [[] for i in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes))]; #prep a holder
        for i in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)):
            OMNI_data_timeMatch[i] = OMNI_data[:,OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]]; #set so no errors
        #END FOR i
        OMNI_timeUnique_timeMatch = OMNI_timeUnique; #set so no errors
        OMNI_dataRate_timeMatch = 360; #overwrite
    #END IF

    #---OMNI---
    #roll through every OMNI needed
    OMNI_dataFilt = np.zeros( [OMNI_timeUnique_timeMatch.size , len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)] ); #preallocate
    OMNI_plot_labelSet = []; #prep empty list
    OMNI_plot_labelSet_noUnits = []; #prep empty list
    for i in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)):
        OMNI_dataFilt[:,i] = subfun_filter( OMNI_data_timeMatch[i], OMNI_timeUnique_timeMatch, 'high-pass', settings_spectra, dataRate = OMNI_dataRate_timeMatch, reduceWindow = 0); #sav-gol filter
        # OMNI_dataFilt[:,i] = subfun_highpass(OMNI_timeUnique_hr, OMNI_dataFilt[:,i], filter_cutoffPeriod=settings_spectra['filter cutoff period'], filter_order=settings_spectra['filter order'], windowType=settings_spectra['window type'], axisToUse=1);
    
        #also get plot labels
        OMNI_plot_labelSet.append(OMNI_dictPlot[OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]]); #get the label
        OMNI_plot_labelSet_noUnits.append(OMNI_dictPlot[OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]][0:OMNI_dictPlot[OMNI_dict[FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes[i]]].find('[')-1]); #remove the (units)
    #END FOR i
    
    thruTime_spectral = [[] for i in range(0,2+len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes))]; #prep a holder for the spectral info
    thruTime_freq = [[] for i in range(0,2+len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes))]; #prep a holder for the spectral info
    for i in range(0,2):
        #TEC
        thruTime_spectral[i] = np.zeros([thruTime_num,np.int64(settings_spectra['nfft']['6min']/2+1)]); #preallocate in the list
        thruTime_freq[i] = np.zeros([thruTime_num,np.int64(settings_spectra['nfft']['6min']/2+1)]); #preallocate in the list
    #END FOR i
    for i in range(1,2+len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)):
        #OMNI
        thruTime_spectral[i] = np.zeros([thruTime_num,np.int64(settings_spectra['nfft']['6min']/2+1)]); #preallocate in the list
        thruTime_freq[i] = np.zeros([thruTime_num,np.int64(settings_spectra['nfft']['6min']/2+1)]); #preallocate in the list
    #END FOR i
    for i in range(0,thruTime_num):
        #TEC NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) )) == np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) ) )[0][0] , \
            np.where(np.min(np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) )) == np.abs( (TEC_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) ) )[0][0] ) ); #get the indexes for that time cutout range
        
        vTECChunked_keo_cutOut = vTECChunked_keo_lined_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        # avgPt_vTEC_HP_cutOut = avgPt_vTEC_timeMatch_HP[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        TEC_timeUnique_cutOut = TEC_timeUnique_timeMatch[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        
        #do some spectral analysis on this
        Cxx_TECkeo, freqs_TECkeo = subfun_spectra( vTECChunked_keo_cutOut, TEC_timeUnique_cutOut, 'fft', settings_spectra, dataRate = TEC_dataRate_timeMatch, reduceWindow = 0, returnFreqs = 1); #calc spectra
                        
        thruTime_spectral[0][i,:] = Cxx_TECkeo/60; #record (scale down by sec -> min conversion to get pwr wrt min which is lower so it is easier to plot)
        thruTime_freq[0][i,:] = freqs_TECkeo; #record
        
        #OMNI NOW
        time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (OMNI_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.min(thruTime[i,:])-OMNI_delay_wrt_TEC*3600) )) == np.abs( (OMNI_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.min(thruTime[i,:])-OMNI_delay_wrt_TEC*3600) ) )[0][0] , \
            np.where(np.min(np.abs( (OMNI_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.max(thruTime[i,:])-OMNI_delay_wrt_TEC*3600) )) == np.abs( (OMNI_timeUnique_timeMatch-dateRange_dayNum_zeroHr[1]*86400)/3600 - (np.max(thruTime[i,:])-OMNI_delay_wrt_TEC*3600) ) )[0][0] ) ); #get the indexes for that time cutout range
        OMNI_timeUnique_cutOut = OMNI_timeUnique_timeMatch[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
        for j in range(0,len(FLG_FFTthruTime_KEOnAMPEREnOMNIintegrated_OMNIindexes)):

            OMNI_dataFilt_cutOut = OMNI_dataFilt[time_cutout_indexes[0]:time_cutout_indexes[1]+1,j];
            
            #do some spectral analysis on this
            Cxx_OMNI, freqs_OMNI = subfun_spectra( OMNI_dataFilt_cutOut, OMNI_timeUnique_cutOut, 'fft', settings_spectra, dataRate = OMNI_dataRate_timeMatch, reduceWindow = 0, returnFreqs = 1); #calc spectra        

            thruTime_spectral[j+1][i,:] = Cxx_OMNI/60; #record (scale down by sec -> min conversion to get pwr wrt min which is lower so it is easier to plot)
            thruTime_freq[j+1][i,:] = freqs_OMNI; #record
        #END FOR j
    #END FOR i
    
    
    #PLOT IT UP
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    FLG_sameColorLimits = 0; #if 0 different, if 1 samesies
    xAxisTicks = np.arange( np.round(np.min(1/freqs_TECkeo)/60/20)*20, settings_spectra['period limit max']/60+20, 20); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    fig, ax = plt.subplots(nrows=2, ncols=3); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    # if( np.max(thruTime_spectral[:,:,1/freqs_TECkeo <= settings_spectra['period limit max']]) > 200 ):
    #     rounder = 50; #set to round to every 50
    # else:
    #     rounder = 25; #set to round to every 25
    # #END IF
    # vMax = np.ceil(np.max(thruTime_spectral[:,:,1/freqs_TECkeo <= settings_spectra['period limit max']])/rounder)*rounder; #get the overall max - FLG_sameColorLimits=0 overrides this
    cntr = -1; #start cntr
    for i in range(0,ax.shape[0]): #helps automagically plot
        for j in range(0,ax.shape[1]): #helps automagically plot
            cntr += 1; #for counting continuously
            if( FLG_sameColorLimits == 0 ):
                if( np.max(thruTime_spectral[cntr][:,:]) > 200 ):
                    rounder = 50; #set to round to every 50
                elif( np.max(thruTime_spectral[cntr][:,:]) < 0.5 ):
                    rounder = 0.5; #set to round to every 50
                else:
                    rounder = 25; #set to round to every 25
                #END IF
                vMax = np.ceil(np.max(thruTime_spectral[cntr][:,:])/rounder)*rounder; #get the max for the plot itself
            #END IF
            #prep colorbar
            divider = make_axes_locatable(ax[i,j]); #prep to add an axis
            cax = divider.append_axes('right', size='2.0%', pad=0.15); #make a color bar axis
            #Remove the aspect ratio from the basemap so it fills the screen better
            ax[i,j].set_aspect('auto');
            
            tempTime = np.copy(thruTime[:,0]);
            
            if( np.all(thruTime_freq[cntr][0,:] == 0) == False ):
                pltHelprX, pltHelprY = np.meshgrid( tempTime/3600, 1/thruTime_freq[cntr][0,:]/60);
                #gotta catch inf
                pltHelprY[np.isinf(pltHelprY)] = np.max(pltHelprY[~np.isinf(pltHelprY)])*2; #remove the infs
                im = ax[i,j].pcolormesh(pltHelprX, pltHelprY,  thruTime_spectral[cntr][:,:].T , \
                    vmin=0, vmax=vMax, cmap='nipy_spectral'); # pseudocolor plot "stretched" to the grid
                cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
                # cax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.1f')); #force a rounded format
                cbar.ax.tick_params(labelsize=FONT_axisTick);
                cbar.mappable.set_clim(vmin=0, vmax=vMax);
                # cax.yaxis.set_ticks(np.linspace(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim']),11)); #create useful tick marks
                ax[i,j].set_title('Power Spectra for TEC at Zenith - '+str(thruTime_width)+' hr width', \
                    fontproperties=FONT_titleFM);
                ax[i,j].set_yticks(xAxisTicks); #set y axis ticks
                ax[i,j].set_ylim( (np.min(1/thruTime_freq[cntr][0,:])/60, settings_spectra['period limit max']/60) ); #set the axis limit
                ax[i,j].set_xlim( (np.min(thruTime[:,0])/3600, np.max(thruTime[:,0])/3600) ); #set the axis limit
                ax[i,j].set_xticks(np.arange( np.min(thruTime[:,0])/3600, np.max(thruTime[:,0])/3600, 8 )); #set y axis ticks
                
                if( (i == (ax.shape[0]-1) ) & (j == (ax.shape[1]-1)//2) ):
                    ax[i,j].set_xlabel('Start Hour - Time in UT [hr] - 0 Hr on '+dateRange_zeroHr_monthName+ \
                        ' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+ \
                        str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM);
                #END IF
                if( j == 0 ):
                    ax[i,j].set_ylabel('Periods [min]',fontproperties=FONT_axisLabelFM);
                elif( j == (ax.shape[1] - 1) ):
                    cbar.set_label('Arb. Power'); #tabel the colorbar
                    cax.yaxis.label.set_font_properties(FONT_axisLabelFM);
                #END IF
                if( (i == 0) & (j == 0) ):
                    ax[i,j].set_title('TEC Keo', fontproperties=FONT_titleFM);
                else:
                    ax[i,j].set_title(OMNI_plot_labelSet_noUnits[cntr-1]+' offset by '+str(OMNI_delay_wrt_TEC)+' hrs', fontproperties=FONT_titleFM);
                #END IF
            #END IF
        #END FOR j
    #END FOR i
    
    #final plot adjusting stuff
    fig.subplots_adjust(hspace = 0.175, wspace = 0.275); #pad the plot spacing correctly
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.060, right = 0.945, top = 0.96, bottom = 0.075 , hspace = 0.175, wspace = 0.275); #sets padding to small numbers for minimal white space
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
#END IF

if( FLG_OMNInAMPERE_correlator_walking >= 1 ):
    print('\nNOTA BENE: Running FLG_OMNInAMPERE_correlator_walking. Walking correlation calcs and plots will take a while.\n');
    from Code.subfun_correlator_walking import subfun_correlator_walking
    from Code.subfun_correlator_walking_plotter import subfun_correlator_walking_plotter
    
    #----- TEC & AMPERE SETTINGS -----
    time2lim = 4*3600; #time limit to check corr coeffs for
    time2span = 6*3600; #time range to cutout and check
    time2step = 1*3600; #time increment to step 
    time2shiftDir = FLG_OMNInAMPERE_correlator_shiftDir; #shift direction (remember POS goes back in time b/c you need to add +offset to a time range to bring it forward to align w/ reference time frame)
    data1types = [settings_AMPERE['labels'][settings_AMPERE['data type']]]; #data1 (1nd set of inputs into function) types involved
    data2types = OMNI_plotSet_name; #data2 (2nd set of inputs into function) types involved
    
    corrRet = [None for i in range(0,len(data1types))];
    for i in range(0,len(data1types)):
        #--- Integrated AMPERE Data ---
        corrRet[i], time_cutout_range_walking = subfun_correlator_walking(
                data['AMPERE'], settings['AMPERE'], 'AMPERE', 'integrated', \
                data['OMNI'], settings['OMNI'], 'OMNI', OMNI_plotSet_name, \
                dates, settings['plot'], settings['paths'], settings['config'], \
                FLG_OMNInAMPERE_correlator, None, FLG_correlator_plot = False, FLG_correlator_tabulator = False, \
                FLG_correlator_shiftDir = time2shiftDir, FLG_correlator_timeLim = time2lim, \
                filt1 = None,  filt2 = None, settings_spectra=settings['spectra'], reportDivisor=[60,'min'],
                time2span=time2span, time2step=time2step, time2bound=[dates['date range full dayNum'][0,1]*86400, (dates['date range full dayNum'][-1,1]+1)*86400], FLG_clipData2=False, FLG_nanLimitData2=False);
    #END FOR i
    
    #--- Plot the returns up ---
    if( FLG_fancyPlot < 2 ):
        subfun_correlator_walking_plotter(corrRet, data1types, data2types, \
            time_cutout_range_walking, time2span, \
            time2step, time2lim, time2shiftDir, \
            settings['plot'], settings['paths'], dates, \
            FLG_showNiteTimes = False, showNiteTimesDict = None, \
            reportDivisor = [3600,'hr'], FLG_fancyPlot = False); #plot that up
    #END IF
    if( FLG_fancyPlot > 0 ):
        subfun_correlator_walking_plotter(corrRet, data1types, data2types, \
            time_cutout_range_walking, time2span, \
            time2step, time2lim, time2shiftDir, \
            settings['plot'], settings['paths'], dates, \
            FLG_showNiteTimes = False, showNiteTimesDict = None, \
            reportDivisor = [3600,'hr'], FLG_fancyPlot = True); #plot that up
    #END IF
#END IF

if( FLG_OMNInAMPERE_correlator >= 1 ):
    from Code.subfun_correlator_corraler import subfun_correlator_corraler
    corrRet = subfun_correlator_corraler(
            data['AMPERE'], settings['AMPERE'], 'AMPERE', 'integrated', \
            data['OMNI'], settings['OMNI'], 'OMNI', OMNI_plotSet_name, \
            dates, settings['plot'], settings['paths'], settings['config'], \
            FLG_OMNInAMPERE_correlator, FLG_OMNInAMPERE_correlator_options, \
            FLG_correlator_shiftDir = FLG_OMNInAMPERE_correlator_shiftDir, \
            FLG_correlator_plot = FLG_OMNInAMPERE_correlator_plot, FLG_correlator_tabulator = FLG_OMNInAMPERE_correlator_tabulator);
#END IF

if( FLG_OMNInAMPERE_Xcorrelator >= 1 ):
    from Code.subfun_Xcorrelator import subfun_Xcorrelator
    from Code.subfun_timeMatch import subfun_timeMatch
    
    print('\nWorking on Xcorrelator_OMNInAMPERE');
    
    if( len(FLG_OMNInAMPERE_Xcorrelator_options) == len(OMNI_plotSet_name) ):
        # AMPERE_integrated = GRITI_AMPERE_integrator(data['AMPERE'], dates, settings_AMPERE, plotLatRange, plotLongRange, AMPERE_integrateMethod, AMPERE_integrateMethod_val, AMPERE_integrateMethod_log=AMPERE_integrateMethod_log); #integrate the AMPERE data according to some settings
        if( settings_AMPERE['data type'].lower() != 'jh' ):
            AMPERE_integrated_noise = np.random.normal(loc=np.nanmean(AMPERE_integrated),scale=np.nanstd(AMPERE_integrated),size=(100,AMPERE_integrated.size)); #create some fake data
        else:
            AMPERE_integrated_noise = np.abs(np.random.normal(loc=0,scale=np.nanstd(AMPERE_integrated),size=(100,AMPERE_integrated.size))); #create some fake data
        #END IF
        
        XcorrRet = [None for i in range(0,len(OMNI_plotSet_name))]; #preallocate
        kr_OMNI = (OMNI_timeUnique >= dateRange_dayNum_full[0,1]*86400) & (OMNI_timeUnique < (dateRange_dayNum_full[-1,1]+1)*86400); #get stuff outside the date range
        kr_AMPERE = (data['AMPERE']['time unique'] >= dateRange_dayNum_full[0,1]*86400) & (data['AMPERE']['time unique'] < (dateRange_dayNum_full[-1,1]+1)*86400); #get stuff outside the date range
        for i in range(0,len(OMNI_plotSet_name)):
            if( FLG_OMNInAMPERE_Xcorrelator_options[i]['time shift'] == 'correlator' ):
                if( FLG_OMNInAMPERE_correlator >= 1 ):
                    FLG_OMNInAMPERE_Xcorrelator_options[i]['time shift'] = corrRet[i]['time shift']; #set it to prev correlator best value
                else:
                    print('ERROR in OMNInAMPERE_Xcorrelator: time shift set to "correlator" but FLG_OMNInAMPERE_correlator was off. Crashing b/c it\'s not there.');
                    import sys
                    sys.crash();
                #END IF
            #END IF
            
            OMNI_noise = np.random.normal(loc=np.nanmean(OMNI_data[kr_OMNI,OMNI_dict[OMNI_plotSet_name[i]]]),scale=np.nanstd(OMNI_data[kr_OMNI,OMNI_dict[OMNI_plotSet_name[i]]]),size=(100,OMNI_data[kr_OMNI,OMNI_dict[OMNI_plotSet_name[i]]].size)); #create some fake data
            if( FLG_OMNInAMPERE_Xcorrelator == 1 ):
                sig1 = OMNI_data[kr_OMNI,OMNI_dict[OMNI_plotSet_name[i]]]; #sig1 stays static
                sig1_noise = OMNI_noise;
                time1 = OMNI_timeUnique[kr_OMNI]-dates['date range zero hr dayNum'][1]*86400;
                dataRate1 = data['OMNI']['data rate'];
                sig2 = AMPERE_integrated[kr_AMPERE]; #sig2 moves around
                sig2_noise = AMPERE_integrated_noise[:,kr_AMPERE];
                time2 = data['AMPERE']['time unique'][kr_AMPERE]-dates['date range zero hr dayNum'][1]*86400;
                dataRate2 = data['AMPERE']['data rate'];
                plotName = OMNI_dictPlot[OMNI_dict[OMNI_plotSet_name[i]]][:OMNI_dictPlot[OMNI_dict[OMNI_plotSet_name[i]]].find(' [')]+ \
                    ' & '+settings_AMPERE['labels'][settings_AMPERE['data type']];
            else:
                sig1 = AMPERE_integrated[kr_AMPERE]; #sig1 stays static
                sig1_noise = AMPERE_integrated_noise[:,kr_AMPERE];
                time1 = data['AMPERE']['time unique'][kr_AMPERE]-dates['date range zero hr dayNum'][1]*86400;
                dataRate1 = data['AMPERE']['data rate'];
                sig2 = OMNI_data[kr_OMNI,OMNI_dict[OMNI_plotSet_name[i]]]; #sig2 moves around
                sig2_noise = OMNI_noise;
                time2 = OMNI_timeUnique[kr_OMNI]-dates['date range zero hr dayNum'][1]*86400;
                dataRate2 = data['OMNI']['data rate'];
                plotName = settings_AMPERE['labels'][settings_AMPERE['data type']]+ \
                    ' & '+OMNI_dictPlot[OMNI_dict[OMNI_plotSet_name[i]]][:OMNI_dictPlot[OMNI_dict[OMNI_plotSet_name[i]]].find(' [')];
            #END IF
            if( np.isclose(dataRate1,dataRate2) == False ):
                if( dataRate1 > dataRate2 ):
                    sig2, _ = subfun_timeMatch(sig2, time2, time1, timeMatch_delta=dataRate1, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                    sig2_noise, time2 = subfun_timeMatch(sig2_noise, time2, time1, timeMatch_delta=dataRate1, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                    dataRate2 = dataRate1; #set it
                else:
                    sig1, _ = subfun_timeMatch(sig1, time1, time2, timeMatch_delta=dataRate2, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                    sig1_noise, time1 = subfun_timeMatch(sig1_noise, time1, time2, timeMatch_delta=dataRate2, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                    dataRate1 = dataRate2; #set it
                #END IF
            #END IF
                       
            if( FLG_OMNInAMPERE_Xcorrelator_options[i]['time shift'] != None ):
                time2shift = FLG_OMNInAMPERE_Xcorrelator_options[i]['time shift']; #set to value
            else:
                time2shift = OMNI_delay_wrt_AMPERE*3600; #use global value
            #END IF
            XcorrRet[i] = subfun_Xcorrelator(sig1, sig2, sig1_filt=FLG_OMNInAMPERE_Xcorrelator_options[i]['sig1 filt'], sig2_filt=FLG_OMNInAMPERE_Xcorrelator_options[i]['sig2 filt'], sig1_noise=sig1_noise, sig2_noise=sig2_noise, time1=time1, time2=time2, time2shift=time2shift, \
                   dataRate=dataRate1, timeRange=FLG_OMNInAMPERE_Xcorrelator_options[i]['time range'], settings_spectra=settings_spectra, FLG_interpGaps=True, reportDivisor=[60,'min'], reportRounder=3, \
                   FLG_plot=True, FLG_plot_onlyXcorr=False, settings_plot=settings_plot, settings_paths=settings_paths, dates=dates, plotName=plotName, FLG_fancyPlot=0);
        #END FOR i
    else:
        print('WARNING in FLG_OMNInAMPERE_Xcorrelator: Length of FLG_OMNInAMPERE_Xcorrelator_options ('+str(len(FLG_OMNInAMPERE_Xcorrelator_options))+') does not equal length of OMNI_plotSet_name ('+str(len(OMNI_plotSet_name))+')');
    #END IF
#END IF


#****************************************************************SuperMAG Indices ANALYSIS****************************************************************
if( FLG_SuperMAG_plot >= 1 ):
    GRITI_SuperMAG_plot(data['SuperMAG'], settings['SuperMAG'], dates, settings_plot, \
            opt=2, time_Ref=time_Ref, time_Reference=time_Reference, \
            settings_paths=settings_paths); #call the plot data
#END IF

if( FLG_SuperMAGnAMPERE_correlator_walking >= 1 ):
    print('\nNOTA BENE: Running FLG_SuperMAGnAMPERE_correlator_walking. Walking correlation calcs and plots will take a while.\n');
    from Code.subfun_correlator_walking import subfun_correlator_walking
    from Code.subfun_correlator_walking_plotter import subfun_correlator_walking_plotter
    
    #----- TEC & AMPERE SETTINGS -----
    time2lim = 4*3600; #time limit to check corr coeffs for
    time2span = 6*3600; #time range to cutout and check
    time2step = 1*3600; #time increment to step 
    time2shiftDir = FLG_SuperMAGnAMPERE_correlator_shiftDir; #shift direction (remember POS goes back in time b/c you need to add +offset to a time range to bring it forward to align w/ reference time frame)
    data1types = [settings_AMPERE['labels'][settings_AMPERE['data type']]]; #data1 (1nd set of inputs into function) types involved
    data2types = SuperMAG_plotSet; #data2 (2nd set of inputs into function) types involved
    
    corrRet = [None for i in range(0,len(data1types))];
    for i in range(0,len(data1types)):
        #--- Integrated AMPERE Data ---
        corrRet[i], time_cutout_range_walking = subfun_correlator_walking(
                data['AMPERE'], settings['AMPERE'], 'AMPERE', 'integrated', \
                data['SuperMAG'], settings['SuperMAG'], 'SuperMAG', SuperMAG_plotSet, \
                dates, settings['plot'], settings['paths'], settings['config'], \
                FLG_OMNInAMPERE_correlator, None, FLG_correlator_plot = False, FLG_correlator_tabulator = False, \
                FLG_correlator_shiftDir = time2shiftDir, FLG_correlator_timeLim = time2lim, \
                filt1 = None,  filt2 = None, settings_spectra=settings['spectra'], reportDivisor=[60,'min'],
                time2span=time2span, time2step=time2step, time2bound=[dates['date range full dayNum'][0,1]*86400, (dates['date range full dayNum'][-1,1]+1)*86400], FLG_clipData2=False, FLG_nanLimitData2=False);
    #END FOR i
    
    #--- Plot the returns up ---
    if( FLG_fancyPlot < 2 ):
        subfun_correlator_walking_plotter(corrRet, data1types, data2types, \
            time_cutout_range_walking, time2span, \
            time2step, time2lim, time2shiftDir, \
            settings['plot'], settings['paths'], dates, \
            FLG_showNiteTimes = False, showNiteTimesDict = None, \
            reportDivisor = [3600,'hr'], FLG_fancyPlot = False); #plot that up
    #END IF
    if( FLG_fancyPlot > 0 ):
        subfun_correlator_walking_plotter(corrRet, data1types, data2types, \
            time_cutout_range_walking, time2span, \
            time2step, time2lim, time2shiftDir, \
            settings['plot'], settings['paths'], dates, \
            FLG_showNiteTimes = False, showNiteTimesDict = None, \
            reportDivisor = [3600,'hr'], FLG_fancyPlot = True); #plot that up
    #END IF
#END IF

if( FLG_SuperMAGnAMPERE_correlator >= 1 ):
    from Code.subfun_correlator_corraler import subfun_correlator_corraler
    corrRet = subfun_correlator_corraler(
            data['AMPERE'], settings['AMPERE'], 'AMPERE', 'integrated', \
            data['SuperMAG'], settings['SuperMAG'], 'SuperMAG', SuperMAG_plotSet, \
            dates, settings['plot'], settings['paths'], settings['config'], \
            FLG_SuperMAGnAMPERE_correlator, FLG_SuperMAGnAMPERE_correlator_options, \
            FLG_correlator_shiftDir = FLG_SuperMAGnAMPERE_correlator_shiftDir, FLG_correlator_plot = FLG_SuperMAGnAMPERE_correlator_plot, FLG_correlator_tabulator = FLG_SuperMAGnAMPERE_correlator_tabulator);
#END IF

if( FLG_SuperMAGnAMPERE_Xcorrelator >= 1 ):
    from Code.subfun_Xcorrelator import subfun_Xcorrelator
    from Code.subfun_timeMatch import subfun_timeMatch
    
    print('\nWorking on Xcorrelator_SuperMAGnAMPERE');
    SuperMAG_data = data['SuperMAG']; #alias
    if( len(FLG_SuperMAGnAMPERE_Xcorrelator_options) == len(SuperMAG_plotSet) ):
        # AMPERE_integrated = GRITI_AMPERE_integrator(data['AMPERE'], dates, settings_AMPERE, plotLatRange, plotLongRange, AMPERE_integrateMethod, AMPERE_integrateMethod_val, AMPERE_integrateMethod_log=AMPERE_integrateMethod_log); #integrate the AMPERE data according to some settings
        if( settings_AMPERE['data type'].lower() != 'jh' ):
            AMPERE_integrated_noise = np.random.normal(loc=np.nanmean(AMPERE_integrated),scale=np.nanstd(AMPERE_integrated),size=(100,AMPERE_integrated.size)); #create some fake data
        else:
            AMPERE_integrated_noise = np.abs(np.random.normal(loc=0,scale=np.nanstd(AMPERE_integrated),size=(100,AMPERE_integrated.size))); #create some fake data
        #END IF
        
        kr_SuperMAG = (SuperMAG_timeUnique >= dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique < (dateRange_dayNum_full[-1,1]+1)*86400); #get stuff outside the date range
        kr_AMPERE = (data['AMPERE']['time unique'] >= dateRange_dayNum_full[0,1]*86400) & (data['AMPERE']['time unique'] < (dateRange_dayNum_full[-1,1]+1)*86400); #get stuff outside the date range
        SuperMAG_timeUnique_limdZerod = SuperMAG_timeUnique[kr_SuperMAG]-dates['date range zero hr dayNum'][1]*86400; #limit once & calc once b/c reused
        AMPERE_integrated_limd = AMPERE_integrated[kr_AMPERE]; #limit once b/c reused
        AMPERE_integrated_noise_limd = AMPERE_integrated_noise[:,kr_AMPERE]; #limit once b/c reused
        AMPERE_timeUnique_limdZerod = data['AMPERE']['time unique'][kr_AMPERE]-dates['date range zero hr dayNum'][1]*86400; #limit once & calc once b/c reused
        
        XcorrRet = [None for i in range(0,len(SuperMAG_plotSet))]; #preallocate
        for i in range(0,len(SuperMAG_plotSet)):
            if( FLG_SuperMAGnAMPERE_Xcorrelator_options[i]['time shift'] == 'correlator' ):
                if( FLG_SuperMAGnAMPERE_correlator >= 1 ):
                    FLG_SuperMAGnAMPERE_Xcorrelator_options[i]['time shift'] = corrRet[i]['time shift']; #set it to prev correlator best value
                else:
                    print('ERROR in SuperMAGnAMPERE_Xcorrelator: time shift set to "correlator" but FLG_SuperMAGnAMPERE_correlator was off. Crashing b/c it\'s not there.');
                    import sys
                    sys.crash();
                #END IF
            #END IF
            
            SuperMAG_dataCurr = SuperMAG_data[SuperMAG_plotSet[i]][kr_SuperMAG];
            SuperMAG_noise = np.random.normal(loc=np.nanmean(SuperMAG_dataCurr),scale=np.nanstd(SuperMAG_dataCurr),size=(100,SuperMAG_dataCurr.size)); #create some fake data
            if( FLG_SuperMAGnAMPERE_Xcorrelator == 1 ):
                sig1 = SuperMAG_dataCurr; #sig1 stays static
                sig1_noise = SuperMAG_noise;
                time1 = SuperMAG_timeUnique_limdZerod;
                dataRate1 = data['SuperMAG']['data rate'];
                sig2 = AMPERE_integrated_limd; #sig2 moves around
                sig2_noise = AMPERE_integrated_noise_limd;
                time2 = AMPERE_timeUnique_limdZerod;
                dataRate2 = data['AMPERE']['data rate'];
                plotName = settings_SuperMAG['labels'][SuperMAG_plotSet[i]]+ \
                    ' & '+settings_AMPERE['labels'][settings_AMPERE['data type']];
            else:
                sig1 = AMPERE_integrated_limd; #sig1 stays static
                sig1_noise = AMPERE_integrated_noise_limd;
                time1 = AMPERE_timeUnique_limdZerod;
                dataRate1 = data['AMPERE']['data rate'];
                sig2 = SuperMAG_dataCurr; #sig2 moves around
                sig2_noise = SuperMAG_noise;
                time2 = SuperMAG_timeUnique_limdZerod;
                dataRate2 = data['SuperMAG']['data rate'];
                plotName = settings_AMPERE['labels'][settings_AMPERE['data type']]+ \
                    ' & '+settings_SuperMAG['labels'][SuperMAG_plotSet[i]];
            #END IF
            if( np.isclose(dataRate1,dataRate2) == False ):
                if( dataRate1 > dataRate2 ):
                    sig2, _ = subfun_timeMatch(sig2, time2, time1, timeMatch_delta=dataRate1, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                    sig2_noise, time2 = subfun_timeMatch(sig2_noise, time2, time1, timeMatch_delta=dataRate1, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                    dataRate2 = dataRate1; #set it
                else:
                    sig1, _ = subfun_timeMatch(sig1, time1, time2, timeMatch_delta=dataRate2, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                    sig1_noise, time1 = subfun_timeMatch(sig1_noise, time1, time2, timeMatch_delta=dataRate2, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
                    dataRate1 = dataRate2; #set it
                #END IF
            #END IF
                       
            if( FLG_SuperMAGnAMPERE_Xcorrelator_options[i]['time shift'] != None ):
                time2shift = FLG_SuperMAGnAMPERE_Xcorrelator_options[i]['time shift']; #set to value
            else:
                time2shift = SuperMAG_delay_wrt_AMPERE*3600; #use global value
            #END IF
            XcorrRet[i] = subfun_Xcorrelator(sig1, sig2, sig1_filt=FLG_SuperMAGnAMPERE_Xcorrelator_options[i]['sig1 filt'], sig2_filt=FLG_SuperMAGnAMPERE_Xcorrelator_options[i]['sig2 filt'], sig1_noise=sig1_noise, sig2_noise=sig2_noise, time1=time1, time2=time2, time2shift=time2shift, \
                   dataRate=dataRate1, timeRange=FLG_SuperMAGnAMPERE_Xcorrelator_options[i]['time range'], settings_spectra=settings_spectra, FLG_interpGaps=True, reportDivisor=[60,'min'], reportRounder=3, \
                   FLG_plot=True, FLG_plot_onlyXcorr=False, settings_plot=settings_plot, settings_paths=settings_paths, dates=dates, plotName=plotName, FLG_fancyPlot=0);
        #END FOR i
    else:
        print('WARNING in FLG_SuperMAGnAMPERE_Xcorrelator: Length of FLG_SuperMAGnAMPERE_Xcorrelator_options ('+str(len(FLG_SuperMAGnAMPERE_Xcorrelator_options))+') does not equal length of SuperMAG_plotSet ('+str(len(SuperMAG_plotSet))+')');
    #END IF
#END IF


#****************************************************************COMBO Kp/OMNI/SuperMAG ANALYSIS****************************************************************
if( FLG_MECHACOMBO_plot >= 1 ):
    if( FLG_fancyPlot < 2 ):
        #plot the mecha combo plot
        GRITI_MECHACOMBO_plot(FLG_MECHACOMBO_plot_names, data, dates, settings, opt=2, FLG_ignoreUnitMismatch=FLG_MECHACOMBO_plot_mixUnits, FLG_MECHACOMBO_plot_timeLim=FLG_MECHACOMBO_plot_timeLim, FLG_MECHACOMBO_plot_localTime=FLG_MECHACOMBO_plot_localTime, FLG_MECHACOMBO_plot_singleColumn=FLG_MECHACOMBO_plot_singleColumn, FLG_fancyPlot=0);
    #END IF
    if( FLG_fancyPlot >= 1 ):
        #plot the mecha combo plot
        GRITI_MECHACOMBO_plot(FLG_MECHACOMBO_plot_names, data, dates, settings, opt=2, FLG_ignoreUnitMismatch=FLG_MECHACOMBO_plot_mixUnits, FLG_MECHACOMBO_plot_timeLim=FLG_MECHACOMBO_plot_timeLim, FLG_MECHACOMBO_plot_localTime=FLG_MECHACOMBO_plot_localTime, FLG_MECHACOMBO_plot_singleColumn=FLG_MECHACOMBO_plot_singleColumn, FLG_fancyPlot=FLG_fancyPlot); #also make one show up if fancyPlot == 1
    #END IF
#END IF


#****************************************************************ISR ANALYSIS****************************************************************

if( FLG_ISR_plot_POPL_HP == 1 ): #plot some of that ISR data on its own to check it out        
    GRITI_ISR_Haystack_plot_POPL_HP(Zenith_time,Zenith_height,Zenith_POPL_hp,MISA_time,MISA_height,MISA_POPL_hp, \
        settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_POPL_plotLimValu, \
        dates, settings_plot, settings_paths, \
        time_cutout_range=None, FLG_dayNite=0, settings_map=None, settings_config=None, FLG_fancyPlot=0);
#END IF

if( (FLG_ISR_plot_POPL_HP == 1) & (FLG_fancyPlot == 1) ): #plot some of that ISR data on its own to check it out
    GRITI_ISR_Haystack_plot_POPL_HP(Zenith_time,Zenith_height,Zenith_POPL_hp,MISA_time,MISA_height,MISA_POPL_hp, \
        settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_POPL_plotLimValu, \
        dates, settings_plot, settings_paths, \
        time_cutout_range=None, FLG_dayNite=1, settings_map=settings_map, settings_config=settings_config, FLG_fancyPlot=1);
#END IF
    
if( FLG_ISR_plot_POPL_HP_cutOut == 1 ):
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range

    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_POPL_hp_cutOut = Zenith_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                                    
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_POPL_hp_cutOut = MISA_POPL_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    GRITI_ISR_Haystack_plot_POPL_HP(Zenith_time,Zenith_height,Zenith_POPL_hp,MISA_time,MISA_height,MISA_POPL_hp, \
        settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_POPL_plotLimValu, \
        dates, settings_plot, settings_paths, \
        time_cutout_range=time_cutout_range, FLG_dayNite=0, settings_map=None, settings_config=None, FLG_fancyPlot=0);
#END IF  
    
if( FLG_ISR_Pokerflat_plot_POPL_HP == 1 ): #plot some of that ISR data on its own to check it out
    GRITI_ISR_Pokerflat_plot_POPL_HP(PFISR_time,PFISR_height,PFISR_POPL_hp,PFISR_el,PFISR_az, \
      settings_spectra['filter cutoff period'],ISR_Pokerflat_RTI_heightLimValues,ISR_POPL_plotLimValu, \
      dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF

if( FLG_ISR_plot_POPL == 1 ): #plot some of that ISR data on its own to check it out
    GRITI_ISR_Haystack_plot_POPL(Zenith_time,Zenith_height,Zenith_POPL, \
       MISA_time,MISA_height,MISA_POPL, \
       settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues, \
       dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF

if( FLG_ISR_Pokerflat_plot_POPL == 1 ): #plot some of that ISR data on its own to check it out
    GRITI_ISR_Pokerflat_plot_POPL(PFISR_time,PFISR_height,PFISR_POPL,PFISR_el,PFISR_az, \
      settings_spectra['filter cutoff period'],ISR_Pokerflat_RTI_heightLimValues,  \
      dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF
    
if( FLG_ISR_plot_POPL_limited == 1 ): #plot some of that ISR data on its own to check it out
    GRITI_ISR_Haystack_plot_POPL_limited(Zenith_time,Zenith_height,Zenith_POPL, \
       MISA_time,MISA_height,MISA_POPL, \
       settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_POPL_plotLimValu_noFilt, \
       dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF
    
if( FLG_ISR_Pokerflat_plot_POPL_limited == 1 ): #plot some of that ISR data on its own to check it out
    GRITI_ISR_Pokerflat_plot_POPL_limited(PFISR_time,PFISR_height,PFISR_POPL,PFISR_el,PFISR_az, \
      settings_spectra['filter cutoff period'],ISR_Pokerflat_RTI_heightLimValues,ISR_POPL_plotLimValu_noFilt,  \
      dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF

if( FLG_ISR_plot_POPL_ScargleSet == 1 ):
    GRITI_ISR_Haystack_plot_POPL_scargleSet(Zenith_time,Zenith_POPL,Zenith_POPL_hp,Zenith_filtHeight, \
        MISA_time,MISA_POPL,MISA_POPL_hp,MISA_filtHeight,pointAltitude,plot_periodLim_max, \
        dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF
    
if( FLG_ISR_plot_POPL_FFTSet == 1 ):
    GRITI_ISR_Haystack_plot_POPL_FFTSet(Zenith_time,Zenith_POPL,Zenith_POPL_hp,Zenith_filtHeight, \
        MISA_time,MISA_POPL,MISA_POPL_hp,MISA_filtHeight,pointAltitude,plot_periodLim_max, \
        dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF

if( FLG_ISR_plot_SNR_HP == 1 ): #plot some of that ISR data on its own to check it out
    GRITI_ISR_Haystack_plot_SNR_HP(Zenith_time,Zenith_height,Zenith_SNR_hp, \
      MISA_time,MISA_height,MISA_SNR_hp, \
      settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_plotLimValu, \
      dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF                                 

if( FLG_ISR_plot_SNR == 1 ): #plot some of that ISR data on its own to check it out
    GRITI_ISR_Haystack_plot_SNR(Zenith_time,Zenith_height,Zenith_SNR, \
       MISA_time,MISA_height,MISA_SNR, \
       settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues, \
       dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF
    
if( FLG_ISR_plot_SNR_limited == 1 ): #plot some of that ISR data on its own to check it out
    GRITI_ISR_Haystack_plot_SNR_limited(Zenith_time,Zenith_height,Zenith_SNR, \
       MISA_time,MISA_height,MISA_SNR, \
       settings_spectra['filter cutoff period'],ISR_RTI_heightLimValues,ISR_plotLimValu, \
       dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF

if( FLG_ISR_plot_ScargleSet == 1 ):
    GRITI_ISR_Haystack_plot_scargleSet(Zenith_time,Zenith_SNR,Zenith_SNR_hp,Zenith_filtHeight, \
        MISA_time,MISA_SNR,MISA_SNR_hp,MISA_filtHeight,pointAltitude,plot_periodLim_max, \
        dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF
    
if( FLG_ISR_plot_ionVel == 1 ):
    GRITI_ISR_Haystack_plot_ionVel(Zenith_time,Zenith_height,Zenith_vel,\
        MISA_time,MISA_height,MISA_vel,ISR_RTI_heightLimValues,ISR_ionVel_plotLimValu_noFilt, \
        dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF
      
if( FLG_ISR_plot_ionVel_cutOut == 1 ):
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range

    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_vel_cutOut = Zenith_vel[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                                    
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_vel_cutOut = MISA_vel[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    GRITI_ISR_Haystack_plot_ionVel_cutOut(Zenith_time_cutOut,Zenith_height,\
        Zenith_vel_cutOut,MISA_time_cutOut,MISA_height,MISA_vel_cutOut,ISR_RTI_heightLimValues, \
        ISR_ionVel_plotLimValu_noFilt,time_cutout_range,dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr, \
        FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF
    
if( FLG_ISR_plot_ionVel_hp == 1 ):
    GRITI_ISR_Haystack_plot_ionVel_HP(Zenith_time,Zenith_height,Zenith_vel_hp,\
        MISA_time,MISA_height,MISA_vel_hp,ISR_RTI_heightLimValues,ISR_ionVel_plotLimValu,settings_spectra['filter cutoff period'], \
        dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF
    
if( FLG_ISR_plot_ionVel_hp_cutOut == 1 ):
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (Zenith_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range

    Zenith_time_cutOut = Zenith_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    Zenith_vel_hp_cutOut = Zenith_vel_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(time_cutout_range) ) )[0][0] , \
        np.where(np.min(np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) )) == np.abs( (MISA_time-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
                                    
    MISA_time_cutOut = MISA_time[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    MISA_vel_hp_cutOut = MISA_vel_hp[:,time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    GRITI_ISR_Haystack_plot_ionVel_HP_cutOut(Zenith_time_cutOut,Zenith_height,\
        Zenith_vel_hp_cutOut,MISA_time_cutOut,MISA_height,MISA_vel_hp_cutOut,ISR_RTI_heightLimValues, \
        ISR_ionVel_plotLimValu,settings_spectra['filter cutoff period'],time_cutout_range,dateRange,dateRange_dayNum,dateRange_dayNum_zeroHr, \
        FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
#END IF
    
#****************************************************************Kp ANALYSIS****************************************************************
if( FLG_Kp_plot == 1 ):
    GRITI_Kp_plot(Kp_data,Kp_time,time_Ref,time_Reference, \
        dateRange_full,dateRange_zeroHr,dateRange_dayNum_zeroHr,dateRange_zeroHr_monthName, \
        dateRange_zeroHr_dayPostfix,FONT_titleFM,FONT_axisLabelFM,opt=2);
#END IF
                                                      
#****************************************************************OMNI ANALYSIS****************************************************************
if( FLG_OMNI_plot == 1 ):
    GRITI_OMNI_plot(OMNI_data,OMNI_timeUnique,OMNI_dict,OMNI_dictPlot,OMNI_plotSet_name, \
        time_Ref,time_Reference,dateRange_full,dateRange_zeroHr,dateRange_dayNum_zeroHr, \
        dateRange_zeroHr_monthName,dateRange_zeroHr_dayPostfix,FONT_titleFM,FONT_axisLabelFM,opt=2);
#END IF

if( (FLG_OMNI_plot == 1) & (FLG_fancyPlot == 1) ):
    GRITI_OMNI_plot(OMNI_data,OMNI_timeUnique,OMNI_dict,OMNI_dictPlot,OMNI_plotSet_name, \
        time_Ref,time_Reference,dateRange_full,dateRange_zeroHr,dateRange_dayNum_zeroHr, \
        dateRange_zeroHr_monthName,dateRange_zeroHr_dayPostfix,FONT_titleFM,FONT_axisLabelFM,opt=2,\
        FLG_fancyPlot=1,settings_plot=settings['plot'],settings_paths=settings['paths']);
#END IF

if( FLG_OMNI_plot_scargle == 1 ):
    GRITI_OMNI_plot_scargle(OMNI_data,OMNI_timeUnique,OMNI_dict,OMNI_dictPlot,OMNI_plot_scargle_name,\
        settings_spectra['filter cutoff period'],dateRange,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisLabelFM,settings, \
        plot_Period_Lim=plot_periodLim_max,OMNI_plot_scargle_highpassOption=OMNI_plot_scargle_highpassOption);
#END IF
    
if( FLG_OMNI_plot_FFT == 1 ):
    GRITI_OMNI_plot_FFT(OMNI_data,OMNI_timeUnique,OMNI_dict,OMNI_dictPlot,OMNI_plot_scargle_name,\
        settings_spectra['filter cutoff period'],dateRange,dateRange_dayNum_zeroHr,FONT_titleFM,FONT_axisLabelFM,settings, \
        plot_Period_Lim=plot_periodLim_max,OMNI_plot_scargle_highpassOption=OMNI_plot_scargle_highpassOption);
#END IF

if( FLG_OMNI_plot_combined == 1 ):
    import numpy as np #import in here I dunno
    import matplotlib.pyplot as plt
    from Code.subfun_figFitter import figFitter
    
    if( FLG_fancyPlot == 1 ):
        print('MAKING FANCY PLOT: OMNI_duelingData IN fancyPlot FOLDER'); #report since you won't see anything
    #END IF
    
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    #--- Prep the plot ---
    if( FLG_fancyPlot == 0 ):
        fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
    else:
        plt.ioff() #disable showing the plot as its size will be larger than the screen, which cannot happen if the plot is shown
        fig, ax = plt.subplots(figsize=(14,8.5),dpi=journal_dpi); #use instead of fig because it inits an axis too (I think I dunno)
    #END IF
    ax = [ax]; #make it a list
    for i in range(0,len(OMNI_plotComb_name)-1):
        ax.append(ax[0].twinx()); #tack it on
        ax[i+1].yaxis.tick_right(); #on right side
    #END FOR i
    
    #-----PREP OMNI STUFF-----
    OMNI_timeUnique_hr = (OMNI_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    if( np.mod(np.round(np.min(OMNI_timeUnique_hr)),2) == 0 ):
        OMNI_time_hr_axis_min = np.round(np.min(OMNI_timeUnique_hr)); #is even, good to go
    else:
        OMNI_time_hr_axis_min = np.round(np.min(OMNI_timeUnique_hr))+1; #is odd, make even
    #END IF
    if( np.mod(np.round(np.max(OMNI_timeUnique_hr)),2) == 0 ):
        OMNI_time_hr_axis_max = np.round(np.max(OMNI_timeUnique_hr)); #is even, good to go
    else:
        OMNI_time_hr_axis_max = np.round(np.max(OMNI_timeUnique_hr))-1; #is odd, make even
    #END IF
    xAxisTicksMax = 18; #maximum number of ticks that can fit on the bottom
    xAxisTicksSteps = np.array( (1,2,4,6,12,24) ); #allowed steps to choose from
    xAxisTicksNum = (OMNI_time_hr_axis_max-OMNI_time_hr_axis_min)/xAxisTicksSteps+1; #calc how many tick marks there will be
    xAxisTicksStep = np.where(xAxisTicksNum <= xAxisTicksMax)[0][0]; #get the step that is good enough
    xAxisTicksOMNI = np.arange(OMNI_time_hr_axis_min,OMNI_time_hr_axis_max+xAxisTicksSteps[xAxisTicksStep],xAxisTicksSteps[xAxisTicksStep]); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
    
    plotHands = []; #prep
    plotLabs = []; #prep
    for i in range(0,len(OMNI_plotComb_name)):
        #--- Actually plot ---
        p1, = ax[i].plot( OMNI_timeUnique_hr, OMNI_data[:,OMNI_dict[OMNI_plotComb_name[i]]] , linewidth=PLOT_lineWidthSmol, color=settings_plot['color'][i], antialiased=True); #plot
        plotHands.append(p1);
        plotLabs.append(OMNI_plotComb_name[i]);
        
        #--- Tick Time ---
        ax[i].set_xticks(xAxisTicksOMNI); #set x axis ticks

        ax[i].set_xlim( OMNI_time_hr_axis_min , OMNI_time_hr_axis_max ); #set y axis limits
        
        ax[i].set_ylabel(OMNI_dictPlot[OMNI_dict[OMNI_plotComb_name[i]]],fontproperties=FONT_axisLabelFM); #set the y axis label
        
        ax[i].set_ylim( np.min(OMNI_data[:,OMNI_dict[OMNI_plotComb_name[i]]]) , np.max(OMNI_data[:,OMNI_dict[OMNI_plotComb_name[i]]]) ); #set y axis limits
    #END FOR i
    
    #--- Label & Clean up plot ---
    ax[0].legend(plotHands,plotLabs);
    ax[0].grid(b=True, which='major', axis='both', color='xkcd:light grey',linewidth=PLOT_lineWidthSmol); #sets major axis grid lines to be on
    ax[0].set_xlabel('Time in UT [hr] - 0 Hr on '+dateRange_zeroHr_monthName+' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM); #set the x axis label
    
    figFitter(fig); #fit the fig fast
    if( FLG_fancyPlot != 0 ):
        fig.savefig(settings_paths['fancyPlots']+'\\'+'OMNI_duelingData.png'); #save the figure
        plt.close(); #close figure b/c it lurks apparently
        plt.ion(); #re-enable it for later stuff
    #END IF
    
#END IF

if( FLG_OMNI_stacker == 1 ):
    from Code.subfun_figFitter import figFitter
    from Code.subfun_insert import subfun_insert
    from scipy.interpolate import interp1d
    
    #-----Unpack-----
    # plotLatRange = settings['map']['lat range'];
    # plotLongRange = settings['map']['long range'];
    
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    #-----Stack-----
    OMNI_timeUnique_uniqueDays, OMNI_timeUnique_uniqueDaysIndex, OMNI_timeUnique_uniqueDayCounts = np.unique(np.int64(OMNI_timeUnique),return_inverse=True,return_counts=True); #get the unique days and the indexes that get us to them
    
    OMNI_stackerDaysStacked = OMNI_timeUnique_uniqueDays.size; #get the number of days to stack
    OMNI_stackerTime = np.int64(np.arange(0,86400,data['OMNI']['data rate'])); #sec, make a time vector to go with the stacker var
    OMNI_stackerHolder = np.zeros( (OMNI_stackerTime.size , OMNI_timeUnique_uniqueDays.size) ); #preallocate
    #STACK EM
    for i in range(0,OMNI_timeUnique_uniqueDays.size):
        k = np.where( OMNI_timeUnique_uniqueDaysIndex == i )[0]; #get indexes with the first day
        if( OMNI_timeUnique_uniqueDayCounts[i] == OMNI_stackerTime.size ):
            OMNI_stackerHolder[:,i] = OMNI_data[:,OMNI_dict[OMNI_plot_name]][k]; #yoink
        else:
            tempTimeSec = np.int64(np.round((OMNI_timeUnique[k]-OMNI_timeUnique_uniqueDays[i])*86400)); #get the seconds in the day
            k2 = np.isin(OMNI_stackerTime, tempTimeSec, assume_unique=True,invert=True); #get missing time steps
            #--- Pad with NaNs ---
            # OMNI_stackerHolder[:,i] = subfun_insert(OMNI_data[:,OMNI_dict[OMNI_plot_name]][k],np.where(k2)[0],np.nan); #yoink, pad with NaN's as needed
            #--- Interpolate over NaNs ---
            k3 = np.isin(np.arange(0,OMNI_stackerTime.size,step=1), np.where(k2)[0], assume_unique=True,invert=True); #get data indexes
            OMNI_stackerHolder[k3,i] = OMNI_data[:,OMNI_dict[OMNI_plot_name]][k]; #record the real data
            nan_interper = interp1d(tempTimeSec,OMNI_data[:,OMNI_dict[OMNI_plot_name]][k],kind='linear',fill_value='extrapolate'); #make an interpolator
            OMNI_stackerHolder[np.where(k2)[0],i] = nan_interper(OMNI_stackerTime[np.where(k2)[0]]); #interpolate over the NaNs
        #END IF     
        #--- Condition data to be normalized ---
        OMNI_stackerHolder[:,i] = OMNI_stackerHolder[:,i] - np.nanmean(OMNI_stackerHolder[:,i]); #0 the mean
        pwr = np.sqrt(1/OMNI_stackerHolder[:,i].size*np.nansum(OMNI_stackerHolder[:,i]**2)); #estimate power of signal
        OMNI_stackerHolder[:,i] = 1/pwr*OMNI_stackerHolder[:,i]; #normalize power
    #END FOR i
    
    OMNI_stacker = np.nanmean(OMNI_stackerHolder,axis=1); #average along the 3rd axis
            
    data['OMNI']['stacker'] = OMNI_stacker; #record
    data['OMNI']['stacker per day'] = OMNI_stackerHolder; #record
    data['OMNI']['stacker time'] = OMNI_stackerTime; #record
    
    #Start the OMNI and OMNI AE plot
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    #-----PLOT OMNI-----
    ax.set_aspect('auto'); #Remove the aspect ratio from the basemap so it fills the screen better
    ax.plot( OMNI_stackerTime/3600, OMNI_stacker , linewidth=PLOT_lineWidthRegular ); #plot
    
    xAxisTicks = np.arange(np.int64(np.floor(np.min(OMNI_stackerTime/3600))),np.int64(np.ceil(np.max(OMNI_stackerTime/3600)))+1,1); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    
#        ax[0].set_xticklabels([]); #if statement to remove x axis labels except for the last line
#        ax[0].tick_params(axis="x",direction="in");
    
    ax.set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set y axis limits
    
    ax.set_ylabel(OMNI_dictPlot[OMNI_dict[OMNI_plot_name]],fontproperties=FONT_axisLabelFM); #set the y axis label
    
    # ax[0].set_ylim( np.min(OMNI_jouleHeating_integrate) , 150000 ); #set y axis limits
    
    ax.grid(b=True, which='major', axis='both', color='xkcd:light grey'); #sets major axis grid lines to be on                
    
    string_title = str(OMNI_stackerDaysStacked)+' Days Stacked of OMNI '+OMNI_plot_name; #create mecha title
    ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title        
            
    ax.set_xlabel('Relative time through a day, aligned to 0 UT [hr]',fontproperties=FONT_axisLabelFM); #set the x axis label
    
    figFitter(fig); #fit the fig fast
    # fig.subplots_adjust(left = 0.090, right = 0.985, top = 0.96, bottom = 0.070); #sets padding to small numbers for minimal white space  
    
    #Start the OMNI and OMNI AE plot
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    #-----PLOT OMNI-----
    ax.set_aspect('auto'); #Remove the aspect ratio from the basemap so it fills the screen better
    for i in range(0,OMNI_stackerHolder.shape[1]):
        ax.plot( OMNI_stackerTime/3600, OMNI_stackerHolder[:,i] , linewidth=PLOT_lineWidthRegular, color=settings['plot']['color'][i] , label='Day '+str(i+1)); #plot
    #END FOR i
    ax.legend(); #make the legend show up
    
    xAxisTicks = np.arange(np.int64(np.floor(np.min(OMNI_stackerTime/3600))),np.int64(np.ceil(np.max(OMNI_stackerTime/3600)))+1,1); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    
#        ax[0].set_xticklabels([]); #if statement to remove x axis labels except for the last line
#        ax[0].tick_params(axis="x",direction="in");
    
    ax.set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set y axis limits
    
    ax.set_ylabel(OMNI_dictPlot[OMNI_dict[OMNI_plot_name]],fontproperties=FONT_axisLabelFM); #set the y axis label
    
    # ax[0].set_ylim( np.min(OMNI_jouleHeating_integrate) , 150000 ); #set y axis limits
    
    ax.grid(b=True, which='major', axis='both', color='xkcd:light grey'); #sets major axis grid lines to be on                
    
    string_title = str(OMNI_stackerDaysStacked)+' Days [Not Stacked] of OMNI '+OMNI_plot_name; #create mecha title
    ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title        
            
    ax.set_xlabel('Relative time through a day, aligned to 0 UT [hr]',fontproperties=FONT_axisLabelFM); #set the x axis label
    
    figFitter(fig); #fit the fig fast
    # fig.subplots_adjust(left = 0.090, right = 0.985, top = 0.96, bottom = 0.070); #sets padding to small numbers for minimal white space
#END IF

if( FLG_OMNI_stacker_FFT == 1 ):
    from Code.subfun_filter import subfun_filter
    from Code.subfun_spectra import subfun_spectra
    from Code.subfun_figFitter import figFitter
    from Code.subfun_timeMatch import subfun_timeMatch
    
    #---- Unpack -----
    settings_spectra = settings['spectra'];

    OMNI_dataRate = np.copy(data['OMNI']['data rate']).item(); #get the data rate
    #---OMNI PREP - time Match & HP---
    if( np.isclose(OMNI_dataRate,360) == False ):
        sixMin_timeUnique_sec = np.arange(0,86400,360); #sec, arange time stamps
        #Match the data in the 1st input (and its time in the 2nd input) to the time scale given in the 3rd input time and return that data and that data's highpassed form
        OMNI_timeMatch, OMNI_timeUnique_timeMatch = subfun_timeMatch(data['OMNI']['stacker'], data['OMNI']['stacker time'], sixMin_timeUnique_sec, timeMatch_delta=OMNI_dataRate, FLG_useSum=0); #match that time scale
        OMNI_dataRate = 6*60; #sec, record the new data rate
    else:
        OMNI_timeMatch = data['OMNI']['stacker']; #set so no errors
        OMNI_timeUnique_timeMatch = data['OMNI']['stacker time']; #set so no errors
    #END IF
    
    OMNI_timeMatch_filt = subfun_filter( OMNI_timeMatch, OMNI_timeUnique_timeMatch, OMNI_FFT_filtMethod, settings_spectra, dataRate = OMNI_dataRate); #filter
    
    Cxx_OMNI, period_OMNI = subfun_spectra( OMNI_timeMatch_filt, OMNI_timeUnique_timeMatch, 'FFT', settings_spectra, dataRate = OMNI_dataRate); #get spectra
    # Cxx_OMNI, period_OMNI, _ = subfun_spectra( OMNI_timeMatch_filt, OMNI_timeUnique_timeMatch, 'Lomb-Scargle', settings_spectra, dataRate = OMNI_dataRate); #get spectra

    #PLOT IT UP
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
    #Start the OMNI stacker FFT plot
    fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    ax.plot( period_OMNI/60, Cxx_OMNI ); #plot
#        ax.plot( OMNI_data_scargPeriod, np.tile(OMNI_data_scarggf,np.size(OMNI_data_scargPeriod)) , color="xkcd:grey" ); #plot
    
    ax.set_xlabel("Periods [min]"+' for Date Range '+str(dateRange[0,1])+'/'+str(dateRange[0,2])+ \
        '/'+str(dateRange[0,0])+' to '+str(dateRange[-1,1])+ '/'+str(dateRange[-1,2])+'/'+str(dateRange[-1,0])+ ' (M/D/Y)',fontproperties=FONT_axisLabelFM); #set the x axis label
    ax.set_ylabel('Normalized Power',fontproperties=FONT_axisLabelFM); #set the y axis label
    
    xAxisTicks = np.arange( 0, settings_spectra['period limit max']/60+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    ax.set_xlim( (settings_spectra['period limit min']/60, settings_spectra['period limit max']/60) ); #set x axis limits

#        if( OMNI_data_scarggf < np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim]) ):
#            ax.set_ylim( (0, np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim]) ) ); #set x axis limits
#        else:
#            ax.set_ylim( (0, OMNI_data_scarggf+0.1*OMNI_data_scarggf ) ); #set x axis limits
#        #END IF 
    

    string_title = str(OMNI_stackerDaysStacked)+' Days Stacked of OMNI '+OMNI_plot_name+' - FFT Power Spectra with '+OMNI_FFT_filtMethod+' Filter with a '+textNice(settings['spectra']['savgol filter period']/60)+' min Cutoff Period'; #create mecha title
    ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
    
    figFitter(fig); #fit the fig fast
    # fig.subplots_adjust(left = 0.050, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space    

    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
    #Start the OMNI stacker per day FFT plot
    fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    for i in range(0,data['OMNI']['stacker per day'].shape[1]):
        OMNI_stackerPerDay = data['OMNI']['stacker per day'][:,i]; #unpack
        OMNI_stackerPerDay[np.isnan(OMNI_stackerPerDay)] = 0; #force NaNs to 0
        OMNI_timeMatch_filt = subfun_filter( OMNI_stackerPerDay, OMNI_timeUnique_timeMatch, OMNI_FFT_filtMethod, settings_spectra, dataRate = OMNI_dataRate); #filter
        Cxx_OMNI, period_OMNI = subfun_spectra( OMNI_timeMatch_filt, OMNI_timeUnique_timeMatch, 'FFT', settings_spectra, dataRate = OMNI_dataRate); #get spectra
        # Cxx_OMNI, period_OMNI, _ = subfun_spectra( OMNI_timeMatch_filt, OMNI_timeUnique_timeMatch, 'Lomb-Scargle', settings_spectra, dataRate = OMNI_dataRate); #get spectra
        ax.plot( period_OMNI/60, Cxx_OMNI , color=settings['plot']['color'][i], label='Day '+str(i+1)); #plot
    #END FOR i
    ax.legend(); #make the legend show up
    
    ax.set_xlabel("Periods [min]"+' for Date Range '+str(dateRange[0,1])+'/'+str(dateRange[0,2])+ \
        '/'+str(dateRange[0,0])+' to '+str(dateRange[-1,1])+ '/'+str(dateRange[-1,2])+'/'+str(dateRange[-1,0])+ ' (M/D/Y)',fontproperties=FONT_axisLabelFM); #set the x axis label
    ax.set_ylabel('Normalized Power',fontproperties=FONT_axisLabelFM); #set the y axis label
    
    xAxisTicks = np.arange( 0, settings_spectra['period limit max']/60+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    ax.set_xlim( (settings_spectra['period limit min']/60, settings_spectra['period limit max']/60) ); #set x axis limits
    
#        if( OMNI_data_scarggf < np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim]) ):
#            ax.set_ylim( (0, np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim]) ) ); #set x axis limits
#        else:
#            ax.set_ylim( (0, OMNI_data_scarggf+0.1*OMNI_data_scarggf ) ); #set x axis limits
#        #END IF 
    
    string_title = str(OMNI_stackerDaysStacked)+' Days [Not Stacked] of OMNI '+OMNI_plot_name+' - FFT Power Spectra with '+OMNI_FFT_filtMethod+' Filter with a '+textNice(settings['spectra']['savgol filter period']/60)+' min Cutoff Period'; #create mecha title
    ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
    
    figFitter(fig); #fit the fig fast
    # fig.subplots_adjust(left = 0.050, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space  

    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
#END IF

if( FLG_OMNI_IMFclockAngle == 1 ):
    import numpy as np #import in here I dunno
    import matplotlib.pyplot as plt
    from matplotlib.ticker import MultipleLocator
    from Code.subfun_figFitter import figFitter
    
    if( FLG_fancyPlot == 1 ):
        print('MAKING FANCY PLOT: OMNI_IMFclockAngle IN fancyPlot FOLDER'); #report since you won't see anything
    #END IF
    
    #--- Unpack ---
    # PLOT_lineWidthThicc = settings_plot['line width']['thicc']; #get the line widths
    # PLOT_lineWidthDoublePlus = settings_plot['line width']['double plus']; #get the line widths
    # PLOT_lineWidthPlus = settings_plot['line width']['plus']; #get the line widths
    # PLOT_lineWidthRegularPlus = settings_plot['line width']['regular plus']; #get the line widths
    # PLOT_lineWidthRegular = settings_plot['line width']['regular']; #get the line widths
    # PLOT_lineWidthSmol = settings_plot['line width']['smol']; #get the line widths
    # PLOT_lineWidthSmoller = settings_plot['line width']['smoller']; #get the line widths
    
    #--- Prep the fig ---
    if( FLG_fancyPlot == 0 ):
        fig, ax = plt.subplots(ncols=2,subplot_kw={'projection': 'polar'}); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
    else:
        plt.ioff() #disable showing the plot as its size will be larger than the screen, which cannot happen if the plot is shown
        fig, ax = plt.subplots(ncols=2,subplot_kw={'projection': 'polar'},figsize=(14,8.5),dpi=journal_dpi); #use instead of fig because it inits an axis too (I think I dunno)
    #END IF
    
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax[0].set_aspect('equal');
    ax[1].set_aspect('equal');
    
    
    #--- Plot IMF clock angle w/ Bz mag info ---
    #1st crunch some numbers
    angleRanges = np.arange(-7.5,360,7.5); #deg, get the angle ranges
    angleRanges_orig = np.copy(angleRanges); #copy over in case needed for plots
    angleRanges[angleRanges > 180] += -360; #deg, convert from 0to360 to -180to180
    angleBzMean = np.zeros((angleRanges.size-1)//2); #preallocate Bz mean
    angleBzStdev = np.zeros((angleRanges.size-1)//2); #preallocate Bz stdev
    for i in range(1,(angleRanges.size-1),2):
        if( angleRanges[i] == 180 ):
            angleLogic = (angleRanges[i-1] < OMNI_data[:,OMNI_dict['IMF clock angle']]) | (angleRanges[i+1] >= OMNI_data[:,OMNI_dict['IMF clock angle']]); #get logical location for each band
        else:
            angleLogic = (angleRanges[i-1] < OMNI_data[:,OMNI_dict['IMF clock angle']]) & (angleRanges[i+1] >= OMNI_data[:,OMNI_dict['IMF clock angle']]); #get logical location for each band
        #END IF
        if( angleLogic.sum() > 0 ):
            angleBzMean[(i-1)//2] = np.mean(OMNI_data[:,OMNI_dict['Bz GSM']][angleLogic]); #nT, mean of Bz for the angle
            angleBzStdev[(i-1)//2] = np.std(OMNI_data[:,OMNI_dict['Bz GSM']][angleLogic]); #nT, mean of Bz for the angle
        else:
            angleBzMean[(i-1)//2] = np.nan;
            angleBzStdev[(i-1)//2] = np.nan;
        #END IF
    #END FOR i
    angleLabels = []; #prep a list
    for i in range(0,(angleRanges.size-1)//2):
        if( np.mod(i,3) != 0 ):
            angleLabels.append(''); #tack on nothing
        elif( angleRanges[1::2][i] == 0.0 ):
            angleLabels.append(str('0° Z (GSM)')); #tack on the label
        elif( angleRanges[1::2][i] == 90.0 ):
            angleLabels.append(str('90° Y (GSM)')); #tack on the label
        else:
            angleLabels.append(textNice(angleRanges[1::2][i])+'°'); #tack on the label
        #END IF
        
        # x,y = label.get_position();
        # lab = ax[pltz].text(x,y, angleLabels[cntr], transform=label.get_transform(),\
        #               ha='center', va='center');
        # if( angleLabels[cntr] != '' ):
        #     #angle calc
        #     angleRot = np.int64(angleLabels[cntr][:angleLabels[cntr].find('°')]); #get the angle value
        #     if( np.abs(angleRot) <= 90 ):
        #         angleRot = -angleRot; #flip it
        #     else:
        #         angleRot = np.mod(B4,90)*((B4>=0)-(B4<0)); #a little more work is req
        #     #END IF
        #     lab.set_rotation(angleRot);
        # #END IF
        # labels.append(lab);
        
    #END FOR i   
    
    #2nd [0] plot with clock angle/mean Bz info
    pltz = 0; #subplot working on
    #--- Prep polar plot ---
    ax[pltz].set_theta_zero_location('N'); #0 deg at top
    ax[pltz].set_theta_direction(-1); #goes clockwise now
    ax[pltz].set_yticklabels([]); #remove radial ticks
    # plt.thetagrids(angleRanges_orig[1::2], labels=angleLabels);
    ax[pltz].set_xticks(angleRanges_orig[1::2]*np.pi/180);
    ax[pltz].set_xticklabels(angleLabels);
    ax[pltz].spines['polar'].set_visible(False); #remove outer circle
    #draw minor grid lines
    for i in range(0,angleRanges_orig[0::2][1:].size):
        ax[pltz].plot((angleRanges_orig[0::2][1:][i]*np.pi/180,angleRanges_orig[0::2][1:][i]*np.pi/180), (0,1), lw=0.72, color='xkcd:grey'); #plot minor grid lines manually
    #END FOR i
    #draw tick marks
    for i in range(0,angleRanges_orig[1::2].size):
        ax[pltz].plot((angleRanges_orig[1::2][i]*np.pi/180,angleRanges_orig[1::2][i]*np.pi/180), (.97,1), lw=0.72, color='xkcd:black'); #plot minor grid lines manually
    #END FOR i
    #draw outline
    for i in range(0,angleRanges_orig[0::2].size-1):
        ax[pltz].plot((angleRanges_orig[0::2][i]*np.pi/180,angleRanges_orig[0::2][i+1]*np.pi/180), (1,1), lw=0.72, color='xkcd:black'); #plot minor grid lines manually
    #END FOR i
    labels = []; #inspired by https://stackoverflow.com/a/46720189/2403531
    for label in ax[pltz].get_xticklabels():
        x,y = label.get_position();
        lab = ax[pltz].text(x,y, label.get_text(), transform=label.get_transform(),\
                      ha=label.get_ha(), va=label.get_va());
        if( label.get_text() != '' ):
            #angle calc
            angleRot = np.int64(label.get_text()[:label.get_text().find('°')]); #get the angle value
            if( np.abs(angleRot) <= 90 ):
                angleRot = -angleRot; #flip it
            else:
                angleRot = np.mod(angleRot,90)*(np.int64((angleRot>=0))-np.int64((angleRot<0))); #a little more work is req
            #END IF
            lab.set_rotation(angleRot);
        #END IF
        labels.append(lab);
    #END FOR label
    ax[pltz].set_xticklabels([]); #remove old labels b/c replaced with text
    
    #--- actually plot ---
    im = ax[pltz].pcolormesh(angleRanges_orig[0::2]*np.pi/180, [0,1],  [angleBzMean] ,cmap='jet'); # pseudocolor plot "stretched" to the grid #, edgecolors='xkcd:black', linewidth=0.5
    cbar = fig.colorbar(im, ax=ax[pltz], orientation='vertical', shrink=.6, pad=0.08); #create a colorbar
    cbar.set_label('Bz Mean [nT]'); #tabel the colorbar
    
    #3rd [1] plot with clock angle/stdev Bz info
    pltz = 1; #subplot working on
    #--- Prep polar plot ---
    ax[pltz].set_theta_zero_location('N'); #0 deg at top
    ax[pltz].set_theta_direction(-1); #goes clockwise now
    ax[pltz].set_yticklabels([]); #remove radial ticks
    # plt.thetagrids(angleRanges_orig[1::2], labels=angleLabels);
    ax[pltz].set_xticks(angleRanges_orig[1::2]*np.pi/180);
    ax[pltz].set_xticklabels(angleLabels);
    ax[pltz].spines['polar'].set_visible(False); #remove outer circle
    #draw minor grid lines
    for i in range(0,angleRanges_orig[0::2][1:].size):
        ax[pltz].plot((angleRanges_orig[0::2][1:][i]*np.pi/180,angleRanges_orig[0::2][1:][i]*np.pi/180), (0,1), lw=0.72, color='xkcd:grey', antialiased=True); #plot minor grid lines manually
    #END FOR i
    #draw tick marks
    for i in range(0,angleRanges_orig[1::2].size):
        ax[pltz].plot((angleRanges_orig[1::2][i]*np.pi/180,angleRanges_orig[1::2][i]*np.pi/180), (.97,1), lw=0.72, color='xkcd:black', antialiased=True); #plot minor grid lines manually
    #END FOR i
    #draw outline
    for i in range(0,angleRanges_orig[0::2].size-1):
        ax[pltz].plot((angleRanges_orig[0::2][i]*np.pi/180,angleRanges_orig[0::2][i+1]*np.pi/180), (1,1), lw=0.72, color='xkcd:black', antialiased=True); #plot minor grid lines manually
    #END FOR i
    labels = []; #inspired by https://stackoverflow.com/a/46720189/2403531
    for label in ax[pltz].get_xticklabels():
        x,y = label.get_position();
        lab = ax[pltz].text(x,y, label.get_text(), transform=label.get_transform(),\
                      ha=label.get_ha(), va=label.get_va());
        if( label.get_text() != '' ):
            #angle calc
            angleRot = np.int64(label.get_text()[:label.get_text().find('°')]); #get the angle value
            if( np.abs(angleRot) <= 90 ):
                angleRot = -angleRot; #flip it
            else:
                angleRot = np.mod(angleRot,90)*(np.int64((angleRot>=0))-np.int64((angleRot<0))); #a little more work is req
            #END IF
            lab.set_rotation(angleRot);
        #END IF
        labels.append(lab);
    #END FOR label
    ax[pltz].set_xticklabels([]); #remove old labels b/c replaced with text
    
    #--- actually plot ---
    im = ax[pltz].pcolormesh(angleRanges_orig[0::2]*np.pi/180, [0,1],  [angleBzStdev] ,cmap='jet', antialiased=True); # pseudocolor plot "stretched" to the grid #, edgecolors='xkcd:black', linewidth=0.5
    cbar = fig.colorbar(im, ax=ax[pltz], orientation='vertical', shrink=.6, pad=0.08); #create a colorbar
    cbar.set_label('Bz Stdev [nT]'); #tabel the colorbar
    
    #--- Finalize and Spruce ---
    # fig.subplots_adjust(wspace=0.25); #sets padding to small numbers for minimal white space
    figFitter(fig); #fit the fig fast
    if( FLG_fancyPlot != 0 ):
        fig.savefig(settings_paths['fancyPlots']+'\\'+'OMNI_IMFclockAngle.png'); #save the figure
        plt.close(); #close figure b/c it lurks apparently
        plt.ion(); #re-enable it for later stuff
    #END IF
#END IF

#****************************************************************Kp AND OMNI ANALYSIS****************************************************************
#this is activated implicitly by fancyPlot and the other 2 plot commands on
if( (FLG_Kp_plot == 1) & (FLG_OMNI_plot == 1) & (FLG_fancyPlot == 1) ):
    GRITI_KpOMNI_fancyPlot(Kp_data,Kp_time, OMNI_data,OMNI_timeUnique, \
        OMNI_dict, OMNI_dictPlot, OMNI_plotSet_name, time_Ref,time_Reference, \
        dateRange_full, dateRange_zeroHr, dateRange_dayNum_zeroHr, dateRange_zeroHr_monthName, \
        dateRange_zeroHr_dayPostfix, FONT_grandioseFM, FONT_titleFM, FONT_axisLabelFM, \
        PLOT_lineWidth, journal_width_2C,journal_height_max,journal_dpi,opt=2);
#END IF

#****************************************************************AMPERE ANALYSIS****************************************************************
#==============Analysis: Any Angle AVG (Keogram)==============
if( (FLG_AMPERE_keo == 1) ):
    AMPERE_plot_label = settings_AMPERE['labels'][settings_AMPERE['data type']]+settings_AMPERE['units'][settings_AMPERE['data type']]; #get the label and units
    AMPERE_plot_label_noUnits = settings_AMPERE['labels'][settings_AMPERE['data type']]; #get the label
                
    data['AMPERE']['keo'], settings['AMPERE']['keo'] = GRITI_keo_keogrammer( \
        data['AMPERE keo input'][settings_AMPERE['data type']], data['AMPERE keo input']['time'], data['AMPERE keo input']['lat'], data['AMPERE keo input']['long'], \
        data['AMPERE keo input']['time unique'], data['time ref'], dates, \
        settings['AMPERE']['keo'], settings_paths, settings_map, settings_plot, \
        FLG_fancyPlot=FLG_fancyPlot,FLG_disablePlot=0,FLG_dataDensity=0,FLG_disableText=0,FLG_disableCache=1,FLG_useRightExact=1);
    #call the mecha function that runs the keo alg and makes a plot showing the averaging are
    AMPERE_keo = data['AMPERE']['keo']; #link
#END IF
  
    
#==============Analysis: Plot Keograms of Any Angle AVG==============
if( (FLG_AMPERE_keo_plot == 1) & (FLG_AMPERE_keo == 1) ):
    # #-----Plot TEC results as a Keogram-----
    # GRITI_TEC_keo_plot_TEC(AMPERE_keo,AMPERE_timeUnique,AMPERE_plotLimValu,AMPERE_colorMap, \
    #     plotLatRange,plotLongRange,latMillstone,longMillstone, \
    #     dateRange_dayNum_zeroHr,settings_AMPERE['keo']['keo angle'],settings['AMPERE']['keo']['keo width'], \
    #     settings['AMPERE']['keo']['keo plot latlong chunks'],settings['AMPERE']['keo']['keo plot latlong name'], \
    #     AMPERE_plot_label_noUnits,AMPERE_plot_label,\
    #     FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
    # #call the mecha function that plots the avg'd delta-vTEC
    
    #-----Plot AMPERE results as a Keogram-----
    GRITI_keo_plot(data['AMPERE']['keo'], data['AMPERE']['time unique'], data['time ref'], dates, \
        settings['AMPERE']['keo'] ,settings_plot, settings_paths, settings_map, \
        FLG_fancyPlot = 0, settings_config=settings['config']);
    #call the mecha function that plots the keo
    if( FLG_fancyPlot >= 1 ):
        #-----Plot AMPERE results as a Keogram-----
        GRITI_keo_plot(data['AMPERE']['keo'], data['AMPERE']['time unique'], data['time ref'], dates, \
            settings['AMPERE']['keo'] ,settings_plot, settings_paths, settings_map, \
            FLG_fancyPlot = FLG_fancyPlot, settings_config=settings['config']);
        #call the mecha function that plots the keo
    #END IF
#END IF
    
    
#==============Analysis: Plot Time Cut-out Keograms of Any Angle AVG==============
if( (FLG_AMPERE_keo_plot_timeCutout == 1) & (FLG_AMPERE_keo == 1) ):
    #-----Plot TEC results as a Keogram-----
    # time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) )) == np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400) - np.min(time_cutout_range) ) )[0][0] , \
    #     np.where(np.min(np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400) - np.max(time_cutout_range) )) == np.abs( (AMPERE_timeUnique-dateRange_dayNum_zeroHr[1]*86400) - np.max(time_cutout_range) ) )[0][0] ) ); #get the indexes for that time cutout range
    
    # AMPERE_keo_cutOut = AMPERE_keo[time_cutout_indexes[0]:time_cutout_indexes[1]+1,:];
    # AMPERE_timeUnique_cutOut = AMPERE_timeUnique[time_cutout_indexes[0]:time_cutout_indexes[1]+1];
    
    # GRITI_TEC_keo_plot_TEC_cutOut(AMPERE_keo_cutOut,AMPERE_timeUnique_cutOut,AMPERE_plotLimValu,AMPERE_colorMap, \
    #     plotLatRange,plotLongRange,latMillstone,longMillstone, \
    #     dateRange_dayNum_zeroHr,settings['AMPERE']['keo']['keo angle'],settings['AMPERE']['keo']['keo width'], \
    #     settings['AMPERE']['keo']['keo plot latlong chunks'],settings['AMPERE']['keo']['keo plot latlong name'],
    #     AMPERE_plot_label_noUnits,AMPERE_plot_label,time_cutout_range, \
    #     FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
    # #call the mecha function that plots the avg'd delta-vTEC
    
    if( FLG_AMPERE_keo_plot_highlightIMFSouth == False ):
        IMFSouthTimes = FLG_AMPERE_keo_plot_highlightIMFSouth; #turn off if not used
    else:
        if( (data['AMPERE']['data rate'] != data['OMNI']['data rate']) | (data['AMPERE']['time unique'].size != data['OMNI']['time unique'].size) ):
            from Code.subfun_timeMatch import subfun_timeMatch
            IMFSouthTimes, _ = subfun_timeMatch(data['OMNI'][FLG_AMPERE_keo_plot_highlightIMFSouth_type], data['OMNI']['time unique'], data['AMPERE']['time unique'], timeMatch_delta=data['AMPERE']['data rate'], FLG_removeNaNs=2, FLG_reportNaNs=False, FLG_useSum=0); #time match if needed
            IMFSouthTimes = IMFSouthTimes < 0; #times to highlight
        else:
            IMFSouthTimes = data['OMNI'][FLG_AMPERE_keo_plot_highlightIMFSouth_type] < 0; #times to highlight
        #END IF
    #END IF
    
    GRITI_keo_plot(data['AMPERE']['keo'], data['AMPERE']['time unique'], data['time ref'], dates, \
        settings['AMPERE']['keo'] ,settings_plot, settings_paths, settings_map, \
        timeCutout = time_cutout_range/3600, FLG_fancyPlot = 0, highlighter=IMFSouthTimes, settings_config=settings['config']);
    #call the mecha function that plots the keo
    if( FLG_fancyPlot >= 1 ):
        #-----Plot AMPERE results as a Keogram-----
        GRITI_keo_plot(data['AMPERE']['keo'], data['AMPERE']['time unique'], data['time ref'], dates, \
            settings['AMPERE']['keo'] ,settings_plot, settings_paths, settings_map, \
            timeCutout = time_cutout_range/3600, FLG_fancyPlot = FLG_fancyPlot, highlighter=IMFSouthTimes, settings_config=settings['config']);
        #call the mecha function that plots the keo
    #END IF
    
#END IF

#==============Analysis: Plot FFT of Keogram==============
if( (FLG_AMPERE_keo_spectra == 1) & (FLG_AMPERE_keo == 1) ):
    if( settings['TEC']['keo']['keo plot latlong name'] == 'Longitude' ):
        goalIndex = np.where( np.abs(settings['AMPERE']['keo']['keo plot latlong chunks'] - avgPt_coords[0,1]) == np.min(np.abs(settings['AMPERE']['keo']['keo plot latlong chunks'] - avgPt_coords[0,1])) )[0].item() - 1; #set the goal index (closet to key pt)
    else:
        goalIndex = np.where( np.abs(settings['AMPERE']['keo']['keo plot latlong chunks'] - avgPt_coords[0,0]) == np.min(np.abs(settings['AMPERE']['keo']['keo plot latlong chunks'] - avgPt_coords[0,0])) )[0].item() - 1; #set the goal index (closet to key pt)
    #END IF
    AMPERE_keo_atIndexNoNAN = np.copy(AMPERE_keo[:,goalIndex]); #copy it
    AMPERE_keo_atIndexNoNAN[np.isnan(AMPERE_keo_atIndexNoNAN)] = 0; #set NaN's to 0
    
    GRITI_spectral_analysisPlot(AMPERE_keo_atIndexNoNAN, AMPERE_timeUnique, 'day', data['AMPERE']['data rate'], 'sec', 'min',
        AMPERE_keo_spectra_filtMethod, AMPERE_keo_spectra_spectraMethod, dates, settings_spectra, settings_plot, settings_paths, settings['AMPERE']['labels'][settings['AMPERE']['data type']]+' Keogram at Pt of Interest' );
#END IF

#==============Analysis: Plot Keogram with Sun Location==============
if( (FLG_AMPERE_keo_plot_wSun == 1) & (FLG_AMPERE_keo == 1) ):
    #-----Plot AMPERE results as a Keogram-----
    GRITI_keo_plot(data['AMPERE']['keo'], data['AMPERE']['time unique'], data['time ref'], dates, \
        settings['AMPERE']['keo'] ,settings_plot, settings_paths, settings_map, \
        FLG_drawSun=True, FLG_fancyPlot = 0, settings_config=settings['config']);
    #call the mecha function that plots the keo
    if( FLG_fancyPlot >= 1 ):
        #-----Plot AMPERE results as a Keogram-----
        GRITI_keo_plot(data['AMPERE']['keo'], data['AMPERE']['time unique'], data['time ref'], dates, \
            settings['AMPERE']['keo'] ,settings_plot, settings_paths, settings_map, \
            FLG_drawSun=True, FLG_fancyPlot = FLG_fancyPlot, settings_config=settings['config']);
        #call the mecha function that plots the keo
    #END IF
    # #-----Plot TEC results as a Keogram-----
    # GRITI_keo_plot_wSun(AMPERE_keo, AMPERE_timeUnique, AMPERE_plotLimValu,AMPERE_colorMap, \
    #   plotLatRange,plotLongRange,latMillstone,longMillstone, \
    #   dates,settings['AMPERE']['keo']['keo angle'],settings['AMPERE']['keo']['keo width'], \
    #   settings['AMPERE']['keo']['keo plot latlong chunks'],settings['AMPERE']['keo']['keo plot latlong name'], \
    #   AMPERE_plot_label_noUnits,AMPERE_plot_label,\
    #   FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
    # #call the mecha function that plots the avg'd delta-vTEC
#END IF

#==============Analysis: Plot Keogram with Centered Roll==============
if( (FLG_AMPERE_keo_plot_wSunCenter == 1) & (FLG_AMPERE_keo == 1) ):
    #-----Plot TEC results as a Keogram-----
    AMPERE_keo_sunAligned = GRITI_keo_plot_sunCentered(AMPERE_keo,AMPERE_timeUnique,AMPERE_plotLimValu,AMPERE_colorMap, \
        plotLatRange,plotLongRange,latMillstone,longMillstone, \
        dates,settings['AMPERE']['keo']['keo angle'],settings['AMPERE']['keo']['keo width'], \
        settings['AMPERE']['keo']['keo plot latlong chunks'],settings['AMPERE']['keo']['keo plot latlong name'], \
        AMPERE_plot_label_noUnits,AMPERE_plot_label,\
        FONT_titleFM,FONT_axisTick,FONT_axisLabelFM);
    #call the mecha function that plots the avg'd delta-vTEC
#END IF

#==============Analysis: Plot FFT of Keogram with Centered Roll==============
if( (FLG_AMPERE_keo_spectra_wSunCenter == 1) & (FLG_AMPERE_keo == 1) ):
    goalIndex = np.where( np.abs(settings['AMPERE']['keo']['keo plot latlong chunks']-0) == np.min(np.abs(settings['AMPERE']['keo']['keo plot latlong chunks']-0)) )[0].item() - 1; #set the goal index (closet to 0)
    AMPERE_keo_sunAligned_sunIndexNoNAN = np.copy(AMPERE_keo_sunAligned[:,goalIndex]); #copy it
    AMPERE_keo_sunAligned_sunIndexNoNAN[np.isnan(AMPERE_keo_sunAligned_sunIndexNoNAN)] = 0; #set NaN's to 0
    
    GRITI_spectral_analysisPlot(AMPERE_keo_sunAligned_sunIndexNoNAN, AMPERE_timeUnique, 'day', data['AMPERE']['data rate'], 'sec', 'min',
        AMPERE_keo_spectra_filtMethod, AMPERE_keo_spectra_spectraMethod, dates, settings_spectra, settings_plot, settings_paths, settings['AMPERE']['labels'][settings['AMPERE']['data type']]+' Keogram Sun-Aligned' );
#END IF

if( FLG_AMPERE_scatter_plot_area >= 1 ):
    import copy
    if( FLG_AMPERE_scatter_plot_area == 2 ):
        boxArea = np.vstack((AMPERE_scatter_plot_area_box.T,AMPERE_scatter_plot_area_box.T)); #build the box area
        boxArea[1,1] = boxArea[0,1]; #shuffle these points
        boxArea[2,1] = boxArea[3,1];  #shuffle these points
        # boxArea[:,1] = np.roll(boxArea[:,1],1); #roll one column along to make the pts work for a nice box
    else:
        boxArea = False; #set to false to skip boxing
    #END IF    
    settings_dataSpecific = copy.deepcopy(settings_AMPERE); #properly copy that dict
    settings_dataSpecific['label'] = settings_AMPERE['labels'][settings_AMPERE['data type']]; #get the label
    settings_dataSpecific['unit'] = settings_AMPERE['units'][settings_AMPERE['data type']]; #get the unit
    GRITI_plot_area_scatter(data['AMPERE'][settings_AMPERE['data type']], data['AMPERE']['time'], data['AMPERE']['lat'], data['AMPERE']['long'], data['AMPERE']['time unique'], time_Ref, dates, \
        settings_dataSpecific ,settings_plot, settings_paths, settings_map, \
        boxArea = boxArea, FLG_fancyPlot = 0);
    if( FLG_fancyPlot == 1 ):
        GRITI_plot_area_scatter(data['AMPERE'][settings_AMPERE['data type']], data['AMPERE']['time'], data['AMPERE']['lat'], data['AMPERE']['long'], data['AMPERE']['time unique'], time_Ref, dates, \
            settings_dataSpecific ,settings_plot, settings_paths, settings_map, \
            boxArea = boxArea, FLG_fancyPlot = FLG_fancyPlot);
    #END IF
#END IF

if( FLG_AMPEREnAMPERE_correlator >= 1):
    from Code.GRITI_AMPERE_integrator import GRITI_AMPERE_integrator
    from Code.subfun_timeMatch import subfun_timeMatch
    from Code.subfun_correlator import subfun_correlator
    import copy
    
    print('\nWorking on Correlator_AMPEREnAMPERE');
    settings_AMPERE1 = copy.deepcopy(settings_AMPERE);
    settings_AMPERE1['data type'] = FLG_AMPEREnAMPERE_correlator_dataTypes[0]; #set 1st data type
    AMPERE_integrated1 = GRITI_AMPERE_integrator(data['AMPERE'], dates, settings_AMPERE1, plotLatRange, plotLongRange, AMPERE_integrateMethod, AMPERE_integrateMethod_val, 
                                    AMPERE_integrateMethod_coordType='reg', AMPERE_integrateMethod_coordType_global=settings['map']['coord type'], GRITI_import_AMPERE=GRITI_import_AMPERE, AMPERE_desired_latLongSteps=settings['AMPERE']['lat long steps'],
                                    AMPERE_import_AMPERE_hemi=settings['map']['hemi'], settings_config=settings['config'], settings_paths=settings['paths'],
                                    AMPERE_integrateMethod_log=AMPERE_integrateMethod_log, AMPERE_integrateMethod_radiusLoc=AMPERE_integrateMethod_radiusNloc[1], AMPERE_integrateMethod_radius=AMPERE_integrateMethod_radiusNloc[0])
    
    settings_AMPERE2 = copy.deepcopy(settings_AMPERE);
    settings_AMPERE2['data type'] = FLG_AMPEREnAMPERE_correlator_dataTypes[1]; #set 2nd data type
    AMPERE_integrated2 = GRITI_AMPERE_integrator(data['AMPERE'], dates, settings_AMPERE2, plotLatRange, plotLongRange, AMPERE_integrateMethod, AMPERE_integrateMethod_val, 
                                    AMPERE_integrateMethod_coordType='reg', AMPERE_integrateMethod_coordType_global=settings['map']['coord type'], GRITI_import_AMPERE=GRITI_import_AMPERE, AMPERE_desired_latLongSteps=settings['AMPERE']['lat long steps'],
                                    AMPERE_import_AMPERE_hemi=settings['map']['hemi'], settings_config=settings['config'], settings_paths=settings['paths'],
                                    AMPERE_integrateMethod_log=AMPERE_integrateMethod_log, AMPERE_integrateMethod_radiusLoc=AMPERE_integrateMethod_radiusNloc[1], AMPERE_integrateMethod_radius=AMPERE_integrateMethod_radiusNloc[0])

    if( FLG_AMPEREnAMPERE_correlator == 1 ):
        sig1 = AMPERE_integrated1; #sig1 stays static
        time1 = data['AMPERE']['time unique']-dates['date range zero hr dayNum'][1]*86400;
        dataRate1 = data['AMPERE']['data rate'];
        sig2 = AMPERE_integrated2; #sig2 moves around
        time2 = data['AMPERE']['time unique']-dates['date range zero hr dayNum'][1]*86400;
        dataRate2 = data['AMPERE']['data rate'];
        plotName = settings_AMPERE1['labels'][settings_AMPERE1['data type']]+ \
            ' & '+settings_AMPERE2['labels'][settings_AMPERE2['data type']];
    else:
        sig1 = AMPERE_integrated2; #sig1 stays static
        time1 = data['AMPERE']['time unique']-dates['date range zero hr dayNum'][1]*86400;
        dataRate1 = data['AMPERE']['data rate'];
        sig2 = AMPERE_integrated1; #sig2 moves around
        time2 = data['AMPERE']['time unique']-dates['date range zero hr dayNum'][1]*86400;
        dataRate2 = data['AMPERE']['data rate'];
        plotName = settings_AMPERE2['labels'][settings_AMPERE2['data type']]+ \
            ' & '+settings_AMPERE1['labels'][settings_AMPERE1['data type']];
    #END IF
    if( np.isclose(dataRate1,dataRate2) == False ):
        if( dataRate1 > dataRate2 ):
            sig2, time2 = subfun_timeMatch(sig2, time2, time1, timeMatch_delta=dataRate1, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
            dataRate2 = dataRate1; #set it
        else:
            sig1, time1 = subfun_timeMatch(sig1, time1, time2, timeMatch_delta=dataRate2, FLG_removeNaNs=2, FLG_reportNaNs=True); #match the times to the same cadence
            dataRate1 = dataRate2; #set it
        #END IF
    #END IF
    
    if( FLG_AMPEREnAMPERE_correlator_options['mode'] == 'corr' ):
        corrRet = subfun_correlator(sig1, sig2, mode='corr', time1=time1, time2=time2, reportDivisor=[60,'min'], FLG_interpGaps=True); #calc some correlation
    elif( FLG_AMPEREnAMPERE_correlator_options['mode'] == 'shift' ):
        corrRet = subfun_correlator(sig1, sig2, mode='shift', time1=time1, time2=time2, dataRate=dataRate1, reportDivisor=[60,'min'], \
            FLG_shiftDir=FLG_AMPEREnAMPERE_correlator_shiftDir, FLG_interpGaps=True, FLG_plot=FLG_AMPEREnAMPERE_correlator_plot, settings_plot=settings['plot'], \
            plotName=plotName, FLG_fancyPlot=0); #calc some correlation
    elif( FLG_AMPEREnAMPERE_correlator_options['mode'] == 'range' ):
        corrRet = subfun_correlator(sig1, sig2, mode='range', timeLimit=14400, time1=time1, time2=time2, dataRate=dataRate1, timeRange=FLG_AMPEREnAMPERE_correlator_options['time range'], reportDivisor=[60,'min'], \
            FLG_shiftDir=FLG_AMPEREnAMPERE_correlator_shiftDir, FLG_interpGaps=True, FLG_plot=FLG_AMPEREnAMPERE_correlator_plot, settings_plot=settings['plot'], \
            plotName=plotName, FLG_fancyPlot=0); #calc some correlation
    elif( FLG_AMPEREnAMPERE_correlator_options['mode'] == 'interval' ):
        corrRet = subfun_correlator(sig1, sig2, mode='interval', timeLimit=14400, time1=time1, time2=time2, dataRate=dataRate1, timeInterval=FLG_AMPEREnAMPERE_correlator_options['time interval'], intervalType=FLG_AMPEREnAMPERE_correlator_options['interval type'], reportDivisor=[60,'min'], \
            FLG_shiftDir=FLG_AMPEREnAMPERE_correlator_shiftDir, FLG_interpGaps=True, FLG_plot=FLG_AMPEREnAMPERE_correlator_plot, settings_plot=settings['plot'], \
            plotName=plotName, FLG_fancyPlot=0); #calc some correlation
    elif( FLG_AMPEREnAMPERE_correlator_options['mode'] == 'interval manual' ):
        # this is a special call that builds time timeInterval off of 
        if( FLG_AMPEREnAMPERE_correlator_options['method'] == 'req' ):
            if( FLG_AMPEREnAMPERE_correlator_options['data type'] == 'SuperMAG' ):
                timeTemp = SuperMAG_timeUnique-dates['date range zero hr dayNum'][1]*86400;
                if( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '>' ):
                    where_indexes = np.where( (SuperMAG_data[FLG_AMPEREnAMPERE_correlator_options['sub data type']] > FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                elif( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '>=' ):
                    where_indexes = np.where( (SuperMAG_data[FLG_AMPEREnAMPERE_correlator_options['sub data type']] >= FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                elif( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '<' ):
                    where_indexes = np.where( (SuperMAG_data[FLG_AMPEREnAMPERE_correlator_options['sub data type']] < FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                elif( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '<=' ):
                    where_indexes = np.where( (SuperMAG_data[FLG_AMPEREnAMPERE_correlator_options['sub data type']] <= FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                elif( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '==' ):
                    where_indexes = np.where( (SuperMAG_data[FLG_AMPEREnAMPERE_correlator_options['sub data type']] == FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                elif( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '!=' ):
                    where_indexes = np.where( (SuperMAG_data[FLG_AMPEREnAMPERE_correlator_options['sub data type']] != FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                #END IF
                where_edges = np.where(np.insert(np.diff(where_indexes),0,0) != 1)[0];
                timeMinEnforcer = FLG_AMPEREnAMPERE_correlator_options['time enforcer']; #copy it out, gonna overwrite FLG_AMPEREnAMPERE_correlator_options
                FLG_AMPEREnAMPERE_correlator_options['time interval'] = np.zeros( (where_edges.size-1,2) ); #prep
                for j in range(0,where_edges.size-1):
                    FLG_AMPEREnAMPERE_correlator_options['time interval'][j,0] = timeTemp[where_indexes[where_edges[j]]];
                    FLG_AMPEREnAMPERE_correlator_options['time interval'][j,1] = timeTemp[where_indexes[where_edges[j+1]-1]];
                #END FOR j
                kj = np.where(np.diff(FLG_AMPEREnAMPERE_correlator_options['time interval'],axis=1) > timeMinEnforcer)[0]; #enforce the minimum time distance
                FLG_AMPEREnAMPERE_correlator_options['time interval'] = FLG_AMPEREnAMPERE_correlator_options['time interval'][kj,:]; #get values that meet the time reqs
            elif( FLG_AMPEREnAMPERE_correlator_options['data type'] == 'AMPERE' ):
                timeTemp = data['AMPERE']['time unique']-dates['date range zero hr dayNum'][1]*86400;
                if( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '>' ):
                    where_indexes = np.where( (data['AMPERE'][FLG_AMPEREnAMPERE_correlator_options['sub data type']] > FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                elif( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '>=' ):
                    where_indexes = np.where( (data['AMPERE'][FLG_AMPEREnAMPERE_correlator_options['sub data type']] >= FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                elif( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '<' ):
                    where_indexes = np.where( (data['AMPERE'][FLG_AMPEREnAMPERE_correlator_options['sub data type']] < FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                elif( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '<=' ):
                    where_indexes = np.where( (data['AMPERE'][FLG_AMPEREnAMPERE_correlator_options['sub data type']] <= FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                elif( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '==' ):
                    where_indexes = np.where( (data['AMPERE'][FLG_AMPEREnAMPERE_correlator_options['sub data type']] == FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                elif( FLG_AMPEREnAMPERE_correlator_options['comparator'] == '!=' ):
                    where_indexes = np.where( (data['AMPERE'][FLG_AMPEREnAMPERE_correlator_options['sub data type']] != FLG_AMPEREnAMPERE_correlator_options['comparator val']) == True )[0];
                #END IF
                where_edges = np.where(np.insert(np.diff(where_indexes),0,0) != 1)[0];
                timeMinEnforcer = FLG_AMPEREnAMPERE_correlator_options['time enforcer']; #copy it out, gonna overwrite FLG_AMPEREnAMPERE_correlator_options
                FLG_AMPEREnAMPERE_correlator_options['time interval'] = np.zeros( (where_edges.size-1,2) ); #prep
                for j in range(0,where_edges.size-1):
                    FLG_AMPEREnAMPERE_correlator_options['time interval'][j,0] = timeTemp[where_indexes[where_edges[j]]];
                    FLG_AMPEREnAMPERE_correlator_options['time interval'][j,1] = timeTemp[where_indexes[where_edges[j+1]-1]];
                #END FOR j
                kj = np.where(np.diff(FLG_AMPEREnAMPERE_correlator_options['time interval'],axis=1) > timeMinEnforcer)[0]; #enforce the minimum time distance
                FLG_AMPEREnAMPERE_correlator_options['time interval'] = FLG_AMPEREnAMPERE_correlator_options['time interval'][kj,:]; #get values that meet the time reqs
            #END IF
        #END IF
        corrRet = subfun_correlator(sig1, sig2, mode='interval manual', timeLimit=14400, time1=time1, time2=time2, dataRate=dataRate1, timeInterval=FLG_AMPEREnAMPERE_correlator_options['time interval'], reportDivisor=[60,'min'], \
            FLG_shiftDir=FLG_AMPEREnAMPERE_correlator_shiftDir, FLG_interpGaps=True, FLG_plot=FLG_AMPEREnAMPERE_correlator_plot, settings_plot=settings['plot'], \
            plotName=plotName, FLG_fancyPlot=0); #calc some correlation
    else:
        print('WARNING in FLG_AMPEREnAMPERE_correlator: Length of FLG_AMPEREnAMPERE_correlator_options ('+str(len(FLG_AMPEREnAMPERE_correlator_options))+') does not equal length of SuperMAG_plotSet ('+str(len(SuperMAG_plotSet))+')');
    #END IF
#END IF

if( FLG_AMPERE_integrate_plot == 1 ):
    
    if( FLG_AMPERE_integrate_plot_highlightIMFSouth == False ):
        IMFSouthTimes = FLG_AMPERE_integrate_plot_highlightIMFSouth; #turn off if not used
    else:
        if( (data['AMPERE']['data rate'] != data['OMNI']['data rate']) | (data['AMPERE']['time unique'].size != data['OMNI']['time unique'].size) ):
            from Code.subfun_timeMatch import subfun_timeMatch
            IMFSouthTimes, _ = subfun_timeMatch(data['OMNI'][FLG_AMPERE_integrate_plot_highlightIMFSouth_type], data['OMNI']['time unique'], data['AMPERE']['time unique'], timeMatch_delta=data['AMPERE']['data rate'], FLG_removeNaNs=2, FLG_reportNaNs=False, FLG_useSum=0); #time match if needed
            IMFSouthTimes = IMFSouthTimes < 0; #times to highlight
        else:
            IMFSouthTimes = data['OMNI'][FLG_AMPERE_integrate_plot_highlightIMFSouth_type] < 0; #times to highlight
        #END IF
    #END IF
    
    GRITI_AMPERE_integrator_plot(data['AMPERE'], data['time ref'], dates, settings['AMPERE'], \
        settings['map'], settings['plot'], settings['paths'], FLG_fancyPlot = 0, highlighter = IMFSouthTimes); #plot the integrated data
    if( FLG_fancyPlot >= 1 ):
        GRITI_AMPERE_integrator_plot(data['AMPERE'], data['time ref'], dates, settings['AMPERE'], \
            settings['map'],settings['plot'], settings['paths'], FLG_fancyPlot = FLG_fancyPlot, highlighter = IMFSouthTimes); #plot the integrated data
    #END IF
#END IF
    
if( FLG_AMPERE_integrate_area >= 1 ):
    GRITI_AMPERE_integrator_plot_area(data['AMPERE'], dates, settings_AMPERE, \
            settings_map, settings_plot, settings_paths, \
            AMPERE_integrateArea_time = AMPERE_integrateArea_time, plot_terrainDraw = True, plot_latLongWords = True, FLG_fancyPlot = 0);
    if( FLG_fancyPlot >= 1 ):
        GRITI_AMPERE_integrator_plot_area(data['AMPERE'], dates, settings_AMPERE, \
                settings_map, settings_plot, settings_paths, \
                AMPERE_integrateArea_time = AMPERE_integrateArea_time, plot_terrainDraw = True, plot_latLongWords = True, FLG_fancyPlot = FLG_fancyPlot);
    #END IF
#END IF

if( FLG_AMPERE_integrate_limArea_plot == 1 ):
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    #limit based on area
    k = (data['AMPERE'][:,6] <= np.max(plotLatRange)) & (data['AMPERE'][:,6] >= np.min(plotLatRange)) & \
        (data['AMPERE'][:,7] <= np.max(plotLongRange)) & (data['AMPERE'][:,7] >= np.min(plotLongRange))
    AMPERE_data_limArea = data['AMPERE'][k,:]; #get the limited area data
    AMPERE_timeUnique_limArea = np.unique(AMPERE_data_limArea[:,5]);  #get the limited time unique
    
    AMPERE_timeUnique_hr = (AMPERE_timeUnique_limArea - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    if( np.mod(np.round(np.min(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr))+1; #is odd, make even
    #END IF
    if( np.mod(np.round(np.max(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr))-1; #is odd, make even
    #END IF
    
    #-----BEGIN THE PLOTTING!------
    AMPERE_integrate = np.zeros( AMPERE_timeUnique_hr.size , dtype=np.float64); #prep integrated joule heating
    for i in range(AMPERE_timeUnique_hr.size):
        k = np.where(AMPERE_timeUnique_limArea[i] == AMPERE_data_limArea[:,locAMPERE_time])[0]
        AMPERE_integrate[i] = np.sum(AMPERE_data_limArea[k,AMPERE_plot_index]); #ergs/(cm^2*sec), get the Joule Heating for the current time stamp
    #END FOR i
    
    AMPERE_plot_label = settings['AMPERE']['labels'][AMPERE_dataType]+settings['AMPERE']['units'][AMPERE_dataType]; #get the label
    AMPERE_plot_label_noUnits = settings['AMPERE']['labels'][AMPERE_dataType]; #remove the (units)
    
    #Start the AMPERE plot
    fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    ax.set_aspect('auto'); #Remove the aspect ratio from the basemap so it fills the screen better
    ax.plot( AMPERE_timeUnique_hr, AMPERE_integrate , linewidth=PLOT_lineWidthRegular ); #plot
    
    if( (np.abs((np.min(AMPERE_timeUnique_hr)/24 + dateRange_dayNum_zeroHr[1]) - np.min(time_Ref))*24 >= 0.25) & ((time_Reference != 'Kp') & (time_Reference != 'AMPERE')) ): #as long as min Kp time is 15 min diff or more from the other time reference, plot where the time ref begins (not Kp tho)
        ax.plot( np.repeat( (np.min(time_Ref) - dateRange_dayNum_zeroHr[1]*86400)/3600 , 10) , np.linspace(np.min(AMPERE_integrate),np.max(AMPERE_integrate),num=10), linewidth=1.75, color='r'); #plot red lines showing ISR data time
    if( (np.abs((np.max(AMPERE_timeUnique_hr)/24 + dateRange_dayNum_zeroHr[1]) - np.max(time_Ref))*24 >= 0.25) & ((time_Reference != 'Kp') & (time_Reference != 'AMPERE')) ): #as long as max Kp time is 15 min diff or more from the other time reference, plot where the time ref ends (not Kp tho)
        ax.plot( np.repeat( (np.max(time_Ref) - dateRange_dayNum_zeroHr[1]*86400)/3600 , 10) , np.linspace(np.min(AMPERE_integrate),np.max(AMPERE_integrate),num=10), linewidth=1.75, color='r'); #plot red lines showing ISR data time
    #END IF
    
    xAxisTicks = np.arange(AMPERE_time_hr_axis_min,AMPERE_time_hr_axis_max+4,4); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks

    ax.set_xlim( AMPERE_time_hr_axis_min , AMPERE_time_hr_axis_max ); #set y axis limits
    
    ax.set_ylabel("Integrated AMPERE "+AMPERE_plot_label,fontproperties=FONT_axisLabelFM); #set the y axis label
    
    ax.set_ylim( np.min(AMPERE_integrate) , np.max(AMPERE_integrate) ); #set y axis limits
    
    ax.grid(b=True, which='major', axis='both', color='xkcd:light grey'); #sets major axis grid lines to be on        
    
    string_title = 'Integrated AMPERE '+AMPERE_plot_label_noUnits+' in the Nothern Hemisphere for '+str(dateRange[0,1])+'/'+str(dateRange[0,2])+ \
    '/'+str(dateRange[0,0])+' to '+str(dateRange[-1,1])+ \
    '/'+str(dateRange[-1,2])+'/'+str(dateRange[-1,0])+ \
    ' (M/D/Y)'+" for "+str(np.min(plotLatRange))+"x"+str(np.max(plotLatRange))+" lat, "+str(np.min(plotLongRange))+"x"+str(np.max(plotLatRange))+" long"; #create mecha title
    ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
    
    ax.set_xlabel('Time in UT (hr) - 0 Hr on '+dateRange_zeroHr_monthName+' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM); #set the x axis label
    
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.070, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
#END IF

if( FLG_AMPERE_integrate_limArea_scargle == 1 ):
    #Unpack line widths
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    #limit based on area
    k = (data['AMPERE'][:,6] <= np.max(plotLatRange)) & (data['AMPERE'][:,6] >= np.min(plotLatRange)) & \
        (data['AMPERE'][:,7] <= np.max(plotLongRange)) & (data['AMPERE'][:,7] >= np.min(plotLongRange))
    AMPERE_data_limArea = data['AMPERE'][k,:]; #get the limited area data
    AMPERE_timeUnique_limArea = np.unique(AMPERE_data_limArea[:,5]);  #get the limited time unique

    AMPERE_timeUnique_hr = (AMPERE_timeUnique_limArea - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    AMPERE_plot_scargle_label = AMPERE_plot_labels[np.where(AMPERE_plot_indexes == AMPERE_plot_scargle_index)[0][0]]; #get the label
    AMPERE_plot_scargle_label = AMPERE_plot_scargle_label[0:AMPERE_plot_scargle_label.find('[')-1]; #remove the (units)

        
    AMPERE_integrate = np.zeros( AMPERE_timeUnique_hr.size , dtype=np.float64); #prep integrated joule heating
    for i in range(AMPERE_timeUnique_hr.size):
        k = np.where(AMPERE_timeUnique_limArea[i] == AMPERE_data_limArea[:,locAMPERE_time])[0]
        AMPERE_integrate[i] = np.sum(AMPERE_data_limArea[k,AMPERE_plot_scargle_index]); #ergs/(cm^2*sec), get the Joule Heating for the current time stamp
    #END FOR i

    if( AMPERE_integrate_highpassOption == 0 ): #only original data, no high-passed data
        
        #Start the AMPERE/OMNI scargle plot
        fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        #-----Plot an AMPERE data index's spectrum-----            
        AMPERE_integrate_scargPeriod, AMPERE_integrate_scargPower, AMPERE_integrate_scarggf = subfun_lombscargle(AMPERE_timeUnique_hr , AMPERE_integrate); #scargle that data
        AMPERE_integrate_scargPeriod = AMPERE_integrate_scargPeriod*60; #min, adjust the period out from hrs to minutes (since hrs goes in)
        
        ax.plot( AMPERE_integrate_scargPeriod, AMPERE_integrate_scargPower , linewidth=PLOT_lineWidthRegular ); #plot
        ax.plot( AMPERE_integrate_scargPeriod, np.tile(AMPERE_integrate_scarggf,np.size(AMPERE_integrate_scargPeriod)) , color="xkcd:grey" ); #plot
        
        ax.set_ylabel(AMPERE_plot_scargle_label+' Normalized Power',fontproperties=FONT_axisLabelFM); #set the y axis label
        
        xAxisTicks = np.arange(0,plot_periodLim_max+10,10); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
        ax.set_xticks(xAxisTicks); #set x axis ticks
        
        ax.set_xlim( (0, plot_periodLim_max) ); #set x axis limits
        if( AMPERE_integrate_scarggf < np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max])+0.1*np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max]) ):
            ax.set_ylim( (0, np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max])+0.1*np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max]) ) ); #set x axis limits
        else:
            ax.set_ylim( (0, AMPERE_integrate_scarggf+0.1*AMPERE_integrate_scarggf ) ); #set x axis limits
        #END IF
        
        ax.grid(b=True, which='major', axis='x', color='xkcd:light grey'); #sets major axis grid lines to be on 
        
        string_title = AMPERE_plot_scargle_label+' - Lomb-Scargle Periodogram for '+str(np.min(plotLatRange))+"x"+str(np.max(plotLatRange))+" lat, "+str(np.min(plotLongRange))+"x"+str(np.max(plotLatRange))+" long"; #create mecha title
        ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
                
        figFitter(fig); #fit that fig fast
        # fig.subplots_adjust(left = 0.070, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space  
        
    elif( AMPERE_integrate_highpassOption == 1 ): #combines original data scargle and high-passed data scargle
        from Code.subfun_highpass import subfun_highpass
        #~~~~~HIGH-PASSED ONE~~~~~       
    
        #Start the AMPERE & OMNI scargle plot
        fig, ax = plt.subplots(nrows=1,ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
                 
        #-----Plot an AMPERE data index's spectrum-----      
        AMPERE_integrate_hp = subfun_highpass(AMPERE_timeUnique_hr,AMPERE_integrate,filter_cutoffPeriod=settings_spectra['filter cutoff period']); #high-pass that data
        
        AMPERE_integrate_scargPeriod, AMPERE_integrate_scargPower, AMPERE_integrate_scarggf = subfun_lombscargle(AMPERE_timeUnique_hr , AMPERE_integrate_hp); #scargle that data
        AMPERE_integrate_scargPeriod = AMPERE_integrate_scargPeriod*60; #min, adjust the period out from hrs to minutes (since hrs goes in)
        
        ax.plot( AMPERE_integrate_scargPeriod, AMPERE_integrate_scargPower , linewidth=PLOT_lineWidthRegular ); #plot
        ax.plot( AMPERE_integrate_scargPeriod, np.tile(AMPERE_integrate_scarggf,np.size(AMPERE_integrate_scargPeriod)) , color="xkcd:grey" ); #plot
        
        ax.set_ylabel(AMPERE_plot_scargle_label+' Normalized Power',fontproperties=FONT_axisLabelFM); #set the y axis label
        
        xAxisTicks = np.arange(0,plot_periodLim_max+10,10); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
        ax.set_xticks(xAxisTicks); #set x axis ticks
        
        ax.set_xlim( (0, plot_periodLim_max) ); #set x axis limits
        if( AMPERE_integrate_scarggf < np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max])+0.1*np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max]) ):
            ax.set_ylim( (0, np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max])+0.1*np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max]) ) ); #set x axis limits
        else:
            ax.set_ylim( (0, AMPERE_integrate_scarggf+0.1*AMPERE_integrate_scarggf ) ); #set x axis limits
        #END IF
        
        ax.grid(b=True, which='major', axis='x', color='xkcd:light grey'); #sets major axis grid lines to be on 
        
        string_title = AMPERE_plot_scargle_label+' w/ High-pass Cutoff Period of '+str(settings_spectra['filter cutoff period'])+' hrs - Lomb-Scargle Periodogram for '+str(np.min(plotLatRange))+"x"+str(np.max(plotLatRange))+" lat, "+str(np.min(plotLongRange))+"x"+str(np.max(plotLatRange))+" long"; #create mecha title
        ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
                
        figFitter(fig); #fit that fig fast
        # fig.subplots_adjust(left = 0.070, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space 
    #END IF
#END IF   
    

if( FLG_AMPERE_integrate_stacker == 1 ):
    from Code.subfun_figFitter import figFitter
    from Code.subfun_insert import subfun_insert
    
    #-----Unpack-----
    # AMPERE_timeUnique = data['AMPERE']['time unique'];
    AMPERE_integrateMethod = settings['AMPERE']['integrate method'];
    AMPERE_integrateMethod_val = settings['AMPERE']['integrate method lat val'];
    AMPERE_integrateMethod_log = settings['AMPERE']['integrate method log'];
    # plotLatRange = settings['map']['lat range'];
    # plotLongRange = settings['map']['long range'];
    
    PLOT_lineWidthThicc = PLOT_lineWidth['thicc']; #get the line widths
    PLOT_lineWidthDoublePlus = PLOT_lineWidth['double plus']; #get the line widths
    PLOT_lineWidthPlus = PLOT_lineWidth['plus']; #get the line widths
    PLOT_lineWidthRegularPlus = PLOT_lineWidth['regular plus']; #get the line widths
    PLOT_lineWidthRegular = PLOT_lineWidth['regular']; #get the line widths
    PLOT_lineWidthSmol = PLOT_lineWidth['smol']; #get the line widths
    
    #-----Integrate-----
    # AMPERE_integrate = GRITI_AMPERE_integrator(data, dates, settings['AMPERE'], settings['map']['lat range'], settings['map']['long range'], AMPERE_integrateMethod,AMPERE_integrateMethod_val,AMPERE_integrateMethod_log); #get the integrated AMPERE data
    
    #-----Stack-----
    AMPERE_timeUnique_uniqueDays, AMPERE_timeUnique_uniqueDaysIndex, AMPERE_timeUnique_uniqueDayCounts = np.unique(np.int64(AMPERE_timeUnique),return_inverse=True,return_counts=True); #get the unique days and the indexes that get us to them
    
    AMPERE_integrate_stackerDaysStacked = AMPERE_timeUnique_uniqueDays.size; #get the number of days to stack
    AMPERE_integrate_stackerTime = np.int64(np.arange(0,86400,data['AMPERE']['data rate'])); #sec, make a time vector to go with the stacker var
    AMPERE_integrate_stackerHolder = np.zeros( (AMPERE_integrate_stackerTime.size , AMPERE_timeUnique_uniqueDays.size) ); #preallocate
    #STACK EM
    for i in range(0,AMPERE_timeUnique_uniqueDays.size):
        k = np.where( AMPERE_timeUnique_uniqueDaysIndex == i )[0]; #get indexes with the first day
        if( AMPERE_timeUnique_uniqueDayCounts[i] == AMPERE_integrate_stackerTime.size ):
            AMPERE_integrate_stackerHolder[:,i] = AMPERE_integrate[k]; #yoink
        else:
            tempTimeSec = np.int64(np.round((AMPERE_timeUnique[k]-AMPERE_timeUnique_uniqueDays[i])*86400)); #get the seconds in the day
            k2 = np.isin(AMPERE_integrate_stackerTime, tempTimeSec, assume_unique=True,invert=True); #get missing time steps
            AMPERE_integrate_stackerHolder[:,i] = subfun_insert(AMPERE_integrate[k],np.where(k2)[0],np.nan); #yoink, pad with NaN's as needed
        #END IF
    #END FOR i
    
    AMPERE_integrate_stacker = np.nanmean(AMPERE_integrate_stackerHolder,axis=1); #average along the 3rd axis
            
    data['AMPERE']['integrated stacker'] = AMPERE_integrate_stacker; #record
    data['AMPERE']['integrated stacker per day'] = AMPERE_integrate_stackerHolder; #record
    data['AMPERE']['integrated stacker time'] = AMPERE_integrate_stackerTime; #record
    
    #Start the AMPERE and OMNI AE plot
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    #-----PLOT AMPERE-----
    ax.set_aspect('auto'); #Remove the aspect ratio from the basemap so it fills the screen better
    ax.plot( AMPERE_integrate_stackerTime/3600, AMPERE_integrate_stacker , linewidth=PLOT_lineWidthRegular ); #plot
    
    xAxisTicks = np.arange(np.int64(np.floor(np.min(AMPERE_integrate_stackerTime/3600))),np.int64(np.ceil(np.max(AMPERE_integrate_stackerTime/3600)))+1,1); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    
#        ax[0].set_xticklabels([]); #if statement to remove x axis labels except for the last line
#        ax[0].tick_params(axis="x",direction="in");
    
    ax.set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set y axis limits
    
    ax.set_ylabel(settings['AMPERE']['labels'][settings['AMPERE']['data type']]+settings['AMPERE']['units'][settings['AMPERE']['data type']],fontproperties=FONT_axisLabelFM); #set the y axis label
    
    # ax[0].set_ylim( np.min(AMPERE_integrate) , 150000 ); #set y axis limits
    
    ax.grid(b=True, which='major', axis='both', color='xkcd:light grey'); #sets major axis grid lines to be on                
    
    if( AMPERE_integrateMethod == 0 ):
        string_title = '('+str(np.min(plotLatRange))+', '+str(np.max(plotLatRange))+') Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 1 ):
        string_title = '('+str(np.min(plotLatRange))+', 90) Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 2 ):
        string_title = '('+str(np.min(plotLatRange))+', '+str(AMPERE_integrateMethod_val)+') Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 3 ):
        if( (np.min(plotLatRange) >= 0) & (np.max(plotLatRange) >= 0) ):
            string_title = 'Northern Hemisphere Integrated'; #say how it was integrated
        else:
            string_title = 'Southern Hemisphere Integrated'; #say how it was integrated
        #END IF
    #END IF
    string_title = str(AMPERE_integrate_stackerDaysStacked)+' Days Stacked of '+string_title+' AMPERE '+settings['AMPERE']['labels'][settings['AMPERE']['data type']]; #create mecha title
    ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title        
            
    ax.set_xlabel('Relative time through a day, aligned to 0 UT [hr]',fontproperties=FONT_axisLabelFM); #set the x axis label
    
    figFitter(fig); #fit the fig fast
    # fig.subplots_adjust(left = 0.090, right = 0.985, top = 0.96, bottom = 0.070); #sets padding to small numbers for minimal white space  
    
    #Start the AMPERE and OMNI AE plot
    fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    #-----PLOT AMPERE-----
    ax.set_aspect('auto'); #Remove the aspect ratio from the basemap so it fills the screen better
    for i in range(0,AMPERE_integrate_stackerHolder.shape[1]):
        ax.plot( AMPERE_integrate_stackerTime/3600, AMPERE_integrate_stackerHolder[:,i] , linewidth=PLOT_lineWidthRegular, color=settings['plot']['color'][i] , label='Day '+str(i+1)); #plot
    #END FOR i
    ax.legend(); #make the legend show up
    
    xAxisTicks = np.arange(np.int64(np.floor(np.min(AMPERE_integrate_stackerTime/3600))),np.int64(np.ceil(np.max(AMPERE_integrate_stackerTime/3600)))+1,1); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    
#        ax[0].set_xticklabels([]); #if statement to remove x axis labels except for the last line
#        ax[0].tick_params(axis="x",direction="in");
    
    ax.set_xlim( np.min(xAxisTicks) , np.max(xAxisTicks) ); #set y axis limits
    
    ax.set_ylabel(settings['AMPERE']['labels'][settings['AMPERE']['data type']]+settings['AMPERE']['units'][settings['AMPERE']['data type']],fontproperties=FONT_axisLabelFM); #set the y axis label
    
    # ax[0].set_ylim( np.min(AMPERE_integrate) , 150000 ); #set y axis limits
    
    ax.grid(b=True, which='major', axis='both', color='xkcd:light grey'); #sets major axis grid lines to be on                
    
    if( AMPERE_integrateMethod == 0 ):
        string_title = '('+str(np.min(plotLatRange))+', '+str(np.max(plotLatRange))+') Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 1 ):
        string_title = '('+str(np.min(plotLatRange))+', 90) Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 2 ):
        string_title = '('+str(np.min(plotLatRange))+', '+str(AMPERE_integrateMethod_val)+') Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 3 ):
        if( (np.min(plotLatRange) >= 0) & (np.max(plotLatRange) >= 0) ):
            string_title = 'Northern Hemisphere Integrated'; #say how it was integrated
        else:
            string_title = 'Southern Hemisphere Integrated'; #say how it was integrated
        #END IF
    #END IF
    string_title = str(AMPERE_integrate_stackerDaysStacked)+' Days [Not Stacked] of '+string_title+' AMPERE '+settings['AMPERE']['labels'][settings['AMPERE']['data type']]; #create mecha title
    ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title        
            
    ax.set_xlabel('Relative time through a day, aligned to 0 UT [hr]',fontproperties=FONT_axisLabelFM); #set the x axis label
    
    figFitter(fig); #fit the fig fast
    # fig.subplots_adjust(left = 0.090, right = 0.985, top = 0.96, bottom = 0.070); #sets padding to small numbers for minimal white space
#END IF

if( FLG_AMPERE_integrate_stacker_FFT == 1 ):
    from Code.subfun_filter import subfun_filter
    from Code.subfun_spectra import subfun_spectra
    from Code.subfun_figFitter import figFitter
    
    #---- Unpack -----
    settings_spectra = settings['spectra'];

    AMPERE_dataRate = np.copy(data['AMPERE']['data rate']).item(); #get the data rate
    #---AMPERE PREP - time Match & HP---
    if( np.abs(AMPERE_dataRate/60-6) > 0.05 ):
        sixMin_timeUnique_sec = np.arange(0,86400,AMPERE_dataRate); #sec, arange time stamps
        #Match the data in the 1st input (and its time in the 2nd input) to the time scale given in the 3rd input time and return that data and that data's highpassed form
        AMPERE_integrate_timeMatch, _, AMPERE_timeUnique_timeMatch = GRITI_TEC_avgPt_timeMatch(data['AMPERE']['integrated stacker'],data['AMPERE']['integrated stacker time']/60,sixMin_timeUnique_sec/60,(0,0),filter_cutoffPeriod=settings_spectra['filter cutoff period']);
        AMPERE_dataRate = 6*60; #record the new data rate
    else:
    #-----Highpass the data to keep the power within the period range we want-----
        AMPERE_integrate_timeMatch = data['AMPERE']['integrated stacker']; #set so no errors
        AMPERE_timeUnique_timeMatch = data['AMPERE']['integrated stacker time']; #set so no errors
    #END IF
    
    AMPERE_integrate_timeMatch_filt = subfun_filter( AMPERE_integrate_timeMatch, AMPERE_timeUnique_timeMatch, AMPERE_integrateFFT_filtMethod, settings_spectra, dataRate = AMPERE_dataRate); #filter
    
    Cxx_AMPERE, period_AMPERE = subfun_spectra( AMPERE_integrate_timeMatch_filt, AMPERE_timeUnique_timeMatch, 'FFT', settings_spectra, dataRate = AMPERE_dataRate); #get spectra
    
    Fs = 1/(AMPERE_dataRate/60); #min, misa time delta in freq form #OMNI_time_delta*24*60

    #PLOT IT UP
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
    #Start the AMPERE stacker FFT plot
    fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    ax.plot( period_AMPERE/60, Cxx_AMPERE ); #plot
#        ax.plot( OMNI_data_scargPeriod, np.tile(OMNI_data_scarggf,np.size(OMNI_data_scargPeriod)) , color="xkcd:grey" ); #plot
    
    ax.set_xlabel("Periods [min]"+' for Date Range '+str(dateRange[0,1])+'/'+str(dateRange[0,2])+ \
        '/'+str(dateRange[0,0])+' to '+str(dateRange[-1,1])+ '/'+str(dateRange[-1,2])+'/'+str(dateRange[-1,0])+ ' (M/D/Y)',fontproperties=FONT_axisLabelFM); #set the x axis label
    ax.set_ylabel('Normalized Power',fontproperties=FONT_axisLabelFM); #set the y axis label
    
    xAxisTicks = np.arange( 0, settings_spectra['period limit max']+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    ax.set_xlim( (settings_spectra['period limit min'], settings_spectra['period limit max']) ); #set x axis limits

#        if( OMNI_data_scarggf < np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim]) ):
#            ax.set_ylim( (0, np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim]) ) ); #set x axis limits
#        else:
#            ax.set_ylim( (0, OMNI_data_scarggf+0.1*OMNI_data_scarggf ) ); #set x axis limits
#        #END IF 
    
    if( AMPERE_integrateMethod == 0 ):
        string_title = '('+str(np.min(plotLatRange))+', '+str(np.max(plotLatRange))+') Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 1 ):
        string_title = '('+str(np.min(plotLatRange))+', 90) Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 2 ):
        string_title = '('+str(np.min(plotLatRange))+', '+str(AMPERE_integrateMethod_val)+') Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 3 ):
        if( (np.min(plotLatRange) >= 0) & (np.max(plotLatRange) >= 0) ):
            string_title = 'Northern Hemisphere Integrated'; #say how it was integrated
        else:
            string_title = 'Southern Hemisphere Integrated'; #say how it was integrated
        #END IF
    #END IF
    string_title = str(AMPERE_integrate_stackerDaysStacked)+' Days Stacked of '+string_title+' AMPERE '+settings['AMPERE']['labels'][settings['AMPERE']['data type']]+' - FFT Power Spectra'; #create mecha title
    ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
    
    figFitter(fig); #fit the fig fast
    # fig.subplots_adjust(left = 0.050, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space

    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
    #Start the AMPERE stacker per day FFT plot
    fig, ax = plt.subplots(); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    for i in range(0,data['AMPERE']['integrated stacker per day'].shape[1]):
        AMPERE_integrate_stackerPerDay = data['AMPERE']['integrated stacker per day'][:,i]; #unpack
        AMPERE_integrate_stackerPerDay[np.isnan(AMPERE_integrate_stackerPerDay)] = 0; #force NaNs to 0
        AMPERE_integrate_timeMatch_filt = subfun_filter( AMPERE_integrate_stackerPerDay, AMPERE_timeUnique_timeMatch, AMPERE_integrateFFT_filtMethod, settings_spectra, dataRate = AMPERE_dataRate); #filter
        Cxx_AMPERE, period_AMPERE = subfun_spectra( AMPERE_integrate_timeMatch_filt, AMPERE_timeUnique_timeMatch, 'FFT', settings_spectra, dataRate = AMPERE_dataRate); #get spectra
        ax.plot( period_AMPERE/60, Cxx_AMPERE , color=settings['plot']['color'][i], label='Day '+str(i+1)); #plot
    #END FOR i
    ax.legend(); #make the legend show up
    
    ax.set_xlabel("Periods [min]"+' for Date Range '+str(dateRange[0,1])+'/'+str(dateRange[0,2])+ \
        '/'+str(dateRange[0,0])+' to '+str(dateRange[-1,1])+ '/'+str(dateRange[-1,2])+'/'+str(dateRange[-1,0])+ ' (M/D/Y)',fontproperties=FONT_axisLabelFM); #set the x axis label
    ax.set_ylabel('Normalized Power',fontproperties=FONT_axisLabelFM); #set the y axis label
    
    ax.set_xticks(xAxisTicks); #set x axis ticks
    ax.set_xlim( (settings_spectra['period limit min'], settings_spectra['period limit max']) ); #set x axis limits
    xAxisTicks = np.arange( 0, settings_spectra['period limit max']+10, 10); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    
#        if( OMNI_data_scarggf < np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim]) ):
#            ax.set_ylim( (0, np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_Period_Lim]) ) ); #set x axis limits
#        else:
#            ax.set_ylim( (0, OMNI_data_scarggf+0.1*OMNI_data_scarggf ) ); #set x axis limits
#        #END IF 
    
    if( AMPERE_integrateMethod == 0 ):
        string_title = '('+str(np.min(plotLatRange))+', '+str(np.max(plotLatRange))+') Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 1 ):
        string_title = '('+str(np.min(plotLatRange))+', 90) Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 2 ):
        string_title = '('+str(np.min(plotLatRange))+', '+str(AMPERE_integrateMethod_val)+') Lat, ('+str(np.min(plotLongRange))+', '+str(np.max(plotLongRange))+') Long Integrated'; #say how it was integrated
    if( AMPERE_integrateMethod == 3 ):
        if( (np.min(plotLatRange) >= 0) & (np.max(plotLatRange) >= 0) ):
            string_title = 'Northern Hemisphere Integrated'; #say how it was integrated
        else:
            string_title = 'Southern Hemisphere Integrated'; #say how it was integrated
        #END IF
    #END IF
    string_title = str(AMPERE_integrate_stackerDaysStacked)+' Days [Not Stacked] of '+string_title+' AMPERE '+settings['AMPERE']['labels'][settings['AMPERE']['data type']]+' - FFT Power Spectra'; #create mecha title
    ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
    
    figFitter(fig); #fit the fig fast
    # fig.subplots_adjust(left = 0.050, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space

    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
#END IF
    
if( FLG_AMPERE_integrate_andOMNI_AE_plot == 1 ):
    
    AMPERE_timeUnique_hr = (AMPERE_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    if( np.mod(np.round(np.min(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_min = np.round(np.min(AMPERE_timeUnique_hr))+1; #is odd, make even
    #END IF
    if( np.mod(np.round(np.max(AMPERE_timeUnique_hr)),2) == 0 ):
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr)); #is even, good to go
    else:
        AMPERE_time_hr_axis_max = np.round(np.max(AMPERE_timeUnique_hr))-1; #is odd, make even
    #END IF
    
    OMNI_timeUnique_hr = (OMNI_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    #OMNI plot prep
    OMNI_plot_label = OMNI_dictPlot[OMNI_dict[OMNI_plot_name]]; #get the label
    OMNI_plot_labelNoUnits = OMNI_plot_label[0:OMNI_plot_label.find('[')-1]; #remove the (units)
    
    #-----BEGIN THE PLOTTING!------
    if( np.min(data['AMPERE']['lat']) < 0 ):
        #that means there is southern hemisphere data
        pass;
    else:
        #otherwise only northern hemisphere data
        
        AMPERE_integrate = np.zeros( AMPERE_timeUnique_hr.size , dtype=np.float64); #prep integrated joule heating
        for i in range(AMPERE_timeUnique_hr.size):
            k = np.where(AMPERE_timeUnique[i] == data['AMPERE']['time'])[0]
            AMPERE_integrate[i] = np.sum(data['AMPERE'][k,locAMPERE_jouleHeating]); #ergs/(cm^2*sec), get the Joule Heating for the current time stamp
        #END FOR i
        
        #Start the AMPERE and OMNI AE plot
        fig, ax = plt.subplots(nrows=2, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        #-----PLOT AMPERE-----
        ax[0].set_aspect('auto'); #Remove the aspect ratio from the basemap so it fills the screen better
        ax[0].plot( AMPERE_timeUnique_hr, AMPERE_integrate , linewidth=PLOT_lineWidthRegular ); #plot
        
        if( (np.abs((np.min(AMPERE_timeUnique_hr)/24 + dateRange_dayNum_zeroHr[1]) - np.min(time_Ref))*24 >= 0.25) & ((time_Reference != 'Kp') & (time_Reference != 'AMPERE')) ): #as long as min Kp time is 15 min diff or more from the other time reference, plot where the time ref begins (not Kp tho)
            ax[0].plot( np.repeat( (np.min(time_Ref) - dateRange_dayNum_zeroHr[1]*86400)/3600 , 10) , np.linspace(np.min(AMPERE_integrate),np.max(AMPERE_integrate),num=10), linewidth=1.75, color='r'); #plot red lines showing ISR data time
        if( (np.abs((np.max(AMPERE_timeUnique_hr)/24 + dateRange_dayNum_zeroHr[1]) - np.max(time_Ref))*24 >= 0.25) & ((time_Reference != 'Kp') & (time_Reference != 'AMPERE')) ): #as long as max Kp time is 15 min diff or more from the other time reference, plot where the time ref ends (not Kp tho)
            ax[0].plot( np.repeat( (np.max(time_Ref) - dateRange_dayNum_zeroHr[1]*86400)/3600 , 10) , np.linspace(np.min(AMPERE_integrate),np.max(AMPERE_integrate),num=10), linewidth=1.75, color='r'); #plot red lines showing ISR data time
        #END IF
        
        xAxisTicks = np.arange(AMPERE_time_hr_axis_min,AMPERE_time_hr_axis_max+4,4); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
        ax[0].set_xticks(xAxisTicks); #set x axis ticks
        
#        ax[0].set_xticklabels([]); #if statement to remove x axis labels except for the last line
#        ax[0].tick_params(axis="x",direction="in");
        
        ax[0].set_xlim( AMPERE_time_hr_axis_min , AMPERE_time_hr_axis_max ); #set y axis limits
        
        ax[0].set_ylabel("Int. AMPERE JH [ergs/(cm^2*sec)]",fontproperties=FONT_axisLabelFM); #set the y axis label
        
        ax[0].set_ylim( np.min(AMPERE_integrate) , 150000 ); #set y axis limits
        
        ax[0].grid(b=True, which='major', axis='both', color='xkcd:light grey'); #sets major axis grid lines to be on                
        
        string_title = 'Integrated AMPERE Joule Heating in the Nothern Hemisphere & '+OMNI_plot_labelNoUnits+' for '+str(dateRange[0,1])+'/'+str(dateRange[0,2])+ \
        '/'+str(dateRange[0,0])+' to '+str(dateRange[-1,1])+ \
        '/'+str(dateRange[-1,2])+'/'+str(dateRange[-1,0])+ \
        ' (M/D/Y)'; #create mecha title
        ax[0].set_title(string_title,fontproperties=FONT_titleFM); #set the title
        
        #-----PLOT OMNI AE-----
        ax[1].set_aspect('auto'); #Remove the aspect ratio from the basemap so it fills the screen better
        ax[1].plot( OMNI_timeUnique_hr, OMNI_data[:,OMNI_dict[OMNI_plot_name]] , linewidth=PLOT_lineWidthRegular ); #plot
        
        if( (np.abs((np.min(AMPERE_timeUnique_hr)/24 + dateRange_dayNum_zeroHr[1]) - np.min(time_Ref))*24 >= 0.25) & ((time_Reference != 'Kp') & (time_Reference != 'AMPERE')) ): #as long as min Kp time is 15 min diff or more from the other time reference, plot where the time ref begins (not Kp tho)
            ax[1].plot( np.repeat( (np.min(time_Ref) - dateRange_dayNum_zeroHr[1]*86400)/3600 , 10) , np.linspace(np.min(AMPERE_integrate),np.max(AMPERE_integrate),num=10), linewidth=1.75, color='r'); #plot red lines showing ISR data time
        if( (np.abs((np.max(AMPERE_timeUnique_hr)/24 + dateRange_dayNum_zeroHr[1]) - np.max(time_Ref))*24 >= 0.25) & ((time_Reference != 'Kp') & (time_Reference != 'AMPERE')) ): #as long as max Kp time is 15 min diff or more from the other time reference, plot where the time ref ends (not Kp tho)
            ax[1].plot( np.repeat( (np.max(time_Ref) - dateRange_dayNum_zeroHr[1]*86400)/3600 , 10) , np.linspace(np.min(AMPERE_integrate),np.max(AMPERE_integrate),num=10), linewidth=1.75, color='r'); #plot red lines showing ISR data time
        #END IF
        
        ax[1].set_xticks(xAxisTicks); #set x axis ticks
        
        ax[1].set_xlim( AMPERE_time_hr_axis_min , AMPERE_time_hr_axis_max ); #set y axis limits
        
        ax[1].set_ylabel(OMNI_dictPlot[OMNI_dict[OMNI_plot_name]],fontproperties=FONT_axisLabelFM); #set the y axis label
        
        ax[1].set_ylim( np.min(OMNI_data[:,OMNI_dict[OMNI_plot_name]]) , np.max(OMNI_data[:,OMNI_dict[OMNI_plot_name]]) ); #set y axis limits
        
        ax[1].grid(b=True, which='major', axis='both', color='xkcd:light grey'); #sets major axis grid lines to be on                
                
        ax[1].set_xlabel('Time in UT (hr) - 0 Hr on '+dateRange_zeroHr_monthName+' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM); #set the x axis label
        
        figFitter(fig); #fit that fig fast
        # fig.subplots_adjust(left = 0.070, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
    #END IF
    
#END IF
    

if( FLG_AMPERE_integrate_andOMNI_AE_plot_scargle == 1 ):

    AMPERE_timeUnique_hr = (AMPERE_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    AMPERE_plot_scargle_label = AMPERE_plot_labels[np.where(AMPERE_plot_indexes == AMPERE_plot_scargle_index)[0][0]]; #get the label
    AMPERE_plot_scargle_label = AMPERE_plot_scargle_label[0:AMPERE_plot_scargle_label.find('[')-1]; #remove the (units)

    OMNI_timeUnique_hr = (OMNI_timeUnique - dateRange_dayNum_zeroHr[1]*86400)/3600; #hr, convert to hr with 0 hr at specified day
    
    OMNI_plot_scargle_label = OMNI_dictPlot[OMNI_dict[OMNI_plot_scargle_name]]; #get the label
    OMNI_plot_scargle_labelNoUnits = OMNI_plot_scargle_label[0:OMNI_plot_scargle_label.find('[')-1]; #remove the (units)
    
    #-----BEGIN THE PLOTTING!------
    if( np.min(data['AMPERE']['lat']) < 0 ):
        #that means there is southern hemisphere data
        pass;
    else:
        #otherwise only northern hemisphere data
        
        AMPERE_integrate = np.zeros( AMPERE_timeUnique_hr.size , dtype=np.float64); #prep integrated joule heating
        for i in range(AMPERE_timeUnique_hr.size):
            k = np.where(AMPERE_timeUnique[i] == data['AMPERE']['time'])[0]
            AMPERE_integrate[i] = np.sum(data['AMPERE'][k,AMPERE_plot_scargle_index]); #ergs/(cm^2*sec), get the Joule Heating for the current time stamp
        #END FOR i
    
        if( AMPERE_integrate_highpassOption == 0 ): #only original data, no high-passed data
            
            #Start the AMPERE/OMNI scargle plot
            fig, ax = plt.subplots(nrows=2, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
            figManager = fig.canvas.manager; #req to maximize
            figManager.window.showMaximized(); #force maximized
            
            #-----Plot an AMPERE data index's spectrum-----            
            AMPERE_integrate_scargPeriod, AMPERE_integrate_scargPower, AMPERE_integrate_scarggf = subfun_lombscargle(AMPERE_timeUnique_hr , AMPERE_integrate); #scargle that data
            AMPERE_integrate_scargPeriod = AMPERE_integrate_scargPeriod*60; #min, adjust the period out from hrs to minutes (since hrs goes in)
            
            ax[0].plot( AMPERE_integrate_scargPeriod, AMPERE_integrate_scargPower , linewidth=PLOT_lineWidthRegular ); #plot
            ax[0].plot( AMPERE_integrate_scargPeriod, np.tile(AMPERE_integrate_scarggf,np.size(AMPERE_integrate_scargPeriod)) , color="xkcd:grey" ); #plot
            
            ax[0].set_ylabel(AMPERE_plot_scargle_label+' Normalized Power',fontproperties=FONT_axisLabelFM); #set the y axis label
            
            xAxisTicks = np.arange(0,plot_periodLim_max+10,10); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
            ax[0].set_xticks(xAxisTicks); #set x axis ticks
            
            ax[0].set_xlim( (0, plot_periodLim_max) ); #set x axis limits
            if( AMPERE_integrate_scarggf < np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max])+0.1*np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max]) ):
                ax[0].set_ylim( (0, np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max])+0.1*np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max]) ) ); #set x axis limits
            else:
                ax[0].set_ylim( (0, AMPERE_integrate_scarggf+0.1*AMPERE_integrate_scarggf ) ); #set x axis limits
            #END IF
            
            ax[0].grid(b=True, which='major', axis='x', color='xkcd:light grey'); #sets major axis grid lines to be on 
            
            string_title = AMPERE_plot_scargle_label+' and '+OMNI_plot_scargle_labelNoUnits+' - Lomb-Scargle Periodogram'; #create mecha title
            ax[0].set_title(string_title,fontproperties=FONT_titleFM); #set the title
            
            #-----Plot an OMNI data index's spectrum-----            
            OMNI_data_scargPeriod, OMNI_data_scargPower, OMNI_data_scarggf = subfun_lombscargle(OMNI_timeUnique_hr , OMNI_data[:,OMNI_dict[OMNI_plot_scargle_name]]); #scargle that data
            OMNI_data_scargPeriod = OMNI_data_scargPeriod*60; #min, adjust the period out from hrs to minutes (since hrs goes in)
                        
            ax[1].plot( OMNI_data_scargPeriod, OMNI_data_scargPower , linewidth=PLOT_lineWidthRegular ); #plot
            ax[1].plot( OMNI_data_scargPeriod, np.tile(OMNI_data_scarggf,np.size(OMNI_data_scargPeriod)) , color="xkcd:grey" ); #plot
            
            ax[1].set_xlabel("Periods (min)"+' for Date Range '+str(dateRange[0,1])+'/'+str(dateRange[0,2])+ \
                '/'+str(dateRange[0,0])+' to '+str(dateRange[-1,1])+ '/'+str(dateRange[-1,2])+'/'+str(dateRange[-1,0])+ ' (M/D/Y)',fontproperties=FONT_axisLabelFM); #set the x axis label
            ax[1].set_ylabel(OMNI_plot_scargle_labelNoUnits+' Normalized Power',fontproperties=FONT_axisLabelFM); #set the y axis label
            
            ax[1].set_xticks(xAxisTicks); #set x axis ticks
            
            ax[1].set_xlim( (0, plot_periodLim_max) ); #set x axis limits
            if( OMNI_data_scarggf < np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_periodLim_max])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_periodLim_max]) ):
                ax[1].set_ylim( (0, np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_periodLim_max])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_periodLim_max]) ) ); #set x axis limits
            else:
                ax[1].set_ylim( (0, OMNI_data_scarggf+0.1*OMNI_data_scarggf ) ); #set x axis limits
            #END IF      
            
            ax[1].grid(b=True, which='major', axis='x', color='xkcd:light grey'); #sets major axis grid lines to be on 
            
            figFitter(fig); #fit that fig fast
            # fig.subplots_adjust(left = 0.070, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
            
        elif( AMPERE_integrate_highpassOption == 1 ): #combines original data scargle and high-passed data scargle
            from Code.subfun_highpass import subfun_highpass
            #~~~~~HIGH-PASSED ONE~~~~~       
        
            #Start the AMPERE & OMNI scargle plot
            fig, ax = plt.subplots(nrows=2,ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
            figManager = fig.canvas.manager; #req to maximize
            figManager.window.showMaximized(); #force maximized
                     
            #-----Plot an AMPERE data index's spectrum-----      
            AMPERE_integrate_hp = subfun_highpass(AMPERE_timeUnique_hr,AMPERE_integrate,filter_cutoffPeriod=settings_spectra['filter cutoff period']); #high-pass that data
            
            AMPERE_integrate_scargPeriod, AMPERE_integrate_scargPower, AMPERE_integrate_scarggf = subfun_lombscargle(AMPERE_timeUnique_hr , AMPERE_integrate_hp); #scargle that data
            AMPERE_integrate_scargPeriod = AMPERE_integrate_scargPeriod*60; #min, adjust the period out from hrs to minutes (since hrs goes in)
            
            ax[0].plot( AMPERE_integrate_scargPeriod, AMPERE_integrate_scargPower , linewidth=PLOT_lineWidthRegular ); #plot
            ax[0].plot( AMPERE_integrate_scargPeriod, np.tile(AMPERE_integrate_scarggf,np.size(AMPERE_integrate_scargPeriod)) , color="xkcd:grey" ); #plot
            
            ax[0].set_ylabel(AMPERE_plot_scargle_label+' Normalized Power',fontproperties=FONT_axisLabelFM); #set the y axis label
            
            xAxisTicks = np.arange(0,plot_periodLim_max+10,10); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
            ax[0].set_xticks(xAxisTicks); #set x axis ticks
            
            ax[0].set_xlim( (0, plot_periodLim_max) ); #set x axis limits
            if( AMPERE_integrate_scarggf < np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max])+0.1*np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max]) ):
                ax[0].set_ylim( (0, np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max])+0.1*np.max(AMPERE_integrate_scargPower[AMPERE_integrate_scargPeriod<=plot_periodLim_max]) ) ); #set x axis limits
            else:
                ax[0].set_ylim( (0, AMPERE_integrate_scarggf+0.1*AMPERE_integrate_scarggf ) ); #set x axis limits
            #END IF
            
            ax[0].grid(b=True, which='major', axis='x', color='xkcd:light grey'); #sets major axis grid lines to be on 
            
            string_title = AMPERE_plot_scargle_label+' and '+OMNI_plot_scargle_label+' w/ High-pass Cutoff Period of '+str(settings_spectra['filter cutoff period'])+' hrs - Lomb-Scargle Periodogram'; #create mecha title
            ax[0].set_title(string_title,fontproperties=FONT_titleFM); #set the title
            
            #-----Plot an OMNI data index's spectrum-----       
            OMNI_data_hp = subfun_highpass(OMNI_timeUnique_hr,OMNI_data[:,OMNI_dict[OMNI_plot_scargle_name]],filter_cutoffPeriod=settings_spectra['filter cutoff period']); #high-pass that data
            
            OMNI_data_scargPeriod, OMNI_data_scargPower, OMNI_data_scarggf = subfun_lombscargle(OMNI_timeUnique_hr , OMNI_data_hp); #scargle that data
            OMNI_data_scargPeriod = OMNI_data_scargPeriod*60; #min, adjust the period out from hrs to minutes (since hrs goes in)
                        
            ax[1].plot( OMNI_data_scargPeriod, OMNI_data_scargPower , linewidth=PLOT_lineWidthRegular ); #plot
            ax[1].plot( OMNI_data_scargPeriod, np.tile(OMNI_data_scarggf,np.size(OMNI_data_scargPeriod)) , color="xkcd:grey" ); #plot
            
            ax[1].set_xlabel("Periods (min)"+' for Date Range '+str(dateRange[0,1])+'/'+str(dateRange[0,2])+ \
                '/'+str(dateRange[0,0])+' to '+str(dateRange[-1,1])+ '/'+str(dateRange[-1,2])+'/'+str(dateRange[-1,0])+ ' (M/D/Y)',fontproperties=FONT_axisLabelFM); #set the x axis label
            ax[1].set_ylabel(OMNI_plot_scargle_label+' Normalized Power',fontproperties=FONT_axisLabelFM); #set the y axis label
        
            ax[1].set_xticks(xAxisTicks); #set x axis ticks
            
            ax[1].set_xlim( (0, plot_periodLim_max) ); #set x axis limits
            if( OMNI_data_scarggf < np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_periodLim_max])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_periodLim_max]) ):
                ax[1].set_ylim( (0, np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_periodLim_max])+0.1*np.max(OMNI_data_scargPower[OMNI_data_scargPeriod<=plot_periodLim_max]) ) ); #set x axis limits
            else:
                ax[1].set_ylim( (0, OMNI_data_scarggf+0.1*OMNI_data_scarggf ) ); #set x axis limits
            #END IF     
            
            ax[1].grid(b=True, which='major', axis='x', color='xkcd:light grey'); #sets major axis grid lines to be on                
            
            figFitter(fig); #fit that fig fast
            # fig.subplots_adjust(left = 0.070, right = 0.985, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
        #END IF
    #END IF
#END IF
   

#****************************************************************Magnetometer Times****************************************************************
if( FLG_MagCAN_viewAll_magF == 1 ):
    from scipy.signal import savgol_filter
    from Code.subfun_strstr import strstr
    
    if( settings['MagCAN']['keo set stations'] != 1 ):
        siteNames = data['MagCAN']['site names']; #get the site names
    else:
        siteNames = settings['MagCAN']['keo set stations names']; #set the site names to whatever the user had
    #END IF
    removeList = []; #prep
    for j in range(0,len(siteNames)):
        if( ~((data['MagCAN'][siteNames[j]]['lat'] >= np.min(settings['MagCAN']['lat range'])) & \
                (data['MagCAN'][siteNames[j]]['lat'] <= np.max(settings['MagCAN']['lat range'])) & \
                (data['MagCAN'][siteNames[j]]['long'] >= np.min(settings['MagCAN']['long range'])) & \
                (data['MagCAN'][siteNames[j]]['long'] <= np.max(settings['MagCAN']['long range']))) ):
            removeList.append(siteNames[j]); #prep for removal b/c not within the range we want
        #END IF
    #END FOR j
    #solving lists takes a lot of slowww lists ohw ell
    for j in range(0,len(removeList)):
        siteNames.remove(removeList[j]); #remove the stuff we don't need
    #END FOR j
    siteNamesIndex = np.where(np.in1d(data['MagCAN']['site names'],siteNames))[0]; #get indexes [keeps site coloring consistent even if all are not in use]
    
    #Start the Mag time series plot
    fig, ax = plt.subplots(nrows=1,ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    #Remove the aspect ratio from the basemap so it fills the screen better
    ax.set_aspect('auto');
    
    pHolder = []; #holds some plot refs
    pLegendTitles = []; #holds the plot names for the legend
    for j in range(0,len(siteNames)):
        currTime = ((np.int64(data['MagCAN'][siteNames[j]]['dayNumF'])*86400+np.int64(data['MagCAN'][siteNames[j]]['secF'])) - dates['date range zero hr dayNum'][1]*86400)/3600; #hr, per site just in case
        
        #filter function here
        temp_deltaMagF = subfun_filter( data['MagCAN'][siteNames[j]]['magF'], data['MagCAN'][siteNames[j]]['secF'], settings['MagCAN']['delta method'], settings['spectra'], dataRate = data['MagCAN'][siteNames[j]]['dataRateF'], reduceWindow = 0); #filter using the all-powerful filter function
        
        pTemp, = ax.plot( currTime, temp_deltaMagF, linewidth=settings['plot']['line width']['double plus'], color=settings['plot']['color'][siteNamesIndex[j]] ); #plot
        pHolder.append(pTemp); #record plot ref
        pLegendTitles.append(siteNames[j]+' '+str(siteNamesIndex[j])); #record the site names
    #END FOR j
    
    string_titleTemp = ''; #prep
    if( strstr(settings['MagCAN']['delta method'],'mean').size > 0 ):
        string_titleTemp += '0 Mean Mag'; #set the specific word to describe the data
    if( strstr(settings['MagCAN']['delta method'],'savgol').size > 0 ):
        if( string_titleTemp != '' ):
            string_titleTemp += ' & '; #add on an ampersand
        #END IF
        string_titleTemp += 'Delta-Mag'; #set the specific word to describe the data
    else: #otherwise do nothing
        string_titleTemp += 'Mag CAN'; #set the specific word to describe the data
    #END IF
    string_title = string_titleTemp+' for '+str(dates['date range full'][0,1])+'/'+str(dates['date range full'][0,2])+ \
        '/'+str(dates['date range full'][0,0])+' to '+str(dates['date range full'][-1,1])+ \
        '/'+str(dates['date range full'][-1,2])+'/'+str(dates['date range full'][-1,0])+ \
        ' (M/D/Y)'; #create mecha title
    ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title
    ax.set_xlabel('Time in UT [hr] - 0 Hr on '+dates['date range zero hr month name']+' '+str(dates['date range zero hr'][2]) + \
                  dates['date range zero hr day post fix']+' | Day '+str(dates['date range zero hr dayNum'][1])+', ' + \
                  str(dates['date range zero hr dayNum'][0]),fontproperties=FONT_axisLabelFM); #set the x axis label
    ax.set_ylabel('Mag Field [nT]',fontproperties=FONT_axisLabelFM); #set the y axis label
    
    if( np.mod(np.min(data['MagCAN']['timeUniqueF_hr']),2) == 0 ):
        time_axis_min = np.min(data['MagCAN']['timeUniqueF_hr']); #is even, good to go
    else:
        time_axis_min = np.min(data['MagCAN']['timeUniqueF_hr'])+1; #is odd, make even
    #END IF
    
    if( np.mod(np.max(data['MagCAN']['timeUniqueF_hr']),2) == 0 ):
        time_axis_max = np.max(data['MagCAN']['timeUniqueF_hr']); #is even, good to go
    else:
        time_axis_max = np.max(data['MagCAN']['timeUniqueF_hr'])-1; #is odd, make even
    #END IF
    xAxisTicks = np.arange(time_axis_min,time_axis_max+4,4); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
    ax.set_xticks(xAxisTicks); #set x axis ticks
    ax.set_xlim( time_axis_min , time_axis_max ); #set x axis limits
    
    ax.legend(pHolder,pLegendTitles,loc='upper left');
    
#    yAxisTicks = ; #creates y ticks automagically
#    ax.set_yticks(yAxisTicks); #set x axis ticks
    # ax.set_ylim( 0 , np.max(Kp_data)+0.5 ); #set y axis limits
    
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.065, right = 0.985, top = 0.96, bottom = 0.075); #sets padding to small numbers for minimal white space
    
    #PLOT IT UP
    cntr = 0; #start cntr
    for arbiter in range(0,np.int64(np.ceil(len(siteNames)/6))):
        if( (np.abs(cntr - len(siteNames)) >= 6) & (np.remainder(np.abs(cntr - len(siteNames)),4) != 0) ):
            fig, ax = plt.subplots(nrows=2, ncols=3); #use instead of fig because it inits an axis too (I think I dunno)
            xAxisTicks = np.arange(time_axis_min,time_axis_max+8,8); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
        elif( np.abs(cntr - len(siteNames)) >= 4 ):
            fig, ax = plt.subplots(nrows=2, ncols=2); #use instead of fig because it inits an axis too (I think I dunno)
            xAxisTicks = np.arange(time_axis_min,time_axis_max+8,8); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
        elif( np.abs(cntr - len(siteNames)) >= 2 ):
            fig, ax = plt.subplots(nrows=1, ncols=2); #use instead of fig because it inits an axis too (I think I dunno)
            xAxisTicks = np.arange(time_axis_min,time_axis_max+8,8); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
        elif( np.abs(cntr - len(siteNames)) == 1 ):
            fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
            xAxisTicks = np.arange(time_axis_min,time_axis_max+4,4); #sets the start hr, stop hr, and the step size between (in this case, 4 hr)
        #END IF
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        if( np.abs(cntr - len(siteNames)) >= 4 ):
            for i in range(0,ax.shape[0]): #helps automagically plot
                for j in range(0,ax.shape[1]): #helps automagically plot
                    if( cntr < len(siteNames) ):
                        #Remove the aspect ratio from the basemap so it fills the screen better
                        ax[i,j].set_aspect('auto');
                        
                        #---PLOT HERE---
                        currTime = ((np.int64(data['MagCAN'][siteNames[cntr]]['dayNumF'])*86400+np.int64(data['MagCAN'][siteNames[cntr]]['secF'])) - dates['date range zero hr dayNum'][1]*86400)/3600; #hr, per site just in case
                        
                        #filter function here
                        temp_deltaMagF = subfun_filter( data['MagCAN'][siteNames[cntr]]['magF'], data['MagCAN'][siteNames[cntr]]['secF'], settings['MagCAN']['delta method'], settings['spectra'], dataRate = data['MagCAN'][siteNames[cntr]]['dataRateF'], reduceWindow = 0); #filter using the all-powerful filter function
        
                        pTemp, = ax[i,j].plot( currTime, temp_deltaMagF, linewidth=settings['plot']['line width']['double plus'], color=settings['plot']['color'][siteNamesIndex[cntr]] ); #plot
                            
                        #---SET AXIS LIMITS HERE---
                        ax[i,j].set_xlim( time_axis_min , time_axis_max ); #set x axis limits
                        ax[i,j].set_xticks(xAxisTicks); #set x axis ticks
                        
                        #---SET TITLES AND AXIS LABELS HERE---
                        string_title = string_titleTemp+' '+siteNames[cntr]+' '+str(siteNamesIndex[cntr]); #create mecha title
                        ax[i,j].set_title(string_title,fontproperties=FONT_titleFM); #set the title
                        if( (i == (ax.shape[0]-1) ) & (j == (ax.shape[1]-1)//2) ):
                            ax[i,j].set_xlabel('Time in UT [hr] - 0 Hr on '+dates['date range zero hr month name']+' '+str(dates['date range zero hr'][2]) + \
                                dates['date range zero hr day post fix']+' | Day '+str(dates['date range zero hr dayNum'][1])+', ' + \
                                str(dates['date range zero hr dayNum'][0]),fontproperties=FONT_axisLabelFM); #set the x axis label
                        #END IF
                        if( j == 0 ):
                            ax[i,j].set_ylabel('Mag Field [nT]',fontproperties=FONT_axisLabelFM); #set the y axis label
                        #END IF
                    #END IF
                    cntr += 1; #for counting continuously
                #END FOR j
            #END FOR i
        elif( np.abs(cntr - len(siteNames)) >= 2 ):
            for i in range(0,ax.shape[0]): #helps automagically plot
                if( cntr < len(siteNames) ):
                    #Remove the aspect ratio from the basemap so it fills the screen better
                    ax[i].set_aspect('auto');
                    
                    #---PLOT HERE---
                    currTime = ((np.int64(data['MagCAN'][siteNames[cntr]]['dayNumF'])*86400+np.int64(data['MagCAN'][siteNames[cntr]]['secF'])) - dates['date range zero hr dayNum'][1]*86400)/3600; #hr, per site just in case
                    #filter function here
                    temp_deltaMagF = subfun_filter( data['MagCAN'][siteNames[cntr]]['magF'], data['MagCAN'][siteNames[cntr]]['secF'], settings['MagCAN']['delta method'], settings['spectra'], dataRate = data['MagCAN'][siteNames[cntr]]['dataRateF'], reduceWindow = 0); #filter using the all-powerful filter function
        
                    pTemp, = ax[i].plot( currTime, temp_deltaMagF, linewidth=settings['plot']['line width']['double plus'], color=settings['plot']['color'][siteNamesIndex[cntr]] ); #plot
                        
                    #---SET AXIS LIMITS HERE---
                    ax[i].set_xlim( time_axis_min , time_axis_max ); #set x axis limits
                    ax[i].set_xticks(xAxisTicks); #set x axis ticks
                    
                    #---SET TITLES AND AXIS LABELS HERE---
                    string_title = string_titleTemp+' '+siteNames[cntr]+' '+str(siteNamesIndex[cntr]); #create mecha title
                    ax[i].set_title(string_title,fontproperties=FONT_titleFM); #set the title
                    ax[i].set_xlabel('Time in UT [hr] - 0 Hr on '+dates['date range zero hr month name']+' '+str(dates['date range zero hr'][2]) + \
                        dates['date range zero hr day post fix']+' | Day '+str(dates['date range zero hr dayNum'][1])+', ' + \
                        str(dates['date range zero hr dayNum'][0]),fontproperties=FONT_axisLabelFM); #set the x axis label
                    if( i == 0 ):
                        ax[i].set_ylabel('Mag Field [nT]',fontproperties=FONT_axisLabelFM); #set the y axis label
                    #END IF
                #END IF
                cntr += 1; #for counting continuously
            #END FOR i
        elif( np.abs(cntr - len(siteNames)) == 1 ):
            if( cntr < len(siteNames) ):
                #Remove the aspect ratio from the basemap so it fills the screen better
                ax.set_aspect('auto');
                
                #---PLOT HERE---
                currTime = ((np.int64(data['MagCAN'][siteNames[cntr]]['dayNumF'])*86400+np.int64(data['MagCAN'][siteNames[cntr]]['secF'])) - dates['date range zero hr dayNum'][1]*86400)/3600; #hr, per site just in case
                #filter function here
                temp_deltaMagF = subfun_filter( data['MagCAN'][siteNames[cntr]]['magF'], data['MagCAN'][siteNames[cntr]]['secF'], settings['MagCAN']['delta method'], settings['spectra'], dataRate = data['MagCAN'][siteNames[cntr]]['dataRateF'], reduceWindow = 0); #filter using the all-powerful filter function
        
                pTemp, = ax.plot( currTime, temp_deltaMagF, linewidth=settings['plot']['line width']['double plus'], color=settings['plot']['color'][siteNamesIndex[cntr]] ); #plot
                    
                #---SET AXIS LIMITS HERE---
                ax.set_xlim( time_axis_min , time_axis_max ); #set x axis limits
                ax.set_xticks(xAxisTicks); #set x axis ticks
                
                #---SET TITLES AND AXIS LABELS HERE---
                string_title = string_titleTemp+' '+siteNames[cntr]+' '+str(siteNamesIndex[cntr]); #create mecha title
                ax.set_title(string_title,fontproperties=FONT_titleFM); #set the title

                ax.set_xlabel('Time in UT [hr] - 0 Hr on '+dates['date range zero hr month name']+' '+str(dates['date range zero hr'][2]) + \
                    dates['date range zero hr day post fix']+' | Day '+str(dates['date range zero hr dayNum'][1])+', ' + \
                    str(dates['date range zero hr dayNum'][0]),fontproperties=FONT_axisLabelFM); #set the x axis label

                ax.set_ylabel('Mag Field [nT]',fontproperties=FONT_axisLabelFM); #set the y axis label
            #END IF
            cntr += 1; #for counting continuously         
        #END IF
        
        #final plot adjusting stuff
        figFitter(fig); #fit that fig fast
        # fig.subplots_adjust(left = 0.065, right = 0.985, top = 0.96, bottom = 0.075 , hspace = 0.175, wspace = 0.275); #sets padding to small numbers for minimal white space
    
#END IF


if( FLG_MagCAN_viewAll_magF_FFT == 1 ):
    from scipy import signal
    from scipy.signal import savgol_filter
    
    if( settings['MagCAN']['keo set stations'] != 1 ):
        siteNames = data['MagCAN']['site names']; #get the site names
    else:
        siteNames = settings['MagCAN']['keo set stations names']; #set the site names to whatever the user had
    #END IF
    removeList = []; #prep
    for j in range(0,len(siteNames)):
        if( ~((data['MagCAN'][siteNames[j]]['lat'] >= np.min(settings['MagCAN']['lat range'])) & \
                (data['MagCAN'][siteNames[j]]['lat'] <= np.max(settings['MagCAN']['lat range'])) & \
                (data['MagCAN'][siteNames[j]]['long'] >= np.min(settings['MagCAN']['long range'])) & \
                (data['MagCAN'][siteNames[j]]['long'] <= np.max(settings['MagCAN']['long range']))) ):
            removeList.append(siteNames[j]); #prep for removal b/c not within the range we want
        #END IF
    #END FOR j
    #solving lists takes a lot of slowww lists ohw ell
    for j in range(0,len(removeList)):
        siteNames.remove(removeList[j]); #remove the stuff we don't need
    #END FOR j
    siteNamesIndex = np.where(np.in1d(data['MagCAN']['site names'],siteNames))[0]; #get indexes [keeps site coloring consistent even if all are not in use]
    
    time_range = np.array( ((time_Ref[0]-dateRange_dayNum_zeroHr[1]*86400)/3600 , (time_Ref[-1]-dateRange_dayNum_zeroHr[1]*86400)/3600) ); #make a time range based on the reference time
    time_rangeRound = np.int64(np.floor(np.abs(time_range))*(time_range/np.abs(time_range))); #get the absolute hours - absolute shennanigans are to get floor to floor -11.3 -> -11 and not -12
    thruTime_num = np.int64((np.diff(time_rangeRound).item()-thruTime_width)/thruTime_step)+1; #number of times the time_rangeRound can be split into the required width and step size
    thruTime = np.zeros( (thruTime_num,2) ); #prep array
    for i in range(0,thruTime_num):
        thruTime[i,0] = time_rangeRound[0]+i*thruTime_step; #get the starting time
        thruTime[i,1] = thruTime[i,0] + thruTime_width; #get the ending time
    #END FOR i
    
    thruTime_spectral = [[] for i in range(0,len(siteNames))]; #prep a holder for the spectral info
    thruTime_freq = [[] for i in range(0,len(siteNames))]; #prep a holder for the spectral info
    for i in range(0,len(siteNames)):
        #OMNI
        thruTime_spectral[i] = np.zeros([thruTime_num,np.int64(settings_spectra['nfft']['6min']/2+1)]); #preallocate in the list
        thruTime_freq[i] = np.zeros([thruTime_num,np.int64(settings_spectra['nfft']['6min']/2+1)]); #preallocate in the list
    #END FOR i
    
    #---MAG---
    magF_delta_timeMatch = [[] for j in range(0,len(siteNames))]; #prep a holder
    magF_timeUnique_timeMatch = [[] for j in range(0,len(siteNames))]; #prep a holder
    for j in range(0,len(siteNames)):
        if( np.abs(data['MagCAN'][siteNames[j]]['dataRateF']/60-6) > 0.05 ):
            sixMin_timeUnique_min = np.arange(0,dateRange_dayNum_full.shape[0]*24*60,6); #-OMNI_delay_wrt_TEC*60; #min, arange time stamps
            sixMin_timeUnique = sixMin_timeUnique_min/60/24+dateRange_dayNum_full[0,1]; #days, get the right day time stamps
            #adjust MAG
            #filter function here
            temp_deltaMagF = subfun_filter( data['MagCAN'][siteNames[j]]['magF'], data['MagCAN'][siteNames[j]]['secF'], settings['MagCAN']['delta method'], settings['spectra'], dataRate = data['MagCAN'][siteNames[j]]['dataRateF'], reduceWindow = 0); #filter using the all-powerful filter function
        
            magF_delta_timeMatch[j] = temp_deltaMagF; #set whatever method was used for adjustments
            magF_timeUnique_timeMatch[j] = np.int64(data['MagCAN'][siteNames[j]]['dayNumF'])*86400 + np.int64(data['MagCAN'][siteNames[j]]['secF']); #sec, get unique times (v useful) 
            magF_delta_timeMatch[j], _, magF_timeUnique_timeMatch[j] = GRITI_TEC_avgPt_timeMatch(magF_delta_timeMatch[j],magF_timeUnique_timeMatch[j],sixMin_timeUnique,dateRange_dayNum_zeroHr,filter_cutoffPeriod=settings_spectra['filter cutoff period']);
        else:
            #fix so it works good
            #filter function here
            temp_deltaMagF = subfun_filter( data['MagCAN'][siteNames[j]]['magF'], data['MagCAN'][siteNames[j]]['secF'], settings['MagCAN']['delta method'], settings['spectra'], dataRate = data['MagCAN'][siteNames[j]]['dataRateF'], reduceWindow = 0); #filter using the all-powerful filter function
        
            magF_delta_timeMatch[j] = temp_deltaMagF; #set whatever method was used for adjustments
            magF_timeUnique_timeMatch[j] = np.int64(data['MagCAN'][siteNames[j]]['dayNumF'])*86400 + np.int64(data['MagCAN'][siteNames[j]]['secF']); #sec, get unique times (v useful) #set so no errors
        #END IF
    #END FOR j
    
    Fs = 1/6; #set the freq to be 1/6 min b/c it's forced to be that
    for j in range(0,len(siteNames)):
        #MAG NOW
        
        for i in range(0,thruTime_num):
            time_cutout_indexes = np.array( ( np.where(np.min(np.abs( (magF_timeUnique_timeMatch[j]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) )) == np.abs( (magF_timeUnique_timeMatch[j]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.min(thruTime[i,:]) ) )[0][0] , \
                np.where(np.min(np.abs( (magF_timeUnique_timeMatch[j]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) )) == np.abs( (magF_timeUnique_timeMatch[j]-dateRange_dayNum_zeroHr[1]*86400)/3600 - np.max(thruTime[i,:]) ) )[0][0] ) ); #get the indexes for that time cutout range
            
            magF_delta_timeMatch_cutOut = magF_delta_timeMatch[j][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
            currTime_cutOut = magF_timeUnique_timeMatch[j][time_cutout_indexes[0]:time_cutout_indexes[1]+1];
            
            pwr_Mag = np.sqrt(1/magF_delta_timeMatch_cutOut.size*np.sum(magF_delta_timeMatch_cutOut**2)); #estimate power of signal
            
            #TEC STUFF
            [freqs_Mag,Cxx_Mag] = signal.welch(1/pwr_Mag*magF_delta_timeMatch_cutOut ,window=settings_spectra['window'],noverlap=settings_spectra['noverlap'],nfft=settings_spectra['nfft']['6min'],fs=Fs);
            
            thruTime_spectral[j][i,:] = Cxx_Mag; #record
            thruTime_freq[j][i,:] = freqs_Mag; #record
        #END FOR i
    #END FOR j

    #PLOT IT UP
    warnings.filterwarnings("ignore", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    FLG_sameColorLimits = 0; #if 0 different, if 1 samesies
    string_titleTemp = ''; #prep
    if( strstr(settings['MagCAN']['delta method'],'mean').size > 0 ):
        string_titleTemp += '0 Mean Mag'; #set the specific word to describe the data
    if( strstr(settings['MagCAN']['delta method'],'savgol').size > 0 ):
        if( string_titleTemp != '' ):
            string_titleTemp += ' & '; #add on an ampersand
        #END IF
        string_titleTemp += 'Delta-Mag'; #set the specific word to describe the data
    else: #otherwise do nothing
        string_titleTemp += 'Mag CAN'; #set the specific word to describe the data
    #END IF
    xAxisTicks = np.arange( np.round(np.min(1/freqs_Mag)/20)*20, settings_spectra['period limit max']+20, 20); #sets the start hr, stop hr, and the step size between (in this case, 2 hr)
    cntr = 0; #start cntr
    for arbiter in range(0,np.int64(np.ceil(len(siteNames)/6))):
        if( (np.abs(cntr - len(siteNames)) >= 6) & (np.remainder(np.abs(cntr - len(siteNames)),4) != 0) ):
            fig, ax = plt.subplots(nrows=2, ncols=3); #use instead of fig because it inits an axis too (I think I dunno)
        elif( np.abs(cntr - len(siteNames)) >= 4 ):
            fig, ax = plt.subplots(nrows=2, ncols=2); #use instead of fig because it inits an axis too (I think I dunno)
        elif( np.abs(cntr - len(siteNames)) >= 2 ):
            fig, ax = plt.subplots(nrows=1, ncols=2); #use instead of fig because it inits an axis too (I think I dunno)
        elif( np.abs(cntr - len(siteNames)) == 1 ):
            fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
        #END IF
        figManager = fig.canvas.manager; #req to maximize
        figManager.window.showMaximized(); #force maximized
        
        # if( np.max(thruTime_spectral[:,:,1/freqs_Mag <= settings_spectra['period limit max']]) > 200 ):
        #     rounder = 50; #set to round to every 50
        # else:
        #     rounder = 25; #set to round to every 25
        # #END IF
        # vMax = np.ceil(np.max(thruTime_spectral[:,:,1/freqs_Mag <= settings_spectra['period limit max']])/rounder)*rounder; #get the overall max - FLG_sameColorLimits=0 overrides this
        
        if( np.abs(cntr - len(siteNames)) >= 4 ):
            for i in range(0,ax.shape[0]): #helps automagically plot
                for j in range(0,ax.shape[1]): #helps automagically plot
                    if( cntr < len(siteNames) ):
                        if( FLG_sameColorLimits == 0 ):
                            if( np.max(thruTime_spectral[cntr][:,:]) > 200 ):
                                rounder = 50; #set to round to every 50
                            elif( np.max(thruTime_spectral[cntr][:,:]) < 0.5 ):
                                rounder = 0.5; #set to round to every 50
                            else:
                                rounder = 25; #set to round to every 25
                            #END IF
                            vMax = np.ceil(np.max(thruTime_spectral[cntr][:,:])/rounder)*rounder; #get the max for the plot itself
                        #END IF
                        #prep colorbar
                        divider = make_axes_locatable(ax[i,j]); #prep to add an axis
                        cax = divider.append_axes('right', size='2.0%', pad=0.15); #make a color bar axis
                        #Remove the aspect ratio from the basemap so it fills the screen better
                        ax[i,j].set_aspect('auto');
                        
                        tempTime = np.copy(thruTime[:,0]);
                        # if( (i == 0) & (j == 1) ):
                        #     tempTime = tempTime + AMPERE_delay_wrt_TEC; #shift by this
                        # #END IF
                        
                        pltHelprX, pltHelprY = np.meshgrid( tempTime, 1/thruTime_freq[cntr][0,:]);
                        #gotta catch inf
                        pltHelprY[np.isinf(pltHelprY)] = np.max(pltHelprY[~np.isinf(pltHelprY)])*2; #remove the infs
                        im = ax[i,j].pcolormesh(pltHelprX, pltHelprY,  thruTime_spectral[cntr][:,:].T , \
                            vmin=0, vmax=vMax, cmap='nipy_spectral'); # pseudocolor plot "stretched" to the grid
                        cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
                        # cax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.1f')); #force a rounded format
                        cbar.ax.tick_params(labelsize=FONT_axisTick);
                        cbar.mappable.set_clim(vmin=0, vmax=vMax);
                        # cax.yaxis.set_ticks(np.linspace(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim']),11)); #create useful tick marks
                        ax[i,j].set_title('Power Spectra for '+string_titleTemp+' - '+str(thruTime_width)+' hr width', \
                            fontproperties=FONT_titleFM);
                        ax[i,j].set_yticks(xAxisTicks); #set y axis ticks
                        ax[i,j].set_ylim( (np.min(1/thruTime_freq[cntr][0,:]), settings_spectra['period limit max']/60) ); #set the axis limit
                        ax[i,j].set_xlim( (np.min(thruTime[:,0]), np.max(thruTime[:,0])) ); #set the axis limit
                        ax[i,j].set_xticks(np.arange( np.min(thruTime[:,0]), np.max(thruTime[:,0]), 8 )); #set y axis ticks
                        
                        if( (i == (ax.shape[0]-1) ) & (j == (ax.shape[1]-1)//2) ):
                            ax[i,j].set_xlabel('Time in UT [hr] - 0 Hr on '+dateRange_zeroHr_monthName+ \
                                ' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+ \
                                str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM);
                        #END IF
                        if( j == 0 ):
                            ax[i,j].set_ylabel('Periods [min]',fontproperties=FONT_axisLabelFM);
                        elif( j == (ax.shape[1] - 1) ):
                            cbar.set_label('Arb. Power'); #tabel the colorbar
                            cax.yaxis.label.set_font_properties(FONT_axisLabelFM);
                        #END IF
                        ax[i,j].set_title(string_titleTemp+' '+siteNames[cntr]+' ['+str(siteNamesIndex[cntr])+']', fontproperties=FONT_titleFM);
                        # ax[i,j].set_title(AMPERE_plot_label_noUnits+' offset by '+str(AMPERE_delay_wrt_TEC)+' hrs', fontproperties=FONT_titleFM);
                        #END IF
                    #END IF
                    cntr += 1; #for counting continuously
                #END FOR j
            #END FOR i
        elif( np.abs(cntr - len(siteNames)) >= 2 ):
            for i in range(0,ax.shape[0]): #helps automagically plot
                if( cntr < len(siteNames) ):
                    if( FLG_sameColorLimits == 0 ):
                        if( np.max(thruTime_spectral[cntr][:,:]) > 200 ):
                            rounder = 50; #set to round to every 50
                        elif( np.max(thruTime_spectral[cntr][:,:]) < 0.5 ):
                            rounder = 0.5; #set to round to every 50
                        else:
                            rounder = 25; #set to round to every 25
                        #END IF
                        vMax = np.ceil(np.max(thruTime_spectral[cntr][:,:])/rounder)*rounder; #get the max for the plot itself
                    #END IF
                    #prep colorbar
                    divider = make_axes_locatable(ax[i]); #prep to add an axis
                    cax = divider.append_axes('right', size='2.0%', pad=0.15); #make a color bar axis
                    #Remove the aspect ratio from the basemap so it fills the screen better
                    ax[i].set_aspect('auto');
                    
                    tempTime = np.copy(thruTime[:,0]);
                    # if( (i == 0) & (j == 1) ):
                    #     tempTime = tempTime + AMPERE_delay_wrt_TEC; #shift by this
                    # #END IF
                    
                    pltHelprX, pltHelprY = np.meshgrid( tempTime, 1/thruTime_freq[cntr][0,:]);
                    #gotta catch inf
                    pltHelprY[np.isinf(pltHelprY)] = np.max(pltHelprY[~np.isinf(pltHelprY)])*2; #remove the infs
                    im = ax[i].pcolormesh(pltHelprX, pltHelprY,  thruTime_spectral[cntr][:,:].T , \
                        vmin=0, vmax=vMax, cmap='nipy_spectral'); # pseudocolor plot "stretched" to the grid
                    cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
                    # cax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.1f')); #force a rounded format
                    cbar.ax.tick_params(labelsize=FONT_axisTick);
                    cbar.mappable.set_clim(vmin=0, vmax=vMax);
                    # cax.yaxis.set_ticks(np.linspace(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim']),11)); #create useful tick marks
                    ax[i].set_title('Power Spectra for '+string_titleTemp+' - '+str(thruTime_width)+' hr width', \
                        fontproperties=FONT_titleFM);
                    ax[i].set_yticks(xAxisTicks); #set y axis ticks
                    ax[i].set_ylim( (np.min(1/thruTime_freq[cntr][0,:]), settings_spectra['period limit max']/60) ); #set the axis limit
                    ax[i].set_xlim( (np.min(thruTime[:,0]), np.max(thruTime[:,0])) ); #set the axis limit
                    ax[i].set_xticks(np.arange( np.min(thruTime[:,0]), np.max(thruTime[:,0]), 8 )); #set y axis ticks
                    
                    ax[i].set_xlabel('Time in UT [hr] - 0 Hr on '+dateRange_zeroHr_monthName+ \
                        ' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+ \
                        str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM);
                            
                    if( i == 0 ):
                        ax[i].set_ylabel('Periods [min]',fontproperties=FONT_axisLabelFM);
                    elif( i == (ax.shape[0] - 1) ):
                        cbar.set_label('Arb. Power'); #tabel the colorbar
                        cax.yaxis.label.set_font_properties(FONT_axisLabelFM);
                    #END IF
                    ax[i].set_title(string_titleTemp+' '+siteNames[cntr]+' ['+str(siteNamesIndex[cntr])+']', fontproperties=FONT_titleFM);
                    # ax[i].set_title(AMPERE_plot_label_noUnits+' offset by '+str(AMPERE_delay_wrt_TEC)+' hrs', fontproperties=FONT_titleFM);
                    #END IF
                #END IF
                cntr += 1; #for counting continuously
            #END FOR i
        elif( np.abs(cntr - len(siteNames)) == 1 ):
            if( cntr < len(siteNames) ):
                if( FLG_sameColorLimits == 0 ):
                    if( np.max(thruTime_spectral[cntr][:,:]) > 200 ):
                        rounder = 50; #set to round to every 50
                    elif( np.max(thruTime_spectral[cntr][:,:]) < 0.5 ):
                        rounder = 0.5; #set to round to every 50
                    else:
                        rounder = 25; #set to round to every 25
                    #END IF
                    vMax = np.ceil(np.max(thruTime_spectral[cntr][:,:])/rounder)*rounder; #get the max for the plot itself
                #END IF
                #prep colorbar
                divider = make_axes_locatable(ax); #prep to add an axis
                cax = divider.append_axes('right', size='2.0%', pad=0.15); #make a color bar axis
                #Remove the aspect ratio from the basemap so it fills the screen better
                ax.set_aspect('auto');
                
                tempTime = np.copy(thruTime[:,0]);
                # if( (i == 0) & (j == 1) ):
                #     tempTime = tempTime + AMPERE_delay_wrt_TEC; #shift by this
                # #END IF
                
                pltHelprX, pltHelprY = np.meshgrid( tempTime, 1/thruTime_freq[cntr][0,:]);
                #gotta catch inf
                pltHelprY[np.isinf(pltHelprY)] = np.max(pltHelprY[~np.isinf(pltHelprY)])*2; #remove the infs
                im = ax.pcolormesh(pltHelprX, pltHelprY,  thruTime_spectral[cntr][:,:].T , \
                    vmin=0, vmax=vMax, cmap='nipy_spectral'); # pseudocolor plot "stretched" to the grid
                cbar = fig.colorbar(im, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
                # cax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.1f')); #force a rounded format
                cbar.ax.tick_params(labelsize=FONT_axisTick);
                cbar.mappable.set_clim(vmin=0, vmax=vMax);
                # cax.yaxis.set_ticks(np.linspace(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim']),11)); #create useful tick marks
                ax.set_title('Power Spectra for '+string_titleTemp+' - '+str(thruTime_width)+' hr width', \
                    fontproperties=FONT_titleFM);
                ax.set_yticks(xAxisTicks); #set y axis ticks
                ax.set_ylim( (np.min(1/thruTime_freq[cntr][0,:]), settings_spectra['period limit max']/60) ); #set the axis limit
                ax.set_xlim( (np.min(thruTime[:,0]), np.max(thruTime[:,0])) ); #set the axis limit
                ax.set_xticks(np.arange( np.min(thruTime[:,0]), np.max(thruTime[:,0]), 8 )); #set y axis ticks
                
                ax.set_xlabel('Time in UT [hr] - 0 Hr on '+dateRange_zeroHr_monthName+ \
                    ' '+str(dateRange_zeroHr[2])+dateRange_zeroHr_dayPostfix+' | Day '+ \
                    str(dateRange_dayNum_zeroHr[1])+', '+str(dateRange_dayNum_zeroHr[0]),fontproperties=FONT_axisLabelFM);
                    
                ax.set_ylabel('Periods [min]',fontproperties=FONT_axisLabelFM);
                
                cbar.set_label('Arb. Power'); #tabel the colorbar
                cax.yaxis.label.set_font_properties(FONT_axisLabelFM);

                ax.set_title(string_titleTemp+' '+siteNames[cntr]+' ['+str(siteNamesIndex[cntr])+']', fontproperties=FONT_titleFM);
                # ax.set_title(AMPERE_plot_label_noUnits+' offset by '+str(AMPERE_delay_wrt_TEC)+' hrs', fontproperties=FONT_titleFM);
                #END IF
            #END IF
            cntr += 1; #for counting continuously         
        #END IF
        
        #final plot adjusting stuff
        figFitter(fig); #fit that fig fast
        # fig.subplots_adjust(left = 0.060, right = 0.945, top = 0.96, bottom = 0.075 , hspace = 0.175, wspace = 0.275); #sets padding to small numbers for minimal white space
    #END FOR arbiter
    warnings.filterwarnings("default", category=RuntimeWarning); #silences warnings about NaNs used in a logical comparisons #yolo
    
#END IF

if( FLG_MagCAN_geoPlot == 1 ):
    import cartopy as cartopy
    import matplotlib.pyplot as plt
    import matplotlib.ticker as mticker
    # from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
    
    def strike(text): #adapted from https://stackoverflow.com/questions/25244454/python-create-strikethrough-strikeout-overstrike-string-type @pdw
        result = '';
        for c in text:
            result += c + '\u0336';
        return result
    #END DEF
    
    #---PREP TO PLOT HERE---
    if( settings['MagCAN']['keo set stations'] != 1 ):
        siteNames = data['MagCAN']['site names']; #get the site names
    else:
        siteNames = settings['MagCAN']['keo set stations names']; #set the site names to whatever the user had
    #END IF
    removeList = []; #prep
    for j in range(0,len(siteNames)):
        if( ~((data['MagCAN'][siteNames[j]]['lat'] >= np.min(settings['MagCAN']['lat range'])) & \
                (data['MagCAN'][siteNames[j]]['lat'] <= np.max(settings['MagCAN']['lat range'])) & \
                (data['MagCAN'][siteNames[j]]['long'] >= np.min(settings['MagCAN']['long range'])) & \
                (data['MagCAN'][siteNames[j]]['long'] <= np.max(settings['MagCAN']['long range']))) ):
            removeList.append(siteNames[j]); #prep for removal b/c not within the range we want
        #END IF
    #END FOR j
    #solving lists takes a lot of slowww lists ohw ell
    for j in range(0,len(removeList)):
        siteNames.remove(removeList[j]); #remove the stuff we don't need
    #END FOR j
    siteNamesIndex = np.where(np.in1d(data['MagCAN']['site names'],siteNames))[0]; #get indexes [keeps site coloring consistent even if all are not in use]
    
    siteLocs = np.zeros( (2, len(siteNames)) ); #preallocate
    for j in range(0,len(siteNames)):
        siteLocs[0,j] = data['MagCAN'][siteNames[j]]['lat'];
        siteLocs[1,j] = data['MagCAN'][siteNames[j]]['long'];
    #END FOR j
    
    map_plotLatRange = settings['MagCAN']['lat range'];
    map_plotLongRange = settings['MagCAN']['long range'];
    
    #plot help with autotick calculating
    map_long_autoTick = (np.max(map_plotLongRange) - np.min(map_plotLongRange))/25; #tries to split the longitude range into 25 parts (based off of 360/15+1)
    if( map_long_autoTick > 14 ):
        map_long_autoTick = 30; #sets the tick setting to 15 arcdegrees per tick
    elif( map_long_autoTick > 10 ):
        map_long_autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
    elif( map_long_autoTick > 5 ):
        map_long_autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
    elif( map_long_autoTick > 2 ):
        map_long_autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
    elif( map_long_autoTick > 1 ):
        map_long_autoTick = 2; #sets the tick setting to 5 arcdegrees per tick
    elif( map_long_autoTick >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
        map_long_autoTick = 1; #sets the tick setting to 1 arcdegree per tick
    else:
        map_long_autoTick = (np.max(map_plotLongRange) - np.min(map_plotLongRange))/15; #just goes for it if it's a super tiny range
    #END IF
    map_lat_autoTick = (np.max(map_plotLatRange) - np.min(map_plotLatRange))/13; #tries to split the latitude range into 13 parts (based off of 180/15+1)
    if( map_lat_autoTick > 10 ):
        map_lat_autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
    elif( map_lat_autoTick > 5 ):
        map_lat_autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
    elif( map_lat_autoTick > 2 ):
        map_lat_autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
    elif( map_lat_autoTick > 1 ):
        map_lat_autoTick = 2; #sets the tick setting to 2 arcdegrees per tick
    elif( map_lat_autoTick > 0.75 ): #0.75 because 10/13 = 0.76something and it sounded good for enough 1 arcdeg ticks
        map_lat_autoTick = 1; #sets the tick setting to 1 arcdegree per tick
    else:
        map_lat_autoTick = (np.max(map_plotLatRange) - np.min(map_plotLatRange))/13; #just goes for it if it's a super tiny range
    #END IF

    #---START TO PLOT HERE---
    fig = plt.figure(); #use instead of fig because it inits an axis too (I think I dunno)
    figManager = fig.canvas.manager; #req to maximize
    figManager.window.showMaximized(); #force maximized
    
    ax = fig.add_subplot(1,1,1, projection=settings['map']['projection']);
    # divider = make_axes_locatable(ax[0]); #prep to add an axis
    # dividerKeo = make_axes_locatable(ax[1]); #prep to add an axis
    ax.set_aspect('auto');
    
    #---ADD GRID LINES, SET PLOTTING AREA---
    gl = ax.gridlines(linewidth=1, color='black', alpha=0.5, linestyle='--', draw_labels=True); #draw some well-described gridlines
    gl.xlabels_top = False; #turn off all, let ticks be handled by set_xticks
    gl.xlabels_bottom = False; #turn off all, let ticks be handled by set_xticks
    gl.ylabels_right = False; #turn off all, let ticks be handled by set_yticks
    gl.ylabels_left = False; #turn off all, let ticks be handled by set_yticks
    gl.xlocator = mticker.FixedLocator(np.arange(np.min(map_plotLongRange),np.max(map_plotLongRange)+map_long_autoTick,map_long_autoTick)); #this works ok, but be consistent use set_xticks
    gl.ylocator = mticker.FixedLocator(np.arange(np.min(map_plotLatRange),np.max(map_plotLatRange)+map_lat_autoTick,map_lat_autoTick)); #this doesn't plot -90 and 90 labels, but is req to get the gridlines right
    ax.set_xticks(np.arange(np.min(map_plotLongRange),np.max(map_plotLongRange)+map_long_autoTick,map_long_autoTick),crs=settings['map']['projection']); #gotta plot ticks with this to get -90 and 90
    ax.set_yticks(np.arange(np.min(map_plotLatRange),np.max(map_plotLatRange)+map_lat_autoTick,map_lat_autoTick),crs=settings['map']['projection']); #gotta plot ticks with this to get -90 and 90
    # gl.xformatter = LONGITUDE_FORMATTER
    # gl.yformatter = LATITUDE_FORMATTER
    # gl.xlabel_style = {'color': 'red', 'weight': 'bold'}
    ax.set_extent(map_plotLongRange + map_plotLatRange); #set the plot extent, set at end - x and y ticks can extend plot area so this'll reign it in
    
    #---DRAW SOME COASTLINES, MAYBE COLOR IN SOME STUFF---
    bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted()); #get info on the size of the plot area to know what geographic scale to use
    mapper_resolution = np.max( [np.abs(map_plotLatRange[0]-map_plotLatRange[1])/bbox.height , np.abs(map_plotLongRange[0]-map_plotLongRange[1])/bbox.width] ); #degc, max extent covered in the plot
    if( mapper_resolution > 20 ): #arbitrary numbers
        mapper_resolution = '110m'; #the resolution to use for plotting geographical features
    elif( mapper_resolution > 0.5 ): #arbitrary numbers
        mapper_resolution = '50m'; #the resolution to use for plotting geographical features
    else:
        #otherwise if the deg/in for the plot is super small use the highest detail possible
        mapper_resolution = '10m'; #the resolution to use for plotting geographical features
    #END IF
    if( settings['map']['world color'] == True ):
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical', 'land', mapper_resolution, edgecolor='face', facecolor=settings['map']['land color'], alpha=0.75)); #idk what these calls really mean
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical', 'ocean', mapper_resolution, edgecolor='face', facecolor=settings['map']['water color'], alpha=0.75)); #idk what these calls really mean
    #END IF
    ax.coastlines(resolution=mapper_resolution, color='xkcd:black'); #draw the coastlines
    #reinforce axis limits after this drawing stuff
    ax.set_xlim(map_plotLongRange); #set x limits
    ax.set_ylim(map_plotLatRange); #set y limits
    
    
    #---ACTUALLY PLOT REAL STUFF HERE---
    sN = []; #prep empty list of text handles
    mN = []; #prep empty list of text handles
    for j in range(0,len(siteNames)):
        mN.append( ax.plot( siteLocs[1,j], siteLocs[0,j], color=settings['plot']['color'][siteNamesIndex[j]], marker=settings['map']['site marker type'], markersize=settings['map']['site marker size'], linewidth=0, zorder=50, transform=settings['map']['projection'] ) ); #plot the sites
        sN.append( ax.text(siteLocs[1,j],siteLocs[0,j],siteNames[j]+'\n  '+str(siteNamesIndex[j])+'', zorder=55, transform=settings['map']['projection']) ); #write name of site
    #END FOR j
    if( settings['MagCAN']['keo set stations'] == 1 ):
        sitesRedacted = np.setxor1d(data['MagCAN']['site names'],settings['MagCAN']['keo set stations names']);
        siteNamesIndex = np.where(np.in1d(data['MagCAN']['site names'],sitesRedacted))[0]; #get indexes [keeps site coloring consistent even if all are not in use]
        sNR = []; #prep empty list of text handles
        mNR = []; #prep empty list of text handles
        for j in range(0,len(sitesRedacted)):
            mNR.append( ax.plot( data['MagCAN'][sitesRedacted[j]]['long'], data['MagCAN'][sitesRedacted[j]]['lat'], color=settings['plot']['color'][siteNamesIndex[j]], marker=settings['map']['site marker type'], markersize=settings['map']['site marker size'], linewidth=0, zorder=50, transform=settings['map']['projection'] ) ); #plot the sites
            sNR.append( ax.text( data['MagCAN'][sitesRedacted[j]]['long'], data['MagCAN'][sitesRedacted[j]]['lat'], strike(sitesRedacted[j])+'\n  '+str(siteNamesIndex[j])+'', zorder=55, transform=settings['map']['projection'], c='xkcd:grey') ); #write name of site
        #END FOR j
    #END IF
    ax.set_title('NR Canada Magnetic Observatories',fontproperties=FONT_titleFM); #set the title
    
    #---FINALIZE PLOTTING---
    figFitter(fig); #fit that fig fast
    # fig.subplots_adjust(left = 0.045, right = 0.980, top = 0.96, bottom = 0.065); #sets padding to small numbers for minimal white space
#END IF


if( FLG_MagCAN_keo == 1 ):
    (data['MagCAN']['keo'], data['MagCAN']['keo time'], data['MagCAN']['keo time hr'], \
    settings['MagCAN']['keo angle'],settings['MagCAN']['keo width'], \
    settings['MagCAN']['keo plot range chunks'],settings['MagCAN']['keo plot range name']) = \
        GRITI_MagCAN_keo(data,dates,settings,FLG_disablePlot=0);
    #call the mecha function that runs the keo alg and makes a plot showing the averaging area [FLG_normalize makes each site normalized to each other - the magnitude reduces as latitude drops]
#END IF

if( FLG_MagCAN_keo_plot == 1 ):
    #-----Plot TEC results as a Keogram-----
    GRITI_MagCAN_keo_plot(data, dates, settings);
    #call the mecha function that plots the keo'd Mag data
#END IF


if( FLG_MagCANnAMPERE_correlator_walking >= 1 ):
    print('\nNOTA BENE: Running FLG_MagCANnAMPERE_correlator_walking. Walking correlation calcs and plots will take a while.\n');
    from Code.subfun_correlator_walking import subfun_correlator_walking
    from Code.subfun_correlator_walking_plotter import subfun_correlator_walking_plotter
    
    #----- TEC & AMPERE SETTINGS -----
    time2lim = 4*3600; #time limit to check corr coeffs for
    time2span = 6*3600; #time range to cutout and check
    time2step = 1*3600; #time increment to step 
    time2shiftDir = FLG_MagCANnAMPERE_correlator_shiftDir; #shift direction (remember POS goes back in time b/c you need to add +offset to a time range to bring it forward to align w/ reference time frame)
    data1types = [settings_AMPERE['labels'][settings_AMPERE['data type']]]; #data1 (1nd set of inputs into function) types involved
    data2types = MagCAN_setStations_names; #data2 (2nd set of inputs into function) types involved
    
    corrRet = [None for i in range(0,len(data1types))];
    for i in range(0,len(data1types)):
        #--- Integrated AMPERE Data ---
        corrRet[i], time_cutout_range_walking = subfun_correlator_walking(
                data['AMPERE'], settings['AMPERE'], 'AMPERE', 'integrated', \
                data['MagCAN'], settings['MagCAN'], 'MagCAN', MagCAN_setStations_names, \
                dates, settings['plot'], settings['paths'], settings['config'], \
                FLG_OMNInAMPERE_correlator, None, FLG_correlator_plot = False, FLG_correlator_tabulator = False, \
                FLG_correlator_shiftDir = time2shiftDir, FLG_correlator_timeLim = time2lim, \
                filt1 = None,  filt2 = None, settings_spectra=settings['spectra'], reportDivisor=[60,'min'],
                time2span=time2span, time2step=time2step, time2bound=[dates['date range full dayNum'][0,1]*86400, (dates['date range full dayNum'][-1,1]+1)*86400], FLG_clipData2=False, FLG_nanLimitData2=False);
    #END FOR i
    
    #--- Plot the returns up ---
    if( FLG_fancyPlot < 2 ):
        subfun_correlator_walking_plotter(corrRet, data1types, data2types, \
            time_cutout_range_walking, time2span, \
            time2step, time2lim, time2shiftDir, \
            settings['plot'], settings['paths'], dates, \
            FLG_showNiteTimes = False, showNiteTimesDict = None, \
            reportDivisor = [3600,'hr'], FLG_fancyPlot = False); #plot that up
    #END IF
    if( FLG_fancyPlot > 0 ):
        subfun_correlator_walking_plotter(corrRet, data1types, data2types, \
            time_cutout_range_walking, time2span, \
            time2step, time2lim, time2shiftDir, \
            settings['plot'], settings['paths'], dates, \
            FLG_showNiteTimes = False, showNiteTimesDict = None, \
            reportDivisor = [3600,'hr'], FLG_fancyPlot = True); #plot that up
    #END IF
#END IF

if( FLG_MagCANnAMPERE_correlator >= 1 ):
    from Code.subfun_correlator_corraler import subfun_correlator_corraler
    corrRet = subfun_correlator_corraler(
            data['AMPERE'], settings['AMPERE'], 'AMPERE', 'integrated', \
            data['MagCAN'], settings['MagCAN'], 'MagCAN', MagCAN_setStations_names, \
            dates, settings['plot'], settings['paths'], settings['config'], \
            FLG_MagCANnAMPERE_correlator, FLG_MagCANnAMPERE_correlator_options, \
            FLG_correlator_shiftDir = FLG_MagCANnAMPERE_correlator_shiftDir, FLG_correlator_plot = FLG_MagCANnAMPERE_correlator_plot, FLG_correlator_tabulator = FLG_MagCANnAMPERE_correlator_tabulator);
#END IF


#****************************************************************Machine Learning Times****************************************************************
if( FLG_magicks == 1 ):
    # magicks_OMNI_setNames = ['SYM/H', 'AL', 'Bz GSM', 'PC(N)', 'Psw', 'Vsw', 'Proton Density'];
    # magicks_OMNI_setNames = ['SYM/H', 'Bz GSM', 'PC(N)', 'Proton Density'];
    # magicks_OMNI_setNames = ['SYM/H', 'Vsw', 'Proton Density'];
    # magicks_OMNI_setNames = ['Bz GSM', 'PC(N)', 'Vsw', 'Proton Density'];
    magicks_OMNI_setNames = ['Proton Density'];
    # magicks_SuperMAG_setNames = ['SME','SMU','SML','SMEs','SMUs','SMLs','SMEd','SMUd','SMLd','SMR'];
    # magicks_SuperMAG_setNames = ['SMUs','SMLs','SMUd','SMLd','SMR'];
    magicks_SuperMAG_setNames = ['SMEs','SMEd','SMR'];
    magicks_AMPERE_dataTypes = ['Ped','Hall','JH','elec poten','FAC'];
    magicks_AMPERE_integrateMethods = [3]*len(magicks_AMPERE_dataTypes); #0 for averaging within the defined plot area, 1 for latitudes max is the pole, 2 for a set upper latitude value, 3 for entire hemisphere (all longitudes, 0-90 latitudes), 4 for 90 to desginated latitude value for longitude range, 5 for 90 to designated latitude for all longitudes, 6 for desginated latitude to 0 all longs
    magicks_AMPERE_integrateVals = [75]*len(magicks_AMPERE_dataTypes);
    # 'Ped' = Pedersen Conductance [?]
    # 'Hall' = Hall Conductance [?]
    # 'JH' = Joule Heat [ergs/(cm^2*sec)]
    # 'elec poten' = Electric Potential [?]
    # 'FAC' = Field-Algined Current [?]
    
    #Runs on PyTorch cause that's what people said was easier
    # import torch
    # import torch.nn as nn
    # import torch.nn.parallel
    # import torch.optim as optim
    # import torch.utils.data
    # from torch.autograd import Variable
    pass; #nothing here yet
    from Code.GRITI_TEC_avgPt import GRITI_TEC_avgPt
    # from Code.GRITI_AMPERE_integrator import GRITI_AMPERE_integrator
    from Code.subfun_timeMatch import subfun_timeMatch
    from Code.subfun_filter import subfun_filter
    from Code.subfun_sunAlsoRises_location import sunAlsoRises_location
    from Code.subfun_figFitter import figFitter
    from Code.subfun_correlator import subfun_correlator
    import copy
    import pickle as pkl
    import os

        
    #===== Assemble test inputs =====
    #***** OMNI inputs ******
    #--- Gather other important data types for analysis ---
    sun_subSolarPoint = sunAlsoRises_location(dateRange_full,dataRate=data['OMNI']['data rate']);
    
    #--- Gather OMNI data for analysis V1 (interps, single values) ---
    # inputType = 'OMNI'; #for saving
    # kj = ((OMNI_timeUnique+0/60*3600)/86400>=dateRange_dayNum_full[0,1]) & ((OMNI_timeUnique+0/60*3600)/86400<(dateRange_dayNum_full[-1,1]+1)); #get the revant times
    # # OMNI_timeUnique_full = subfun_filter(OMNI_timeUnique[kj], 'interp', dataTime = OMNI_timeUnique[kj], dataRate = data['OMNI']['data rate']);
    # OMNI_timeUnique_full = np.arange(dateRange_dayNum_full[0,1]*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']); #prep full time
    # OMNI_timeUnique_TECref = OMNI_timeUnique_full; #prep full time
    # OMNI_data_full = np.empty( (OMNI_timeUnique_full.size, len(magicks_OMNI_setNames)) ); #preallocate
    # for i in range(0,len(magicks_OMNI_setNames)):
    #     OMNI_data_full[:,i] = subfun_filter(OMNI_data[kj,OMNI_dict[magicks_OMNI_setNames[i]]], 'interp', dataTime = OMNI_timeUnique[kj], dataRate = data['OMNI']['data rate']);
    # #END FOR i
    # #--- Stitch it all together v1 ---
    # input_size = len(magicks_OMNI_setNames)*2+3; #set size
    # input_data = np.empty( (OMNI_timeUnique_full.size, input_size) ); #preallocate
    # input_data[:,0:len(magicks_OMNI_setNames)] = OMNI_data_full; #load in the OMNI data
    # input_data[:,len(magicks_OMNI_setNames):len(magicks_OMNI_setNames)*2] = np.concatenate((np.zeros((1,OMNI_data_full.shape[1])),np.diff(OMNI_data_full,axis=0)),axis=0); #load in the OMNI data
    # input_data[:,len(magicks_OMNI_setNames)*2+0] = np.mod(OMNI_timeUnique_full,86400); #load in the time of the year
    # input_data[:,len(magicks_OMNI_setNames)*2+1] = np.asarray(sun_subSolarPoint['lat']).flatten(); #load in the sun latitude
    # input_data[:,len(magicks_OMNI_setNames)*2+2] = np.asarray(sun_subSolarPoint['long']).flatten(); #load in the sun longitude
    # # input_data[:,len(magicks_OMNI_setNames)*2+3] = avgPt_coords[0,0]; #load in the location latitude
    # # input_data[:,len(magicks_OMNI_setNames)*2+4] = avgPt_coords[0,1]; #load in the location longitude
    
    #--- Gather OMNI data for analysis V2 ---
    # inputType = 'OMNI'; #for saving
    # magicks_timePreviousLimit = 1*3600; #previous hours worth of data to include (in seconds)
    # kj = ((OMNI_timeUnique+magicks_timePreviousLimit)>=dateRange_dayNum_full[0,1]*86400) & (OMNI_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for extra data to be tacked on]
    # kr = ((OMNI_timeUnique)>=dateRange_dayNum_full[0,1]*86400) & (OMNI_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for initial data pts data avail during the time period desired]
    # # OMNI_timeUnique_full = subfun_filter(OMNI_timeUnique[kj], 'interp', dataTime = OMNI_timeUnique[kj], dataRate = data['OMNI']['data rate']);
    # OMNI_timeUnique_TECref = np.arange(dateRange_dayNum_full[0,1]*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']); #prep full time
    # OMNI_timeUnique_full = np.arange(dateRange_dayNum_full[0,1]*86400-magicks_timePreviousLimit,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']); #prep full time
    # # kk = np.in1d(OMNI_timeUnique_full, OMNI_timeUnique[kr], assume_unique=True); # get the missing data pts
    # # kk_gapLen = np.diff(np.where(np.diff(kk))[0])[0::2]; #get the gap length
    # # kk_gapLenMax = 6; #how many missing data pts are too much
    # # kk_gapTooMuch = np.ones( OMNI_timeUnique_full.size, dtype=np.bool_); #prep truth
    # # kk_gapTooMuchIndexes = np.vstack((np.where(np.diff(kk))[0][0::2][kk_gapLen > kk_gapLenMax]+1,np.where(np.diff(kk))[0][1::2][kk_gapLen > kk_gapLenMax]+1)).T; #get where its too mcuh
    # # for i in range(0,kk_gapTooMuchIndexes.shape[0]):
    # #     kk_gapTooMuch[kk_gapTooMuchIndexes[i,0]:kk_gapTooMuchIndexes[i,1]] = False; #set too long gaps to false
    # # #END FOR i
    # OMNI_data_full = np.empty( (OMNI_timeUnique_full.size, len(magicks_OMNI_setNames)) ); #preallocate
    # OMNI_timeUnique_reqTimes = OMNI_timeUnique[kj]; #get the cutout times
    # # if( OMNI_timeUnique_reqTimes[0] != OMNI_timeUnique_full[0] ):
    # #     OMNI_timeUnique_reqTimes = np.insert(OMNI_timeUnique_reqTimes,0,OMNI_timeUnique_full[0]); #put in the first value
    # # #END IF
    # for i in range(0,len(magicks_OMNI_setNames)):
    #     if( OMNI_timeUnique_reqTimes[0] != OMNI_timeUnique_full[0] ):
    #         kj2 = kj.copy();
    #         kj2[np.where(np.diff(kj))[0].item()] = True; #set value just before Trues to True so that that value is used
    #         OMNI_data_tooFull = subfun_filter(OMNI_data[:,OMNI_dict[magicks_OMNI_setNames[i]]], 'interp', dataTime = OMNI_timeUnique, dataRate = data['OMNI']['data rate']);
    #         OMNI_timeUnique_tooFull = np.arange((dateRange_dayNum_full[0,1]-1)*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']);
    #         OMNI_data_full[:,i] = OMNI_data_tooFull[np.where(OMNI_timeUnique_full[0] == OMNI_timeUnique_tooFull)[0].item():]; #get relevant bits (not the time before that was used to interpolate to the new data)
    #     else:
    #         OMNI_data_full[:,i] = subfun_filter(OMNI_data[kj,OMNI_dict[magicks_OMNI_setNames[i]]], 'interp', dataTime = OMNI_timeUnique_reqTimes, dataRate = data['OMNI']['data rate']);
    #     #END IF
    # #END FOR i
    # OMNI_dataDiff_full = np.concatenate((np.zeros((1,OMNI_data_full.shape[1])),np.diff(OMNI_data_full,axis=0)),axis=0)/data['OMNI']['data rate'];
    # #--- Stitch it all together v2 ---
    # input_size = len(magicks_OMNI_setNames)*np.int64(magicks_timePreviousLimit/data['OMNI']['data rate'])*2+3; #set size
    # input_sizePer = len(magicks_OMNI_setNames)*np.int64(magicks_timePreviousLimit/data['OMNI']['data rate']);
    # input_data = np.empty( (OMNI_timeUnique_TECref.size, input_size) ); #preallocate
    # for i in range(0,OMNI_timeUnique_TECref.size):
    #     input_data[i,0:input_sizePer] = OMNI_data_full[((OMNI_timeUnique_TECref[i]-magicks_timePreviousLimit)<OMNI_timeUnique_full) & (OMNI_timeUnique_TECref[i]>=OMNI_timeUnique_full),:].flatten(); #load in the data
    #     input_data[i,input_sizePer:input_sizePer*2] = OMNI_dataDiff_full[((OMNI_timeUnique_TECref[i]-magicks_timePreviousLimit)<OMNI_timeUnique_full) & (OMNI_timeUnique_TECref[i]>=OMNI_timeUnique_full),:].flatten(); #load in the data
    # #END FOR i
    # input_data[:,input_size-3] = np.mod(OMNI_timeUnique_TECref,86400); #load in the time of the year
    # input_data[:,input_size-2] = np.asarray(sun_subSolarPoint['lat']).flatten(); #load in the sun latitude
    # input_data[:,input_size-1] = np.asarray(sun_subSolarPoint['long']).flatten(); #load in the sun longitude
    # # input_data[:,len(magicks_OMNI_setNames)*2+3] = avgPt_coords[0,0]; #load in the location latitude
    # # input_data[:,len(magicks_OMNI_setNames)*2+4] = avgPt_coords[0,1]; #load in the location longitude
    
    #***** SuperMAG inputs ******
    # inputType = 'SuperMAG'; #for saving
    # SuperMAG_data = data['SuperMAG']; #load in
    # SuperMAG_timeUnique = data['SuperMAG']['time unique'];
    # #--- Gather SuperMAG data for analysis V1 (interps, single values) ---
    # kj = ((SuperMAG_timeUnique+0/60*3600)/86400>=dateRange_dayNum_full[0,1]) & ((SuperMAG_timeUnique+0/60*3600)/86400<(dateRange_dayNum_full[-1,1]+1)); #get the revant times
    # # SuperMAG_timeUnique_full = subfun_filter(SuperMAG_timeUnique[kj], 'interp', dataTime = SuperMAG_timeUnique[kj], dataRate = data['SuperMAG']['data rate']);
    # SuperMAG_timeUnique_full = np.arange(dateRange_dayNum_full[0,1]*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']); #prep full time
    # SuperMAG_timeUnique_TECref = SuperMAG_timeUnique_full; #prep full time
    # SuperMAG_data_full = np.empty( (SuperMAG_timeUnique_full.size, len(magicks_SuperMAG_setNames)) ); #preallocate
    # for i in range(0,len(magicks_SuperMAG_setNames)):
        # SuperMAG_data_full[:,i] = subfun_filter(SuperMAG_data[magicks_SuperMAG_setNames[i]][kj], 'interp', dataTime = SuperMAG_timeUnique[kj], dataRate = data['SuperMAG']['data rate']);
    # #END FOR i
    # #--- Stitch it all together v1 ---
    # input_size = len(magicks_SuperMAG_setNames)*2+3; #set size
    # input_data = np.empty( (SuperMAG_timeUnique_full.size, input_size) ); #preallocate
    # input_data[:,0:len(magicks_SuperMAG_setNames)] = SuperMAG_data_full; #load in the SuperMAG data
    # input_data[:,len(magicks_SuperMAG_setNames):len(magicks_SuperMAG_setNames)*2] = np.concatenate((np.zeros((1,SuperMAG_data_full.shape[1])),np.diff(SuperMAG_data_full,axis=0)),axis=0); #load in the SuperMAG data
    # input_data[:,len(magicks_SuperMAG_setNames)*2+0] = np.mod(SuperMAG_timeUnique_full,86400); #load in the time of the year
    # input_data[:,len(magicks_SuperMAG_setNames)*2+1] = np.asarray(sun_subSolarPoint['lat']).flatten(); #load in the sun latitude
    # input_data[:,len(magicks_SuperMAG_setNames)*2+2] = np.asarray(sun_subSolarPoint['long']).flatten(); #load in the sun longitude
    # # input_data[:,len(magicks_SuperMAG_setNames)*2+3] = avgPt_coords[0,0]; #load in the location latitude
    # # input_data[:,len(magicks_SuperMAG_setNames)*2+4] = avgPt_coords[0,1]; #load in the location longitude
    
    #--- Gather SuperMAG data for analysis V2 ---
    # inputType = 'SuperMAG'; #for saving
    # SuperMAG_data = data['SuperMAG']; #load in
    # SuperMAG_timeUnique = data['SuperMAG']['time unique'];
    # magicks_timePreviousLimit = 1*3600; #previous hours worth of data to include (in seconds)
    # kj = ((SuperMAG_timeUnique+magicks_timePreviousLimit)>=dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for extra data to be tacked on]
    # kr = ((SuperMAG_timeUnique)>=dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for initial data pts data avail during the time period desired]
    # # SuperMAG_timeUnique_full = subfun_filter(SuperMAG_timeUnique[kj], 'interp', dataTime = SuperMAG_timeUnique[kj], dataRate = data['SuperMAG']['data rate']);
    # SuperMAG_timeUnique_TECref = np.arange(dateRange_dayNum_full[0,1]*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']); #prep full time
    # SuperMAG_timeUnique_full = np.arange(dateRange_dayNum_full[0,1]*86400-magicks_timePreviousLimit,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']); #prep full time
    # # kk = np.in1d(SuperMAG_timeUnique_full, SuperMAG_timeUnique[kr], assume_unique=True); # get the missing data pts
    # # kk_gapLen = np.diff(np.where(np.diff(kk))[0])[0::2]; #get the gap length
    # # kk_gapLenMax = 6; #how many missing data pts are too much
    # # kk_gapTooMuch = np.ones( SuperMAG_timeUnique_full.size, dtype=np.bool_); #prep truth
    # # kk_gapTooMuchIndexes = np.vstack((np.where(np.diff(kk))[0][0::2][kk_gapLen > kk_gapLenMax]+1,np.where(np.diff(kk))[0][1::2][kk_gapLen > kk_gapLenMax]+1)).T; #get where its too mcuh
    # # for i in range(0,kk_gapTooMuchIndexes.shape[0]):
    # #     kk_gapTooMuch[kk_gapTooMuchIndexes[i,0]:kk_gapTooMuchIndexes[i,1]] = False; #set too long gaps to false
    # # #END FOR i
    # SuperMAG_data_full = np.empty( (SuperMAG_timeUnique_full.size, len(magicks_SuperMAG_setNames)) ); #preallocate
    # SuperMAG_timeUnique_reqTimes = SuperMAG_timeUnique[kj]; #get the cutout times
    # # if( SuperMAG_timeUnique_reqTimes[0] != SuperMAG_timeUnique_full[0] ):
    # #     SuperMAG_timeUnique_reqTimes = np.insert(SuperMAG_timeUnique_reqTimes,0,SuperMAG_timeUnique_full[0]); #put in the first value
    # # #END IF
    # for i in range(0,len(magicks_SuperMAG_setNames)):
    #     if( SuperMAG_timeUnique_reqTimes[0] != SuperMAG_timeUnique_full[0] ):
    #         kj2 = kj.copy();
    #         kj2[np.where(np.diff(kj))[0].item()] = True; #set value just before Trues to True so that that value is used
    #         SuperMAG_data_tooFull = subfun_filter(SuperMAG_data[magicks_SuperMAG_setNames[i]], 'interp', dataTime = SuperMAG_timeUnique, dataRate = data['SuperMAG']['data rate']);
    #         SuperMAG_timeUnique_tooFull = np.arange((dateRange_dayNum_full[0,1]-1)*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']);
    #         SuperMAG_data_full[:,i] = SuperMAG_data_tooFull[np.where(SuperMAG_timeUnique_full[0] == SuperMAG_timeUnique_tooFull)[0].item():]; #get relevant bits (not the time before that was used to interpolate to the new data)
    #     else:
    #         SuperMAG_data_full[:,i] = subfun_filter(SuperMAG_data[magicks_SuperMAG_setNames[i]][kj], 'interp', dataTime = SuperMAG_timeUnique_reqTimes, dataRate = data['SuperMAG']['data rate']);
    #     #END IF
    # #END FOR i
    # SuperMAG_dataDiff_full = np.concatenate((np.zeros((1,SuperMAG_data_full.shape[1])),np.diff(SuperMAG_data_full,axis=0)),axis=0)/data['SuperMAG']['data rate'];
    # #--- Stitch it all together v2 ---
    # input_size = len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/data['SuperMAG']['data rate'])*2+3; #set size
    # input_sizePer = len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/data['SuperMAG']['data rate']);
    # input_data = np.empty( (SuperMAG_timeUnique_TECref.size, input_size) ); #preallocate
    # for i in range(0,SuperMAG_timeUnique_TECref.size):
    #     input_data[i,0:input_sizePer] = SuperMAG_data_full[((SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit)<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]>=SuperMAG_timeUnique_full),:].flatten(); #load in the data
    #     input_data[i,input_sizePer:input_sizePer*2] = SuperMAG_dataDiff_full[((SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit)<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]>=SuperMAG_timeUnique_full),:].flatten(); #load in the data
    # #END FOR i
    # input_data[:,input_size-3] = np.mod(SuperMAG_timeUnique_TECref,86400); #load in the time of the year
    # input_data[:,input_size-2] = np.asarray(sun_subSolarPoint['lat']).flatten(); #load in the sun latitude
    # input_data[:,input_size-1] = np.asarray(sun_subSolarPoint['long']).flatten(); #load in the sun longitude
    # # input_data[:,len(magicks_SuperMAG_setNames)*2+3] = avgPt_coords[0,0]; #load in the location latitude
    # # input_data[:,len(magicks_SuperMAG_setNames)*2+4] = avgPt_coords[0,1]; #load in the location longitude
    
    # #--- Gather SuperMAG data for analysis V3 ---
    # inputType = 'SuperMAG'; #for saving
    # SuperMAG_data = data['SuperMAG']; #load in
    # SuperMAG_timeUnique = data['SuperMAG']['time unique'];
    # magicks_timeStepper = 15*60; #previous minutes worth of steps of data to include
    # magicks_timePreviousLimit = 2*3600; #previous hours worth of data to include (in seconds)
    # kj = ((SuperMAG_timeUnique+magicks_timePreviousLimit)>=dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for extra data to be tacked on]
    # kr = ((SuperMAG_timeUnique)>=dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for initial data pts data avail during the time period desired]
    # # SuperMAG_timeUnique_full = subfun_filter(SuperMAG_timeUnique[kj], 'interp', dataTime = SuperMAG_timeUnique[kj], dataRate = data['SuperMAG']['data rate']);
    # SuperMAG_timeUnique_TECref = np.arange(dateRange_dayNum_full[0,1]*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']); #prep full time
    # SuperMAG_timeUnique_full = np.arange(dateRange_dayNum_full[0,1]*86400-magicks_timePreviousLimit,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']); #prep full time
    # # kk = np.in1d(SuperMAG_timeUnique_full, SuperMAG_timeUnique[kr], assume_unique=True); # get the missing data pts
    # # kk_gapLen = np.diff(np.where(np.diff(kk))[0])[0::2]; #get the gap length
    # # kk_gapLenMax = 6; #how many missing data pts are too much
    # # kk_gapTooMuch = np.ones( SuperMAG_timeUnique_full.size, dtype=np.bool_); #prep truth
    # # kk_gapTooMuchIndexes = np.vstack((np.where(np.diff(kk))[0][0::2][kk_gapLen > kk_gapLenMax]+1,np.where(np.diff(kk))[0][1::2][kk_gapLen > kk_gapLenMax]+1)).T; #get where its too mcuh
    # # for i in range(0,kk_gapTooMuchIndexes.shape[0]):
    # #     kk_gapTooMuch[kk_gapTooMuchIndexes[i,0]:kk_gapTooMuchIndexes[i,1]] = False; #set too long gaps to false
    # # #END FOR i
    # SuperMAG_data_full = np.empty( (SuperMAG_timeUnique_full.size, len(magicks_SuperMAG_setNames)) ); #preallocate
    # SuperMAG_timeUnique_reqTimes = SuperMAG_timeUnique[kj]; #get the cutout times
    # # if( SuperMAG_timeUnique_reqTimes[0] != SuperMAG_timeUnique_full[0] ):
    # #     SuperMAG_timeUnique_reqTimes = np.insert(SuperMAG_timeUnique_reqTimes,0,SuperMAG_timeUnique_full[0]); #put in the first value
    # # #END IF
    # for i in range(0,len(magicks_SuperMAG_setNames)):
    #     if( SuperMAG_timeUnique_reqTimes[0] != SuperMAG_timeUnique_full[0] ):
    #         kj2 = kj.copy();
    #         kj2[np.where(np.diff(kj))[0].item()] = True; #set value just before Trues to True so that that value is used
    #         SuperMAG_data_tooFull = subfun_filter(SuperMAG_data[magicks_SuperMAG_setNames[i]], 'interp', dataTime = SuperMAG_timeUnique, dataRate = data['SuperMAG']['data rate']);
    #         SuperMAG_timeUnique_tooFull = np.arange((dateRange_dayNum_full[0,1]-1)*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']);
    #         SuperMAG_data_full[:,i] = SuperMAG_data_tooFull[np.where(SuperMAG_timeUnique_full[0] == SuperMAG_timeUnique_tooFull)[0].item():]; #get relevant bits (not the time before that was used to interpolate to the new data)
    #     else:
    #         SuperMAG_data_full[:,i] = subfun_filter(SuperMAG_data[magicks_SuperMAG_setNames[i]][kj], 'interp', dataTime = SuperMAG_timeUnique_reqTimes, dataRate = data['SuperMAG']['data rate']);
    #     #END IF
    # #END FOR i
    # SuperMAG_dataDiff_full = np.concatenate((np.zeros((1,SuperMAG_data_full.shape[1])),np.diff(SuperMAG_data_full,axis=0)),axis=0)/data['SuperMAG']['data rate'];
    # #--- Stitch it all together v3 ---
    # input_size = len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/magicks_timeStepper)*2+3; #set size
    # input_sizePer = len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/magicks_timeStepper);
    # input_data = np.empty( (SuperMAG_timeUnique_TECref.size, input_size) ); #preallocate
    # magicks_timeVect = np.arange(0,magicks_timePreviousLimit+magicks_timeStepper,magicks_timeStepper); #make an array of times to avg between
    # for i in range(0,SuperMAG_timeUnique_TECref.size):
    #     for j in range(0,magicks_timeVect.size-1):
    #         input_data[i,len(magicks_SuperMAG_setNames)*j:len(magicks_SuperMAG_setNames)*(j+1)] = np.mean(SuperMAG_data_full[((SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j+1])<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j]>=SuperMAG_timeUnique_full),:],axis=0); #load in the data
    #         input_data[i,len(magicks_SuperMAG_setNames)*j+input_sizePer:len(magicks_SuperMAG_setNames)*(j+1)+input_sizePer] = np.mean(SuperMAG_dataDiff_full[((SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j+1])<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j]>=SuperMAG_timeUnique_full),:],axis=0); #load in the data
    #     #END FOR j
    # #END FOR i
    # input_data[:,input_size-3] = np.mod(SuperMAG_timeUnique_TECref,86400); #load in the time of the year
    # input_data[:,input_size-2] = np.asarray(sun_subSolarPoint['lat']).flatten(); #load in the sun latitude
    # input_data[:,input_size-1] = np.asarray(sun_subSolarPoint['long']).flatten(); #load in the sun longitude
    # # input_data[:,len(magicks_SuperMAG_setNames)*2+3] = avgPt_coords[0,0]; #load in the location latitude
    # # input_data[:,len(magicks_SuperMAG_setNames)*2+4] = avgPt_coords[0,1]; #load in the location longitude
    
    
    #***** OMNI & SuperMAG inputs ******
    # inputType = 'OMNI&SuperMAG'; #for saving
    # magicks_timePreviousLimit = 0*3600; #previous hours worth of data to include (in seconds)
    # #--- Gather OMNI data for analysis V1 ---
    # kj = ((OMNI_timeUnique+magicks_timePreviousLimit)>=dateRange_dayNum_full[0,1]*86400) & (OMNI_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for extra data to be tacked on]
    # kr = ((OMNI_timeUnique)>=dateRange_dayNum_full[0,1]*86400) & (OMNI_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for initial data pts data avail during the time period desired]
    # # OMNI_timeUnique_full = subfun_filter(OMNI_timeUnique[kj], 'interp', dataTime = OMNI_timeUnique[kj], dataRate = data['OMNI']['data rate']);
    # OMNI_timeUnique_TECref = np.arange(dateRange_dayNum_full[0,1]*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']); #prep full time
    # OMNI_timeUnique_full = np.arange(dateRange_dayNum_full[0,1]*86400-magicks_timePreviousLimit,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']); #prep full time
    # # kk = np.in1d(OMNI_timeUnique_full, OMNI_timeUnique[kr], assume_unique=True); # get the missing data pts
    # # kk_gapLen = np.diff(np.where(np.diff(kk))[0])[0::2]; #get the gap length
    # # kk_gapLenMax = 6; #how many missing data pts are too much
    # # kk_gapTooMuch = np.ones( OMNI_timeUnique_full.size, dtype=np.bool_); #prep truth
    # # kk_gapTooMuchIndexes = np.vstack((np.where(np.diff(kk))[0][0::2][kk_gapLen > kk_gapLenMax]+1,np.where(np.diff(kk))[0][1::2][kk_gapLen > kk_gapLenMax]+1)).T; #get where its too mcuh
    # # for i in range(0,kk_gapTooMuchIndexes.shape[0]):
    # #     kk_gapTooMuch[kk_gapTooMuchIndexes[i,0]:kk_gapTooMuchIndexes[i,1]] = False; #set too long gaps to false
    # # #END FOR i
    # OMNI_data_full = np.empty( (OMNI_timeUnique_full.size, len(magicks_OMNI_setNames)) ); #preallocate
    # OMNI_timeUnique_reqTimes = OMNI_timeUnique[kj]; #get the cutout times
    # # if( OMNI_timeUnique_reqTimes[0] != OMNI_timeUnique_full[0] ):
    # #     OMNI_timeUnique_reqTimes = np.insert(OMNI_timeUnique_reqTimes,0,OMNI_timeUnique_full[0]); #put in the first value
    # # #END IF
    # for i in range(0,len(magicks_OMNI_setNames)):
    #     if( OMNI_timeUnique_reqTimes[0] != OMNI_timeUnique_full[0] ):
    #         kj2 = kj.copy();
    #         kj2[np.where(np.diff(kj))[0].item()] = True; #set value just before Trues to True so that that value is used
    #         OMNI_data_tooFull = subfun_filter(OMNI_data[:,OMNI_dict[magicks_OMNI_setNames[i]]], 'interp', dataTime = OMNI_timeUnique, dataRate = data['OMNI']['data rate']);
    #         OMNI_timeUnique_tooFull = np.arange((dateRange_dayNum_full[0,1]-1)*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']);
    #         OMNI_data_full[:,i] = OMNI_data_tooFull[np.where(OMNI_timeUnique_full[0] == OMNI_timeUnique_tooFull)[0].item():]; #get relevant bits (not the time before that was used to interpolate to the new data)
    #     else:
    #         OMNI_data_full[:,i] = subfun_filter(OMNI_data[kj,OMNI_dict[magicks_OMNI_setNames[i]]], 'interp', dataTime = OMNI_timeUnique_reqTimes, dataRate = data['OMNI']['data rate']);
    #     #END IF
    # #END FOR i
    # OMNI_dataDiff_full = np.concatenate((np.zeros((1,OMNI_data_full.shape[1])),np.diff(OMNI_data_full,axis=0)),axis=0)/data['OMNI']['data rate'];
    # #--- Gather SuperMAG data for analysis V1 ---
    # SuperMAG_data = data['SuperMAG']; #load in
    # SuperMAG_timeUnique = data['SuperMAG']['time unique'];
    # kj = ((SuperMAG_timeUnique+magicks_timePreviousLimit)>=dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for extra data to be tacked on]
    # kr = ((SuperMAG_timeUnique)>=dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for initial data pts data avail during the time period desired]
    # # SuperMAG_timeUnique_full = subfun_filter(SuperMAG_timeUnique[kj], 'interp', dataTime = SuperMAG_timeUnique[kj], dataRate = data['SuperMAG']['data rate']);
    # SuperMAG_timeUnique_TECref = np.arange(dateRange_dayNum_full[0,1]*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']); #prep full time
    # SuperMAG_timeUnique_full = np.arange(dateRange_dayNum_full[0,1]*86400-magicks_timePreviousLimit,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']); #prep full time
    # # kk = np.in1d(SuperMAG_timeUnique_full, SuperMAG_timeUnique[kr], assume_unique=True); # get the missing data pts
    # # kk_gapLen = np.diff(np.where(np.diff(kk))[0])[0::2]; #get the gap length
    # # kk_gapLenMax = 6; #how many missing data pts are too much
    # # kk_gapTooMuch = np.ones( SuperMAG_timeUnique_full.size, dtype=np.bool_); #prep truth
    # # kk_gapTooMuchIndexes = np.vstack((np.where(np.diff(kk))[0][0::2][kk_gapLen > kk_gapLenMax]+1,np.where(np.diff(kk))[0][1::2][kk_gapLen > kk_gapLenMax]+1)).T; #get where its too mcuh
    # # for i in range(0,kk_gapTooMuchIndexes.shape[0]):
    # #     kk_gapTooMuch[kk_gapTooMuchIndexes[i,0]:kk_gapTooMuchIndexes[i,1]] = False; #set too long gaps to false
    # # #END FOR i
    # SuperMAG_data_full = np.empty( (SuperMAG_timeUnique_full.size, len(magicks_SuperMAG_setNames)) ); #preallocate
    # SuperMAG_timeUnique_reqTimes = SuperMAG_timeUnique[kj]; #get the cutout times
    # kg = ((SuperMAG_timeUnique_reqTimes)>=dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique_reqTimes<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for initial data pts data avail during the time period desired]
    # # if( SuperMAG_timeUnique_reqTimes[0] != SuperMAG_timeUnique_full[0] ):
    # #     SuperMAG_timeUnique_reqTimes = np.insert(SuperMAG_timeUnique_reqTimes,0,SuperMAG_timeUnique_full[0]); #put in the first value
    # # #END IF
    # for i in range(0,len(magicks_SuperMAG_setNames)):
    #     if( SuperMAG_timeUnique_reqTimes[0] != SuperMAG_timeUnique_full[0] ):
    #         kj2 = kj.copy();
    #         kj2[np.where(np.diff(kj))[0].item()] = True; #set value just before Trues to True so that that value is used
    #         SuperMAG_data_tooFull = subfun_filter(SuperMAG_data[magicks_SuperMAG_setNames[i]], 'interp', dataTime = SuperMAG_timeUnique, dataRate = data['SuperMAG']['data rate']);
    #         SuperMAG_timeUnique_tooFull = np.arange((dateRange_dayNum_full[0,1]-1)*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']);
    #         SuperMAG_data_full[:,i] = SuperMAG_data_tooFull[np.where(SuperMAG_timeUnique_full[0] == SuperMAG_timeUnique_tooFull)[0].item():]; #get relevant bits (not the time before that was used to interpolate to the new data)
    #     else:
    #         SuperMAG_data_full[:,i] = subfun_filter(SuperMAG_data[magicks_SuperMAG_setNames[i]][kj], 'interp', dataTime = SuperMAG_timeUnique_reqTimes, dataRate = data['SuperMAG']['data rate']);
    #     #END IF
    # #END FOR i
    # SuperMAG_dataDiff_full = np.concatenate((np.zeros((1,SuperMAG_data_full.shape[1])),np.diff(SuperMAG_data_full,axis=0)),axis=0)/data['SuperMAG']['data rate'];
    # #--- Stitch it all together v1 ---
    # input_size = len(magicks_SuperMAG_setNames)*2+len(magicks_OMNI_setNames)*2+3; #set size
    # input_sizePer = len(magicks_SuperMAG_setNames)+len(magicks_OMNI_setNames);
    # input_data = np.empty( (SuperMAG_timeUnique_TECref.size, input_size) ); #preallocate
    # # for i in range(0,SuperMAG_timeUnique_TECref.size):
    # #     input_data[i,0:len(magicks_SuperMAG_setNames)] = SuperMAG_data_full[((SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit)<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit>=SuperMAG_timeUnique_full),:],axis=0); #load in the data
    # #     input_data[i,len(magicks_OMNI_setNames)+len(magicks_SuperMAG_setNames):len(magicks_OMNI_setNames)+len(magicks_SuperMAG_setNames)] = OMNI_data_full[((SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit)<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit>=SuperMAG_timeUnique_full),:],axis=0); #load in the data
    # #     input_data[i,len(magicks_SuperMAG_setNames)+input_sizePer:len(magicks_SuperMAG_setNames)+input_sizePer] = SuperMAG_dataDiff_full[((SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit)<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit>=SuperMAG_timeUnique_full),:],axis=0); #load in the data
    # #     input_data[i,len(magicks_OMNI_setNames)+input_sizePer+len(magicks_SuperMAG_setNames):len(magicks_OMNI_setNames)+input_sizePer+len(magicks_SuperMAG_setNames)] = OMNI_dataDiff_full[((SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit)<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit>=SuperMAG_timeUnique_full),:],axis=0); #load in the data
    # # #END FOR i
    # input_data[:,0:len(magicks_SuperMAG_setNames)] = SuperMAG_data_full[kg,:]; #load in the SuperMAG data
    # input_data[:,len(magicks_SuperMAG_setNames):len(magicks_SuperMAG_setNames)*2] = np.concatenate((np.zeros((1,SuperMAG_data_full.shape[1])),np.diff(SuperMAG_data_full[kg,:],axis=0)),axis=0); #load in the SuperMAG data
    # input_data[:,0+len(magicks_SuperMAG_setNames)*2:len(magicks_OMNI_setNames)+len(magicks_SuperMAG_setNames)*2] = OMNI_data_full[kg,:]; #load in the OMNI data
    # input_data[:,len(magicks_OMNI_setNames)+len(magicks_SuperMAG_setNames)*2:len(magicks_OMNI_setNames)*2+len(magicks_SuperMAG_setNames)*2] = np.concatenate((np.zeros((1,OMNI_data_full.shape[1])),np.diff(OMNI_data_full[kg,:],axis=0)),axis=0); #load in the OMNI data
    
    # input_data[:,input_size-3] = np.mod(SuperMAG_timeUnique_TECref,86400); #load in the time of the year
    # input_data[:,input_size-2] = np.asarray(sun_subSolarPoint['lat']).flatten(); #load in the sun latitude
    # input_data[:,input_size-1] = np.asarray(sun_subSolarPoint['long']).flatten(); #load in the sun longitude
    # # input_data[:,len(magicks_SuperMAG_setNames)*2+3] = avgPt_coords[0,0]; #load in the location latitude
    # # input_data[:,len(magicks_SuperMAG_setNames)*2+4] = avgPt_coords[0,1]; #load in the location longitude
    
    # inputType = 'OMNI&SuperMAG'; #for saving
    # magicks_timePreviousLimit = 4*3600; #previous hours worth of data to include (in seconds)
    # #--- Gather OMNI data for analysis V2 ---
    # kj = ((OMNI_timeUnique+magicks_timePreviousLimit)>=dateRange_dayNum_full[0,1]*86400) & (OMNI_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for extra data to be tacked on]
    # kr = ((OMNI_timeUnique)>=dateRange_dayNum_full[0,1]*86400) & (OMNI_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for initial data pts data avail during the time period desired]
    # # OMNI_timeUnique_full = subfun_filter(OMNI_timeUnique[kj], 'interp', dataTime = OMNI_timeUnique[kj], dataRate = data['OMNI']['data rate']);
    # OMNI_timeUnique_TECref = np.arange(dateRange_dayNum_full[0,1]*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']); #prep full time
    # OMNI_timeUnique_full = np.arange(dateRange_dayNum_full[0,1]*86400-magicks_timePreviousLimit,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']); #prep full time
    # # kk = np.in1d(OMNI_timeUnique_full, OMNI_timeUnique[kr], assume_unique=True); # get the missing data pts
    # # kk_gapLen = np.diff(np.where(np.diff(kk))[0])[0::2]; #get the gap length
    # # kk_gapLenMax = 6; #how many missing data pts are too much
    # # kk_gapTooMuch = np.ones( OMNI_timeUnique_full.size, dtype=np.bool_); #prep truth
    # # kk_gapTooMuchIndexes = np.vstack((np.where(np.diff(kk))[0][0::2][kk_gapLen > kk_gapLenMax]+1,np.where(np.diff(kk))[0][1::2][kk_gapLen > kk_gapLenMax]+1)).T; #get where its too mcuh
    # # for i in range(0,kk_gapTooMuchIndexes.shape[0]):
    # #     kk_gapTooMuch[kk_gapTooMuchIndexes[i,0]:kk_gapTooMuchIndexes[i,1]] = False; #set too long gaps to false
    # # #END FOR i
    # OMNI_data_full = np.empty( (OMNI_timeUnique_full.size, len(magicks_OMNI_setNames)) ); #preallocate
    # OMNI_timeUnique_reqTimes = OMNI_timeUnique[kj]; #get the cutout times
    # # if( OMNI_timeUnique_reqTimes[0] != OMNI_timeUnique_full[0] ):
    # #     OMNI_timeUnique_reqTimes = np.insert(OMNI_timeUnique_reqTimes,0,OMNI_timeUnique_full[0]); #put in the first value
    # # #END IF
    # for i in range(0,len(magicks_OMNI_setNames)):
    #     if( OMNI_timeUnique_reqTimes[0] != OMNI_timeUnique_full[0] ):
    #         kj2 = kj.copy();
    #         kj2[np.where(np.diff(kj))[0].item()] = True; #set value just before Trues to True so that that value is used
    #         OMNI_data_tooFull = subfun_filter(OMNI_data[:,OMNI_dict[magicks_OMNI_setNames[i]]], 'interp', dataTime = OMNI_timeUnique, dataRate = data['OMNI']['data rate']);
    #         OMNI_timeUnique_tooFull = np.arange((dateRange_dayNum_full[0,1]-1)*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']);
    #         OMNI_data_full[:,i] = OMNI_data_tooFull[np.where(OMNI_timeUnique_full[0] == OMNI_timeUnique_tooFull)[0].item():]; #get relevant bits (not the time before that was used to interpolate to the new data)
    #     else:
    #         OMNI_data_full[:,i] = subfun_filter(OMNI_data[kj,OMNI_dict[magicks_OMNI_setNames[i]]], 'interp', dataTime = OMNI_timeUnique_reqTimes, dataRate = data['OMNI']['data rate']);
    #     #END IF
    # #END FOR i
    # OMNI_dataDiff_full = np.concatenate((np.zeros((1,OMNI_data_full.shape[1])),np.diff(OMNI_data_full,axis=0)),axis=0)/data['OMNI']['data rate'];
    # #--- Gather SuperMAG data for analysis V2 ---
    # SuperMAG_data = data['SuperMAG']; #load in
    # SuperMAG_timeUnique = data['SuperMAG']['time unique'];
    # kj = ((SuperMAG_timeUnique+magicks_timePreviousLimit)>=dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for extra data to be tacked on]
    # kr = ((SuperMAG_timeUnique)>=dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for initial data pts data avail during the time period desired]
    # # SuperMAG_timeUnique_full = subfun_filter(SuperMAG_timeUnique[kj], 'interp', dataTime = SuperMAG_timeUnique[kj], dataRate = data['SuperMAG']['data rate']);
    # SuperMAG_timeUnique_TECref = np.arange(dateRange_dayNum_full[0,1]*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']); #prep full time
    # SuperMAG_timeUnique_full = np.arange(dateRange_dayNum_full[0,1]*86400-magicks_timePreviousLimit,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']); #prep full time
    # # kk = np.in1d(SuperMAG_timeUnique_full, SuperMAG_timeUnique[kr], assume_unique=True); # get the missing data pts
    # # kk_gapLen = np.diff(np.where(np.diff(kk))[0])[0::2]; #get the gap length
    # # kk_gapLenMax = 6; #how many missing data pts are too much
    # # kk_gapTooMuch = np.ones( SuperMAG_timeUnique_full.size, dtype=np.bool_); #prep truth
    # # kk_gapTooMuchIndexes = np.vstack((np.where(np.diff(kk))[0][0::2][kk_gapLen > kk_gapLenMax]+1,np.where(np.diff(kk))[0][1::2][kk_gapLen > kk_gapLenMax]+1)).T; #get where its too mcuh
    # # for i in range(0,kk_gapTooMuchIndexes.shape[0]):
    # #     kk_gapTooMuch[kk_gapTooMuchIndexes[i,0]:kk_gapTooMuchIndexes[i,1]] = False; #set too long gaps to false
    # # #END FOR i
    # SuperMAG_data_full = np.empty( (SuperMAG_timeUnique_full.size, len(magicks_SuperMAG_setNames)) ); #preallocate
    # SuperMAG_timeUnique_reqTimes = SuperMAG_timeUnique[kj]; #get the cutout times
    # # if( SuperMAG_timeUnique_reqTimes[0] != SuperMAG_timeUnique_full[0] ):
    # #     SuperMAG_timeUnique_reqTimes = np.insert(SuperMAG_timeUnique_reqTimes,0,SuperMAG_timeUnique_full[0]); #put in the first value
    # # #END IF
    # for i in range(0,len(magicks_SuperMAG_setNames)):
    #     if( SuperMAG_timeUnique_reqTimes[0] != SuperMAG_timeUnique_full[0] ):
    #         kj2 = kj.copy();
    #         kj2[np.where(np.diff(kj))[0].item()] = True; #set value just before Trues to True so that that value is used
    #         SuperMAG_data_tooFull = subfun_filter(SuperMAG_data[magicks_SuperMAG_setNames[i]], 'interp', dataTime = SuperMAG_timeUnique, dataRate = data['SuperMAG']['data rate']);
    #         SuperMAG_timeUnique_tooFull = np.arange((dateRange_dayNum_full[0,1]-1)*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']);
    #         SuperMAG_data_full[:,i] = SuperMAG_data_tooFull[np.where(SuperMAG_timeUnique_full[0] == SuperMAG_timeUnique_tooFull)[0].item():]; #get relevant bits (not the time before that was used to interpolate to the new data)
    #     else:
    #         SuperMAG_data_full[:,i] = subfun_filter(SuperMAG_data[magicks_SuperMAG_setNames[i]][kj], 'interp', dataTime = SuperMAG_timeUnique_reqTimes, dataRate = data['SuperMAG']['data rate']);
    #     #END IF
    # #END FOR i
    # SuperMAG_dataDiff_full = np.concatenate((np.zeros((1,SuperMAG_data_full.shape[1])),np.diff(SuperMAG_data_full,axis=0)),axis=0)/data['SuperMAG']['data rate'];
    # #--- Stitch it all together v2 ---
    # input_size = len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/data['SuperMAG']['data rate'])*2+len(magicks_OMNI_setNames)*np.int64(magicks_timePreviousLimit/data['OMNI']['data rate'])*2+3; #set size
    # input_sizePer = len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/data['SuperMAG']['data rate'])+len(magicks_OMNI_setNames)*np.int64(magicks_timePreviousLimit/data['OMNI']['data rate']);
    # input_data = np.empty( (SuperMAG_timeUnique_TECref.size, input_size) ); #preallocate
    # for i in range(0,SuperMAG_timeUnique_TECref.size):
    #     input_data[i,0:len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/data['SuperMAG']['data rate'])] = SuperMAG_data_full[((SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit)<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]>=SuperMAG_timeUnique_full),:].flatten(); #load in the data
    #     input_data[i,0+len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/data['SuperMAG']['data rate']):len(magicks_OMNI_setNames)*np.int64(magicks_timePreviousLimit/data['OMNI']['data rate'])+len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/data['SuperMAG']['data rate'])] = OMNI_data_full[((SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit)<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]>=SuperMAG_timeUnique_full),:].flatten(); #load in the data
    #     input_data[i,0+input_sizePer:len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/data['SuperMAG']['data rate'])+input_sizePer] = SuperMAG_dataDiff_full[((SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit)<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]>=SuperMAG_timeUnique_full),:].flatten(); #load in the data
    #     input_data[i,0+len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/data['SuperMAG']['data rate'])+input_sizePer:len(magicks_OMNI_setNames)*np.int64(magicks_timePreviousLimit/data['OMNI']['data rate'])+len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/data['SuperMAG']['data rate'])+input_sizePer] = OMNI_dataDiff_full[((SuperMAG_timeUnique_TECref[i]-magicks_timePreviousLimit)<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]>=SuperMAG_timeUnique_full),:].flatten(); #load in the data
    # #END FOR i
    # input_data[:,input_size-3] = np.mod(SuperMAG_timeUnique_TECref,86400); #load in the time of the year
    # input_data[:,input_size-2] = np.asarray(sun_subSolarPoint['lat']).flatten(); #load in the sun latitude
    # input_data[:,input_size-1] = np.asarray(sun_subSolarPoint['long']).flatten(); #load in the sun longitude
    # # input_data[:,len(magicks_SuperMAG_setNames)*2+3] = avgPt_coords[0,0]; #load in the location latitude
    # # input_data[:,len(magicks_SuperMAG_setNames)*2+4] = avgPt_coords[0,1]; #load in the location longitude
    
    
    inputType = 'OMNI&SuperMAG'; #for saving
    magicks_timeStepper = 15*60; #previous minutes worth of steps of data to include
    magicks_timePreviousLimit = 4*3600; #previous hours worth of data to include (in seconds)
    #--- Gather OMNI data for analysis V3 ---
    kj = ((OMNI_timeUnique+magicks_timePreviousLimit)>=dateRange_dayNum_full[0,1]*86400) & (OMNI_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for extra data to be tacked on]
    kr = ((OMNI_timeUnique)>=dateRange_dayNum_full[0,1]*86400) & (OMNI_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for initial data pts data avail during the time period desired]
    # OMNI_timeUnique_full = subfun_filter(OMNI_timeUnique[kj], 'interp', dataTime = OMNI_timeUnique[kj], dataRate = data['OMNI']['data rate']);
    OMNI_timeUnique_TECref = np.arange(dateRange_dayNum_full[0,1]*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']); #prep full time
    OMNI_timeUnique_full = np.arange(dateRange_dayNum_full[0,1]*86400-magicks_timePreviousLimit,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']); #prep full time
    # kk = np.in1d(OMNI_timeUnique_full, OMNI_timeUnique[kr], assume_unique=True); # get the missing data pts
    # kk_gapLen = np.diff(np.where(np.diff(kk))[0])[0::2]; #get the gap length
    # kk_gapLenMax = 6; #how many missing data pts are too much
    # kk_gapTooMuch = np.ones( OMNI_timeUnique_full.size, dtype=np.bool_); #prep truth
    # kk_gapTooMuchIndexes = np.vstack((np.where(np.diff(kk))[0][0::2][kk_gapLen > kk_gapLenMax]+1,np.where(np.diff(kk))[0][1::2][kk_gapLen > kk_gapLenMax]+1)).T; #get where its too mcuh
    # for i in range(0,kk_gapTooMuchIndexes.shape[0]):
    #     kk_gapTooMuch[kk_gapTooMuchIndexes[i,0]:kk_gapTooMuchIndexes[i,1]] = False; #set too long gaps to false
    # #END FOR i
    OMNI_data_full = np.empty( (OMNI_timeUnique_full.size, len(magicks_OMNI_setNames)) ); #preallocate
    OMNI_timeUnique_reqTimes = OMNI_timeUnique[kj]; #get the cutout times
    # if( OMNI_timeUnique_reqTimes[0] != OMNI_timeUnique_full[0] ):
    #     OMNI_timeUnique_reqTimes = np.insert(OMNI_timeUnique_reqTimes,0,OMNI_timeUnique_full[0]); #put in the first value
    # #END IF
    for i in range(0,len(magicks_OMNI_setNames)):
        if( OMNI_timeUnique_reqTimes[0] != OMNI_timeUnique_full[0] ):
            kj2 = kj.copy();
            kj2[np.where(np.diff(kj))[0].item()] = True; #set value just before Trues to True so that that value is used
            OMNI_data_tooFull = subfun_filter(OMNI_data[:,OMNI_dict[magicks_OMNI_setNames[i]]], 'interp', dataTime = OMNI_timeUnique, dataRate = data['OMNI']['data rate']);
            OMNI_timeUnique_tooFull = np.arange((dateRange_dayNum_full[0,1]-1)*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['OMNI']['data rate']);
            OMNI_data_full[:,i] = OMNI_data_tooFull[np.where(OMNI_timeUnique_full[0] == OMNI_timeUnique_tooFull)[0].item():]; #get relevant bits (not the time before that was used to interpolate to the new data)
        else:
            OMNI_data_full[:,i] = subfun_filter(OMNI_data[kj,OMNI_dict[magicks_OMNI_setNames[i]]], 'interp', dataTime = OMNI_timeUnique_reqTimes, dataRate = data['OMNI']['data rate']);
        #END IF
        if( np.any(np.isnan(OMNI_data_full[:,i])) ):
            OMNI_data_full[:,i] = subfun_filter(OMNI_data_full[:,i],'nan',dataTime=OMNI_timeUnique_full); #remove nans
        #END IF
    #END FOR i
    OMNI_dataDiff_full = np.concatenate((np.zeros((1,OMNI_data_full.shape[1])),np.diff(OMNI_data_full,axis=0)),axis=0)/data['OMNI']['data rate'];
    #--- Gather SuperMAG data for analysis V3 ---
    SuperMAG_data = data['SuperMAG']; #load in
    SuperMAG_timeUnique = data['SuperMAG']['time unique'];
    kj = ((SuperMAG_timeUnique+magicks_timePreviousLimit)>=dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for extra data to be tacked on]
    kr = ((SuperMAG_timeUnique)>=dateRange_dayNum_full[0,1]*86400) & (SuperMAG_timeUnique<(dateRange_dayNum_full[-1,1]+1)*86400); #get the revant times [for initial data pts data avail during the time period desired]
    # SuperMAG_timeUnique_full = subfun_filter(SuperMAG_timeUnique[kj], 'interp', dataTime = SuperMAG_timeUnique[kj], dataRate = data['SuperMAG']['data rate']);
    SuperMAG_timeUnique_TECref = np.arange(dateRange_dayNum_full[0,1]*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']); #prep full time
    SuperMAG_timeUnique_full = np.arange(dateRange_dayNum_full[0,1]*86400-magicks_timePreviousLimit,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']); #prep full time
    # kk = np.in1d(SuperMAG_timeUnique_full, SuperMAG_timeUnique[kr], assume_unique=True); # get the missing data pts
    # kk_gapLen = np.diff(np.where(np.diff(kk))[0])[0::2]; #get the gap length
    # kk_gapLenMax = 6; #how many missing data pts are too much
    # kk_gapTooMuch = np.ones( SuperMAG_timeUnique_full.size, dtype=np.bool_); #prep truth
    # kk_gapTooMuchIndexes = np.vstack((np.where(np.diff(kk))[0][0::2][kk_gapLen > kk_gapLenMax]+1,np.where(np.diff(kk))[0][1::2][kk_gapLen > kk_gapLenMax]+1)).T; #get where its too mcuh
    # for i in range(0,kk_gapTooMuchIndexes.shape[0]):
    #     kk_gapTooMuch[kk_gapTooMuchIndexes[i,0]:kk_gapTooMuchIndexes[i,1]] = False; #set too long gaps to false
    # #END FOR i
    SuperMAG_data_full = np.empty( (SuperMAG_timeUnique_full.size, len(magicks_SuperMAG_setNames)) ); #preallocate
    SuperMAG_timeUnique_reqTimes = SuperMAG_timeUnique[kj]; #get the cutout times
    # if( SuperMAG_timeUnique_reqTimes[0] != SuperMAG_timeUnique_full[0] ):
    #     SuperMAG_timeUnique_reqTimes = np.insert(SuperMAG_timeUnique_reqTimes,0,SuperMAG_timeUnique_full[0]); #put in the first value
    # #END IF
    for i in range(0,len(magicks_SuperMAG_setNames)):
        if( SuperMAG_timeUnique_reqTimes[0] != SuperMAG_timeUnique_full[0] ):
            kj2 = kj.copy();
            kj2[np.where(np.diff(kj))[0].item()] = True; #set value just before Trues to True so that that value is used
            SuperMAG_data_tooFull = subfun_filter(SuperMAG_data[magicks_SuperMAG_setNames[i]], 'interp', dataTime = SuperMAG_timeUnique, dataRate = data['SuperMAG']['data rate']);
            SuperMAG_timeUnique_tooFull = np.arange((dateRange_dayNum_full[0,1]-1)*86400,(dateRange_dayNum_full[-1,1]+1)*86400,data['SuperMAG']['data rate']);
            SuperMAG_data_full[:,i] = SuperMAG_data_tooFull[np.where(SuperMAG_timeUnique_full[0] == SuperMAG_timeUnique_tooFull)[0].item():]; #get relevant bits (not the time before that was used to interpolate to the new data)
        else:
            SuperMAG_data_full[:,i] = subfun_filter(SuperMAG_data[magicks_SuperMAG_setNames[i]][kj], 'interp', dataTime = SuperMAG_timeUnique_reqTimes, dataRate = data['SuperMAG']['data rate']);
        #END IF
        if( np.any(np.isnan(SuperMAG_data_full[:,i])) ):
            SuperMAG_data_full[:,i] = subfun_filter(SuperMAG_data_full[:,i],'nan',dataTime=SuperMAG_timeUnique_full); #remove nans
        #END IF
    #END FOR i
    SuperMAG_dataDiff_full = np.concatenate((np.zeros((1,SuperMAG_data_full.shape[1])),np.diff(SuperMAG_data_full,axis=0)),axis=0)/data['SuperMAG']['data rate'];
    #--- Stitch it all together v3 ---
    input_size = len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/magicks_timeStepper)*2+len(magicks_OMNI_setNames)*np.int64(magicks_timePreviousLimit/magicks_timeStepper)*2+3; #set size
    input_sizePer = len(magicks_SuperMAG_setNames)*np.int64(magicks_timePreviousLimit/magicks_timeStepper)+len(magicks_OMNI_setNames)*np.int64(magicks_timePreviousLimit/magicks_timeStepper);
    input_data = np.empty( (SuperMAG_timeUnique_TECref.size, input_size) ); #preallocate
    magicks_timeVect = np.arange(0,magicks_timePreviousLimit+magicks_timeStepper,magicks_timeStepper); #make an array of times to avg between
    for i in range(0,SuperMAG_timeUnique_TECref.size):
        for j in range(0,magicks_timeVect.size-1):
            input_data[i,len(magicks_SuperMAG_setNames)*j:len(magicks_SuperMAG_setNames)*(j+1)] = np.mean(SuperMAG_data_full[((SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j+1])<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j]>=SuperMAG_timeUnique_full),:],axis=0); #load in the data
            input_data[i,len(magicks_OMNI_setNames)*j+len(magicks_SuperMAG_setNames)*(magicks_timeVect.size-1):len(magicks_OMNI_setNames)*(j+1)+len(magicks_SuperMAG_setNames)*(magicks_timeVect.size-1)] = np.mean(OMNI_data_full[((SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j+1])<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j]>=SuperMAG_timeUnique_full),:],axis=0); #load in the data
            input_data[i,len(magicks_SuperMAG_setNames)*j+input_sizePer:len(magicks_SuperMAG_setNames)*(j+1)+input_sizePer] = np.mean(SuperMAG_dataDiff_full[((SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j+1])<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j]>=SuperMAG_timeUnique_full),:],axis=0); #load in the data
            input_data[i,len(magicks_OMNI_setNames)*j+input_sizePer+len(magicks_SuperMAG_setNames)*(magicks_timeVect.size-1):len(magicks_OMNI_setNames)*(j+1)+input_sizePer+len(magicks_SuperMAG_setNames)*(magicks_timeVect.size-1)] = np.mean(OMNI_dataDiff_full[((SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j+1])<SuperMAG_timeUnique_full) & (SuperMAG_timeUnique_TECref[i]-magicks_timeVect[j]>=SuperMAG_timeUnique_full),:],axis=0); #load in the data
          #END FOR j
    #END FOR i
    input_data[:,input_size-3] = np.mod(SuperMAG_timeUnique_TECref,86400); #load in the time of the year
    input_data[:,input_size-2] = np.asarray(sun_subSolarPoint['lat']).flatten(); #load in the sun latitude
    input_data[:,input_size-1] = np.asarray(sun_subSolarPoint['long']).flatten(); #load in the sun longitude
    # input_data[:,len(magicks_SuperMAG_setNames)*2+3] = avgPt_coords[0,0]; #load in the location latitude
    # input_data[:,len(magicks_SuperMAG_setNames)*2+4] = avgPt_coords[0,1]; #load in the location longitude
        
    
    #***** AMPERE inputs ******
    # inputType = 'AMPERE'; #for saving
    # #----- Integrate AMPERE Data -----
    # magicks_settings_AMPERE = copy.deepcopy(settings_AMPERE); #copy safely
    # #--- Gather other important data types for analysis ---
    # sun_subSolarPoint = sunAlsoRises_location(dateRange_full,dataRate=data['AMPERE']['data rate']);
    
    # #--- Stitch it all together ---
    # input_size = 3+len(magicks_AMPERE_dataTypes); #set size
    # input_data = np.empty( (AMPERE_timeUnique.size, input_size) ); #preallocate
    # input_data[:,0] = np.asarray(sun_subSolarPoint['lat']).flatten(); #load in the sun latitude
    # input_data[:,1] = np.asarray(sun_subSolarPoint['long']).flatten(); #load in the sun longitude
    # input_data[:,2] = np.mod(AMPERE_timeUnique,86400); #load in the OMNI data
    # for i in range(0,len(magicks_AMPERE_dataTypes)):
    #     magicks_settings_AMPERE['data type'] = magicks_AMPERE_dataTypes[i];
    #     magicks_settings_AMPERE['integrate method'] = magicks_AMPERE_integrateMethods[i];
    #     magicks_settings_AMPERE['integrate method lat val'] = magicks_AMPERE_integrateVals[i]
    #     AMPERE_integrated = GRITI_AMPERE_integrator(data['AMPERE'], dates, magicks_settings_AMPERE, plotLatRange, plotLongRange, magicks_settings_AMPERE['integrate method'], magicks_settings_AMPERE['integrate method lat val'], AMPERE_integrateMethod_log=magicks_settings_AMPERE['integrate method log']); #integrate with the integrator function
    #     input_data[:,3+i] = AMPERE_integrated; #load in the OMNI data
    # #END FOR i
    
    #===== Assemble test outputs =====
    avgPt_vTEC, _, avgPt_vTEC_time, _, _, _ = GRITI_TEC_avgPt(TEC_timeUnique,data['TEC']['lat'],data['TEC']['long'],data['TEC']['time'],data['TEC']['dTEC'], \
        avgPt_coords[0,:],avgPt_pointRadius,Re,dateRange_dayNum_zeroHr, \
        dataReject,dataRejectOrig,dataRejectLimit,dataRejectLimitOrig,dataRejectMax,FLG_report=1); #average points in a radius
    if( inputType == 'OMNI' ):
        #***** OMNI time associated *****
        avgPt_vTEC_timeMatch, avgPt_vTEC_time_timeMatch = subfun_timeMatch(avgPt_vTEC, avgPt_vTEC_time, OMNI_timeUnique_TECref, timeMatch_delta=data['OMNI']['data rate'], FLG_removeNaNs=1, FLG_reportNaNs=False);
        dataRate_curr = data['OMNI']['data rate'];
    elif( inputType == 'SuperMAG' ):
        #***** SuperMAG time associated *****
        avgPt_vTEC_timeMatch, avgPt_vTEC_time_timeMatch = subfun_timeMatch(avgPt_vTEC, avgPt_vTEC_time, SuperMAG_timeUnique_TECref, timeMatch_delta=data['SuperMAG']['data rate'], FLG_removeNaNs=1, FLG_reportNaNs=False);
        dataRate_curr = data['SuperMAG']['data rate'];
    elif( inputType == 'OMNI&SuperMAG' ):
        if( data['OMNI']['data rate'] > data['SuperMAG']['data rate'] ):
            avgPt_vTEC_timeMatch, avgPt_vTEC_time_timeMatch = subfun_timeMatch(avgPt_vTEC, avgPt_vTEC_time, OMNI_timeUnique_TECref, timeMatch_delta=data['OMNI']['data rate'], FLG_removeNaNs=1, FLG_reportNaNs=False);
            dataRate_curr = data['OMNI']['data rate'];
        else:
            avgPt_vTEC_timeMatch, avgPt_vTEC_time_timeMatch = subfun_timeMatch(avgPt_vTEC, avgPt_vTEC_time, SuperMAG_timeUnique_TECref, timeMatch_delta=data['SuperMAG']['data rate'], FLG_removeNaNs=1, FLG_reportNaNs=False);
            dataRate_curr = data['SuperMAG']['data rate'];
        #END IF
    elif( inputType == 'AMPERE' ):
        #***** AMPERE time associated *****
        avgPt_vTEC_timeMatch, avgPt_vTEC_time_timeMatch = subfun_timeMatch(avgPt_vTEC, avgPt_vTEC_time, AMPERE_timeUnique, timeMatch_delta=data['AMPERE']['data rate'], FLG_removeNaNs=1, FLG_reportNaNs=False);
        dataRate_curr = data['AMPERE']['data rate'];
    #END IF
    # output_data = avgPt_vTEC_timeMatch;
    output_data = subfun_filter(avgPt_vTEC_timeMatch,'savgolsmooth', dataTime = avgPt_vTEC_time_timeMatch, dataRate = dataRate_curr, settings_spectra = {'savgol filter period':15*60,'savgol filter order':1}); #sooth it out
    # if( output_data.ndim > 1 ):
    #     output_data = np.concatenate((np.zeros((1,output_data.shape[1])),np.diff(output_data,axis=0)/data['TEC']['data rate']),axis=0); #set it n' forget it
    # else:
    #     output_data = np.concatenate((np.zeros((1,1)),np.diff(output_data.reshape(-1, 1),axis=0)/data['TEC']['data rate']),axis=0).ravel(); #set it n' forget it
    # #END IF
    
    #***testing***
    # input_data = np.random.uniform(low=-5,high=5,size=(4320,5));
    # # output_data = input_data[:,0]*input_data[:,1]+input_data[:,2];
    # output_data = np.sin(input_data[:,1])*input_data[:,2]+input_data[:,3];

    #~~~~~ scikit-learn ~~~~~
    from sklearn.preprocessing import StandardScaler
    from sklearn.neural_network import MLPRegressor
    if( os.path.isfile(settings['paths']['cache']+'\\'+'magicks_sklearn_'+inputType+'2TEC.pkl') == False ):      
        
        #--- scale input data for training ---
        scaler = StandardScaler(); #prep a scaler function
        scaler.fit(input_data); #scale the scaler function to the input data 
        input_data_scaled = scaler.transform(input_data); #use the scaler function to scale the input data
            
        #===== Scale the output data for stability(?) =====
        scaler_out = StandardScaler(); #prep a scaler function
        scaler_out.fit(output_data.reshape(-1, 1)); #scale the scaler function to the input data 
        output_data_scaled = scaler_out.transform(output_data.reshape(-1, 1)).ravel(); #use the scaler function to scale the output data
        
        #===== Train the model =====
        from Code.subfun_filter import subfun_filter
        model_activations = ('relu','tanh','logistic','identity'); #models to try
        magicks = [None for i in range(0,len(model_activations))]; #prep
        for i in range(0,len(model_activations)):
            magicks[i] = MLPRegressor(solver='adam', alpha=1e-5, hidden_layer_sizes=(150, 3), random_state=1 ,max_iter=20000, activation=model_activations[i]); #prep the model
            magicks[i].fit(input_data_scaled, output_data_scaled); #train the model
            
            output_data_predictedSci = magicks[i].predict(input_data_scaled); #test the model
            
            #===== Check quality =====
            # err = output_data-output_data_predicted;
            # err_percDiff = np.abs(err/output_data)*100;
            # err_rsq = 1-np.sum((err)**2)/np.sum((output_data-np.mean(output_data))**2);
            # err_mse = ((err)**2).mean();
            # err_multRator = np.nanmean(np.abs(output_data*output_data_predicted - output_data**2));
            
            err = output_data_scaled-output_data_predictedSci;
            err_percDiff = np.abs(err/output_data_scaled)*100;
            err_rsq = 1-np.sum((err)**2)/np.sum((output_data_scaled-np.mean(output_data_scaled))**2);
            err_mse = ((err)**2).mean();
            err_multRator = np.nanmean(np.abs(output_data_scaled*output_data_predictedSci - output_data_scaled**2));
            
            print('Training scikit-learn % error: '+str(np.mean(err_percDiff)));
            
            output_data_predictedSci_recovered = scaler_out.inverse_transform(output_data_predictedSci.reshape(-1, 1)).ravel();
            
            fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
            figManager = fig.canvas.manager; #req to maximize
            figManager.window.showMaximized(); #force maximized
            p1, = ax.plot(output_data);
            p2, = ax.plot(output_data_predictedSci_recovered);
            ax.legend((p1,p2),('real','predicted'));
            ax.set_title('Training Scikit-Learn '+model_activations[i]+' TEC from '+str(inputType));
            figFitter(fig);
            
            corr = subfun_correlator(output_data,output_data_predictedSci_recovered,plotName='Training Scikit-Learn '+model_activations[i]+' TEC from '+str(inputType));
        #END FOR i
        
        magicks_dateTrained = dates['date range'];
        with open(settings['paths']['cache']+'\\'+'magicks_sklearn_'+inputType+'2TEC.pkl', 'wb') as pklr:
            pkl.dump([magicks,model_activations,scaler,scaler_out,magicks_dateTrained], pklr); #save the data
        #END WITH
    else:
        with open(settings['paths']['cache']+'\\'+'magicks_sklearn_'+inputType+'2TEC.pkl', 'rb') as pklr:
            [magicks,model_activations,scaler,scaler_out,magicks_dateTrained] = pkl.load(pklr); #load the data if there
        #END WITH
        
        input_data_scaled = scaler.transform(input_data); #use the scaler function to scale the input data
        output_data_scaled = scaler_out.transform(output_data.reshape(-1, 1)).ravel(); #use the scaler function to scale the output data
        
        for i in range(0,len(model_activations)):
            output_data_predictedSci = magicks[i].predict(input_data_scaled); #test the model
            
            #===== Check quality =====
            # err = output_data-output_data_predicted;
            # err_percDiff = np.abs(err/output_data)*100;
            # err_rsq = 1-np.sum((err)**2)/np.sum((output_data-np.mean(output_data))**2);
            # err_mse = ((err)**2).mean();
            # err_multRator = np.nanmean(np.abs(output_data*output_data_predicted - output_data**2));
            
            err = output_data_scaled-output_data_predictedSci;
            err_percDiff = np.abs(err/output_data_scaled)*100;
            err_rsq = 1-np.sum((err)**2)/np.sum((output_data_scaled-np.mean(output_data_scaled))**2);
            err_mse = ((err)**2).mean();
            err_multRator = np.nanmean(np.abs(output_data_scaled*output_data_predictedSci - output_data_scaled**2));
            
            print('Training scikit-learn % error: '+str(np.mean(err_percDiff)));
            
            output_data_predictedSci_recovered = scaler_out.inverse_transform(output_data_predictedSci.reshape(-1, 1)).ravel();
            
            fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
            figManager = fig.canvas.manager; #req to maximize
            figManager.window.showMaximized(); #force maximized
            p1, = ax.plot(output_data);
            p2, = ax.plot(output_data_predictedSci_recovered);
            ax.legend((p1,p2),('real','predicted'));
            ax.set_title('Training Scikit-Learn '+model_activations[i]+' TEC from '+str(inputType));
            figFitter(fig);
            
            corr = subfun_correlator(output_data,output_data_predictedSci_recovered,plotName='Training Scikit-Learn '+model_activations[i]+' TEC from '+str(inputType));
        #END FOR i
    #END IF
    
    # # #~~~~~ Razzle Dazzle mode 2 ~~~~~
    # from RazDazMod_conjuncture2 import varOnTrial, RD_eqForm, RD_imageMake
    # from RegridderZenMats import RegridderZenMats
    # from RegridderZenAccel import RegridderZenAccel
    # accelorPwr = 0.0000000005; #value to accelerate by (closer to 0 accelerates more)
    # # accelorPwr = 10**5; #value to accelerate by (closer to 0 accelerates more)
    # trialsAndTribulations = 200; #number of loops through the alg
    # nSets = 50; #number of variable sets
    # nVars = 6; #number of variables in a set (corresponds to RD_eqForm's varRow size)
    # nVignettes = 250; #number of various types of sets to try
    # ratingKeepPerc = 0.10; #a percentage to keep
    # bottomShufflePerc = 0.10; #a percentage to keep 
    # ratingKeep = np.int64(np.round(nVignettes*ratingKeepPerc)); #calc how many to keep in mind
    # bottomShuffle = np.int64(np.round(nVignettes*bottomShufflePerc)); #calc how many to keep in mind
    # bottomShuffleOrig = np.copy(bottomShuffle).item(); #prep original value
    # # varBottomShuffleThresh = 5; #if it's beent he same for 5 iterations start shaking the tree
    # varSet = 10**2*(np.random.uniform(size=(nSets,nVars,nVignettes) )-0.5); #prep the random variables
    
    # outputImageShape = np.shape(output_data.reshape(-1, 1)); #get the shape of an input image
    # outputX = np.arange(0,output_data.reshape(-1, 1).shape[0]); #get X points
    # outputY = np.arange(0,output_data.reshape(-1, 1).shape[1]); #get Y points
    # outputMeshXY = tuple(np.meshgrid( outputX, outputY)); #helps the pcolor work, since it's static make it a tuple so Numba stops complaining
    
    
    # tic = time.time(); #start timing
    
    # nImages = 1;
    # output_data_rdy = output_data.reshape(-1, 1, 1); #gotta be a 3 dim thing
    # input_data_rdy = np.expand_dims(input_data,2); #gotta be a 3 dim thing
    # # inputImage_precalcd = np.zeros( (nSets,1, nImages) ); #preallocate
    # inputImage_precalcd = np.zeros( (nSets,nVars, nImages) ); #preallocate
    # inputImage_arange = np.arange(0,input_data_rdy.shape[0]*input_data_rdy.shape[1]); #prep
    # nSets_arange = np.arange(0,nSets); #prep
    # # output_data_sqr = np.zeros( output_data_rdy.shape); #preallocate
    # yMatrix, xMatrix = RegridderZenMats((input_data_rdy.shape[0],input_data_rdy.shape[1]), (nSets,nVars)); #prep matricies for regridder
    # for i in range(0,nImages):
    #     inputImage = input_data_rdy[:,:,i]; #flatten
    #     inputImage[np.isnan(inputImage)] = 0.; #turn NaNs into 0s
    #     # inputImage_precalcd[:,:,i] = np.interp(nSets_arange,inputImage_arange,inputImage).reshape(-1,1); #interpolate to variable size
    #     inputImage_precalcd[:,:,i] = RegridderZenAccel(inputImage, yMatrix, xMatrix);  #interpolate to variable size using flawless regridder function
    #     # output_data_sqr[:,:,i] = output_data_rdy[:,:,i]**2; #also pre-calc this
    # #END FOR i
    
    # print('Beginning RazDazMod V2');
    # varTop, ratorTop = varOnTrial(output_data_rdy,inputImage_precalcd,outputImageShape,outputMeshXY,nVars,nSets,nVignettes,nImages,trialsAndTribulations,varSet,ratingKeep,bottomShuffle,bottomShuffleOrig,accelorPwr); #jit accelerate this work
    
    # varOpt = np.mean(varTop,axis=2); #get the final optimal, based on the top instances
    # varOpt2 = varTop[:,:,0]; #get the final optimal, based on the top instance
    # toc = time.time() - tic; #end timing
    # print('\n\n\nTOP RATING: '+str(ratorTop[0])); #report top
    # print('Time to run: '+str(toc)+' sec | '+str(toc/60)+' min\n\n\n'); #report time to run
    
    # NUMtoPLOT = 0;
    # inputImage = input_data_rdy[:,:,NUMtoPLOT]; #get the input image .flatten()
    # inputImage[np.isnan(inputImage)] = 0; #turn NaNs into 0s
    # # inputImage = np.interp(np.arange(0,varOpt.shape[0]),np.arange(0,inputImage.size),inputImage); #interpolate to variable size
    # inputImage = RegridderZenAccel(inputImage, yMatrix, xMatrix);  #interpolate to variable size using flawless regridder function
    # # inputImageInterp = np.interp(np.arange(0,nSets - np.int64(nSets/inputImage.size)*inputImage.size),np.arange(0,inputImage.size),inputImage); #interpolate prep
    # # inputImage = np.tile(inputImage,(1,np.int64(nSets/inputImage.size))).flatten(); #make it the size of the sets of variables
    # # inputImage = np.hstack((inputImage,inputImageInterp)); #finish making it the size of the sets of variables
    # #https://stackoverflow.com/questions/18522216/multiplying-across-in-a-numpy-array
    # # RD_input = inputImage[:,np.newaxis]*varOpt+varOpt; #mutiply "image
    # # outputImageSets = np.zeros( (outputImageShape[0],outputImageShape[1],nSets) ); #preallocate
    # # for j in range(0,nSets): #output is the total of a bunch of something
    # #     outputImageSets[:,:,j] = RD_eqForm(outputMeshXY,RD_input[j,:]).T; #get some values
    # # #END FOR j
    # # outputImage = np.mean(outputImageSets,axis=2);
    
    # RD_input = inputImage*varOpt+inputImage*varOpt+varOpt; #mutiply "image" into variable set, add too to prevent 0's wiping things out
    
    # output_data_predicted_RDM2 = RD_imageMake(RD_input,outputImageShape,outputMeshXY,nSets).ravel(); #function to speed stuff up
    
    # err_RDM2 = output_data-output_data_predicted_RDM2;
    # err_percDiff_RDM2 = np.abs(err_RDM2/output_data)*100;
    # err_rsq_RDM2 = 1-np.sum((err_RDM2)**2)/np.sum((output_data-np.mean(output_data))**2);
    # err_mse_RDM2 = ((err_RDM2)**2).mean();
    # err_multRator_RDM2 = np.nanmean(np.abs(output_data*output_data_predicted_RDM2 - output_data**2));
    
    # print('RazDazMod V2 % error: '+str(np.mean(err_percDiff_RDM2)));
    
    # corr = subfun_correlator(output_data,output_data_predicted_RDM2,plotName='Training RazDazModv2 TEC from '+str(magicks_AMPERE_dataTypes));
    
    # fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    # figManager = fig.canvas.manager; #req to maximize
    # figManager.window.showMaximized(); #force maximized
    # p1, = ax.plot(output_data);
    # p2, = ax.plot(output_data_predicted_RDM2);
    # ax.legend((p1,p2),('real','predicted'));
    # ax.set_title('Training RazDazModv2 TEC from '+str(magicks_AMPERE_dataTypes));
    # figFitter(fig);
    
    # #~~~~~ Razzle Dazzle mode 3 ~~~~~
    # from RazDazMod_conjuncture3 import varOnTrial as varOnTrial_v3, RD_maker
    # # from RegridderZenMats import RegridderZenMats
    # # from RegridderZenAccel import RegridderZenAccel
    # input_shape = input_data.shape;
    # if( output_data.ndim == 1 ):
    #     output_dataMatd = output_data.reshape(-1, 1); #add a dim
    # #END IF
    # output_shape = output_dataMatd.shape;
    
    
    # accelorPwr = 0.0000000005; #value to accelerate by (closer to 0 accelerates more)
    # # accelorPwr = 5e-12
    # # accelorPwr = 10**5; #value to accelerate by (closer to 0 accelerates more)
    # trialsAndTribulations = 200; #number of loops through the alg
    # nSets = (100,); #number of variable sets
    # nLayers = len(nSets); #number of layers
    # nVars = 4; #number of variables in a set (corresponds to RD_eqForm's varRow size)
    # nVignettes = 250; #number of various types of sets to try
    # ratingKeepPerc = 0.10; #a percentage to keep
    # bottomShufflePerc = 0.10; #a percentage to keep 
    # ratingKeep = np.int64(np.round(nVignettes*ratingKeepPerc)); #calc how many to keep in mind
    # bottomShuffle = np.int64(np.round(nVignettes*bottomShufflePerc)); #calc how many to keep in mind
    # bottomShuffleOrig = np.copy(bottomShuffle).item(); #prep original value
    # # varBottomShuffleThresh = 5; #if it's beent he same for 5 iterations start shaking the tree'
    # varSet = [None for i in range(0,nLayers)]; #Prep
    # arbiterSet = [None for i in range(0,nLayers+1)]; #Prep
    # for lyr in range(0,nLayers): #~~~ contiguous ~~~
    #     varSet[lyr] = 10**1*(np.random.uniform(size=(nVignettes,nSets[lyr],nVars) )-0.5); #prep the random variables
    #     if( lyr == 0 ):
    #         arbiterSet[lyr] = np.random.uniform(size=(nVignettes,input_data.shape[1],nSets[lyr]) ); #translate between input_data shape and nSets here
    #     else:
    #         arbiterSet[lyr] = np.random.uniform(size=(nVignettes,nSets[lyr-1],nSets[lyr]) ); #translate between prev nSets and nSets here
    #     #END IF
    # #END FOR i
    # arbiterSet[nLayers] = np.random.uniform(size=(nVignettes,output_shape[1],nSets[nLayers-1]) ); #translate between prev nSets and nSets here
    
    # # for lyr in range(0,nLayers): #~~~ anti-contiguous ~~~
    # #     varSet[lyr] = 10**1*(np.random.uniform(size=(nSets[lyr],nVars,nVignettes) )-0.5); #prep the random variables
    # #     if( lyr == 0 ):
    # #         arbiterSet[lyr] = np.random.uniform(size=(input_data.shape[1],nSets[lyr],nVignettes) ); #translate between input_data shape and nSets here
    # #     else:
    # #         arbiterSet[lyr] = np.random.uniform(size=(nSets[lyr-1],nSets[lyr],nVignettes) ); #translate between prev nSets and nSets here
    # #     #END IF
    # # #END FOR i
    # # arbiterSet[nLayers] = np.random.uniform(size=(output_shape[1],nSets[nLayers-1],nVignettes) ); #translate between prev nSets and nSets here
    # nImages = input_shape[0];
    
    # tic = time.time(); #start timing
    
    # from numba.typed import List as nlist
    # print('Beginning RazDazMod_v3');
    # varTop, arbiterTop, ratorTop = varOnTrial_v3(input_data,output_dataMatd,nVars,nSets,nLayers,nVignettes,nImages,trialsAndTribulations,nlist(varSet),nlist(arbiterSet),ratingKeep,bottomShuffle,bottomShuffleOrig,accelorPwr); #jit accelerate this work
    
    # varOptSet = [None for lyr in range(0,nLayers)];
    # varOptMeanSet = [None for lyr in range(0,nLayers)];
    # arbiterOptSet = [None for lyr in range(0,nLayers+1)];
    # arbiterMeanOptSet = [None for lyr in range(0,nLayers+1)];
    # for lyr in range(0,nLayers):
    #     varOptSet[lyr] = varTop[lyr][0,:,:]; #get the final optimal, based on the top instance
    #     arbiterOptSet[lyr] = arbiterTop[lyr][0,:,:]; #get the final optimal, based on the top instance
    #     varOptMeanSet[lyr] = np.mean(varTop[lyr],axis=0); #get the final optimal, based on the top instances
    #     arbiterMeanOptSet[lyr] = np.mean(arbiterTop[lyr],axis=0); #get the final optimal, based on the top instances
    # #END FOR lyr
    # arbiterOptSet[nLayers] = arbiterTop[nLayers][0,:,:]; #get the final optimal, based on the top instance
    # arbiterMeanOptSet[nLayers] = np.mean(arbiterTop[nLayers],axis=0); #get the final optimal, based on the top instances
    # toc = time.time() - tic; #end timing
    # print('\n\n\nTOP RATING: '+str(ratorTop[0])); #report top
    # print('Time to run: '+str(toc)+' sec | '+str(toc/60)+' min\n\n\n'); #report time to run
    
    # output_data_predicted_RDM3 = RD_maker(input_data,nlist(varOptSet),nlist(arbiterOptSet)); #function to speed stuff up
    
    # # output_data_predicted_RDM3 = RD_maker(input_data,nlist(varOptMeanSet),nlist(arbiterMeanOptSet)); #function to speed stuff up
    
    # err_RDM3 = output_dataMatd-output_data_predicted_RDM3;
    # err_percDiff_RDM3 = np.abs(err_RDM3/output_dataMatd)*100;
    # err_rsq_RDM3 = 1-np.sum((err_RDM3)**2)/np.sum((output_dataMatd-np.mean(output_dataMatd))**2);
    # err_mse_RDM3 = ((err_RDM3)**2).mean();
    # err_multRator_RDM3 = np.nanmean(np.abs(output_dataMatd*output_data_predicted_RDM3 - output_dataMatd**2));
    
    # print('RazDazMod V3 % error: '+str(np.mean(err_percDiff_RDM3)));
    
    # corr = subfun_correlator(output_data,output_data_predicted_RDM3.ravel(),plotName='Training RazDazModv3 TEC from '+str(magicks_AMPERE_dataTypes));

    # fig, ax = plt.subplots(nrows=1, ncols=1); #use instead of fig because it inits an axis too (I think I dunno)
    # figManager = fig.canvas.manager; #req to maximize
    # figManager.window.showMaximized(); #force maximized
    # p1, = ax.plot(output_data);
    # p2, = ax.plot(output_data_predicted_RDM3);
    # ax.legend((p1,p2),('real','predicted'));
    # ax.set_title('Training RazDazModv3 TEC from '+str(magicks_AMPERE_dataTypes));
    # figFitter(fig);
#END IF

      
#****************************************************************MOVIE ANALYSIS****************************************************************
#!!! Make Animated Gif of TEC with Time - Fixed Dot Version !!!
if(FLG_movieCreation_enable == 1): #if the flag for this is on, do it!
    GRITI_movieMaker(data, dates, settings); #call the movie maker creation function (big!)
#END IF MOVIE CREATION
    
    
if( FLG_enable_movieSnaps  == 1 ):
#!!! SNAP TIMES !!! 
    import matplotlib.gridspec as gridspec
    from cartopy.feature.nightshade import Nightshade
    from Code.GRITI_plotHelper_area_init import GRITI_plotHelper_area_init
    from Code.GRITI_plotHelper_axisizerLatLong import GRITI_plotHelper_axisizerLatLong
    from Code.subfun_figFitter import figFitter
    
    #----------------------GENERAL PREP-----------------------------
    if( settings_plot['save file type'].lower() != '.pdf' ):
        snaps_rasterize = False; #don't need to bother
    else:
        snaps_rasterize = True; #it needs it
    #END IF
    
    #----------------------PRIME THE SNAP SHOT TIMES-----------------------------
    if( snaps_auto_start == 'auto' ):
        snaps_auto_start = dateRange_zeroHr_hrBounds[0]; #automatically set it to the minimum hour bounds
    #END IF
    if( snaps_auto_end == 'auto' ):
        snaps_auto_end = dateRange_zeroHr_hrBounds[-1]; #automatically set it to the maximum hour bounds
    #END IF
    if( snaps_auto == 0 ): #use manually defined snap_times
        snaps_times = np.array( snaps_times ); #convert to useful form, makes it bulky to have it declared like this tho
    elif( snaps_auto == 1 ): #otherwise auto make snap_times
        snaps_times = np.arange(0,snaps_auto_stepsToTake)*snaps_auto_step/60+snaps_auto_start; #make snap_times automagically
    elif( snaps_auto == 2 ):
        snaps_auto_stepsToTake = np.round((snaps_auto_end - snaps_auto_start)/(snaps_auto_step/60)); #calculate stepsToTake based off of _end automagically
        snaps_times = np.arange(0,snaps_auto_stepsToTake)*snaps_auto_step/60+snaps_auto_start; #make snap_times automagically
    #END IF
    snaps_timesDays = snaps_times/24+dateRange_dayNum_zeroHr[1]; #days, convert to days for comparison with stuff
    snaps_timesSec = snaps_times*3600+dateRange_dayNum_zeroHr[1]*86400; #sec, convert to sec for comparison with stuff
    
    #----------------------CHOOSE THE CORRECT ARRANGEMENT-----------------------------
    snaps_supported_plotsPerPlot = np.array((4, 6, 9, 12));
    snaps_optimal_plotsPerPlot = np.where( np.mod(snaps_timesDays.size/snaps_supported_plotsPerPlot,1) == np.min(np.mod(snaps_timesDays.size/snaps_supported_plotsPerPlot,1)))[0];
    # snaps_optimal_plotsPerPlot = snaps_optimal_plotsPerPlot[snaps_optimal_plotsPerPlot.size//2]; #choose middle option
    snaps_optimal_plotsPerPlot = snaps_optimal_plotsPerPlot[-1]; #choose last (densist) option
    snaps_chosen_plotsPerPlot = snaps_supported_plotsPerPlot[snaps_optimal_plotsPerPlot]; #choose a size
    snaps_chosen_plotNum = np.int64(np.ceil(snaps_times.size/snaps_chosen_plotsPerPlot)); #calc the number of plots needed
    snaps_chosen_plotsPerPlot_vect = np.arange(0,snaps_times.size+snaps_chosen_plotsPerPlot,snaps_chosen_plotsPerPlot);
    
    #----------------------PRIME TTHE SNAP SHOT ARRANGEMENT-----------------------------
    if( snaps_chosen_plotsPerPlot == 4 ):
        snaps_rows = 2; #set pre-determined row/col stuff
        snaps_cols = 2;
        
        snaps_left = 0.045; #for the figure to adjust its sizing
        snaps_right = 0.945;
        snaps_top = 0.96;
        snaps_bottom = 0.035;  
        snaps_hspace = 0.135; 
        snaps_wspace = 0.265;
    elif( snaps_chosen_plotsPerPlot == 6 ):
        snaps_rows = 2; #set pre-determined row/col stuff
        snaps_cols = 3;
        
        snaps_left = 0.045; #for the figure to adjust its sizing
        snaps_right = 0.945;
        snaps_top = 0.96;
        snaps_bottom = 0.035;  
        snaps_hspace = 0.155; 
        snaps_wspace = 0.265;
    elif( snaps_chosen_plotsPerPlot == 9 ):
        snaps_rows = 3; #set pre-determined row/col stuff
        snaps_cols = 3;
        
        snaps_left = 0.045; #for the figure to adjust its sizing
        snaps_right = 0.945;
        snaps_top = 0.96;
        snaps_bottom = 0.035;  
        snaps_hspace = 0.225; 
        snaps_wspace = 0.205;
    elif( snaps_chosen_plotsPerPlot == 12 ):
        snaps_rows = 3; #set pre-determined row/col stuff
        snaps_cols = 4;
        
        # snaps_left = 0.045; #for the figure to adjust its sizing
        # snaps_right = 0.945;
        # snaps_top = 0.96;
        # snaps_bottom = 0.035;  
        snaps_hspace = 0.225; 
        snaps_wspace = 0.195;
    # elif( snaps_chosen_plotsPerPlot == 16 ): #too dense
    #     snaps_rows = 4; #set pre-determined row/col stuff
    #     snaps_cols = 4;
        
    #     # snaps_left = 0.045; #for the figure to adjust its sizing
    #     # snaps_right = 0.945;
    #     # snaps_top = 0.96;
    #     # snaps_bottom = 0.035;  
    #     # snaps_hspace = 0.225; 
    #     snaps_wspace = 0.195;
    else:
        print('\nERROR:\nIN SNAPS FUNCTION - UNSUPPORTED SUBPLOT NUMBER OF '+str(snaps_times.size)+' REQUESTED. GIVING UP.\n');
        sys.crash(); #yeet that program
    #END IF
    
    
    #----------------------CALCULATE SUNRISE SUNSET TIMES----------------------
    # #SECOND STEP: CALC LOCAL SUNRISE/SUNSET TIMES
    # #calcs done in UT/GMT
    # # based on calc steps in https://www.mathworks.com/examples/matlab/community/21093-estimating-sunrise-and-sunset
    # #Preallocate
    # dayNite_Grid_size = 1000; #number to subdivide grid into
    # dayNite_sunrise = np.zeros( (dayNite_Grid_size,dayNite_Grid_size,dateRange_dayNum_full.shape[0]) ,dtype=np.float64); #hr UT, prep sunrise time for each day in the lat/long grid
    # dayNite_sunset = np.zeros( (dayNite_Grid_size,dayNite_Grid_size,dateRange_dayNum_full.shape[0]) ,dtype=np.float64); #hr UT, prep sunset time for each day in the lat/long grid
    # [dayNite_Grid_Long,dayNite_Grid_Lat] = np.meshgrid(np.linspace(np.min(plotLongRange),np.max(plotLongRange),dayNite_Grid_size),np.linspace(np.min(plotLatRange),np.max(plotLatRange),dayNite_Grid_size)); #degc, make two matrixes that have all the corresponding points in a lat/long grid
    # dayNite_long_corrected = 4*(dayNite_Grid_Long); #calc corrected longitude, for sunrise/sunset time
    
    # for i in range(0,dateRange_dayNum_full.shape[0]):
    
    #     dayNite_B = 360*(dateRange_dayNum_full[i,1] - 81)/365*np.pi/180; #rad, some sort of angle based on days and stuff
    #     dayNite_EoT_corrected = 9.87*np.sin(2*dayNite_B) - 7.53*np.cos(dayNite_B) - 1.5*np.sin(dayNite_B); #eq for Time Correction
    #     dayNite_solar_corrected = dayNite_long_corrected + np.tile(dayNite_EoT_corrected,(dayNite_Grid_size,dayNite_Grid_size) ); #min, solar time correction - for noon
    
    #     dayNite_solar_declination = np.arcsin(np.sin(23.45*np.pi/180)*np.sin(360*(dateRange_dayNum_full[i,1] - 81)/365*np.pi/180)); #rad, solar declination
    
    #     dayNite_temp = -np.tan(dayNite_Grid_Lat*np.pi/180)*np.tan(dayNite_solar_declination); #calc some mid step
    # #     dayNite_temp( dayNite_temp >= 1 ) = dayNite_temp( dayNite_temp >= 1 ) - -2*(1 - dayNite_temp( dayNite_temp >= 1 )); #attempt a flip
    # #     dayNite_temp( dayNite_temp <= -1) = dayNite_temp( dayNite_temp <= -1) + -2*(1 + dayNite_temp( dayNite_temp <= -1) ); #attempt a flip
    #     k = (dayNite_temp[:,0] <= -1) | (dayNite_temp[:,0] >= 1); #prep to replace these
    # #     kF = find(k == 1,1,'first');
        
    #     dayNite_sunrise[:,:,i] = 12 - np.real(np.arccos(dayNite_temp)*180/np.pi)/15 - dayNite_solar_corrected/60; #hr UT, sunrise time
    # #     for(j = 1:dayNite_Grid_size) %interpolation didn't work - too precipitous
    # #         dayNite_sunrise(k,j,i) = interp1(1:1:(kF-1),dayNite_sunrise(~k,j,i),kF:1:dayNite_Grid_size,'spline','extrap'); %interp for each long set (calc oofs out at specific lat)
    # #     end
    #     dayNite_sunset[:,:,i] = 12 + np.real(np.arccos(dayNite_temp)*180/np.pi)/15 - dayNite_solar_corrected/60; #hr UT, sunrise time
    #     #Accurate to like 10 minutes or whatever (breaks at high latitudes...)
        
    #     dayNite_sunrise[k,:,i] = np.nan; #remove data that we can't calc with this alg
    #     dayNite_sunset[k,:,i] = np.nan; #remove data that we can't calc with this alg
        
    #     dayNite_sunrise[:,:,i] = dayNite_sunrise[:,:,i] + dateRange_zeroHr_hrs[i]; #adjust to make it align to the hourly schedule
    #     dayNite_sunset[:,:,i] = dayNite_sunset[:,:,i] + dateRange_zeroHr_hrs[i]; #adjust to make it align to the hourly schedule
    # #EMD FOR i
    
    # #yo I straight up just transpose and reshape in different ways till it works how I want, matlab's is so much easier
    # dayNite_sunrise =  np.reshape(dayNite_sunrise.transpose(2,1,0), (dayNite_Grid_size*dateRange_dayNum_full.shape[0], dayNite_Grid_size) ).T; #reshape into one big thing since each day's 6 AM sunrise or whatever is now per-day (+/-24 etc)
    # dayNite_sunset = np.reshape(dayNite_sunset.transpose(2,1,0), (dayNite_Grid_size*dateRange_dayNum_full.shape[0], dayNite_Grid_size) ).T; #reshape into one big thing since each day's 6 AM sunrise or whatever is now per-day (+/-24 etc)
    # dayNite_Grid_Lat = np.tile(dayNite_Grid_Lat, (1, dateRange_dayNum_full.shape[0]) ); #copy this to match above 1:1
    # dayNite_Grid_Long = np.tile(dayNite_Grid_Long, (1, dateRange_dayNum_full.shape[0]) ); #copy this to match above 1:1
    if( ((snaps_type == 11) | (snaps_type == 12)) & \
       ((np.isclose(np.min(plotLatRange),40) & np.isclose(np.max(plotLatRange),90)) | \
        (np.isclose(np.min(plotLatRange),-90) & np.isclose(np.max(plotLatRange),40))) & \
       (np.isclose(np.min(plotLongRange),-180) & np.isclose(np.max(plotLongRange),180)) & \
       ((settings_map['projection name'] != 'npstere') | (settings_map['projection name'] != 'spstere')) ):
        
        settings_map_snaps = copy.deepcopy(settings_map); #copy it
        if( np.isclose(np.min(plotLatRange),40) & np.isclose(np.max(plotLatRange),90) ):
            settings_map_snaps['projection'] = cartopy.crs.NorthPolarStereo(); #set the projection type to use
            settings_map_snaps['projection name'] = 'npstere';
        else:
            settings_map_snaps['projection'] = cartopy.crs.SouthPolarStereo(); #set the projection type to use
            settings_map_snaps['projection name'] = 'spstere';
        #END IF
        geoMap_projectionStyle_polar = 1; #oop it's actually this
    else:
        settings_map_snaps = settings_map; #alias it
    #END IF
    
    if( snaps_sunPos == 1 ):
        FLG_sunSpin = 0; #no spin for now, cartopy can't spin it seems
        from Code.subfun_sunAlsoRises_location import sunAlsoRises_location
        sunSubSolar_loc_geo = sunAlsoRises_location(dateRange_dayNum_full, timeIndexes=snaps_timesSec, timeZone='UTC'); #calc sun locations
        
        if( settings_map_snaps['coord type'] == 'mag' ):
            if( (snaps_type == 11) | (snaps_type == 12) ):
                if( 'altitude' in settings_AMPERE ):
                    magCalcAlt = settings_AMPERE['altitude']; #use AMPERE altitude
                else:
                    magCalcAlt = 120.; #default, great for auroral zone stuff (like field aligned currents)
                #END IF
            else:
                magCalcAlt = np.median(data['TEC']['pierceAlt']); #use TEC if TEC involved instead
            #END IF
            time4mag_hr = np.int32(np.mod(snaps_timesSec, 86400)//3600); #get hours
            time4mag_min = np.int32(np.mod(snaps_timesSec, 86400)//60-time4mag_hr*60); #get the minutes
            time4mag_sec = np.int32(np.mod(snaps_timesSec, 86400)-time4mag_min*60-time4mag_hr*3600); #get the seconds
            sunSubSolar_loc = copy.deepcopy(sunSubSolar_loc_geo); #copy it to overwrite it
            for jj in range(0, snaps_timesSec.size): #easier to loop for now
                kk = np.where(np.int64(snaps_timesSec[jj]/86400) == dates['date range full dayNum'][:,1])[0].item(); #get where the year is gonna be
                time4mag = datetime.datetime(dates['date range full'][kk,0],dates['date range full'][kk,1],dates['date range full'][kk,2], \
                                             hour = time4mag_hr[jj], minute = time4mag_min[jj], second = time4mag_sec[jj]); #date time object for aacgmv2
                #---nan result protection---
                incrementor = 0; #increments
                tempLat = np.nan; #set nan to start
                tempLong = np.nan;
                while( np.isnan(tempLat) | np.isnan(tempLong) ):
                    tempAlt = magCalcAlt+incrementor*100;
                    # if( tempAlt > 2000 ):
                    #     tempTrace = True;
                    # else:
                    #     tempTrace = False;
                    # #END IF
                    [tempLat, tempLong, _] = aacgmv2.convert_latlon(sunSubSolar_loc_geo['lat'][jj], sunSubSolar_loc_geo['long'][jj], tempAlt, time4mag, method_code='G2A|ALLOWTRACE'); #converts from geographic to geomagnetic (AACGMv2)
                    incrementor += 1; #increment
                    if( incrementor > 40 ):
                        break
                    #END IF
                #END WHILE
                sunSubSolar_loc['lat'][jj] = tempLat; #record, this way we avoid NaNs (but get spammed, oh well)
                sunSubSolar_loc['long'][jj] = tempLong;
            #END FOR jj
        else:
            sunSubSolar_loc = sunSubSolar_loc_geo; #alias
        #END IF
    #END IF
        
    #----------------------MAKE CUSTOM AUTOTICKS FOR THESE CRUNCHED SUBPLOTS----------------------
    #plot help with autotick calculating
    plotLongRange_autoTick = (np.max(plotLongRange) - np.min(plotLongRange))/(20/snaps_cols); #tries to split the longitude range into 20 parts (based off of what fits goodish) a nd divided by the number of columns
    if( plotLongRange_autoTick > 10 ):
        plotLongRange_autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
    elif( plotLongRange_autoTick > 5 ):
        plotLongRange_autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
    elif( plotLongRange_autoTick > 2 ):
        plotLongRange_autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
    elif( plotLongRange_autoTick > 1 ):
        plotLongRange_autoTick = 2; #sets the tick setting to 2 arcdegrees per tick
    elif( plotLongRange_autoTick >= 0.6 ): #0.6 because 15/25 = 0.6, so there will be enough 1 arcdeg ticks
        plotLongRange_autoTick = 1; #sets the tick setting to 1 arcdegree per tick
    else:
        plotLongRange_autoTick = (np.max(plotLongRange) - np.min(plotLongRange))/15; #just goes for it if it's a super tiny range
    #END IF
    plotLatRange_autoTick = (np.max(plotLatRange) - np.min(plotLatRange))/(16/snaps_rows); #tries to split the latitude range into 16 parts (based off of what fits goodish) and divided by the number of rows
    if( plotLatRange_autoTick > 10 ):
        plotLatRange_autoTick = 15; #sets the tick setting to 15 arcdegrees per tick
    elif( plotLatRange_autoTick > 5 ):
        plotLatRange_autoTick = 10; #sets the tick setting to 10 arcdegrees per tick
    elif( plotLatRange_autoTick > 2 ):
        plotLatRange_autoTick = 5; #sets the tick setting to 5 arcdegrees per tick
    elif( plotLatRange_autoTick > 1 ):
        plotLatRange_autoTick = 2; #sets the tick setting to 2 arcdegrees per tick
    elif( plotLatRange_autoTick > 0.75 ): #0.75 because 10/13 = 0.76something and it sounded good for enough 1 arcdeg ticks
        plotLatRange_autoTick = 1; #sets the tick setting to 1 arcdegree per tick
    else:
        plotLatRange_autoTick = (np.max(plotLatRange) - np.min(plotLatRange))/15; #just goes for it if it's a super tiny range
    #END IF
    
        
    #----------------------PRIME THE FIGURE WINDOW-----------------------------
    #get some arrays that indentify the indexes of the plots [0,0], [0,1], etc.
    snaps_rowsArray, snaps_colsArray = np.meshgrid( np.arange(0,snaps_rows) , np.arange(0,snaps_cols) );
    snaps_rowsArray = np.ndarray.flatten(snaps_rowsArray.T); #yy stuff
    snaps_colsArray = np.ndarray.flatten(snaps_colsArray.T); #xx stuff
    
    #----------------------PRIME THE LAT/LONG GRID-----------------------------
    if( FLG_snaps_grid_spaces_auto == 1 ):
        snaps_Grid_Long_Size = snaps_Grid_Lat_Size/1.0; #degc, calc the long avg square size - hard-coded ratio for now
        snaps_Grid_Lat_Spaces = np.int64(np.round((np.max(plotLatRange)-np.min(plotLatRange))/snaps_Grid_Lat_Size,0)); #calc the number of spaces
        snaps_Grid_Long_Spaces = np.int64(np.round((np.max(plotLongRange)-np.min(plotLongRange))/snaps_Grid_Long_Size,0)); #calc the number of spaces
    #END IF
    
    gif_Grid_Lat = np.linspace(np.min(plotLatRange),np.max(plotLatRange),snaps_Grid_Lat_Spaces+1); #degc, create lat points (+1 lets us use delta to edge wanted range - yields correct # of spaces)
    gif_Grid_Long = np.linspace(np.min(plotLongRange),np.max(plotLongRange),snaps_Grid_Long_Spaces+1); #degc, create long points (+1 lets us use delta to edge wanted range - yields correct # of spaces)
    gif_Grid_Lat_Delta = np.abs(gif_Grid_Lat[1] - gif_Grid_Lat[0]); #degc, lat delta
    gif_Grid_Long_Delta = np.abs(gif_Grid_Long[1] - gif_Grid_Long[0]); #degc, long delta
    
    for snpz in range(0,snaps_chosen_plotNum): #start making multiple pictures
        #fire up the figure
        
        FLG_fancyPlot_curr = 1; #manually turn on here for now
        
        # #Prime the plot
        if( FLG_fancyPlot_curr == 0 ):
            fig = plt.figure();
            figManager = fig.canvas.manager; #req to maximize
            figManager.window.showMaximized(); #force maximized
        else:
            plt.ioff() #disable showing the plot as its size will be larger than the screen, which cannot happen if the plot is shown
            fig = plt.figure(figsize=(14,14.5),dpi=journal_dpi);
        #END IF
        
        if( snaps_type not in [5] ):
            #one colorbar needed
            gridr = gridspec.GridSpec(nrows=snaps_rows, ncols=snaps_cols+1, figure=fig, width_ratios=np.append(np.repeat(30,snaps_cols),1)); #make a grid (used in case need larger than 1 "grid" plots)
            if( FLG_fancyPlot_curr == 0 ):
                gridr.update(wspace=0.05); # set the spacing between axes.
            else:
                gridr.update(hspace=0.12,wspace=0.05); # set the spacing between axes.
            #END IF
            #this just won't activate anywhere else - so putting it at the end
            ax = np.empty([snaps_rows,snaps_cols],dtype=object); #preallocate
            for i in range(0,snaps_rows):
                for j in range(0,snaps_cols):
                    ax[i,j] = plt.subplot(gridr[i,j], projection=settings_map['projection']); #create the axes
                    # ax[i,j].set_aspect('auto'); #Remove the aspect ratio from the basemap so it fills the screen better
                #END FOR j
            #END FOR i
        else:
            #double colorbar needs minor adjustments
            gridr = gridspec.GridSpec(nrows=snaps_rows, ncols=snaps_cols+2, figure=fig, width_ratios=np.append(np.insert(np.repeat(30,snaps_cols),0,1),1)); #make a grid (used in case need larger than 1 "grid" plots)
            if( FLG_fancyPlot_curr == 0 ):
                gridr.update(wspace=0.05); # set the spacing between axes.
            else:
                gridr.update(hspace=0.12,wspace=0.05); # set the spacing between axes.
            #END IF
            #this just won't activate anywhere else - so putting it at the end
            ax = np.empty([snaps_rows,snaps_cols],dtype=object); #preallocate
            for i in range(0,snaps_rows):
                for j in range(1,snaps_cols+1):
                    ax[i,j-1] = plt.subplot(gridr[i,j], projection=settings_map['projection']); #create the axes
                    # ax[i,j].set_aspect('auto'); #Remove the aspect ratio from the basemap so it fills the screen better
                #END FOR j
            #END FOR i
        #END IF, 
        
        for i in range(0,snaps_chosen_plotsPerPlot):     
            fig.canvas.flush_events(); #this is req. to get get_window_extent() to get the current window size
            #Remove the aspect ratio from the basemap so it fills the screen better
            ax[snaps_rowsArray[i],snaps_colsArray[i]].set_aspect('auto');
        #END FOR i
        
        #----------------------CREATE THE SNAPS----------------------
        if( snaps_type == 1 ):
            #------------Time keeping for various data sources-------------
            snaps_times_curr = snaps_times[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]]; #pull out the current snaps_times
            snaps_times_currDays = snaps_timesDays[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]]; #pull out the current snaps_times
            snaps_times_currSec = snaps_timesSec[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]]; #pull out the current snaps_times
            #-------------------------Start Making Pictures------------------------
            for i in range(0,snaps_chosen_plotsPerPlot):
                if( i+1 <= snaps_times_curr.size ): #this if statement allows for empty subplots if things didn't divide evenly
                    #------------Make human readable time-------------
                    if( np.int64(np.round(np.abs(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60)-np.int64(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60)))*60,2)) == 0 ):
                        snaps_timeReadable = str(np.int64(snaps_times_curr[i])).zfill(2)+':'+str(np.int64(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60))).zfill(2); #create a human-readable time, no seconds
                    else:
                        snaps_timeReadable = str(np.int64(snaps_times_curr[i])).zfill(2)+':'+str(np.int64(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60))).zfill(2)+':'+\
                            str( np.int64(np.round(np.abs(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60)-np.int64(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60)))*60,2)) ).zfill(2); #create a human-readable time
                        if( snaps_timeReadable[-2:] == '60' ): #fix 60 second issue
                            snaps_timeReadable = str(np.int64(snaps_times_curr[i])).zfill(2)+':'+str(np.int64(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60+1))).zfill(2); #create a human-readable time
                        #END IF
                    #END IF
                    
                    #----------------Corral the data to the right place----------------
                    k =  np.where( np.min(np.abs(data['TEC']['time'] - snaps_times_currSec[i])) == np.abs(data['TEC']['time'] - snaps_times_currSec[i]) ) [0]; #gets during a time period
                    vTEC_portion = data['TEC']['dTEC'][k]; #pull out the vTEC now
                    pplat_portion = data['TEC']['lat'][k]; #get the pplat (pierce-point lat) at the time required
                    pplong_portion = data['TEC']['long'][k]; #get the pplong (pierce-point long) at the time required
                                
                    gif_Grid = GRITI_movieMaker_subfun_dataGridder(pplat_portion,pplong_portion,vTEC_portion,gif_Grid_Lat,gif_Grid_Long,snaps_Grid_Lat_Spaces,snaps_Grid_Long_Spaces,gif_Grid_Lat_Delta,gif_Grid_Long_Delta,dataRejectOrig,dataRejectLimitOrig,dataRejectMax);
                    #call a numba'd function that makes the movie quicker by crunching the numbers gooder
                    
                    #----------------------------Tack on Title-------------------------
                    # string_title = 'Time =  '+'{0:.2f}'.format(np.round(snaps_times_curr[i],2))+\
                    #     ', '+snaps_timeReadable; #create mecha title
                    string_title = snaps_timeReadable; #create mecha title
                    
                    if( geoMap_projectionStyle_polar == 0 ):
                        ax[snaps_rowsArray[i],snaps_colsArray[i]].set_title(string_title,fontproperties=FONT_titleFM); #set the title
                    else:
                        ax[snaps_rowsArray[i],snaps_colsArray[i]].set_title(string_title,fontproperties=FONT_titleFM,y=1.035); #set the title
                    #END IF
                                        
                    #-------------------Starting the Plotting--------------------------
                    kk = np.where(np.int64(snaps_times_currSec[i]/86400) == dates['date range full dayNum'][:,1])[0].item(); #get where the year is gonna be
                    time4mag_hr = np.int32(np.mod(snaps_times_currSec[i],86400)//3600); #get hours
                    time4mag_min = np.int32(np.mod(snaps_times_currSec[i],86400)//60-time4mag_hr*60); #get the minutes
                    time4mag_sec = np.int32(np.mod(snaps_times_currSec[i],86400)-time4mag_min*60-time4mag_hr*3600); #get the seconds
                    time4mag = datetime.datetime(dates['date range full'][kk,0],dates['date range full'][kk,1],dates['date range full'][kk,2], \
                                                 hour = time4mag_hr, minute = time4mag_min, second = time4mag_sec); #date time object for aacgmv2    
                    
                    if( (geoMap_projectionStyle_polar == 1) & (snaps_colsArray[i] == np.min(snaps_colsArray)) & (snaps_rowsArray[i] == np.min(snaps_rowsArray)) ):
                        FLG_latLabel= False;
                        FLG_longLabel= True;
                    elif( (geoMap_projectionStyle_polar == 1) & (snaps_colsArray[i] == (np.min(snaps_colsArray)+1)) & (snaps_rowsArray[i] == np.min(snaps_rowsArray)) ):
                        FLG_latLabel= True;
                        FLG_longLabel= False;
                    elif( geoMap_projectionStyle_polar == 1 ):
                        FLG_latLabel= False;
                        FLG_longLabel= False;
                    else:
                        FLG_latLabel= True;
                        FLG_longLabel= True;
                    #END IF
                        
                    ax[snaps_rowsArray[i],snaps_colsArray[i]] = GRITI_plotHelper_area_init(plotLatRange, plotLongRange, settings_map, settings_plot, FLG_fancyPlot, time4mag=time4mag, alt4mag=settings['TEC']['pierceAlt'], figAlreadyInfo={'fig':fig,'ax':ax[snaps_rowsArray[i],snaps_colsArray[i]],'fancy plot':FLG_fancyPlot_curr},FLG_latLabel=FLG_latLabel,FLG_longLabel=FLG_longLabel); #init a cartopy thing
    
                    #Do the TEC plotting
                    pltHelprX, pltHelprY = np.meshgrid( gif_Grid_Long, gif_Grid_Lat); #helps the pcolor work
                    imTEC = ax[snaps_rowsArray[i],snaps_colsArray[i]].pcolormesh(pltHelprX, pltHelprY,  gif_Grid.T ,vmin=np.min(settings_TEC['plot lim']), vmax=np.max(settings_TEC['plot lim']), transform=cartopy.crs.PlateCarree(), cmap='jet', zorder=150); # pseudocolor plot "stretched" to the grid
                    
                    ax[snaps_rowsArray[i],snaps_colsArray[i]].add_feature(Nightshade(time4mag, alpha=0.2),zorder=150); #nighttime shading
                    
                    #Now drawing point of interest
                    # Millstone_latLongMapped = geoMap(longMillstone,latMillstone); #convert the lat/long arcdeg to the current map coordinates
                    if( (latMillstone <= np.max(plotLatRange)) & (latMillstone >= np.min(plotLatRange)) & (longMillstone <= np.max(plotLongRange)) & (longMillstone >= np.min(plotLongRange)) ):
                        imMillstone = ax[snaps_rowsArray[i],snaps_colsArray[i]].plot(longMillstone,latMillstone,marker=gif_Millstone_Marker, color=gif_Millstone_Marker_Color, markersize=gif_Millstone_Marker_Size, zorder=550); #plot this, 50 always on top
                    #END IF
                    
                    if(geoMap_projectionStyle_polar == 0):
                        if( snaps_colsArray[i] == np.min(snaps_colsArray) ):
                            GRITI_plotHelper_axisizerLatLong(plotLatRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='y',tickNumGoal=10,tickReducer=1,FLG_removeLabels=False);
                        else:
                            GRITI_plotHelper_axisizerLatLong(plotLatRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='y',tickNumGoal=10,tickReducer=1,FLG_removeLabels=True);
                        #END IF
                        if( snaps_rowsArray[i] == np.max(snaps_rowsArray) ):
                            GRITI_plotHelper_axisizerLatLong(plotLongRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='x',tickNumGoal=6,tickReducer=1,FLG_removeLabels=False);
                        else:
                            GRITI_plotHelper_axisizerLatLong(plotLongRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='x',tickNumGoal=6,tickReducer=1,FLG_removeLabels=True);
                        #END IF
                    #END IF
                #END IF
            #END FOR i
            axEnd = plt.subplot(gridr[:,-1]); #create an axis for the cbar
            cbar = fig.colorbar(imTEC, cax=axEnd, orientation='vertical', aspect=50); #aspect=50 makes it thin
            cbar.set_ticks(np.linspace(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim']),11)); #create useful tick marks
            # cax.yaxis.set_major_formatter(FormatStrFormatter('%.2f')); #force a rounded format
            cbar.set_label('delta-vTEC [TECU]'); #tabel the colorbar
            cbar.ax.tick_params(labelsize=FONT_axisTick);
            cbar.mappable.set_clim(vmin=np.min(settings_TEC['plot lim']), vmax=np.max(settings_TEC['plot lim']));
            
        elif( snaps_type == 5 ):
            #------------Time keeping for various data sources-------------
            AMPERE_dataRate = data['AMPERE']['data rate']; #days, get the median data rate for AMPERE data (avoids outliers)
            
            snaps_times_curr = snaps_times[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]]; #pull out the current snaps_times
            snaps_times_currDays = snaps_timesDays[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]]; #pull out the current snaps_times
            snaps_times_currSec = snaps_timesSec[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]]; #pull out the current snaps_times
            #-------------------------Start Making Pictures------------------------
            for i in range(0,snaps_chosen_plotsPerPlot):     
                #------------Make human readable time-------------
                if( np.int64(np.round(np.abs(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60)-np.int64(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60)))*60,2)) == 0 ):
                    snaps_timeReadable = str(np.int64(snaps_times_curr[i])).zfill(2)+':'+str(np.int64(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60))).zfill(2); #create a human-readable time, no seconds
                else:
                    snaps_timeReadable = str(np.int64(snaps_times_curr[i])).zfill(2)+':'+str(np.int64(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60))).zfill(2)+':'+\
                        str( np.int64(np.round(np.abs(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60)-np.int64(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60)))*60,2)) ).zfill(2); #create a human-readable time
                #END IF
                
                #------------Corral the AMPERE data to the right place-------------
                k = np.where( (data['AMPERE']['time'] <= snaps_times_currSec[i]) & (data['AMPERE']['time'] >= (snaps_times_currSec[i]-AMPERE_dataRate)) )[0]; #get where the time point is, make sure it is within the data rate window
                AMPERE_data_portion = data['AMPERE'][settings['AMPERE']['data type']][k]; #ergs/(cm^2*sec), get the Joule Heating for the current time step
                AMPERE_lat_portion = data['AMPERE']['lat'][k]; #degc, corresponding lat values
                AMPERE_long_portion = data['AMPERE']['long'][k]; #degc, corresponding long values
                
                #----------------Corral the data to the right place----------------
                k =  np.where( np.min(np.abs(data['TEC']['time'] - snaps_times_currSec[i])) == np.abs(data['TEC']['time'] - snaps_times_currSec[i]) ) [0]; #gets during a time period
                vTEC_portion = data['TEC']['dTEC'][k]; #pull out the vTEC now
                pplat_portion = data['TEC']['lat'][k]; #get the pplat (pierce-point lat) at the time required
                pplong_portion = data['TEC']['long'][k]; #get the pplong (pierce-point long) at the time required
                            
                gif_Grid = GRITI_movieMaker_subfun_dataGridder(pplat_portion,pplong_portion,vTEC_portion,gif_Grid_Lat,gif_Grid_Long,snaps_Grid_Lat_Spaces,snaps_Grid_Long_Spaces,gif_Grid_Lat_Delta,gif_Grid_Long_Delta,dataRejectOrig,dataRejectLimitOrig,dataRejectMax);
                #call a numba'd function that makes the movie quicker by crunching the numbers gooder
                
                #----------------------------Tack on Title-------------------------
                # string_title = 'Time =  '+'{0:.2f}'.format(np.round(snaps_times_curr[i],2))+\
                #     ', '+snaps_timeReadable; #create mecha title
                # ax[snaps_rowsArray[i],snaps_colsArray[i]].set_title(string_title,fontproperties=FONT_titleFM); #set the title, properties always needed
                string_title = snaps_timeReadable; #create mecha title
                
                if( geoMap_projectionStyle_polar == 0 ):
                    ax[snaps_rowsArray[i],snaps_colsArray[i]].set_title(string_title,fontproperties=FONT_titleFM); #set the title
                else:
                    ax[snaps_rowsArray[i],snaps_colsArray[i]].set_title(string_title,fontproperties=FONT_titleFM,y=1.035); #set the title
                #END IF 
                
                #-------------------Starting the Plotting--------------------------
    
                # #prime the colorbars
                # if( snaps_colsArray[i] == np.max(snaps_colsArray) ): #only plot the label on the right side
                #     divider = make_axes_locatable(ax[snaps_rowsArray[i],snaps_colsArray[i]]); #prep to add an axis
                #     cax = divider.append_axes('right', size='3%', pad=0.35); #make a color bar axis
                #     cax.yaxis.label.set_font_properties(FONT_axisLabelFM);
                # #END IF
                # if( snaps_colsArray[i] == np.min(snaps_colsArray) ): #only plot the label on the left side
                #     divider = make_axes_locatable(ax[snaps_rowsArray[i],snaps_colsArray[i]]); #prep to add an axis
                #     cax2 = divider.append_axes('left', size='3%', pad=0.65); #make a color bar axis
                #     cax2.yaxis.label.set_font_properties(FONT_axisLabelFM);
                # #END IF
                            
                # #Prime the basemap for each axis
                # geoMap = Basemap(projection=geoMap_projectionStyle, lat_0=np.mean(plotLatRange), lon_0=np.mean(plotLongRange), #projection type, and I think lat_0/lon_0 are the centers?
                #     resolution = 'i', area_thresh = 10000, ax=ax[snaps_rowsArray[i],snaps_colsArray[i]], #resolutions I know are l, i, h - i seems good. area_thresh being big prevents it drawing lil lakes, 0.1 makes everything
                #     llcrnrlon=np.float32(plotLongRange[0]), llcrnrlat=np.float32(plotLatRange[0]), #lower left corner lat/long - MUST BE FLOAT cause CODED BY THE BEST
                #     urcrnrlon=np.float32(plotLongRange[1]), urcrnrlat=np.float32(plotLatRange[1])); #upper right corner lat/long - MUST BE FLOAT cause CODED BY THE BEST
    
                # geoMap.drawcoastlines(zorder=25); #always on top
                # if( gif_ContinentFill == 1 ): #color in stuff if this is on
                #     #geoMap.drawcountries();
                #     #geoMap.drawmapboundary();
                #     geoMap.fillcontinents(color=gif_ContientColor,lake_color=gif_ContinentWaterColor,zorder=1);
                #     geoMap.drawmapboundary(fill_color=gif_ContinentWaterColor,zorder=0);
                # #END IF
                            
                # #np.linspace(startlat,endlat,5) # 5 = number of "ticks"
                # geoMap.drawmeridians( np.round(np.arange(np.floor(np.min(plotLongRange)),np.ceil(np.max(plotLongRange))+1,plotLongRange_autoTick),2), 
                #     labels=[True,False,False,True], labelstyle='+/-', dashes=[6,15000], color='black' ); #adds the labels but keeps the lines invisible
                # geoMap.drawparallels(np.round(np.arange(np.floor(np.min(plotLatRange)),np.ceil(np.max(plotLatRange))+1,plotLatRange_autoTick),2), 
                #     labels=[True,False,True,False], labelstyle='+/-', dashes=[6,15000], color='black' ); #adds the labels but keeps the lines invisible
                # #dashes[6,15000] seems to be enough to keep the repeating dash from happening on a world plot (I think it's how wide a dash is and the dash spacing). 900 was good for 22 degc longitude, for ref.
                # #labels=[left,right,top,bottom] is the order. true/false to turn them on and off. not sure why there's a top/bottom for the parallels but w/e people do it
                
                kk = np.where(np.int64(snaps_times_currSec[i]/86400) == dates['date range full dayNum'][:,1])[0].item(); #get where the year is gonna be
                time4mag_hr = np.int32(np.mod(snaps_times_currSec[i],86400)//3600); #get hours
                time4mag_min = np.int32(np.mod(snaps_times_currSec[i],86400)//60-time4mag_hr*60); #get the minutes
                time4mag_sec = np.int32(np.mod(snaps_times_currSec[i],86400)-time4mag_min*60-time4mag_hr*3600); #get the seconds
                time4mag = datetime.datetime(dates['date range full'][kk,0],dates['date range full'][kk,1],dates['date range full'][kk,2], \
                                             hour = time4mag_hr, minute = time4mag_min, second = time4mag_sec); #date time object for aacgmv2    
                
                if( (geoMap_projectionStyle_polar == 1) & (snaps_colsArray[i] == np.min(snaps_colsArray)) & (snaps_rowsArray[i] == np.min(snaps_rowsArray)) ):
                    FLG_latLabel= False;
                    FLG_longLabel= True;
                elif( (geoMap_projectionStyle_polar == 1) & (snaps_colsArray[i] == (np.min(snaps_colsArray)+1)) & (snaps_rowsArray[i] == np.min(snaps_rowsArray)) ):
                    FLG_latLabel= True;
                    FLG_longLabel= False;
                elif( geoMap_projectionStyle_polar == 1 ):
                    FLG_latLabel= False;
                    FLG_longLabel= False;
                else:
                    FLG_latLabel= True;
                    FLG_longLabel= True;
                #END IF
                    
                ax[snaps_rowsArray[i],snaps_colsArray[i]] = GRITI_plotHelper_area_init(plotLatRange, plotLongRange, settings_map, settings_plot, FLG_fancyPlot, time4mag=time4mag, alt4mag=settings['TEC']['pierceAlt'], figAlreadyInfo={'fig':fig,'ax':ax[snaps_rowsArray[i],snaps_colsArray[i]],'fancy plot':FLG_fancyPlot_curr},FLG_latLabel=FLG_latLabel,FLG_longLabel=FLG_longLabel); #init a cartopy thing

                #Do the TEC plotting
                pltHelprX, pltHelprY = np.meshgrid( gif_Grid_Long, gif_Grid_Lat); #helps the pcolor work
                imTEC = ax[snaps_rowsArray[i],snaps_colsArray[i]].pcolormesh(pltHelprX, pltHelprY,  gif_Grid.T ,vmin=np.min(settings_TEC['plot lim']), vmax=np.max(settings_TEC['plot lim']), transform=cartopy.crs.PlateCarree(), cmap='jet', zorder=150); # pseudocolor plot "stretched" to the grid
                
                #Do the AMPERE plotting
                # AMPERE_latLongMapped = geoMap(AMPERE_long_portion,AMPERE_lat_portion); #convert the lat/long arcdeg to the current map coordinates
                if( ~np.any(np.isinf(AMPERE_plotLimValu)) ):
                    imAMP = ax[snaps_rowsArray[i],snaps_colsArray[i]].scatter(AMPERE_long_portion,AMPERE_lat_portion,s=gif_Scatter_Point_Size_AMPERE,c=AMPERE_data_portion,cmap=AMPERE_colorMap, transform=cartopy.crs.PlateCarree(), vmin=np.min(AMPERE_plotLimValu), vmax=np.max(AMPERE_plotLimValu), zorder=151);
                else:
                    imAMP = ax[snaps_rowsArray[i],snaps_colsArray[i]].scatter(AMPERE_long_portion,AMPERE_lat_portion,s=gif_Scatter_Point_Size_AMPERE,c=AMPERE_data_portion,cmap=AMPERE_colorMap, transform=cartopy.crs.PlateCarree(), zorder=151);
                #END IF
                ax[snaps_rowsArray[i],snaps_colsArray[i]].add_feature(Nightshade(time4mag, alpha=0.2),zorder=150); #nighttime shading
                
    #             #Do the TEC plotting
    #             pltHelprX, pltHelprY = np.meshgrid( gif_Grid_Long, gif_Grid_Lat); #helps the pcolor work
    #             TEC_latLongMapped = geoMap(pltHelprX,pltHelprY); #convert the lat/long arcdeg to the current map coordinates
    #             imTEC = ax[snaps_rowsArray[i],snaps_colsArray[i]].pcolormesh(TEC_latLongMapped[0], TEC_latLongMapped[1],  gif_Grid.T ,vmin=np.min(settings_TEC['plot lim']), vmax=np.max(settings_TEC['plot lim']),cmap='jet',zorder=5); # pseudocolor plot "stretched" to the grid
    #             if( snaps_colsArray[i] == np.max(snaps_colsArray) ): #only plot the label on the right side
    #                 cbar = fig.colorbar(imTEC, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
    #                 cax.yaxis.set_ticks(np.linspace(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim']),5)); #create useful tick marks
    #                 cax.yaxis.set_major_formatter(FormatStrFormatter('%.2f')); #force a rounded format
    #                 cbar.set_label("delta-vTEC [TECU]"); #tabel the colorbar
    #                 cbar.ax.tick_params(labelsize=FONT_axisTick);
    #                 cbar.mappable.set_clim(vmin=np.min(settings_TEC['plot lim']), vmax=np.max(settings_TEC['plot lim']));
    #             #END IF
    
    #             #Do the AMPERE plotting
    #             AMPERE_colorMap = ListedColormap( np.hstack(( np.array( ( (np.linspace(1,0.492063492063492,128)),(np.linspace(1,0.507936507936508,128)),(np.linspace(1,1,128)) ) ) , np.array( ( (np.linspace(0.492063492063492,1,128)) , (np.linspace(0.507936507936508,0,128)) , (np.linspace(1,1,128)) ) ) )).T ); #white to purpleblue to pink (based off of 'cool')
    #             AMPERE_latLongMapped = geoMap(AMPERE_long_portion,AMPERE_lat_portion); #convert the lat/long arcdeg to the current map coordinates
    #             imAMP = ax[snaps_rowsArray[i],snaps_colsArray[i]].scatter(AMPERE_latLongMapped[0],AMPERE_latLongMapped[1],s=gif_Scatter_Point_Size_AMPERE,c=AMPERE_data_portion,cmap=AMPERE_colorMap, vmin=np.min(AMPERE_plotLimValu), vmax=np.max(AMPERE_plotLimValu), zorder=7);
    #             if( snaps_colsArray[i] == np.min(snaps_colsArray) ): #only plot the label on the left side
    #                 cbar2 = fig.colorbar(imAMP, cax=cax2, orientation='vertical'); #create a colorbar using the prev. defined cax
    #     #                cbar2.ax.set_yticklabels(np.linspace(np.min(AMPERE_plotLimValu),np.max(AMPERE_plotLimValu),5)); #create useful tick marks
    #                 cax2.yaxis.set_major_formatter(FormatStrFormatter('%.1f')); #force a rounded format
    #                 cax2.yaxis.set_ticks_position('left'); #move it to the left
    #                 cax2.yaxis.set_label_position('left'); #move it to the left
                
    #                 cbar2.set_label('Joule Heating ['+'$erg/cm^{2}·s$]'); #tabel the colorbar
    #                 cbar2.ax.tick_params(labelsize=FONT_axisTick);
    #                 cbar2.mappable.set_clim(vmin=np.min(AMPERE_plotLimValu), vmax=np.max(AMPERE_plotLimValu));
    #             #END IF
                
    #             if( snaps_dayNiteLine == 1 ):
    #                 fig.canvas.flush_events(); #this is req. to get get_window_extent() to get the current window size
    #                 #Plot the sunrise/sunset terminators
    #                 dayNite_temp = np.abs(dayNite_sunrise - snaps_times_curr[i]) <= 10/3600; #gets the sunrise locations that are within 10 sec of the current TEC time (2 min had way too many hits, zigzags)
    #                 hLgd_FLG_day = np.sum(dayNite_temp); #plotting flag, shows when legend is active
    #                 #constants will use all the time - only for plotting of day/nite line so minor importance
    #                 #this stuff makes the text angle plotted mostly correct most of the time
    #                 bboxFig = fig.get_window_extent().transformed(fig.dpi_scale_trans.inverted()); #get the entire figure dimensions
    #                 bboxAx0 = ax[snaps_rowsArray[i],snaps_colsArray[i]].get_window_extent().transformed(fig.dpi_scale_trans.inverted()); #get the plot dimensions
    # #                    plot_ratio = (bboxAx0.width/bboxAx0.height)/( (bboxAx0.width/bboxAx0.height)/(bboxFig.width/bboxFig.height) )**2; #get the plot ratio, will use it to fix up the angle
    #                 plot_ratio = (bboxAx0.width/bboxAx0.height); #get the plot ratio, will use it to fix up the angle
    #                 dayNite_textRotationLenOrig = 35; #length to go up and down the sunrise/sunset line to estimate an angle
    #                 dayNite_savgolFiltLenOrig = 101; #set it as a constant to start off
    #                 dayNite_textLatAbs = (np.max(plotLatRange)-np.min(plotLatRange))*.9 + np.min(plotLatRange); #calc like 80% of the max latitude
    #                 if( hLgd_FLG_day > 0 ): #only do work if it is there
    #                     #calc all that day/nite stuff in one function to keep it from getting cluttered
    #                     dayNite_Lat_line, dayNite_Long_line, dayNite_Lat_text, dayNite_Long_text, dayNite_textRotation = GRITI_movieMaker_subfun_dayniteCalc(0,np.sum(dayNite_temp),dayNite_Grid_Long[dayNite_temp],dayNite_Grid_Lat[dayNite_temp],dayNite_textLatAbs,plot_ratio,dayNite_savgolFiltLenOrig,dayNite_textRotationLenOrig);
    #                     dayNite_latLongMapped = geoMap(dayNite_Long_line,dayNite_Lat_line); #convert the lat/long arcdeg to the current map coordinates
    #                     imDayNite_day = ax[snaps_rowsArray[i],snaps_colsArray[i]].plot(dayNite_latLongMapped[0],dayNite_latLongMapped[1],color='g',linewidth=1.75,zorder=6); #plots a line to show the sunrise time
    #                     if( snaps_dayNiteText == 1 ):
    #                         dayNite_latLongMapped = geoMap(dayNite_Long_text,dayNite_Lat_text); #convert the lat/long arcdeg to the current map coordinates
    #                         textDayNite_day = ax[snaps_rowsArray[i],snaps_colsArray[i]].text(dayNite_latLongMapped[0], dayNite_latLongMapped[1], "Sunrise", rotation=dayNite_textRotation, color='g', fontsize=FONT_axisTick, zorder=6);
    #                     #END IF
    #                 #END IF
                    
    #                 dayNite_temp = np.abs(dayNite_sunset - snaps_times_curr[i]) <= 10/3600; #gets the sunset locations that are within 10 sec of the current TEC time (2 min had way too many hits, zigzags)
    #                 hLgd_FLG_nite = np.sum(dayNite_temp); #plotting flag, shows when legend is active
    #                 if( hLgd_FLG_nite > 0 ): #only do work if it is there
    #                     #calc all that day/nite stuff in one function to keep it from getting cluttered
    #                     dayNite_Lat_line, dayNite_Long_line, dayNite_Lat_text, dayNite_Long_text, dayNite_textRotation = GRITI_movieMaker_subfun_dayniteCalc(1,np.sum(dayNite_temp),dayNite_Grid_Long[dayNite_temp],dayNite_Grid_Lat[dayNite_temp],dayNite_textLatAbs,plot_ratio,dayNite_savgolFiltLenOrig,dayNite_textRotationLenOrig);
    #                     dayNite_latLongMapped = geoMap(dayNite_Long_line,dayNite_Lat_line); #convert the lat/long arcdeg to the current map coordinates
    #                     imDayNite_nite = ax[snaps_rowsArray[i],snaps_colsArray[i]].plot(dayNite_latLongMapped[0],dayNite_latLongMapped[1],color='b',linewidth=1.75,zorder=6); #plots a line to show the sunset time
    #                     if( snaps_dayNiteText == 1 ):
    #                         dayNite_latLongMapped = geoMap(dayNite_Long_text,dayNite_Lat_text); #convert the lat/long arcdeg to the current map coordinates
    #                         textDayNite_nite = ax[snaps_rowsArray[i],snaps_colsArray[i]].text(dayNite_latLongMapped[0], dayNite_latLongMapped[1], "Sunset", rotation=dayNite_textRotation, color='b', fontsize=FONT_axisTick, zorder=6);
    #                     #EMD IF
    #                 #END IF
    #             elif( snaps_dayNiteLine == 2 ):
    #                 dayNite_currentDay = subfun_dayNum_to_date( np.array((dateRange_dayNum_zeroHr[0],np.int64(TEC_timeUnique[i])),ndmin=2))[0]; #get the current yr/month/day
    #                 dayNite_currentHr = np.int64((TEC_timeUnique[i]-np.int64(TEC_timeUnique[i]))*24); #hr, get the current hour
    #                 dayNite_currentMin = np.int64( ((TEC_timeUnique[i]-np.int64(TEC_timeUnique[i]))*24 - dayNite_currentHr)*60); #min, get the current min
    #                 dayNite_currentSec = np.int64( (((TEC_timeUnique[i]-np.int64(TEC_timeUnique[i]))*24 - dayNite_currentHr)*60 - dayNite_currentMin)*60); #min, get the current min
    #                 dayNite_currentTime = datetime.datetime(dayNite_currentDay[0], dayNite_currentDay[1], dayNite_currentDay[2], dayNite_currentHr, dayNite_currentMin,dayNite_currentSec);
    #                 dayNite_shade = geoMap.nightshade(dayNite_currentTime, color='k', delta=0.25, alpha=0.25, ax=ax[snaps_rowsArray[i],snaps_colsArray[i]], zorder=2);
    #             #END IF
                
                #Now drawing point of interest
                # Millstone_latLongMapped = geoMap(longMillstone,latMillstone); #convert the lat/long arcdeg to the current map coordinates
                # imMillstone = ax[snaps_rowsArray[i],snaps_colsArray[i]].plot(Millstone_latLongMapped[0],Millstone_latLongMapped[1],marker=gif_Millstone_Marker, color=gif_Millstone_Marker_Color, markersize=gif_Millstone_Marker_Size, zorder=50); #plot this, 50 always on top
                if( (latMillstone <= np.max(plotLatRange)) & (latMillstone >= np.min(plotLatRange)) & (longMillstone <= np.max(plotLongRange)) & (longMillstone >= np.min(plotLongRange)) ):
                    imMillstone = ax[snaps_rowsArray[i],snaps_colsArray[i]].plot(longMillstone,latMillstone,marker=gif_Millstone_Marker, color=gif_Millstone_Marker_Color, markersize=gif_Millstone_Marker_Size, zorder=550); #plot this, 50 always on top
                #END IF
                
                if(geoMap_projectionStyle_polar == 0):
                    if( snaps_colsArray[i] == np.min(snaps_colsArray) ):
                        GRITI_plotHelper_axisizerLatLong(plotLatRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='y',tickNumGoal=10,tickReducer=1,FLG_removeLabels=False);
                    else:
                        GRITI_plotHelper_axisizerLatLong(plotLatRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='y',tickNumGoal=10,tickReducer=1,FLG_removeLabels=True);
                    #END IF
                    if( snaps_rowsArray[i] == np.max(snaps_rowsArray) ):
                        GRITI_plotHelper_axisizerLatLong(plotLongRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='x',tickNumGoal=6,tickReducer=1,FLG_removeLabels=False);
                    else:
                        GRITI_plotHelper_axisizerLatLong(plotLongRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='x',tickNumGoal=6,tickReducer=1,FLG_removeLabels=True);
                    #END IF
                #END IF
            #END FOR i
            axEnd = plt.subplot(gridr[:,-1]); #create an axis for the cbar
            cbar = fig.colorbar(imTEC, cax=axEnd, orientation='vertical', aspect=50); #aspect=50 makes it thin
            cbar.set_ticks(np.linspace(np.min(settings_TEC['plot lim']),np.max(settings_TEC['plot lim']),11)); #create useful tick marks
            # cax.yaxis.set_major_formatter(FormatStrFormatter('%.2f')); #force a rounded format
            cbar.set_label('delta-vTEC [TECU]'); #tabel the colorbar
            cbar.ax.tick_params(labelsize=FONT_axisTick);
            cbar.mappable.set_clim(vmin=np.min(settings_TEC['plot lim']), vmax=np.max(settings_TEC['plot lim']));
            
            axStart = plt.subplot(gridr[:,0]); #create an axis for the cbar 
            cbar = fig.colorbar(imAMP, cax=axStart, orientation='vertical', aspect=50); #create a colorbar using the prev. defined cax, aspect=50 makes it thin
            # cax.yaxis.set_major_formatter(FormatStrFormatter('%.2f')); #force a rounded format
            cbar.set_label(settings['AMPERE']['labels'][AMPERE_dataType]+settings['AMPERE']['units'][AMPERE_dataType]); #tabel the colorbar
            # cax.yaxis.label.set_font_properties(FONT_smolFM);
            cbar.ax.tick_params(labelsize=FONT_axisTick);
            if( ~np.any(np.isinf(AMPERE_plotLimValu)) ):
                cbar.mappable.set_clim(vmin=np.min(AMPERE_plotLimValu), vmax=np.max(AMPERE_plotLimValu));
                cbar.set_ticks(np.linspace(np.min(AMPERE_plotLimValu),np.max(AMPERE_plotLimValu),6)); #create useful tick marks
            #END IF
            
        elif( (snaps_type == 11) | (snaps_type == 12) ):
            #------------Time keeping for various data sources-------------
            AMPERE_dataRate = data['AMPERE']['data rate']; #time, get the median data rate for AMPERE data (avoids outliers)
            
            AMPERE_lat_delta = np.median(np.diff(np.unique(data['AMPERE']['lat'])));
            if( np.isclose(AMPERE_lat_delta,np.int64(AMPERE_lat_delta)) ):
                AMPERE_lat_delta = np.int64(AMPERE_lat_delta); #convert to integer if it's an integer
            elif( AMPERE_lat_delta < 1e-4 ):
                AMPERE_lat_delta = 1; #override
            #END IF
            AMPERE_long_delta = np.median(np.diff(np.unique(data['AMPERE']['long'])));
            if( np.isclose(AMPERE_long_delta,np.int64(AMPERE_long_delta)) ):
                AMPERE_long_delta = np.int64(AMPERE_long_delta); #convert to integer if it's an integer
            elif( AMPERE_long_delta < 1e-4 ):
                AMPERE_long_delta = 15; #override
            #END IF
            
            if( snaps_type == 11 ):
                snaps_times_curr = snaps_times[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]]; #pull out the current snaps_times
                snaps_times_currDays = snaps_timesDays[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]]; #pull out the current snaps_times
                snaps_times_currSec = snaps_timesSec[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]]; #pull out the current snaps_times
            elif( snaps_type == 12 ):
                snaps_times_delta = np.median(np.diff(snaps_times)); #calc delta
                snaps_times_curr = np.append(snaps_times[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]],snaps_times_delta+snaps_times[snaps_chosen_plotsPerPlot_vect[snpz+1]-1]); #pull out the current snaps_times
                snaps_times_currDays = np.append(snaps_timesDays[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]],snaps_times_delta/24+snaps_timesDays[snaps_chosen_plotsPerPlot_vect[snpz+1]-1]); #pull out the current snaps_times
                snaps_times_currSec = np.append(snaps_timesSec[snaps_chosen_plotsPerPlot_vect[snpz]:snaps_chosen_plotsPerPlot_vect[snpz+1]],snaps_times_delta*3600+snaps_timesSec[snaps_chosen_plotsPerPlot_vect[snpz+1]-1]); #pull out the current snaps_times
            #END IF
            
            #----------------------CUSTOM COLORS IN CASE----------------------
            if( isinstance(settings['AMPERE']['colormap'],str) ):
                # keogramLine_color = 'xkcd:fuchsia'; #stands out
                snaps_color_pt = settings_map['site marker color']; #default
            else:
                if( np.any(np.all(np.abs(settings['AMPERE']['colormap'].colors - np.array([237,17,217])/255) < 0.15, axis=1)) ):
                    # keogramLine_color = 'xkcd:vermillion'; #if colormap uses fuschia-like color use red instead b/c looks different to colorblind
                    snaps_color_pt = 'xkcd:dark teal'; #not more purple
                else:
                    # keogramLine_color = 'xkcd:fuchsia'; #stands out
                    snaps_color_pt = settings_map['site marker color']; #default
               #END IF
            #END IF
            
            #-------------------------Start Making Pictures------------------------
            for i in range(0,snaps_chosen_plotsPerPlot):
                itot = i + snaps_chosen_plotsPerPlot*snpz; #total counter
                #------------Make human readable time-------------
                if( snaps_type == 11 ):
                    if( np.int64(np.round(np.abs(np.round(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60),8)-np.int64(np.round(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60),8)))*60,2)) == 0 ):
                        snaps_timeReadable = str(np.int64(snaps_times_curr[i])).zfill(2)+':'+str(np.int64(np.round(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60),8))).zfill(2); #create a human-readable time, no seconds
                    else:
                        snaps_timeReadable = str(np.int64(snaps_times_curr[i])).zfill(2)+':'+str(np.int64(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60))).zfill(2)+':'+\
                            str( np.int64(np.round(np.abs(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60)-np.int64(np.abs((snaps_times_curr[i]-np.int64(snaps_times_curr[i]))*60)))*60,2)) ).zfill(2); #create a human-readable time
                    #END IF
                elif( snaps_type == 12 ):
                    if( np.int64(np.round(np.abs(np.round(np.abs((snaps_times_curr[i+1]-np.int64(snaps_times_curr[i+1]))*60),8)-np.int64(np.round(np.abs((snaps_times_curr[i+1]-np.int64(snaps_times_curr[i+1]))*60),8)))*60,2)) == 0 ):
                        snaps_timeReadable = str(np.int64(snaps_times_curr[i+1])).zfill(2)+':'+str(np.int64(np.round(np.abs((snaps_times_curr[i+1]-np.int64(snaps_times_curr[i+1]))*60),8))).zfill(2); #create a human-readable time, no seconds
                    else:
                        snaps_timeReadable = str(np.int64(snaps_times_curr[i+1])).zfill(2)+':'+str(np.int64(np.abs((snaps_times_curr[i+1]-np.int64(snaps_times_curr[i+1]))*60))).zfill(2)+':'+\
                            str( np.int64(np.round(np.abs(np.abs((snaps_times_curr[i+1]-np.int64(snaps_times_curr[i+1]))*60)-np.int64(np.abs((snaps_times_curr[i+1]-np.int64(snaps_times_curr[i+1]))*60)))*60,2)) ).zfill(2); #create a human-readable time
                    #END IF
                #END IF
                
                #------------Corral the AMPERE data to the right place-------------
                if( snaps_type == 11 ):
                    k = np.where( (data['AMPERE']['time'] <= (snaps_times_currDays[i]*86400)) & (data['AMPERE']['time'] > ((snaps_times_currDays[i]*86400)-data['AMPERE']['data rate'])) )[0]; #get where the time point is, make sure it is within the data rate window
                elif( snaps_type == 12 ):
                    k = np.where( (data['AMPERE']['time'] <= (snaps_times_currDays[i+1]*86400)) & (data['AMPERE']['time'] > ((snaps_times_currDays[i]*86400)-data['AMPERE']['data rate'])) )[0]; #get where the time point is, make sure it is within the data rate window
                #END IF
                AMPERE_data_portion = data['AMPERE'][AMPERE_dataType][k]; #ergs/(cm^2*sec), get the Joule Heating for the current time step
                AMPERE_lat_portion = data['AMPERE']['lat'][k]; #degc, corresponding lat values
                AMPERE_long_portion = data['AMPERE']['long'][k]; #degc, corresponding long values
                  
                gif_Grid_Lat = np.arange(np.min(plotLatRange),np.max(plotLatRange)+AMPERE_lat_delta,AMPERE_lat_delta); #degc, create lat points (+1 lets us use delta to edge wanted range - yields correct # of spaces)
                gif_Grid_Long = np.arange(np.min(plotLongRange),np.max(plotLongRange)+AMPERE_long_delta,AMPERE_long_delta); #degc, create long points specilized for AMPERE
                
                if( snaps_type == 11 ):
                    #1st works for OLD _preprepared AMPERE data
                    # gif_Grid2 = np.vstack((np.hstack((np.roll(AMPERE_data_portion.reshape(gif_Grid_Lat.size-1,gif_Grid_Long.size-1),np.int64((360/AMPERE_long_delta)//2),axis=1),np.nan*np.ones((gif_Grid_Lat.size-1,1)))),np.nan*np.ones((1,gif_Grid_Long.size)))); # replicate what gif_Grid would do with reshaping b/c there's no need to avg pts
                    #2nd works for new AMPERE data, both disabled b/c the gridder does work with extra steps
                    #gif_Grid2 = np.vstack((np.hstack((np.roll(AMPERE_data_portion.reshape(gif_Grid_Long.size-1,gif_Grid_Lat.size-1),12,axis=0).T,np.nan*np.ones((gif_Grid_Lat.size-1,1)))),np.nan*np.ones((1,gif_Grid_Long.size)))); # replicate what gif_Grid would do with reshaping b/c there's no need to avg pts
                    gif_Grid = GRITI_movieMaker_subfun_dataGridder(AMPERE_lat_portion,AMPERE_long_portion,AMPERE_data_portion,gif_Grid_Lat,gif_Grid_Long,gif_Grid_Lat.size-1,gif_Grid_Long.size-1,AMPERE_lat_delta,AMPERE_long_delta,dataRejectOrig,101,dataRejectMax).T; #101 disables the data rejection stuff b/c AMPERE doesn't need it
                    # gif_Grid = np.roll(gif_Grid,-1,axis=1);
                elif( snaps_type == 12 ):
                    #actually need to avg here b/c we're avging across time
                    gif_Grid = GRITI_movieMaker_subfun_dataGridder(AMPERE_lat_portion,AMPERE_long_portion,AMPERE_data_portion,gif_Grid_Lat,gif_Grid_Long,gif_Grid_Lat.size-1,gif_Grid_Long.size-1,AMPERE_lat_delta,AMPERE_long_delta,dataRejectOrig,101,dataRejectMax).T; #101 disables the data rejection stuff b/c AMPERE doesn't need it
                #END IF
                                
                #----------------------------Tack on Title-------------------------
                # string_title = 'Time =  '+'{0:.2f}'.format(np.round(snaps_times_curr[i],2))+\
                #     ', '+snaps_timeReadable; #create mecha title
                string_title = snaps_timeReadable; #create mecha title
                               
                #-------------------Starting the Plotting--------------------------
                
                # #mill for square Mercator style
                # #robin for oval shape
                # if( geoMap_projectionStyle_polar == 1):
                #     #prime the colorbars
                #     if( snaps_colsArray[i] == np.max(snaps_colsArray) ): #only plot the label on the right side
                #         divider = make_axes_locatable(ax[snaps_rowsArray[i],snaps_colsArray[i]]); #prep to add an axis
                #         cax = divider.append_axes('right', size='3.0%', pad=0.80); #make a color bar axis
                #         cax.yaxis.label.set_font_properties(FONT_smolFM);
                #         if( ((snaps_colsArray[i] == np.max(snaps_colsArray)) & (snaps_rowsArray[i] == np.int64(np.median(snaps_rowsArray)))) == False ):
                #             cax.set_visible(False); #mkae it invisible so it matches the other plots in width
                #         #END IF
                #     #END IF
                    
                #     geoMap = Basemap(projection=geoMap_projectionStyle,boundinglat=np.min(plotLatRange),lon_0=np.mean(plotLongRange),
                #         resolution = 'i', area_thresh = 10000, ax=ax[snaps_rowsArray[i],snaps_colsArray[i]], round=True);
                #     if( gif_dayNiteLine == 1 ): # == 2 is OK as it's better than my rough calcs
                #         gif_dayNiteLine = 0; #override, they do weird things on polar
                #         gif_dayNiteText = 0; #override, they do weird things on polar
                #     #END IF
                #         #np.linspace(startlat,endlat,5) # 5 = number of "ticks"
                #     geoMap.drawmeridians( np.round(np.arange(np.floor(np.min(plotLongRange)),np.ceil(np.max(plotLongRange))+1,30),0), 
                #         labels=[0,0,0,0], labelstyle='+/-', color='black' , zorder=100); #adds the labels but keeps the lines invisible
                #     geoMap.drawparallels(np.round(np.arange(90,np.min(plotLatRange),-15),0), 
                #         labels=[0,0,0,0], labelstyle='+/-', color='black' , zorder=100); #adds the labels but keeps the lines invisible
                #     #dashes[6,15000] seems to be enough to keep the repeating dash from happening on a world plot (I think it's how wide a dash is and the dash spacing). 900 was good for 22 degc longitude, for ref.
                #     #labels=[left,right,top,bottom] is the order. true/false to turn them on and off. not sure why there's a top/bottom for the parallels but w/e people do it
                    
                #     if( (snaps_colsArray[i] == np.min(snaps_colsArray)) & (snaps_rowsArray[i] == np.min(snaps_rowsArray)) ):
                #         for j in np.arange(0,360,30): #longitude labels
                #             x = (1.05*0.5*np.sin(np.deg2rad(j)))+0.5; #geoMap coordinate 
                #             y = (1.05*0.5*np.cos(np.deg2rad(j+180)))+0.5;
                #             if( j > 180 ):
                #                 angle = j-360; #deg, flip to negative
                #             else:
                #                 angle = j; #deg, angle is OK
                #             #END IF
                #             if( angle == 180):
                #                 y = y - 0.01; #small nudge, cause this one is too close
                #             #END IF
                #             if( angle == -60):
                #                 x = x - 0.003; #small nudge, cause this one is too close
                #             #END IF
                #             # if( angle != 180): #disable 180, too crowded
                #             ax[snaps_rowsArray[i],snaps_colsArray[i]].text(x,y,str(angle)+'\N{DEGREE SIGN}',transform=ax[snaps_rowsArray[i],snaps_colsArray[i]].transAxes,horizontalalignment='center',verticalalignment='center',fontproperties=FONT_smolFM, zorder=100)
                #             #END IF
                #         #END FOR j
                #     #END IF
                #     if( (snaps_colsArray[i] == 1) & (snaps_rowsArray[i] == np.min(snaps_rowsArray)) ):
                #         latPts = np.roll(np.arange(90,np.min(plotLatRange),-15),-1); #degc, latitude points to note (this extra work is to replace the 90 w/ the last latitude value)
                #         # latPts[-1] = np.min(plotLatRange); #degc, last is the final latitude value
                #         latPts = latPts[:-1]; #remove last one for small plot
                #         latPts_mapped = geoMap(np.tile(180,(latPts.size,)),latPts); #convert to geoMap values
                #         for j in range(0,latPts.size): #latitude labels
                #             x = latPts_mapped[0][j]/latPts_mapped[1][-1] + 0.025; #geoMap coordinate 
                #             y = latPts_mapped[1][j]/latPts_mapped[1][-1] - 0.0085; #geoMap coordinate 
                #             ax[snaps_rowsArray[i],snaps_colsArray[i]].text(x,y,str(latPts[j])+'\N{DEGREE SIGN}',transform=ax[snaps_rowsArray[i],snaps_colsArray[i]].transAxes,horizontalalignment='center',verticalalignment='center',fontproperties=FONT_smolFM, zorder=100)
                #             #ax.text(x,y,str(latPts[j])+'\N{DEGREE SIGN}',horizontalalignment='center',verticalalignment='center',fontproperties=FONT_smolFM)
                #         #END FOR j
                #     #END IF
        
                #     #Remove the aspect ratio from the basemap so it fills the screen better
                #     ax[snaps_rowsArray[i],snaps_colsArray[i]].set_aspect('equal');
                #     geoCircle = geoMap.drawmapboundary(linewidth=2, color='k'); #polar circle is clipped, so this draws it then makes sure it isn't
                #     geoCircle.set_clip_on(False); #prevent weird things where the circle is clipped off
                    
                if( geoMap_projectionStyle_polar == 0 ):
                    ax[snaps_rowsArray[i],snaps_colsArray[i]].set_title(string_title,fontproperties=FONT_titleFM); #set the title
                else:
                    ax[snaps_rowsArray[i],snaps_colsArray[i]].set_title(string_title,fontproperties=FONT_titleFM,y=1.075); #set the title
                #END IF
                    
                # elif(geoMap_projectionStyle_polar == 2):
                #     #prime the colorbars
                #     if( snaps_colsArray[i] == np.max(snaps_colsArray) ): #only plot the label on the right side
                #         divider = make_axes_locatable(ax[snaps_rowsArray[i],snaps_colsArray[i]]); #prep to add an axis
                #         cax = divider.append_axes('right', size='3.0%', pad=0.80); #make a color bar axis
                #         cax.yaxis.label.set_font_properties(FONT_smolFM);
                #         if( ((snaps_colsArray[i] == np.max(snaps_colsArray)) & (snaps_rowsArray[i] == np.int64(np.median(snaps_rowsArray)))) == False ):
                #             cax.set_visible(False); #mkae it invisible so it matches the other plots in width
                #         #END IF
                #     #END IF
                    
                #     geoMap = Basemap(projection=geoMap_projectionStyle,boundinglat=np.max(plotLatRange),lon_0=np.mean(plotLongRange),
                #          resolution = 'i', area_thresh = 10000, ax=ax[snaps_rowsArray[i],snaps_colsArray[i]], round=True);
                #     if( gif_dayNiteLine == 1 ): # == 2 is OK as it's better than my rough calcs
                #         gif_dayNiteLine = 0; #override, they do weird things on polar
                #         gif_dayNiteText = 0; #override, they do weird things on polar
                #     #END IF
                #     #np.linspace(startlat,endlat,5) # 5 = number of "ticks"
                #     geoMap.drawmeridians( np.round(np.arange(np.floor(np.min(plotLongRange)),np.ceil(np.max(plotLongRange))+1,30),2), 
                #         labels=[True,True,True,True], labelstyle='+/-', color='black' ); #adds the labels but keeps the lines invisible
                #     geoMap.drawparallels(np.round(np.arange(-90,np.max(plotLatRange),15),0), 
                #         labels=[True,True,True,True], labelstyle='+/-', color='black' ); #adds the labels but keeps the lines invisible
                #     #dashes[6,15000] seems to be enough to keep the repeating dash from happening on a world plot (I think it's how wide a dash is and the dash spacing). 900 was good for 22 degc longitude, for ref.
                #     #labels=[left,right,top,bottom] is the order. true/false to turn them on and off. not sure why there's a top/bottom for the parallels but w/e people do it
                    
                #     if( (snaps_colsArray[i] == np.min(snaps_colsArray)) & (snaps_rowsArray[i] == np.min(snaps_rowsArray)) ):
                #         for j in np.arange(0,360,30): #longitude labels
                #             x = (1.05*0.5*np.sin(np.deg2rad(j)))+0.5; #geoMap coordinate 
                #             y = (1.05*0.5*np.cos(np.deg2rad(j+180)))+0.5;
                #             if( j > 180 ):
                #                 angle = j-360; #deg, flip to negative
                #             else:
                #                 angle = j; #deg, angle is OK
                #             #END IF
                #             if( angle == 180):
                #                 y = y - 0.01; #small nudge, cause this one is too close
                #             #END IF
                #             if( angle == -60):
                #                 x = x - 0.003; #small nudge, cause this one is too close
                #             #END IF
                #             # if( angle != 180): #disable 180, too crowded
                #             ax[snaps_rowsArray[i],snaps_colsArray[i]].text(x,y,str(angle)+'\N{DEGREE SIGN}',transform=ax[snaps_rowsArray[i],snaps_colsArray[i]].transAxes,horizontalalignment='center',verticalalignment='center',fontproperties=FONT_smolFM)
                #             #END IF
                #         #END FOR j
                #     #END IF
                #     if( (snaps_colsArray[i] == 1) & (snaps_rowsArray[i] == np.min(snaps_rowsArray)) ):
                #         latPts = np.roll(np.arange(-90,np.max(plotLatRange),15),-1); #degc, latitude points to note (this extra work is to replace the 90 w/ the last latitude value)
                #         # latPts[-1] = np.max(plotLatRange); #degc, last is the final latitude value
                #         latPts = latPts[:-1]; #remove last one for small plot
                #         latPts_mapped = geoMap(np.tile(180,(latPts.size,)),latPts); #convert to geoMap values
                #         for j in range(0,latPts.size): #latitude labels
                #             x = latPts_mapped[0][j]/latPts_mapped[1][-1] + 0.025; #geoMap coordinate 
                #             y = latPts_mapped[1][j]/latPts_mapped[1][-1] - 0.0085; #geoMap coordinate 
                #             ax[snaps_rowsArray[i],snaps_colsArray[i]].text(x,y,str(latPts[j])+'\N{DEGREE SIGN}',transform=ax[snaps_rowsArray[i],snaps_colsArray[i]].transAxes,horizontalalignment='center',verticalalignment='center',fontproperties=FONT_smolFM)
                #             #ax.text(x,y,str(latPts[j])+'\N{DEGREE SIGN}',horizontalalignment='center',verticalalignment='center',fontproperties=FONT_smolFM)
                #         #END FOR j
                #     #END IF
                    
                #     #Remove the aspect ratio from the basemap so it fills the screen better
                #     ax[snaps_rowsArray[i],snaps_colsArray[i]].set_aspect('equal');
                #     geoCircle = geoMap.drawmapboundary(linewidth=2, color='k'); #polar circle is clipped, so this draws it then makes sure it isn't
                #     geoMap.set_clip_on(False); #prevent weird things where the circle is clipped off
                    
                #     ax[snaps_rowsArray[i],snaps_colsArray[i]].set_title(string_title,fontproperties=FONT_smolFM,y=1.030); #set the title
                # else:
                #     #prime the colorbars
                #     if( snaps_colsArray[i] == np.max(snaps_colsArray) ): #only plot the label on the right side
                #         divider = make_axes_locatable(ax[snaps_rowsArray[i],snaps_colsArray[i]]); #prep to add an axis
                #         cax = divider.append_axes('right', size='2.0%', pad=0.35); #make a color bar axis
                #         cax.yaxis.label.set_font_properties(FONT_smolFM);
                #         if( ((snaps_colsArray[i] == np.max(snaps_colsArray)) & (snaps_rowsArray[i] == np.int64(np.median(snaps_rowsArray)))) == False ):
                #             cax.set_visible(False); #mkae it invisible so it matches the other plots in width
                #         #END IF
                #     #END IF
                    
                #     geoMap = Basemap(projection=geoMap_projectionStyle, lat_0=np.mean(plotLatRange), lon_0=np.mean(plotLongRange), #projection type, and I think lat_0/lon_0 are the centers?
                #         resolution = 'i', area_thresh = 10000, ax=ax[snaps_rowsArray[i],snaps_colsArray[i]], #resolutions I know are l, i, h - i seems good. area_thresh being big prevents it drawing lil lakes, 0.1 makes everything
                #         llcrnrlon=np.float32(plotLongRange[0]), llcrnrlat=np.float32(plotLatRange[0]), #lower left corner lat/long - MUST BE FLOAT cause CODED BY THE BEST
                #         urcrnrlon=np.float32(plotLongRange[1]), urcrnrlat=np.float32(plotLatRange[1])); #upper right corner lat/long - MUST BE FLOAT cause CODED BY THE BEST
                                
                #     #Remove the aspect ratio from the basemap so it fills the screen better
                #     ax[snaps_rowsArray[i],snaps_colsArray[i]].set_aspect('auto');
                    
                #     #np.linspace(startlat,endlat,5) # 5 = number of "ticks"
                #     geoMap.drawmeridians( np.round(np.arange(np.floor(np.min(plotLongRange)),np.ceil(np.max(plotLongRange))+1,plotLongRange_autoTick),2), 
                #         labels=[True,False,False,True], labelstyle='+/-', dashes=[6,15000], color='black' ); #adds the labels but keeps the lines invisible
                #     geoMap.drawparallels(np.round(np.arange(np.floor(np.min(plotLatRange)),np.ceil(np.max(plotLatRange))+1,plotLatRange_autoTick),2), 
                #         labels=[True,False,True,False], labelstyle='+/-', dashes=[6,15000], color='black' ); #adds the labels but keeps the lines invisible
                #     #dashes[6,15000] seems to be enough to keep the repeating dash from happening on a world plot (I think it's how wide a dash is and the dash spacing). 900 was good for 22 degc longitude, for ref.
                #     #labels=[left,right,top,bottom] is the order. true/false to turn them on and off. not sure why there's a top/bottom for the parallels but w/e people do it
                
                #     ax[snaps_rowsArray[i],snaps_colsArray[i]].set_title(string_title,fontproperties=FONT_smolFM); #set the title, properties always needed
                # #END IF
    
                # geoMap.drawcoastlines(zorder=25); #always on top
                # if( gif_ContinentFill == 1 ): #color in stuff if this is on
                #     #geoMap.drawcountries();
                #     #geoMap.drawmapboundary();
                #     geoMap.fillcontinents(color=gif_ContientColor,lake_color=gif_ContinentWaterColor,zorder=1);
                #     geoMap.drawmapboundary(fill_color=gif_ContinentWaterColor,zorder=0);
                # #END IF
                kk = np.where(np.int64(snaps_times_currSec[i]/86400) == dates['date range full dayNum'][:,1])[0].item(); #get where the year is gonna be
                time4mag_hr = np.int32(np.mod(snaps_times_currSec[i],86400)//3600); #get hours
                time4mag_min = np.int32(np.mod(snaps_times_currSec[i],86400)//60-time4mag_hr*60); #get the minutes
                time4mag_sec = np.int32(np.mod(snaps_times_currSec[i],86400)-time4mag_min*60-time4mag_hr*3600); #get the seconds
                time4mag = datetime.datetime(dates['date range full'][kk,0],dates['date range full'][kk,1],dates['date range full'][kk,2], \
                                             hour = time4mag_hr, minute = time4mag_min, second = time4mag_sec); #date time object for aacgmv2    
                
                if( (geoMap_projectionStyle_polar == 1) & (snaps_colsArray[i] == np.min(snaps_colsArray)) & (snaps_rowsArray[i] == np.min(snaps_rowsArray)) ):
                    FLG_latLabel= False;
                    FLG_longLabel= True;
                elif( (geoMap_projectionStyle_polar == 1) & (snaps_colsArray[i] == (np.min(snaps_colsArray)+1)) & (snaps_rowsArray[i] == np.min(snaps_rowsArray)) ):
                    FLG_latLabel= True;
                    FLG_longLabel= False;
                elif( geoMap_projectionStyle_polar == 1 ):
                    FLG_latLabel= False;
                    FLG_longLabel= False;
                else:
                    FLG_latLabel= True;
                    FLG_longLabel= True;
                #END IF
                    
                ax[snaps_rowsArray[i],snaps_colsArray[i]] = GRITI_plotHelper_area_init(plotLatRange, plotLongRange, settings_map, settings_plot, FLG_fancyPlot, time4mag=time4mag, alt4mag=120., figAlreadyInfo={'fig':fig,'ax':ax[snaps_rowsArray[i],snaps_colsArray[i]],'fancy plot':FLG_fancyPlot_curr},FLG_latLabel=FLG_latLabel,FLG_longLabel=FLG_longLabel); #init a cartopy thing
    
                #Do the AMPERE plotting
                AMPERE_latLongMapped = np.meshgrid( gif_Grid_Long, gif_Grid_Lat); #helps the pcolor work
                # AMPERE_latLongMapped = geoMap(pltHelprX,pltHelprY); #convert the lat/long arcdeg to the current map coordinates
                if( ~np.any(np.isinf(AMPERE_plotLimValu)) ):
                    imAMP = ax[snaps_rowsArray[i],snaps_colsArray[i]].pcolormesh(AMPERE_latLongMapped[0], AMPERE_latLongMapped[1], gif_Grid, vmin=np.min(AMPERE_plotLimValu), vmax=np.max(AMPERE_plotLimValu), transform=cartopy.crs.PlateCarree(),  cmap=settings['AMPERE']['colormap'], zorder=150, rasterized=snaps_rasterize); # pseudocolor plot "stretched" to the grid
                else:
                    imAMP = ax[snaps_rowsArray[i],snaps_colsArray[i]].pcolormesh(AMPERE_latLongMapped[0], AMPERE_latLongMapped[1], gif_Grid, transform=cartopy.crs.PlateCarree(), cmap=settings['AMPERE']['colormap'],zorder=150, rasterized=snaps_rasterize); # pseudocolor plot "stretched" to the grid
                #END IF
                # if( (snaps_colsArray[i] == np.max(snaps_colsArray)) & (snaps_rowsArray[i] == np.int64(np.median(snaps_rowsArray))) ): #only plot the label on the right side
                #     cbar = fig.colorbar(imAMP, cax=cax, orientation='vertical'); #create a colorbar using the prev. defined cax
                #     # cax.yaxis.set_major_formatter(FormatStrFormatter('%.2f')); #force a rounded format
                #     cbar.set_label(settings['AMPERE']['labels'][AMPERE_dataType]+settings['AMPERE']['units'][AMPERE_dataType]); #tabel the colorbar
                #     cax.yaxis.label.set_font_properties(FONT_smolFM);
                #     cbar.ax.tick_params(labelsize=FONT_smol);
                #     if( ~np.any(np.isinf(AMPERE_plotLimValu)) ):
                #         cbar.mappable.set_clim(vmin=np.min(AMPERE_plotLimValu), vmax=np.max(AMPERE_plotLimValu));
                #         cax.yaxis.set_ticks(np.linspace(np.min(AMPERE_plotLimValu),np.max(AMPERE_plotLimValu),6)); #create useful tick marks
                #     # else:
                #     #     cbar.mappable.set_clim(vmin=np.min(AMPERE_plotLimValu_override), vmax=np.max(AMPERE_plotLimValu_override));
                #     #END IF
                #     # if( np.all(np.mod(cbar.get_ticks(),1) == 0) ):
                #     #     cax.yaxis.set_major_formatter(FormatStrFormatter('%.0f')); #force a rounded format
                #     # else:
                #     #     cax.yaxis.set_major_formatter(FormatStrFormatter('%.1f')); #force a rounded format
                #     # #END IF
                    
                # #END IF
                
    #             if( snaps_type == 11 ):
    #                 snaps_time_dayNite = snaps_times_curr[i];
    #             elif( snaps_type == 12 ):
    #                 snaps_time_dayNite = (snaps_times_curr[i+1]+snaps_times_curr[i])/2;
    #             #END IF
                
    #             if( snaps_dayNiteLine == 1 ):
    #                 fig.canvas.flush_events(); #this is req. to get get_window_extent() to get the current window size
    #                 #Plot the sunrise/sunset terminators
    #                 dayNite_temp = np.abs(dayNite_sunrise - snaps_time_dayNite) <= 10/3600; #gets the sunrise locations that are within 10 sec of the current TEC time (2 min had way too many hits, zigzags)
    #                 hLgd_FLG_day = np.sum(dayNite_temp); #plotting flag, shows when legend is active
    #                 #constants will use all the time - only for plotting of day/nite line so minor importance
    #                 #this stuff makes the text angle plotted mostly correct most of the time
    #                 bboxFig = fig.get_window_extent().transformed(fig.dpi_scale_trans.inverted()); #get the entire figure dimensions
    #                 bboxAx0 = ax[snaps_rowsArray[i],snaps_colsArray[i]].get_window_extent().transformed(fig.dpi_scale_trans.inverted()); #get the plot dimensions
    # #                    plot_ratio = (bboxAx0.width/bboxAx0.height)/( (bboxAx0.width/bboxAx0.height)/(bboxFig.width/bboxFig.height) )**2; #get the plot ratio, will use it to fix up the angle
    #                 plot_ratio = (bboxAx0.width/bboxAx0.height); #get the plot ratio, will use it to fix up the angle
    #                 dayNite_textRotationLenOrig = 35; #length to go up and down the sunrise/sunset line to estimate an angle
    #                 dayNite_savgolFiltLenOrig = 101; #set it as a constant to start off
    #                 dayNite_textLatAbs = (np.max(plotLatRange)-np.min(plotLatRange))*.9 + np.min(plotLatRange); #calc like 80% of the max latitude
    #                 if( hLgd_FLG_day > 0 ): #only do work if it is there
    #                     #calc all that day/nite stuff in one function to keep it from getting cluttered
    #                     dayNite_Lat_line, dayNite_Long_line, dayNite_Lat_text, dayNite_Long_text, dayNite_textRotation = GRITI_movieMaker_subfun_dayniteCalc(0,np.sum(dayNite_temp),dayNite_Grid_Long[dayNite_temp],dayNite_Grid_Lat[dayNite_temp],dayNite_textLatAbs,plot_ratio,dayNite_savgolFiltLenOrig,dayNite_textRotationLenOrig);
    #                     dayNite_latLongMapped = geoMap(dayNite_Long_line,dayNite_Lat_line); #convert the lat/long arcdeg to the current map coordinates
    #                     imDayNite_day = ax[snaps_rowsArray[i],snaps_colsArray[i]].plot(dayNite_latLongMapped[0],dayNite_latLongMapped[1],color='g',linewidth=1.75,zorder=6); #plots a line to show the sunrise time
    #                     if( snaps_dayNiteText == 1 ):
    #                         dayNite_latLongMapped = geoMap(dayNite_Long_text,dayNite_Lat_text); #convert the lat/long arcdeg to the current map coordinates
    #                         textDayNite_day = ax[snaps_rowsArray[i],snaps_colsArray[i]].text(dayNite_latLongMapped[0], dayNite_latLongMapped[1], "Sunrise", rotation=dayNite_textRotation, color='g', fontsize=FONT_smol, zorder=6);
    #                     #END IF
    #                 #END IF
                    
    #                 dayNite_temp = np.abs(dayNite_sunset - snaps_time_dayNite) <= 10/3600; #gets the sunset locations that are within 10 sec of the current TEC time (2 min had way too many hits, zigzags)
    #                 hLgd_FLG_nite = np.sum(dayNite_temp); #plotting flag, shows when legend is active
    #                 if( hLgd_FLG_nite > 0 ): #only do work if it is there
    #                     #calc all that day/nite stuff in one function to keep it from getting cluttered
    #                     dayNite_Lat_line, dayNite_Long_line, dayNite_Lat_text, dayNite_Long_text, dayNite_textRotation = GRITI_movieMaker_subfun_dayniteCalc(1,np.sum(dayNite_temp),dayNite_Grid_Long[dayNite_temp],dayNite_Grid_Lat[dayNite_temp],dayNite_textLatAbs,plot_ratio,dayNite_savgolFiltLenOrig,dayNite_textRotationLenOrig);
    #                     dayNite_latLongMapped = geoMap(dayNite_Long_line,dayNite_Lat_line); #convert the lat/long arcdeg to the current map coordinates
    #                     imDayNite_nite = ax[snaps_rowsArray[i],snaps_colsArray[i]].plot(dayNite_latLongMapped[0],dayNite_latLongMapped[1],color='b',linewidth=1.75,zorder=6); #plots a line to show the sunset time
    #                     if( snaps_dayNiteText == 1 ):
    #                         dayNite_latLongMapped = geoMap(dayNite_Long_text,dayNite_Lat_text); #convert the lat/long arcdeg to the current map coordinates
    #                         textDayNite_nite = ax[snaps_rowsArray[i],snaps_colsArray[i]].text(dayNite_latLongMapped[0], dayNite_latLongMapped[1], "Sunset", rotation=dayNite_textRotation, color='b', fontsize=FONT_smol, zorder=6);
    #                     #EMD IF
    #                 #END IF
    #             elif( snaps_dayNiteLine == 2 ):
    #                 dayNite_currentDay = subfun_dayNum_to_date( np.array((dateRange_dayNum_zeroHr[0],np.int64(snaps_times_currDays[i])),ndmin=2))[0]; #get the current yr/month/day
    #                 jk = np.where(np.all(dayNite_currentDay == dates['date range full'],axis=1))[0].item(); #get the day index to apply the req'd hour offset
    #                 dayNite_currentHr = np.int64( np.mod(np.abs(snaps_time_dayNite-dates['date range zero hr hours'][jk]),24) ); #hr, get the current hour
    #                 dayNite_currentMin = np.int64( (np.mod(np.abs(snaps_time_dayNite-dates['date range zero hr hours'][jk]),24)  - dayNite_currentHr)*60 ); #min, get the current min
    #                 dayNite_currentSec = np.int64( ((np.mod(np.abs(snaps_time_dayNite-dates['date range zero hr hours'][jk]),24)   - dayNite_currentHr)*60 - dayNite_currentMin)*60 ); #min, get the current min
    #                 dayNite_currentTime = datetime.datetime(dayNite_currentDay[0], dayNite_currentDay[1], dayNite_currentDay[2], dayNite_currentHr, dayNite_currentMin,dayNite_currentSec);
    #                 dayNite_shade = geoMap.nightshade(dayNite_currentTime, color='k', delta=0.25, alpha=0.25, ax=ax[snaps_rowsArray[i],snaps_colsArray[i]], zorder=25);
    #             #END IF
                
    #             #Now drawing point of interest
    #             Millstone_latLongMapped = geoMap(latLong_ref[0][1],latLong_ref[0][0]); #convert the lat/long arcdeg to the current map coordinates
    #             imMillstone = ax[snaps_rowsArray[i],snaps_colsArray[i]].plot(Millstone_latLongMapped[0],Millstone_latLongMapped[1],marker=settings_map['site marker type'], color=settings_map['site marker color'], markersize=settings_map['site marker size'], clip_on=False, zorder=50); #plot this, 50 always on top
                
                if( settings_map_snaps['coord type'] == 'geo' ):
                    ax[snaps_rowsArray[i],snaps_colsArray[i]].add_feature(Nightshade(time4mag, alpha=0.2),zorder=150); #nighttime shading, only relevant for geographic
                else:
                    #this ain't perfect, but it's plenty good for general where not sun
                    shifter = (np.mod(sunSubSolar_loc['long'][itot],360) - np.mod(sunSubSolar_loc_geo['long'][itot],360))*240 #sec, effective time to shift by so Sun is in right spot; 240 = 24*3600/360
                    shifted = snaps_times_currSec[i] - shifter; #shift the time so Sun is in the right spot
                    kk = np.where(np.int64(shifted/86400) == dates['date range full padded dayNum'][:,1])[0].item(); #get where the year is gonna be
                    time4mag_hr = np.int32(np.mod(shifted,86400)//3600); #get hours
                    time4mag_min = np.int32(np.mod(shifted,86400)//60-time4mag_hr*60); #get the minutes
                    time4mag_sec = np.int32(np.mod(shifted,86400)-time4mag_min*60-time4mag_hr*3600); #get the seconds
                    time4mag_shifted = datetime.datetime(dates['date range full padded'][kk,0],dates['date range full padded'][kk,1],dates['date range full padded'][kk,2], \
                                                  hour = time4mag_hr, minute = time4mag_min, second = time4mag_sec); #date time object for aacgmv2 
                    ax[snaps_rowsArray[i],snaps_colsArray[i]].add_feature(Nightshade(time4mag_shifted, alpha=0.2),zorder=150); #nighttime shading, only relevant for geographic
                #END IF
                
                if( snaps_sunPos == 1 ):
                    if( FLG_sunSpin == 0):
                        x = (1.05*0.5*np.cos((sunSubSolar_loc['long'][itot]-90)*np.pi/180))+0.5; #geoMap coordinate 
                        y = (1.05*0.5*np.sin((sunSubSolar_loc['long'][itot]-90)*np.pi/180))+0.5; #geoMap coordinate 
                        #hSun = ax.text(x,y,'SUN\N{DEGREE SIGN}',transform=ax.transAxes,horizontalalignment='center',verticalalignment='center',fontproperties=FONT_axisTickFM);
                        circleSun = plt.Circle((x, y), radius=0.015, color='xkcd:sun yellow', clip_on=False,transform=ax[snaps_rowsArray[i],snaps_colsArray[i]].transAxes); #make a sun figure
                        hSun = ax[snaps_rowsArray[i],snaps_colsArray[i]].add_artist(circleSun); #plot the sun
                    else:
                        #this does not work in cartopy!! so don't
                        hSun = ax[snaps_rowsArray[i],snaps_colsArray[i]].set_theta_offset((sunSubSolar_loc['long'][itot]-90)*np.pi/180); #turn the whole plot so top is where the sun is
                        #I'm not sure if I can get this working easily - not a lot of optons.
                    #END IF
                #END IF
                
                #Now drawing point of interest
                # Millstone_latLongMapped = geoMap(longMillstone,latMillstone); #convert the lat/long arcdeg to the current map coordinates
                if( (latMillstone <= np.max(plotLatRange)) & (latMillstone >= np.min(plotLatRange)) & (longMillstone <= np.max(plotLongRange)) & (longMillstone >= np.min(plotLongRange)) ):
                    imMillstone = ax[snaps_rowsArray[i],snaps_colsArray[i]].plot(longMillstone,latMillstone,marker=gif_Millstone_Marker, color=snaps_color_pt, markersize=gif_Millstone_Marker_Size, transform=cartopy.crs.PlateCarree(), zorder=550); #plot this, 50 always on top
                #END IF
                
                if(geoMap_projectionStyle_polar == 0):
                    if( snaps_colsArray[i] == np.min(snaps_colsArray) ):
                        GRITI_plotHelper_axisizerLatLong(plotLatRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='y',tickNumGoal=10,tickReducer=1,FLG_removeLabels=False);
                    else:
                        GRITI_plotHelper_axisizerLatLong(plotLatRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='y',tickNumGoal=10,tickReducer=1,FLG_removeLabels=True);
                    #END IF
                    if( snaps_rowsArray[i] == np.max(snaps_rowsArray) ):
                        GRITI_plotHelper_axisizerLatLong(plotLongRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='x',tickNumGoal=6,tickReducer=1,FLG_removeLabels=False);
                    else:
                        GRITI_plotHelper_axisizerLatLong(plotLongRange,ax=ax[snaps_rowsArray[i],snaps_colsArray[i]],axDir='x',tickNumGoal=6,tickReducer=1,FLG_removeLabels=True);
                    #END IF
                #END IF
            #END FOR i
            axEnd = plt.subplot(gridr[:,-1]); #create an axis for the cbar 
            cbar = fig.colorbar(imAMP, cax=axEnd, orientation='vertical', aspect=50); #create a colorbar using the prev. defined cax, aspect=50 makes it thin
            # cax.yaxis.set_major_formatter(FormatStrFormatter('%.2f')); #force a rounded format
            cbar.set_label(settings['AMPERE']['labels'][AMPERE_dataType]+settings['AMPERE']['units'][AMPERE_dataType]); #tabel the colorbar
            # cax.yaxis.label.set_font_properties(FONT_smolFM);
            cbar.ax.tick_params(labelsize=FONT_axisTick);
            if( ~np.any(np.isinf(AMPERE_plotLimValu)) ):
                cbar.set_ticks(np.linspace(np.min(AMPERE_plotLimValu),np.max(AMPERE_plotLimValu),6)); #create useful tick marks
                cbar.mappable.set_clim(vmin=np.min(AMPERE_plotLimValu), vmax=np.max(AMPERE_plotLimValu));
            # else:
            #     cbar.mappable.set_clim(vmin=np.min(AMPERE_plotLimValu_override), vmax=np.max(AMPERE_plotLimValu_override));
            #END IF
            # if( np.all(np.mod(cbar.get_ticks(),1) == 0) ):
            #     cax.yaxis.set_major_formatter(FormatStrFormatter('%.0f')); #force a rounded format
            # else:
            #     cax.yaxis.set_major_formatter(FormatStrFormatter('%.1f')); #force a rounded format
            # #END IF            
        #END IF snaps_type
        
        #this just won't activate anywhere else - so putting it at the end
        if(geoMap_projectionStyle_polar == 0):
            for i in range(0,snaps_chosen_plotsPerPlot):     
                #Remove the aspect ratio from the basemap so it fills the screen better
                ax[snaps_rowsArray[i],snaps_colsArray[i]].set_aspect('auto');
            #END FOR i
        else:
            for i in range(0,snaps_chosen_plotsPerPlot):     
                #Remove the aspect ratio from the basemap so it fills the screen better
                ax[snaps_rowsArray[i],snaps_colsArray[i]].set_aspect('equal');
            #END FOR i
        #END IF
        if( snpz == 0 ):
            fig.subplots_adjust(wspace = snaps_wspace, hspace = snaps_hspace);
            figFitter(fig); #fit that fig fast
            offsets = np.float64(np.array( (fig.subplotpars.left, fig.subplotpars.right, fig.subplotpars.bottom, fig.subplotpars.top) )); #get the current offsets
        else:
            fig.subplots_adjust(left = offsets[0], right = offsets[1], top = offsets[3], bottom = offsets[2], wspace = snaps_wspace);
        #END IF
        if( (snaps_chosen_plotNum > 1) & (FLG_fancyPlot_curr >= 1) ):
            fig.savefig(settings['paths']['plots']+'\\snaps_type'+str(snaps_type)+'_'+str(snpz+1)+settings['plot']['save file type']); #save the figure
            plt.close(); #cleans up fancy plot after saving
        #END IF
    #END FOR snpz
#END IF FLG_enable_movieSnaps
    
    
